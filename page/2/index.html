<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="fonts.lug.ustc.edu.cn/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="算法工程师的日常">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="算法工程师的日常">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Tom">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>算法工程师的日常</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">算法工程师的日常</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益 404</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">推荐系统常见模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-23 20:48:21" itemprop="dateModified" datetime="2024-03-23T20:48:21+08:00">2024-03-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h1><h2 id="推荐理论"><a href="#推荐理论" class="headerlink" title="推荐理论"></a>推荐理论</h2><h2 id="算法模型"><a href="#算法模型" class="headerlink" title="算法模型"></a>算法模型</h2><h3 id="简单介绍下GBDT-LR模型？"><a href="#简单介绍下GBDT-LR模型？" class="headerlink" title="简单介绍下GBDT+LR模型？"></a>简单介绍下GBDT+LR模型？</h3><p>GBDT+LR利用GBDT进行“自动化”的特征组合，将原始特征向量转换成离散型特征向量，并输入逻辑回归模型，进行最终的CTR预估。</p>
<p>相比深度模型，GBDT+LR模型在架构而言十分的简洁。GBDT部分通过多颗回归树将输入特征重新筛选组合后为新的特征离散，LR部分则通过读取GBDT的输出特征进行模型训练。</p>
<h3 id="GBDT-LR组合模型的步骤是什么？"><a href="#GBDT-LR组合模型的步骤是什么？" class="headerlink" title="GBDT+LR组合模型的步骤是什么？"></a>GBDT+LR组合模型的步骤是什么？</h3><p>GBDT+LR 由两部分组成，其中GBDT用来对训练集提取特征作为新的训练输入数据，LR作为新训练输入数据的分类器。</p>
<p>具体来讲，有以下几个步骤：</p>
<ol>
<li><p>GBDT首先对原始训练数据做训练，得到一个二分类器，当然这里也需要利用网格搜索寻找最佳参数组合。</p>
</li>
<li><p>与通常做法不同的是，当GBDT训练好做预测的时候，输出的并不是最终的二分类概率值，而是要把模型中的每棵树计算得到的预测概率值所属的叶子结点位置记为1，这样，就构造出了新的训练数据。</p>
</li>
<li><p>新的训练数据构造完成后，下一步就要与原始的训练数据中的label(输出)数据一并输入到Logistic Regression分类器中进行最终分类器的训练。</p>
</li>
</ol>
<h3 id="为什么GBDT-LR模型中建树采用ensemble决策树？"><a href="#为什么GBDT-LR模型中建树采用ensemble决策树？" class="headerlink" title="为什么GBDT+LR模型中建树采用ensemble决策树？"></a>为什么GBDT+LR模型中建树采用ensemble决策树？</h3><p>一棵树的表达能力很弱，不足以表达多个有区分性的特征组合，多棵树的表达能力更强一些。GBDT每棵树都在学习前面棵树尚存的不足，迭代多少次就会生成多少颗树。按paper以及Kaggle竞赛中的GBDT+LR融合方式，多棵树正好满足LR每条训练样本可以通过GBDT映射成多个特征的需求。</p>
<h3 id="为什么建树采用GBDT而非RF？"><a href="#为什么建树采用GBDT而非RF？" class="headerlink" title="为什么建树采用GBDT而非RF？"></a>为什么建树采用GBDT而非RF？</h3><p>RF也是多棵树，但从效果上有实践证明不如GBDT。且GBDT前面的树，特征分裂主要体现对多数样本有区分度的特征；后面的树，主要体现的是经过前N颗树，残差仍然较大的少数样本。优先选用在整体上有区分度的特征，再选用针对少数样本有区分度的特征，思路更加合理，这应该也是用GBDT的原因。</p>
<h3 id="为什么GBDT可用于特征选择和特征组合？"><a href="#为什么GBDT可用于特征选择和特征组合？" class="headerlink" title="为什么GBDT可用于特征选择和特征组合？"></a>为什么GBDT可用于特征选择和特征组合？</h3><p>GBDT是由多颗回归树组成的树林，后一棵树以前面树林的结果与真实结果的残差为拟合目标。每棵树生成的过程是一课标准的回归树生成过程，因此回归树中每个节点的分裂是一个自然的特征选择过程，而多层节点的结构则对特征进行了有效的自动组合，也就非常高效地解决了特征选择和特征组合的问题。</p>
<h3 id="GBDT的叶子节点能够表示多个特征的组合？"><a href="#GBDT的叶子节点能够表示多个特征的组合？" class="headerlink" title="GBDT的叶子节点能够表示多个特征的组合？"></a>GBDT的叶子节点能够表示多个特征的组合？</h3><p>GBDT中的CART回归树的深度决定了特征交叉的阶数。如果决策树的深度为4，则通过3次节点分裂，最终的叶节点实际上是进行三阶特征组合后的结果。</p>
<p>所以我们说可以用GBDT自动进行特征（一阶、二阶、三阶…）筛选和组合。</p>
<h3 id="GBDT-LR的缺点是什么？"><a href="#GBDT-LR的缺点是什么？" class="headerlink" title="GBDT+LR的缺点是什么？"></a>GBDT+LR的缺点是什么？</h3><p>GBDT容易产生过拟合，以及GBDT的特征转换方式实际上丢失了大量特征的数值信息，因此在模型的选择和调试上，永远都是多种因素综合作用的结果。</p>
<h3 id="GBDT-LR在工程上使用需要注意哪些点？"><a href="#GBDT-LR在工程上使用需要注意哪些点？" class="headerlink" title="GBDT+LR在工程上使用需要注意哪些点？"></a>GBDT+LR在工程上使用需要注意哪些点？</h3><p>在实际应用中，需要注意模型训练，通常在海量特征的情况下，按照大厂的做法，GBDT是每个一周跑一次，而LR是每天跑一次，这样可以保证模型的有效性，从本质上说，因为GBDT在海量的特征维度的下跑的比较慢而已，一般小厂可以再资源不够的情况下用。</p>
<h3 id="GBDT-LR是分阶段的吗？"><a href="#GBDT-LR是分阶段的吗？" class="headerlink" title="GBDT+LR是分阶段的吗？"></a>GBDT+LR是分阶段的吗？</h3><p>用GBDT构建特征工程，利用LR预估CTR这两步是独立训练的，所以不存在如何将LR的梯度回传到GBDT这类复杂的问题。LR训练时候的特征维度是由GBDT训练出来的多棵回归树的叶子节点总数决定的。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/400403326">https://zhuanlan.zhihu.com/p/400403326</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_43827595/article/details/12373526">https://blog.csdn.net/qq_43827595/article/details/12373526</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/" class="post-title-link" itemprop="url">机器学习理论</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-21 23:17:17" itemprop="dateModified" datetime="2024-03-21T23:17:17+08:00">2024-03-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="机器学习理论"><a href="#机器学习理论" class="headerlink" title="机器学习理论"></a>机器学习理论</h1><h2 id="数学知识"><a href="#数学知识" class="headerlink" title="数学知识"></a>数学知识</h2><h3 id="机器学习中的距离和相似度度量方式有哪些？"><a href="#机器学习中的距离和相似度度量方式有哪些？" class="headerlink" title="机器学习中的距离和相似度度量方式有哪些？"></a>机器学习中的距离和相似度度量方式有哪些？</h3><ul>
<li>欧氏距离</li>
<li>曼哈顿距离</li>
<li>切比雪夫距离</li>
<li>闵可夫斯基距离</li>
<li>标准化欧氏距离</li>
<li>马氏距离</li>
<li>夹角余弦</li>
<li>汉明距离<br>这里无法给出具体的公式，定义是两个等长字符串s1与s2之间的汉明距离定义为将其中一个变为另外一个所需要作的最小替换次数。例如字符串“1111”与“1001”之间的汉明距离为2</li>
<li>杰卡德距离 &amp; 杰卡德相似系数</li>
<li>相关系数 &amp; 相关距离</li>
</ul>
<h3 id="马氏距离比欧式距离的异同点？"><a href="#马氏距离比欧式距离的异同点？" class="headerlink" title="马氏距离比欧式距离的异同点？"></a>马氏距离比欧式距离的异同点？</h3><p>马氏距离（Mahalanobis Distance）是由印度统计学家马哈拉诺比斯（P. C. Mahalanobis）提出的，表示数据的协方差距离。它是一种有效的计算两个未知样本集的相似度的方法。与欧氏距离不同的是它考虑到各种特性之间的联系（例如：一条关于身高的信息会带来一条关于体重的信息，因为两者是有关联的）并且是尺度无关的（scale-invariant），即独立于测量尺度。</p>
<p>马氏距离有很多优点，马氏距离不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。马氏距离还可以排除变量之间的相关性的干扰。它的缺点是夸大了变化微小的变量的作用。</p>
<h3 id="张量与矩阵的区别？"><a href="#张量与矩阵的区别？" class="headerlink" title="张量与矩阵的区别？"></a>张量与矩阵的区别？</h3><ul>
<li>从代数角度讲， 矩阵它是向量的推广。向量可以看成一维的“表格”（即分量按照顺序排成一排）， 矩阵是二维的“表格”（分量按照纵横位置排列）， 那么阶张量就是所谓的维的“表格”。张量的严格定义是利用线性映射来描述。</li>
<li>从几何角度讲， 矩阵是一个真正的几何量，也就是说，它是一个不随参照系的坐标变换而变化的东西。向量也具有这种特性。</li>
</ul>
<h3 id="如何判断矩阵为正定？"><a href="#如何判断矩阵为正定？" class="headerlink" title="如何判断矩阵为正定？"></a>如何判断矩阵为正定？</h3><p>判定一个矩阵是否为正定，通常有以下几个方面：</p>
<ul>
<li>顺序主子式全大于0；</li>
<li>存在可逆矩阵$C$使得$C^TC$等于该矩阵；</li>
<li>正惯性指数等于n；</li>
<li>合同于单位矩阵$E$（即：规范形为$E$）</li>
<li>标准形中主对角元素全为正；</li>
<li>特征值全为正；</li>
<li>是某基的度量矩阵。</li>
</ul>
<h3 id="距离的严格定义？"><a href="#距离的严格定义？" class="headerlink" title="距离的严格定义？"></a>距离的严格定义？</h3><p>距离的定义：在一个集合中，如果每一对元素均可唯一确定一个实数，使得三条距离公理（正定性，对称性，三角不等式）成立，则该实数可称为这对元素之间的距离。</p>
<p>在机器学习领域，被俗称为距离，却不满足三条距离公理的不仅仅有余弦距离，还有 KL 距离，也叫作相对熵，它常用于计算两个分布之间的差异，但不满足对称性和三角不等式。<br>来自</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/85408804">https://zhuanlan.zhihu.com/p/85408804</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/27057384/answer/2182368961">https://www.zhihu.com/question/27057384/answer/2182368961</a></p>
</blockquote>
<h2 id="概率论"><a href="#概率论" class="headerlink" title="概率论"></a>概率论</h2><h3 id="什么是概率？"><a href="#什么是概率？" class="headerlink" title="什么是概率？"></a>什么是概率？</h3><p>“概率，亦称“或然率”，它是反映随机事件出现的可能性大小。</p>
<h3 id="概率和频率的区别？"><a href="#概率和频率的区别？" class="headerlink" title="概率和频率的区别？"></a>概率和频率的区别？</h3><p>概率是一个稳定的数值，也就是某件事发生或不发生的概率是多少。频率是在一定数量的某件事情上面，发生的数与总数的比值。频率是有限次数的试验所得的结果，概率是频数无限大时对应的频率。</p>
<h3 id="泊松分布与二项分布的关系？"><a href="#泊松分布与二项分布的关系？" class="headerlink" title="泊松分布与二项分布的关系？"></a>泊松分布与二项分布的关系？</h3><p>泊松分布可看成是二项分布的极限而得到，当$\lambda = np$时，两者是相同的。</p>
<h3 id="常见分布的期望和方差是什么？"><a href="#常见分布的期望和方差是什么？" class="headerlink" title="常见分布的期望和方差是什么？"></a>常见分布的期望和方差是什么？</h3><center>
<img src="https://img-blog.csdnimg.cn/56baf6bc2d9c4ccca51e454373162b97.png" width="90%">  
</center>

<h3 id="什么是大数定理？"><a href="#什么是大数定理？" class="headerlink" title="什么是大数定理？"></a>什么是大数定理？</h3><p>大数定理简单来说，指得是某个随机事件在单次试验中可能发生也可能不发生，但在大量重复实验中往往呈现出明显的规律性，即该随机事件发生的频率会向某个常数值收敛，该常数值即为该事件发生的概率。</p>
<p>另一种表达方式为当样本数据无限大时，样本均值趋于总体均值。</p>
<p>因为现实生活中，我们无法进行无穷多次试验，也很难估计出总体的参数。</p>
<p>大数定律告诉我们能用频率近似代替概率；能用样本均值近似代替总体均值。</p>
<h3 id="什么是中心极限定理？"><a href="#什么是中心极限定理？" class="headerlink" title="什么是中心极限定理？"></a>什么是中心极限定理？</h3><p>中心极限定理是概率论中的一组重要定理，它的中心思想是无论是什么分布的数据，当我们从中抽取相互独立的随机样本，且采集的样本足够多时，样本均值的分布将收敛于正态分布。</p>
<h3 id="求最大似然估计量的一般步骤？"><a href="#求最大似然估计量的一般步骤？" class="headerlink" title="求最大似然估计量的一般步骤？"></a>求最大似然估计量的一般步骤？</h3><ol>
<li>写出似然函数</li>
<li>对似然函数取对数，并整理</li>
<li>求导数</li>
<li>解似然方程</li>
</ol>
<h3 id="什么是无偏性？"><a href="#什么是无偏性？" class="headerlink" title="什么是无偏性？"></a>什么是无偏性？</h3><p>无偏性（Unbiasedness）是指单凭某一次抽样的样本是不具有说服力的，必须要通过很多次抽样的样本来衡量。因此，我们容易能想到的就是，经过多次抽样后，将所有的点估计值平均起来，也就是取期望值，这个期望值应该和总体参数一样。这就是所谓的无偏性（Unbiasedness）。</p>
<h3 id="说一下条件概率、全概率和贝叶斯公式？"><a href="#说一下条件概率、全概率和贝叶斯公式？" class="headerlink" title="说一下条件概率、全概率和贝叶斯公式？"></a>说一下条件概率、全概率和贝叶斯公式？</h3><ul>
<li>条件概率/分布律（乘法公式）</li>
</ul>
<p>P(A|B)=P(AB)/P(B)，演化式P(A|B)<em>P(B)=P(B|A)</em>P(A)</p>
<ul>
<li>全概率公式</li>
</ul>
<p>P(A)= P(A|B1)+P(A|B2)+P(A|B3)+…+P(A|Bn)，其中A为样本空间的事件，B1、B2、B3…Bn为样本空间的一个划分。</p>
<ul>
<li>贝叶斯公式</li>
</ul>
<p>P(Bi|A)= P(A|Bi)*P(Bi)/[P(A|B1)+P(A|B2)+P(A|B3)+…+P(A|Bn)]，其中A为样本空间的事件，B1、B2、B3…Bn为样本空间的一个划分。</p>
<h3 id="一句话解释极大似然估计法和概率的区别"><a href="#一句话解释极大似然估计法和概率的区别" class="headerlink" title="一句话解释极大似然估计法和概率的区别?"></a>一句话解释极大似然估计法和概率的区别?</h3><p>概率是已知分布和参数，求事件结果出现的次数；极大似然估计是已知分布和事件结果出现的次数，估计事件结果以最大概率的出现情况下的参数。</p>
<h3 id="极大似然估计，最大后验估计的区别？"><a href="#极大似然估计，最大后验估计的区别？" class="headerlink" title="极大似然估计，最大后验估计的区别？"></a>极大似然估计，最大后验估计的区别？</h3><p>当先验概率是分布均匀的情况下，则相当于没有给参数提供任何有用的信息，例如每种情况都是等概率的事件，那此时的极大似然估计就等于最大后验估计。</p>
<p>因此，可以把极大似然估计看成一种特殊的先验概率为均匀分布的最大后验估计，</p>
<p>也可以把最大后验估计估计看成是必须考虑先验概率的极大似然估计（即最大后验估计是规则化的)极大似然估计）</p>
<h3 id="协方差为0，一定独立吗？"><a href="#协方差为0，一定独立吗？" class="headerlink" title="协方差为0，一定独立吗？"></a>协方差为0，一定独立吗？</h3><p>因为协方差等于零只能推出不相关的，所以不能推出互相独立的。但互相独立的可以推出互不相干的。比如X=cosa, Y=sina, 则X和Y的协方差为0, 但是X,Y两者不独立.</p>
<p>协方差的算法：COV(X,Y)=E{(X-E(X))(Y=E(Y))}E为数学期望；它反映随机变量平均取值的大小。又称期望或均值。它是简单算术平均的一种推广。</p>
<h3 id="参考-1"><a href="#参考-1" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/87299555">https://zhuanlan.zhihu.com/p/87299555</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/427883809">https://zhuanlan.zhihu.com/p/427883809</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41897154/article/details/109125820">https://blog.csdn.net/qq_41897154/article/details/109125820</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_37382341/article/details/80049976">https://blog.csdn.net/m0_37382341/article/details/80049976</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/159115973">https://zhuanlan.zhihu.com/p/159115973</a></p>
</blockquote>
<h2 id="学习理论"><a href="#学习理论" class="headerlink" title="学习理论"></a>学习理论</h2><h3 id="什么是表示学习？"><a href="#什么是表示学习？" class="headerlink" title="什么是表示学习？"></a>什么是表示学习？</h3><p>在深度学习领域内，表示是指通过模型的参数，采用何种形式、何种方式来表示模型的输入观测样本X。表示学习指学习对观测样本X有效的表示。   </p>
<h3 id="什么是端到端学习？"><a href="#什么是端到端学习？" class="headerlink" title="什么是端到端学习？"></a>什么是端到端学习？</h3><p>端到端学习（End-to-End Learning），也称端到端训练，是指在学习过程中不进行分模块或分阶段训练，直接优化任务的总体目标．在端到端学习中，一般不需要明确地给出不同模块或阶段的功能，中间过程不需要人为干预</p>
<h3 id="机器学习的学习方式主要有哪些"><a href="#机器学习的学习方式主要有哪些" class="headerlink" title="机器学习的学习方式主要有哪些?"></a>机器学习的学习方式主要有哪些?</h3><p>监督学习</p>
<p>非监督式学习</p>
<p>半监督式学习</p>
<p>弱监督学习</p>
<h3 id="如何开展监督学习"><a href="#如何开展监督学习" class="headerlink" title="如何开展监督学习?"></a>如何开展监督学习?</h3><p>步骤1：数据集的创建和分类 。</p>
<p>步骤2：数据增强（Data Augmentation） </p>
<p>步骤3：特征工程（Feature Engineering） </p>
<p>步骤4：构建预测模型和损失 </p>
<p>步骤5：训练</p>
<p>步骤6：验证和模型选择</p>
<p>步骤7：测试及应用</p>
<h3 id="类别不均衡问题怎么做"><a href="#类别不均衡问题怎么做" class="headerlink" title="类别不均衡问题怎么做?"></a>类别不均衡问题怎么做?</h3><p>防止类别不平衡对学习造成的影响，在构建分类模型之前，需要对分类不平衡性问题进行处理。主要解决方法有：</p>
<p>1、扩大数据集</p>
<p>增加包含小类样本数据的数据，更多的数据能得到更多的分布信息。</p>
<p>2、对大类数据欠采样</p>
<p>减少大类数据样本个数，使与小样本个数接近。 缺点：欠采样操作时若随机丢弃大类样本，可能会丢失重要信息。 代表算法：EasyEnsemble。其思想是利用集成学习机制，将大类划分为若干个集合供不同的学习器使用。相当于对每个学习器都进行欠采样，但对于全局则不会丢失重要信息。</p>
<p>3、对小类数据过采样</p>
<p>过采样：对小类的数据样本进行采样来增加小类的数据样本个数。</p>
<p>代表算法：SMOTE和ADASYN。</p>
<p>SMOTE：通过对训练集中的小类数据进行插值来产生额外的小类样本数据。</p>
<p>新的少数类样本产生的策略：对每个少数类样本a，在a的最近邻中随机选一个样本b，然后在a、b之间的连线上随机选一点作为新合成的少数类样本。 ADASYN：根据学习难度的不同，对不同的少数类别的样本使用加权分布，对于难以学习的少数类的样本，产生更多的综合数据。通过减少类不平衡引入的偏差和将分类决策边界自适应地转移到困难的样本两种手段，改善了数据分布。</p>
<p>4、使用新评价指标</p>
<p>如果当前评价指标不适用，则应寻找其他具有说服力的评价指标。比如准确度这个评价指标在类别不均衡的分类任务中并不适用，甚至进行误导。因此在类别不均衡分类任务中，需要使用更有说服力的评价指标来对分类器进行评价。</p>
<p>5、选择新算法</p>
<p>不同的算法适用于不同的任务与数据，应该使用不同的算法进行比较。</p>
<p>6、数据代价加权</p>
<p>例如当分类任务是识别小类，那么可以对分类器的小类样本数据增加权值，降低大类样本的权值，从而使得分类器将重点集中在小类样本身上。</p>
<p>7、转化问题思考角度</p>
<p>例如在分类问题时，把小类的样本作为异常点，将问题转化为异常点检测或变化趋势检测问题。异常点检测即是对那些罕见事件进行识别。变化趋势检测区别于异常点检测在于其通过检测不寻常的变化趋势来识别。</p>
<p>8、将问题细化分析</p>
<p>对问题进行分析与挖掘，将问题划分成多个更小的问题，看这些小问题是否更容易解决。</p>
<h3 id="维度灾难是啥？怎么避免？"><a href="#维度灾难是啥？怎么避免？" class="headerlink" title="维度灾难是啥？怎么避免？"></a>维度灾难是啥？怎么避免？</h3><p>维数灾难(Curse of Dimensionality)：通常是指在涉及到向量的计算的问题中，随着维数的增加，计算量呈指数倍增长的一种现象。维数灾难涉及数字分析、抽样、组合、机器学习、数据挖掘和数据库等诸多领域。在机器学习的建模过程中，通常指的是随着特征数量的增多，计算量会变得很大，如特征得到上亿维的话，在进行计算的时候是算不出来的。如我们熟悉的KNN的问题，如果不是 构建Kd数等可以加快计算，按照暴力的话，计算量是很大的。而且有的时候，维度太大也会导致机器学习性能的下降，并不是特征维度越大越好，模型的性能会随着特征的增加先上升后下降。</p>
<p>解决维度灾难问题：</p>
<ol>
<li>主成分分析法PCA，线性判别法LDA</li>
<li>奇异值分解简化数据、拉普拉斯特征映射</li>
<li>Lassio缩减系数法、小波分析法</li>
</ol>
<h3 id="生成模型和判别模型的区别"><a href="#生成模型和判别模型的区别" class="headerlink" title="生成模型和判别模型的区别?"></a>生成模型和判别模型的区别?</h3><p>判别模型：由数据直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。基本思想是有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。典型的判别模型包括k近邻，感知级，决策树，支持向量机等。  </p>
<p>生成模型：由数据学习联合概率密度分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：P(Y|X)= P(X,Y)/ P(X)。基本思想是首先建立样本的联合概率概率密度模型P(X,Y)，然后再得到后验概率P(Y|X)，再利用它进行分类。常见的有NB HMM模型。</p>
<h2 id="优化理论"><a href="#优化理论" class="headerlink" title="优化理论"></a>优化理论</h2><h3 id="什么是凸优化？"><a href="#什么是凸优化？" class="headerlink" title="什么是凸优化？"></a>什么是凸优化？</h3><p>凸优化问题（OPT，convex optimization problem）指定义在凸集中的凸函数最优化的问题。尽管凸优化的条件比较苛刻，但仍然在机器学习领域有十分广泛的应用。</p>
<h3 id="凸优化的优势是什么？"><a href="#凸优化的优势是什么？" class="headerlink" title="凸优化的优势是什么？"></a>凸优化的优势是什么？</h3><ol>
<li>凸优化问题的局部最优解就是全局最优解</li>
<li>很多非凸问题都可以被等价转化为凸优化问题或者被近似为凸优化问题（例如拉格朗日对偶问题）</li>
<li>凸优化问题的研究较为成熟，当一个具体被归为一个凸优化问题，基本可以确定该问题是可被求解的</li>
</ol>
<h3 id="如何判断函数是否为凸的"><a href="#如何判断函数是否为凸的" class="headerlink" title="如何判断函数是否为凸的?"></a>如何判断函数是否为凸的?</h3><p>熟悉凸函数的定义，即在凸的定义域上取两个点$x,y$ ，其凸组合的值应该小于等于其值的凸组合，对任意$\lambda  \in [0,1]$,有的话$f(\lambda x + (1 - \lambda )y) \le \lambda f(x) + (1 - \lambda )f(y)$,那么它就是凸函数。</p>
<h3 id="什么是鞍点？"><a href="#什么是鞍点？" class="headerlink" title="什么是鞍点？"></a>什么是鞍点？</h3><p>鞍点（Saddle point）在微分方程中，沿着某一方向是稳定的，另一条方向是不稳定的奇点，叫做鞍点。在泛函中，既不是极大值点也不是极小值点的临界点，叫做鞍点。在矩阵中，一个数在所在行中是最大值，在所在列中是最小值，则被称为鞍点。在物理上要广泛一些，指在一个方向是极大值，另一个方向是极小值的点。从海塞矩阵的角度来说，Hessian矩阵不定的点称为鞍点，它不是函数的极值点。</p>
<center>
<img src="https://img-blog.csdnimg.cn/1e5fd6d5b70c423292ef603088b05908.png" width="70%">  
</center>

<h3 id="解释什么是局部极小值，什么是全局极小值？"><a href="#解释什么是局部极小值，什么是全局极小值？" class="headerlink" title="解释什么是局部极小值，什么是全局极小值？"></a>解释什么是局部极小值，什么是全局极小值？</h3><p>局部极值点：假设是一个$X^<em>$可行解，如果对可行域内所有点$X$都有$f({x^</em>}) \le f(x)$，则称为全局极小值。</p>
<p>全局极值点。对于可行解$X^<em>$，如果存在其邻域$\delta$，使得该邻域内的所有点即所有满足$||x - x</em>|| \le \delta$的点$x$，都有$f({x^*}) \le f(x)$，则称为局部极小值。</p>
<h3 id="既然有全局最优，为什么还需要有局部最优呢？"><a href="#既然有全局最优，为什么还需要有局部最优呢？" class="headerlink" title="既然有全局最优，为什么还需要有局部最优呢？"></a>既然有全局最优，为什么还需要有局部最优呢？</h3><p>对于优化问题，尤其是最优化问题，总是希望能找到全局最优的解决策略，但是当问题的复杂度过于⾼，要考虑的因素和处理的信息量过多的时候，我们往往会倾向于接受局部最优解，因为局部最优解的质量不⼀定最差的。尤其是当我们有确定的评判标准标明得出的解释可以接受的话，通常会接受局部最优的结果。这样，从成本、效率等多⽅⾯考虑，才是实际⼯程中会才去的策略。</p>
<h3 id="机器学习有哪些优化方法？"><a href="#机器学习有哪些优化方法？" class="headerlink" title="机器学习有哪些优化方法？"></a>机器学习有哪些优化方法？</h3><p>机器学习和深度学习中常用的算法包含不局限如下：梯度下降、牛顿法和拟牛顿、动量法momentum、Adagrad、RMSProp、Adadelta、Adam等，无梯度优化算法也有很多，像粒子群优化算法、蚁群算法、遗传算法、模拟退火等群体智能优化算法。<br>几个常见的优化方法的比较如下：<br><img src="https://img-blog.csdnimg.cn/82bec7295ab342abbb690513901431c5.png" alt="img"></p>
<h3 id="梯度下降法和牛顿法能保证找到函数的极小值点吗，为什么？"><a href="#梯度下降法和牛顿法能保证找到函数的极小值点吗，为什么？" class="headerlink" title="梯度下降法和牛顿法能保证找到函数的极小值点吗，为什么？"></a>梯度下降法和牛顿法能保证找到函数的极小值点吗，为什么？</h3><p>不能，可能收敛到鞍点，不是极值点。</p>
<h3 id="解释一元函数极值判别法则是什么？"><a href="#解释一元函数极值判别法则是什么？" class="headerlink" title="解释一元函数极值判别法则是什么？"></a>解释一元函数极值判别法则是什么？</h3><p>假设为函数的驻点，可分为以下三种情况。</p>
<p>情况一：在该点处的二阶导数大于0，则为函数的极小值点；<br>情况二：在该点处的二阶导数小于0，则为极大值点；<br>情况三：在该点处的二阶导数等于0，则情况不定，可能是极值点，也可能不是极值点。</p>
<h3 id="解释多元函数极值判别法则是什么？"><a href="#解释多元函数极值判别法则是什么？" class="headerlink" title="解释多元函数极值判别法则是什么？"></a>解释多元函数极值判别法则是什么？</h3><p>假设多元函数在点M的梯度为0，即M是函数的驻点。其Hessian矩阵有如下几种情况。</p>
<p>情况一：Hessian矩阵正定，函数在该点有极小值。<br>情况二：Hessian矩阵负定，函数在该点有极大值。<br>情况三：Hessian矩阵不定，则不是极值点，称为鞍点。</p>
<p>Hessian矩阵正定类似于一元函数的二阶导数大于0，负定则类似于一元函数的二阶导数小于0。</p>
<h3 id="什么是对偶问题？"><a href="#什么是对偶问题？" class="headerlink" title="什么是对偶问题？"></a>什么是对偶问题？</h3><p>可以将对偶问题看成是关于原问题松弛问题的优化问题，对偶问题的目标，是以一定方式，找到最贴近原问题的松弛问题。如果将原问题以对偶变量为参数进行松弛，将得到一系列以对偶变量为参数的松弛问题（例如拉格朗日松弛问题，是以拉格朗日乘子为参数，将原问题约束松弛到目标函数后得到的松弛问题）对偶问题则是通过优化对偶变量，找到最逼近原问题的松弛问题（例如拉格朗日对偶问题，是优化拉格朗日乘子，得到最接近原问题的松弛问题，即原问题的下界）</p>
<h3 id="随机梯度下降法、批量梯度下降法有哪些区别？"><a href="#随机梯度下降法、批量梯度下降法有哪些区别？" class="headerlink" title="随机梯度下降法、批量梯度下降法有哪些区别？"></a>随机梯度下降法、批量梯度下降法有哪些区别？</h3><p>批量梯度下降：<br>(1) 采用所有数据来梯度下降。<br>(2) 批量梯度下降法在样本量很大的时候，训练速度慢。    </p>
<p>随机梯度下降<br>(1) 随机梯度下降用一个样本来梯度下降。<br>(2) 训练速度很快。<br>(3) 随机梯度下降法仅仅用一个样本决定梯度方向，导致解有可能不是全局最优。<br>(4) 收敛速度来说，随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。  </p>
<h3 id="各种梯度下降法性能对比？"><a href="#各种梯度下降法性能对比？" class="headerlink" title="各种梯度下降法性能对比？"></a>各种梯度下降法性能对比？</h3><p><img src="https://img-blog.csdnimg.cn/58bcff710aec4120920b4d156267e653.png" alt="img"></p>
<h3 id="说一下梯度下降法缺点"><a href="#说一下梯度下降法缺点" class="headerlink" title="说一下梯度下降法缺点?"></a>说一下梯度下降法缺点?</h3><ol>
<li>靠近极小值时收敛速度减慢<br>在极小值点附近的话，梯度比较小了，毕竟那个点的梯度都快为零了，收敛的就慢了</li>
<li>直线搜索时可能会产生一些问题<br>步子大或者小会导致来回的震荡，导致不太好收敛</li>
<li>可能会“之字形”地下降<br>如下所示，梯度下降会来回走之字，导致优化速度慢</li>
</ol>
<h3 id="如何对梯度下降法进行调优"><a href="#如何对梯度下降法进行调优" class="headerlink" title="如何对梯度下降法进行调优?"></a>如何对梯度下降法进行调优?</h3><ol>
<li><p>算法迭代步长选择<br>在算法参数初始化时，有时根据经验将步长初始化为1。实际取值取决于数据样本。可以从大到小，多取一些值，分别运行算法看迭代效果，如果损失函数在变小，则取值有效。如果取值无效，说明要增大步长。但步长太大，有时会导致迭代速度过快，错过最优解。步长太小，迭代速度慢，算法运行时间长。</p>
</li>
<li><p>参数的初始值选择<br>初始值不同，获得的最小值也有可能不同，梯度下降有可能得到的是局部最小值。如果损失函数是凸函数，则一定是最优解。由于有局部最优解的风险，需要多次用不同初始值运行算法，关键损失函数的最小值，选择损失函数最小化的初值。</p>
</li>
<li><p>标准化处理<br>由于样本不同，特征取值范围也不同，导致迭代速度慢。为了减少特征取值的影响，可对特征数据标准化，使新期望为0，新方差为1，可节省算法运行时间。</p>
</li>
</ol>
<h3 id="随机梯度下降法、批量梯度下降法有哪些区别？-1"><a href="#随机梯度下降法、批量梯度下降法有哪些区别？-1" class="headerlink" title="随机梯度下降法、批量梯度下降法有哪些区别？"></a>随机梯度下降法、批量梯度下降法有哪些区别？</h3><p>批量梯度下降：<br>(1) 采用所有数据来梯度下降。<br>(2) 批量梯度下降法在样本量很大的时候，训练速度慢。<br>随机梯度下降<br>(1) 随机梯度下降用一个样本来梯度下降。<br>(2) 训练速度很快。<br>(3) 随机梯度下降法仅仅用一个样本决定梯度方向，导致解有可能不是全局最优。<br>(4) 收敛速度来说，随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。  </p>
<h3 id="梯度下降法缺点"><a href="#梯度下降法缺点" class="headerlink" title="梯度下降法缺点"></a>梯度下降法缺点</h3><p>梯度下降法是最早最简单，也是最为常用的最优化方法。梯度下降法实现简单，当目标函数是凸函数时，梯度下降法的解是全局解。<br>一般情况下，其解不保证是全局最优解，梯度下降法的速度也未必是最快的。梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，因为该方向为当前位置的最快下降方向，所以也被称为是”最速下降法“。最速下降法越接近目标值，步长越小，前进越慢。</p>
<p>梯度下降法缺点有以下几点：<br>（1）靠近极小值时收敛速度减慢。<br>在极小值点附近的话，梯度比较小了，毕竟那个点的梯度都快为零了，收敛的就慢了<br>（2）直线搜索时可能会产生一些问题。<br>步子大或者小会导致来回的震荡，导致不太好收敛<br>（3）可能会“之字形”地下降。<br>如下所示，梯度下降会来回走之字，导致优化速度慢</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40722827/article/details/107297535、">https://blog.csdn.net/qq_40722827/article/details/107297535、</a></p>
<h3 id="批量梯度下降和随机梯度下降法的缺点？"><a href="#批量梯度下降和随机梯度下降法的缺点？" class="headerlink" title="批量梯度下降和随机梯度下降法的缺点？"></a>批量梯度下降和随机梯度下降法的缺点？</h3><p>批量梯度下降<br>a）采用所有数据来梯度下降。<br>b）批量梯度下降法在样本量很大的时候，训练速度慢。<br>随机梯度下降<br>a）随机梯度下降用一个样本来梯度下降。<br>b）训练速度很快。<br>c）随机梯度下降法仅仅用一个样本决定梯度方向，导致解有可能不是全局最优。<br>d）收敛速度来说，随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。  </p>
<h3 id="如何对梯度下降法进行调优-1"><a href="#如何对梯度下降法进行调优-1" class="headerlink" title="如何对梯度下降法进行调优?"></a>如何对梯度下降法进行调优?</h3><p>实际使用梯度下降法时，各项参数指标不能一步就达到理想状态，对梯度下降法调优主要体现在以下几个方面：</p>
<p>（1）算法迭代步长$\alpha$选择。 在算法参数初始化时，有时根据经验将步长初始化为1。实际取值取决于数据样本。可以从大到小，多取一些值，分别运行算法看迭代效果，如果损失函数在变小，则取值有效。如果取值无效，说明要增大步长。但步长太大，有时会导致迭代速度过快，错过最优解。步长太小，迭代速度慢，算法运行时间长。</p>
<p>（2）参数的初始值选择。 初始值不同，获得的最小值也有可能不同，梯度下降有可能得到的是局部最小值。如果损失函数是凸函数，则一定是最优解。由于有局部最优解的风险，需要多次用不同初始值运行算法，关键损失函数的最小值，选择损失函数最小化的初值。</p>
<p>（3）标准化处理。 由于样本不同，特征取值范围也不同，导致迭代速度慢。为了减少特征取值的影响，可对特征数据标准化，使新期望为0，新方差为1，可节省算法运行时间。</p>
<h3 id="各种梯度下降法性能比较"><a href="#各种梯度下降法性能比较" class="headerlink" title="各种梯度下降法性能比较"></a>各种梯度下降法性能比较</h3><p>对比维度-BGD-SGD-Mini-batch GD-Online GD<br>训练集-固定-固定-固定-实时更新<br>单次迭代样本数-整个训练集-单个样本-训练集的子集-根据具体算法定<br>算法复杂度-高-低-一般-低<br>时效性-低-一般-一般-高<br>收敛性-稳定-不稳定-较稳定-不稳定  </p>
<h3 id="为什么归一化能加快梯度下降法求优化速度？"><a href="#为什么归一化能加快梯度下降法求优化速度？" class="headerlink" title="为什么归一化能加快梯度下降法求优化速度？"></a>为什么归一化能加快梯度下降法求优化速度？</h3><p>归一化后的数据有助于在求解是缓解求解过程中的参数寻优的动荡，以加快收敛。对于不归一化的收敛，可以发现其参数更新、收敛如左图，归一化后的收敛如右图。可以看到在左边是呈现出之字形的寻优路线，在右边则是呈现较快的梯度下降。<br><img src="https://img-blog.csdnimg.cn/9c7f06b6c6b04381916796a03570cfb5.png" alt="img"></p>
<h3 id="标准化和归一化有什么区别？"><a href="#标准化和归一化有什么区别？" class="headerlink" title="标准化和归一化有什么区别？"></a>标准化和归一化有什么区别？</h3><p>归一化是将样本的特征值转换到同一量纲下把数据映射到[0,1]或者[-1, 1]区间内，仅由变量的极值决定，因区间放缩法是归一化的一种。<br>$$
x' = \frac{{x - \min (x)}}{{\max (x) - \min (x)}}
$$<br>标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，转换为标准正态分布，和整体样本分布相关，每个样本点都能对标准化产生影响。它们的相同点在于都能取消由于量纲不同引起的误差；都是一种线性变换，都是对向量X按照比例压缩再进行平移。<br>$$
x' = \frac{{x - \bar x}}{\sigma }
$$</p>
<h3 id="批量梯度下降和随机梯度下降法的缺点"><a href="#批量梯度下降和随机梯度下降法的缺点" class="headerlink" title="批量梯度下降和随机梯度下降法的缺点"></a>批量梯度下降和随机梯度下降法的缺点</h3><p>批量梯度下降  </p>
<p>a）采用所有数据来梯度下降。  </p>
<p>b）批量梯度下降法在样本量很大的时候，训练速度慢。  </p>
<p>随机梯度下降  </p>
<p>a）随机梯度下降用一个样本来梯度下降。  </p>
<p>b）训练速度很快。  </p>
<p>c）随机梯度下降法仅仅用一个样本决定梯度方向，导致解有可能不是全局最优。  </p>
<p>d）收敛速度来说，随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。  </p>
<h3 id="极大似然估计和最小二乘法区别？"><a href="#极大似然估计和最小二乘法区别？" class="headerlink" title="极大似然估计和最小二乘法区别？"></a>极大似然估计和最小二乘法区别？</h3><p>对于最小二乘法，当从模型总体随机抽取n组样本观测值后，最合理的参数估计量应该使得模型能最好地拟合样本数据，也就是估计值和观测值之差的平方和最小。</p>
<p>而对于最大似然法，当从模型总体随机抽取n组样本观测值后，最合理的参数估计量应该使得从模型中抽取该n组样本观测值的概率最大。</p>
<p>在最大似然法中，通过选择参数，使已知数据在某种意义下最有可能出现，而某种意义通常指似然函数最大，而似然函数又往往指数据的概率分布函数。与最小二乘法不同的是，最大似然法需要已知这个概率分布函数，这在实践中是很困难的。一般假设其满足正态分布函数的特性，在这种情况下，最大似然估计和最小二乘估计相同。</p>
<p>最小二乘法以估计值与观测值的差的平方和作为损失函数，极大似然法则是以最大化目标值的似然概率函数为目标函数，从概率统计的角度处理线性回归并在似然概率函数为高斯函数的假设下同最小二乘建立了的联系。</p>
<h2 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h2><h3 id="什么是信息增益？"><a href="#什么是信息增益？" class="headerlink" title="什么是信息增益？"></a>什么是信息增益？</h3><p>定义：以某特征划分数据集前后的熵的差值。 熵可以表示样本集合的不确定性，熵越大，样本的不确定性就越大。因此可以使用划分前后集合熵的差值来衡量使用当前特征对于样本集合D划分效果的好坏。  假设划分前样本集合D的熵为H(D)。使用某个特征A划分数据集D，计算划分后的数据子集的熵为H(D|A)。<br>则信息增益为：g(D,A)=H(D)-H(D|A)</p>
<h3 id="熵是什么？"><a href="#熵是什么？" class="headerlink" title="熵是什么？"></a>熵是什么？</h3><p>熵 Entropy 也叫信息熵（Information Entropy）或香农熵（Shannon Entropy）,是度量 信息的随机度和不确定度。实验中的不确定性使用熵来测量，因此，如果实验中存在固有的不确定性越多，那么它的熵就会越高。</p>
<h3 id="交叉熵表示的意义是什么？"><a href="#交叉熵表示的意义是什么？" class="headerlink" title="交叉熵表示的意义是什么？"></a>交叉熵表示的意义是什么？</h3><p>交叉熵（Cross-Entropy）用来比较两个概率分布的。它会告诉我们两个分布的相似程度。 在同一组结果上定义的两个概率分布p和q之间的交叉熵，也就是$H(p,q) = \sum {p\log q}$.</p>
<h3 id="KL散度是什么？"><a href="#KL散度是什么？" class="headerlink" title="KL散度是什么？"></a>KL散度是什么？</h3><p>KL 散度通常用来度量两个分布之间的差异。KL 散度全称叫kullback leibler 散度，也叫做相对熵（relative entropy）。在机器学习中常用到，譬如近似推断中，有变分推断和期望传播，都是通过 Minimize KL散度来实现推断实现逼近目标分布。<br>$$
{D_{kl}}(A||B) = \sum\limits_i {{p_A}({v_i})\log \frac{{{p_A}({v_i})}}{{{p_B}({v_i})}}}
$$</p>
<h3 id="KL散度有哪些问题，该如何解决？"><a href="#KL散度有哪些问题，该如何解决？" class="headerlink" title="KL散度有哪些问题，该如何解决？"></a>KL散度有哪些问题，该如何解决？</h3><p>我们从上面的公式可以看到，KL上散度是非对称的，因此在算两个分布相似性的时候，分布计算的顺序会影响到计算的结果，因此有的时候会导致无法解释。为了解决这个这个问题，可以使用JS散度，计算结果如下：<br>$$
{D_{js}}(A||B) = \frac{1}{2}({D_{kl}}(A||B) + {D_{kl}}(B||A))
$$</p>
<h3 id="KL散度和交叉熵的区别？"><a href="#KL散度和交叉熵的区别？" class="headerlink" title="KL散度和交叉熵的区别？"></a>KL散度和交叉熵的区别？</h3><p>从交叉熵的定义来看，得到KL散度的计算方法如下：<br>$$
H(A,B) = {D_{kl}}(A||B) + S(A)
$$<br>可以看到两者相差一个常数，优化的时候可以看到两者是一样的。</p>
<h3 id="什么是最大熵模型以及它的基本原理？"><a href="#什么是最大熵模型以及它的基本原理？" class="headerlink" title="什么是最大熵模型以及它的基本原理？"></a>什么是最大熵模型以及它的基本原理？</h3><p>MaxEnt （最大熵模型）是概率模型学习中一个准则，其思想为：在学习概率模型时，所有可能的模型中熵最大的模型是最好的模型；若概率模型需要满足一些约束，则最大熵原理就是在满足已知约束的条件集合中选择熵最大模型。最大熵原理指出，对一个随机事件的概率分布进行预测时，预测应当满足全部已知的约束，而对未知的情况不要做任何主观假设。在这种情况下，概率分布最均匀，预测的风险最小，因此得到的概率分布的熵是最大</p>
<h3 id="最大熵与逻辑回归的区别？"><a href="#最大熵与逻辑回归的区别？" class="headerlink" title="最大熵与逻辑回归的区别？"></a>最大熵与逻辑回归的区别？</h3><p>逻辑回归是最大熵对应类别为两类时的特殊情况，也就是当逻辑回归类别扩展到多类别时，就是最大熵。</p>
<p>其联系在于：最大熵与逻辑回归均属于对数线性模型。它们的学习一般采用极大似然估计，或正则化的极大似然估计，可以形式化为无约束最优化问题。求解该优化问题的算法有改进的迭代尺度法、梯度下降法、拟牛顿法。<br>指数簇分布的最大熵等价于其指数形式的最大似然界；二项式的最大熵解等价于二项式指数形式(sigmoid)的最大似然，多项式分布的最大熵等价于多项式分布指数形式(softmax)的最大似然。</p>
<h3 id="最大熵优缺点？"><a href="#最大熵优缺点？" class="headerlink" title="最大熵优缺点？"></a>最大熵优缺点？</h3><p>最大熵模型的优点有：</p>
<ul>
<li>最大熵统计模型获得的是所有满足约束条件的模型中信息熵极大的模型,作为经典的分类模型时准确率较高。</li>
<li>可以灵活地设置约束条件，通过约束条件的多少可以调节模型对未知数据的适应度和对已知数据的拟合程度。</li>
</ul>
<p>最大熵模型的缺点有：</p>
<ul>
<li>由于约束函数数量和样本数目有关系，导致迭代过程计算量巨大，实际应用比较难。</li>
</ul>
<h3 id="参考-2"><a href="#参考-2" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/SecondLieutenant/article/details/79042717">https://blog.csdn.net/SecondLieutenant/article/details/79042717</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hellojamest/p/10862264.html">https://www.cnblogs.com/hellojamest/p/10862264.html</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/292434104">https://zhuanlan.zhihu.com/p/292434104</a></p>
</blockquote>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="分类问题标签长尾分布该怎么办？"><a href="#分类问题标签长尾分布该怎么办？" class="headerlink" title="分类问题标签长尾分布该怎么办？"></a>分类问题标签长尾分布该怎么办？</h3><p>1.最常用的技巧，up-sampling 或 down-sampling, 其实在 long tail 的 data 做这两种 sampling 都不是特别好的办法. 由于 tail label 数据非常 scarce, 如果对 head label 做 down-sampling 会丢失绝大部分信息. 同理, 对 tail label 做 up-sampling, 则引入大量冗余数据. 这里有篇文章对比了这两种采样方法。 可以参考文献1</p>
<p>2.divide-and-conquer, 即将 head label 和 tail label 分别建模. 比如先利用 data-rich 的 head label 训练 deep model, 然后将学到的样本的 representation 迁移到 tail label model, 利用少量 tail label data 做 fine-tune. 具体做法可以参考文献2</p>
<p>3.对 label 加权, 每个 label 赋予不同的 cost. 如给予 head label 较低的 weight, 而 tail label 则给予较高的 weight, 但是这个权重是怎么设置还需要参考相关文献。</p>
<h3 id="当机器学习性能不是很好时，你会如何优化？"><a href="#当机器学习性能不是很好时，你会如何优化？" class="headerlink" title="当机器学习性能不是很好时，你会如何优化？"></a>当机器学习性能不是很好时，你会如何优化？</h3><ol>
<li>基于数据来改善性能  </li>
<li>基于算法  </li>
<li>算法调参</li>
<li>模型融合  </li>
</ol>
<h3 id="包含百万、上亿特征的数据在深度学习中怎么处理？"><a href="#包含百万、上亿特征的数据在深度学习中怎么处理？" class="headerlink" title="包含百万、上亿特征的数据在深度学习中怎么处理？"></a>包含百万、上亿特征的数据在深度学习中怎么处理？</h3><p>这么多的特征，肯定不能直接拿去训练，特征多，数据少，很容易导致模型过拟合。<br>（1）特征降维：PCA或LDA<br>（2）使用正则化，L1或L2<br>引入 L_1 范数除了降低过拟合风险之外，还有一个好处：它求得的 w 会有较多的分量为零。即：它更容易获得稀疏解。<br>（3）样本扩充：数据增强<br>（4）特征选择：去掉不重要的特征</p>
<h3 id="类别型数据你是如何处理的？比如游戏品类，地域，设备？"><a href="#类别型数据你是如何处理的？比如游戏品类，地域，设备？" class="headerlink" title="类别型数据你是如何处理的？比如游戏品类，地域，设备？"></a>类别型数据你是如何处理的？比如游戏品类，地域，设备？</h3><p>序号编码、one-hot编码、多热编码，二进制编码，搞成嵌入向量</p>
<h3 id="参考-3"><a href="#参考-3" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_46838716/article/details/124424903">https://blog.csdn.net/weixin_46838716/article/details/124424903</a><br>learning-to-model-the-tail<br>deepxml: scalable &amp; accurate deep extreme classification for matching user ueries to advertiser bid phrases<br>extreme multi-label learning with label features for warm-start tagging, ranking &amp; recommendation</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A0%91%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A0%91%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">树模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-23 20:47:33" itemprop="dateModified" datetime="2024-03-23T20:47:33+08:00">2024-03-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="树模型"><a href="#树模型" class="headerlink" title="树模型"></a>树模型</h1><h2 id="基础树"><a href="#基础树" class="headerlink" title="基础树"></a>基础树</h2><h3 id="介绍下ID3和C4-5"><a href="#介绍下ID3和C4-5" class="headerlink" title="介绍下ID3和C4.5?"></a>介绍下ID3和C4.5?</h3><p>构造决策树有多种算法，国际上最早的、具有影响力的决策树是由Quinlan于1986年提出的ID3算法，是基于信息熵的决策树分类算法。该算法是决策树的一个经典的构造算法，内部使用信息熵以及信息增益来进行构建；每次迭代选择信息增益最大的特征属性作为分割属性。</p>
<h3 id="ID3的优缺点？"><a href="#ID3的优缺点？" class="headerlink" title="ID3的优缺点？"></a>ID3的优缺点？</h3><p>优点:<br>决策树构建速度快；实现简单；</p>
<p>缺点：</p>
<ul>
<li>ID3算法避免了搜索不完整假设空间的一个主要风险：假设空间可能不包含目标函数。</li>
<li>ID3算法在搜索的每一步都使用当前的所有训练样例，大大降低了对个别训练样例错误的敏感性。</li>
<li>ID3算法在搜索过程中不进行回溯。所以，它易受无回溯的爬山搜索中的常见风险影响：收敛到局部最优而不是全局最优。</li>
<li>ID3算法只能处理离散值的属性。</li>
<li>信息增益度量存在一个内在偏置，它偏袒具有较多值的属性。</li>
<li>ID3算法增长树的每一个分支的深度，直到恰好能对训练样例完美地分类，存在决策树过度拟合。</li>
<li>ID3算法没有考虑缺失值的情况</li>
</ul>
<h3 id="ID3划分特征的标准是什么？"><a href="#ID3划分特征的标准是什么？" class="headerlink" title="ID3划分特征的标准是什么？"></a>ID3划分特征的标准是什么？</h3><p>ID3 使用的分类标准是信息增益，它表示得知特征 A 的信息而使得样本集合不确定性减少的程度。信息增益=信息熵-条件熵：<br> $$
G{\rm{ai}}n(D,A) = H(D) - H(D|A)
$$<br>信息增益越大表示使用特征 A 来划分所获得的“纯度提升越大”。</p>
<h3 id="介绍下C4-5算法？"><a href="#介绍下C4-5算法？" class="headerlink" title="介绍下C4.5算法？"></a>介绍下C4.5算法？</h3><p>算法发明者Quinlan于1993年又提出了ID3的改进版本C4.5算法，C4.5算法用信息增益率来选择决策属性，它继承了ID3算法的全部优点，在ID3的基础上还增加了对连续属性的离散化、对未知属性的处理和产生规则等功能。</p>
<h3 id="C4-5的划分标准是什么？"><a href="#C4-5的划分标准是什么？" class="headerlink" title="C4.5的划分标准是什么？"></a>C4.5的划分标准是什么？</h3><p>利用信息增益比可以克服信息增益的缺点，其公式为:<br> $$
I(D,A) = \frac{{I(D,A)}}{{H(D)}}
$$<br>这里是特征熵，特征越多对应的特征熵越大，它作为分母，可以校正信息增益容易偏向取值较多的特征的问题。</p>
<h3 id="CART是如何处理类别不平衡问题的？"><a href="#CART是如何处理类别不平衡问题的？" class="headerlink" title="CART是如何处理类别不平衡问题的？"></a>CART是如何处理类别不平衡问题的？</h3><p>CART 的一大优势在于：无论训练数据集有多失衡，它都可以将其自动消除，而不需要建模人员采取其他操作。</p>
<p>CART 使用了一种先验机制，其作用相当于对类别进行加权。这种先验机制嵌入于 CART 算法判断分裂优劣的运算里，在 CART 默认的分类模式中，总是要计算每个节点关于根节点的类别频率的比值，这就相当于对数据自动重加权，对类别进行均衡。</p>
<p>对于一个二分类问题，节点 node 被分成类别 1 当且仅当：<br> $$
\frac{{{N_1}(node)}}{{{N_1}(root)}} > \frac{{{N_0}(node)}}{{{N_0}(root)}}
$$<br>比如二分类，根节点属于 1 类和 0 类的分别有 20 和 80 个。在子节点上有 30 个样本，其中属于 1 类和 0 类的分别是 10 和 20 个。如果 10/20&gt;20/80，该节点就属于 1 类。</p>
<p>通过这种计算方式就无需管理数据真实的类别分布。假设有 K 个目标类别，就可以确保根节点中每个类别的概率都是 1/K。这种默认的模式被称为“先验相等”。先验设置和加权不同之处在于先验不影响每个节点中的各类别样本的数量或者份额。先验影响的是每个节点的类别赋值和树生长过程中分裂的选择。</p>
<h3 id="C4-5划分标准的缺陷是什么？"><a href="#C4-5划分标准的缺陷是什么？" class="headerlink" title="C4.5划分标准的缺陷是什么？"></a>C4.5划分标准的缺陷是什么？</h3><p>采用的是信息增益比，信息增益率对可取值较少的特征有所偏好（分母越小，整体越大），因此 C4.5 并不是直接用增益率最大的特征进行划分，而是使用一个启发式方法：先从候选划分特征中找到信息增益高于平均值的特征，再从中选择增益率最高的。</p>
<h3 id="C4-5算法的优缺点？"><a href="#C4-5算法的优缺点？" class="headerlink" title="C4.5算法的优缺点？"></a>C4.5算法的优缺点？</h3><p>C4.5算法的优点是产生的分类规则易于理解，准确率较高。缺点就是在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效。此外，C4.5算法只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时，程序无法运行。</p>
<h3 id="C4-5如何处理缺失值？"><a href="#C4-5如何处理缺失值？" class="headerlink" title="C4.5如何处理缺失值？"></a>C4.5如何处理缺失值？</h3><p>C4.5对于缺失值的处理主要有以下步骤：<br>对于具有缺失值特征，用没有缺失的样本子集所占比重来折算；选定该划分特征，对于缺失该特征值的样本同时划分到所有子节点，不过要调整样本的权重值，其实也就是以不同概率划分到不同节点中。</p>
<h3 id="ID3和C4-5区别？"><a href="#ID3和C4-5区别？" class="headerlink" title="ID3和C4.5区别？"></a>ID3和C4.5区别？</h3><p>相比于之前的ID3算法，C4.5进行了改进。主要如下</p>
<ul>
<li>用信息增益率来选择划分特征，克服了用信息增益选择的不足，但信息增益率对可取值数目较少的属性有所偏好；</li>
<li>能够处理离散型和连续型的属性类型，即将连续型的属性进行离散化处理；</li>
<li>能够处理具有缺失属性值的训练数据；</li>
<li>在构造树的过程中进行剪枝；</li>
</ul>
<h3 id="CART是如何对连续值处理的？"><a href="#CART是如何对连续值处理的？" class="headerlink" title="CART是如何对连续值处理的？"></a>CART是如何对连续值处理的？</h3><p>对于连续值的处理，CART分类树采用基尼系数的大小来度量特征的各个划分点。在回归模型中，我们使用常见的和方差度量方式，对于任意划分特征 A，对应的任意划分点 s 两边划分成的数据集和D1和D2，求出使各自集合的均方差最小，同时两个的均方差之和最小所对应的特征和特征值划分点。表达式为：<br> $$
{\min _{a,s}}[{\min _{{c_1}}}\sum\limits_{{x_i} \in {D_1}} {{{({y_i} - {c_1})}^2}}  + {\min _{{c_2}}}\sum\limits_{{x_i} \in {D_2}} {{{({y_i} - {c_2})}^2}} ]
$$<br>其中，为数据集得到样本输出均值，为数据集的样本输出均值。</p>
<h3 id="CART算法为什么选用gini指数？"><a href="#CART算法为什么选用gini指数？" class="headerlink" title="CART算法为什么选用gini指数？"></a>CART算法为什么选用gini指数？</h3><p>介绍下熵的公式：<br> $$
H(x) =  - \sum\limits_{k = 1}^K {{p_k}\ln ({p_k})}
$$<br>将其在x=1处进行泰勒展开<br> $$
H(x) =  - \sum\limits_{k = 1}^K {{p_k}\ln ({p_k})}  =  - \sum\limits_{k = 1}^K {{p_k}(1 - {p_k})}
$$<br>比较一下的结果如下，别人总结的<br><img src="https://img-blog.csdnimg.cn/img_convert/d6fe6db604230ea2506263149d660e3c.png" alt="img"></p>
<h3 id="基尼系数的的定义及其优势是什么？"><a href="#基尼系数的的定义及其优势是什么？" class="headerlink" title="基尼系数的的定义及其优势是什么？"></a>基尼系数的的定义及其优势是什么？</h3><p>熵模型拥有大量耗时的对数运算，基尼指数在简化模型的同时还保留了熵模型的优点。</p>
<p>基尼系数的计算公式如下所示：</p>
 $$
G{\rm{i}}ni(p) = \sum\limits_{k - 1}^K {{p_k}(1 - {p_k}) = 1 - \sum\limits_{k = 1}^K {{p^2}_k} } 
$$ 
<p>代表了模型的不纯度，基尼系数越小，不纯度越低，特征越好。这和信息增益（率）正好相反。</p>
<p>基尼系数的优点：在保证准确率的情况下大大减小了计算量。</p>
<p>基尼指数反映了从数据集中随机抽取两个样本，其类别标记不一致的概率。因此基尼指数越小，则数据集纯度越高。基尼指数偏向于特征值较多的特征，类似信息增益。基尼指数可以用来度量任何不均匀分布，是介于 0~1 之间的数，0是完全相等，1是完全不相等</p>
<h3 id="CART是如何在特征值缺失的情况下进行划分特征的选择？"><a href="#CART是如何在特征值缺失的情况下进行划分特征的选择？" class="headerlink" title="CART是如何在特征值缺失的情况下进行划分特征的选择？"></a>CART是如何在特征值缺失的情况下进行划分特征的选择？</h3><p>CART 一开始严格要求分裂特征评估时只能使用在该特征上没有缺失值的那部分数据，在后续版本中，CART 算法使用了一种惩罚机制来抑制提升值，从而反映出缺失值的影响（例如，如果一个特征在节点的 20% 的记录是缺失的，那么这个特征就会减少 20% 或者其他数值）。</p>
<h3 id="CART模型对于缺失该特征值的样本该进行怎样处理？"><a href="#CART模型对于缺失该特征值的样本该进行怎样处理？" class="headerlink" title="CART模型对于缺失该特征值的样本该进行怎样处理？"></a>CART模型对于缺失该特征值的样本该进行怎样处理？</h3><p>CART 算法的机制是为树的每个节点都找到代理分裂器，无论在训练数据上得到的树是否有缺失值都会这样做。在代理分裂器中，特征的分值必须超过默认规则的性能才有资格作为代理（即代理就是代替缺失值特征作为划分特征的特征），当 CART 树中遇到缺失值时，这个实例划分到左边还是右边是决定于其排名最高的代理，如果这个代理的值也缺失了，那么就使用排名第二的代理，以此类推，如果所有代理值都缺失，那么默认规则就是把样本划分到较大的那个子节点。代理分裂器可以确保无缺失训练数据上得到的树可以用来处理包含确实值的新数据。</p>
<h3 id="决策树出现过拟合的原因及其解决办法？"><a href="#决策树出现过拟合的原因及其解决办法？" class="headerlink" title="决策树出现过拟合的原因及其解决办法？"></a>决策树出现过拟合的原因及其解决办法？</h3><p>对训练数据预测效果很好，但是测试数据预测效果较差的现象称为过拟合。</p>
<p>原因：</p>
<p>在决策树构建的过程中，对决策树的生长没有进行合理的限制（剪枝）；<br>样本中有一些噪声数据，没有对噪声数据进行有效的剔除；<br>在构建决策树过程中使用了较多的输出变量，变量较多也容易产生过拟合<br>解决办法</p>
<p>选择合理的参数进行剪枝，可以分为预剪枝和后剪枝，我们一般采用后剪枝的方法；<br>利用K−folds交叉验证，将训练集分为K份，然后进行K次交叉验证，每次使用K−1份作为训练样本数据集，另外一份作为测试集；<br>减少特征，计算每一个特征和响应变量的相关性，常见得为皮尔逊相关系数，将相关性较小的变量剔除；当然还有一些其他的方法来进行特征筛选，比如基于决策树的特征筛选，通过正则化的方式来进行特征选取等（决策的正则化）。</p>
<h3 id="为什么C4-5能处理连续特征而ID3不行？"><a href="#为什么C4-5能处理连续特征而ID3不行？" class="headerlink" title="为什么C4.5能处理连续特征而ID3不行？"></a>为什么C4.5能处理连续特征而ID3不行？</h3><p>这是因为ID3在设计的时候根本就没考虑过要处理连续特征，所以它自然就不能处理连续特征。那为什么ID3不考虑连续特征？这是因为任何研究都是循循渐进的，每一个研究只会将精力放在当前最重要的研究点之上。ID3与C4.5都是Quinlan 的作品，而ID3的研究重点是如何设计高效的节点分裂方法来生长决策树，因此它并不太在意如何去处理连续特征。为此，ID3提出了使用信息增益来衡量一次节点分裂的优劣，它是第一个成功将信息论相关理论使用到决策树算法中的，从这点来看它的时代意义比较重要。因此从学术贡献来看，它确实也没有必要再去处理一些琐碎而简单的问题了。而C4.5的重点则是将ID3的成果工程化，让决策树能真正解决实际中的复杂问题，所以C4.5设计了详细的连续特征处理方法和剪枝算法。以现在的眼光来看，只要你愿意，可以很容易地将ID3改造为有能力处理连续特征的决策树。</p>
<h3 id="剪枝的策略是啥"><a href="#剪枝的策略是啥" class="headerlink" title="剪枝的策略是啥?"></a>剪枝的策略是啥?</h3><p>在决策树算法中，为了尽可能正确分类训练样本， 节点划分过程不断重复， 有时候会造成决策树分支过多，以至于将训练样本集自身特点当作泛化特点， 而导致过拟合。因此可以采用剪枝处理来去掉一些分支来降低过拟合的风险。</p>
<p>剪枝的基本策略有预剪枝（pre-pruning）和后剪枝（post-pruning）。</p>
<p>预剪枝：在决策树生成过程中，在每个节点划分前先估计其划分后的泛化性能， 如果不能提升，则停止划分，将当前节点标记为叶结点。</p>
<p>后剪枝：生成决策树以后，再自下而上对非叶结点进行考察， 若将此节点标记为叶结点可以带来泛化性能提升，则修改之。</p>
<h3 id="树模型one-hot有哪些问题？"><a href="#树模型one-hot有哪些问题？" class="headerlink" title="树模型one_hot有哪些问题？"></a>树模型one_hot有哪些问题？</h3><p>one-hot coding是类别特征的一种通用解决方法，然而在树模型里面，这并不是一个比较好的方案，尤其当类别特征维度很高的时候。主要的问题是：</p>
<p>1.可能无法在这个类别特征上进行切分。使用one-hot coding的话，意味着在每一个决策节点上只能用 one-vs-rest (例如是不是狗，是不是猫，等等) 的切分方式。当特征纬度高时，每个类别上的数据都会比较少，这时候产生的切分不平衡，切分增益（split gain）也会很小（比较直观的理解是，不平衡的切分和不切分几乎没有区别）。<br>2.会影响决策树的学习。因为就算可以在这个类别特征进行切分，也会把数据切分到很多零散的小空间上，如图1左所示。而决策树学习时利用的是统计信息，在这些数据量小的空间上，统计信息不准确，学习会变差。但如果使用图1右边的切分方法，数据会被切分到两个比较大的空间，进一步的学习也会更好。<br><img src="https://img-blog.csdnimg.cn/41dd460bbcd146abb0fbba9916d8d49f.png" alt="img"></p>
<h3 id="如何解决树模型中one-hot的问题"><a href="#如何解决树模型中one-hot的问题" class="headerlink" title="如何解决树模型中one_hot的问题?"></a>如何解决树模型中one_hot的问题?</h3><p>1.类别特征的最优切分。这个方法需要对应工具的支持，我所知的支持这个方法的工具有h2o.gbm和LightGBM,用LightGBM可以直接输入类别特征，并产生同图1右边的最优切分。在一个k维的类别特征寻找最优切分，朴素的枚举算法的复杂度是指数的 O(2^k)。LightGBM 用了一个 O(klogk)[1] 的算法。算法流程如图2所示：在枚举分割点之前，先把直方图按照每个类别对应的label均值进行排序；然后按照排序的结果依次枚举最优分割点。当然，这个方法很容易过拟合，所以LightGBM里面还增加了很多对于这个方法的约束和正则化。图3是一个简单的对比实验，可以看到Optimal的切分方法在AUC提高了1.5个点，并且时间只多了20% 。 </p>
<p>2.转成数值特征。在使用 sklearn 或 XGBoost 等不支持类别特征的最优切分工具时，可以用这个方法。常见的转换方法有: a) 把类别特征转成one-hot coding扔到NN里训练个embedding；b) 类似于CTR特征，统计每个类别对应的label(训练目标)的均值。统计的时候有一些小技巧，比如不把自身的label算进去(leave-me-out, leave-one-out)统计， 防止信息泄露。  </p>
<p>3.其他的编码方法，比如binary coding等等，同样可以用于不支持类别特征的算法。这里有一个比较好的开源项目，封装了常见的各种编码方法: <a target="_blank" rel="noopener" href="https://github.com/scikit-learn-contrib/category_encoders">https://github.com/scikit-learn-contrib/category_encoders</a></p>
<h3 id="为啥决策树后剪枝比预剪枝要好？"><a href="#为啥决策树后剪枝比预剪枝要好？" class="headerlink" title="为啥决策树后剪枝比预剪枝要好？"></a>为啥决策树后剪枝比预剪枝要好？</h3><ul>
<li><p>预剪枝<br>预剪枝使得决策树的很多分支没有展开，也就是没有一步一步计算然后分裂下去了，这不仅降低了过拟合的风险，还显著减少了树模型的训练时间开销。但是另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但是在其基础上进行的后续划分有可能导致性能显著提升(但是我们简单嘛，就不继续划分了)。预剪枝基于贪心本质，抱着能多剪就多剪枝从而招来欠拟合的风险。采用这种方法得到的决策树可能就是如下这种：<br><img src="https://img-blog.csdnimg.cn/984eef32683a46c389f6e824772773eb.png" alt="image"><br>可以看到在这棵树比价简单，泛化性能比较好，也不会过拟合，但是就是太太简单了，会导致预测的时候偏差较大，也是我们说的欠拟合。</p>
</li>
<li><p>后剪枝<br>在决策树生成后进行剪枝，这也符合我们做事的逻辑和条理。后剪枝决策树通常比预剪枝决策树保留了更多的分支(所以说计算开销还是比较大滴)。一般情况下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。所以剪枝后的树大概就是你看到的下面的这个样子：<br><img src="https://img-blog.csdnimg.cn/d263dde49a5b40cab90c86f11297ed08.png" alt="image"></p>
</li>
</ul>
<h3 id="决策树中有哪些剪枝算法"><a href="#决策树中有哪些剪枝算法" class="headerlink" title="决策树中有哪些剪枝算法"></a>决策树中有哪些剪枝算法</h3><p>决策树中常见的剪枝算法有：<br>Reduced-Error Pruning（REP,错误率降低剪枝）<br>Pesimistic-Error Pruning（PEP,悲观错误剪枝）<br>Cost-Complexity Pruning（CCP，代价复杂度剪枝）<br>Minimum Error Pruning （MEP, 最小误差剪枝）  </p>
<p>REP：通过一个新的验证集来纠正树的过拟合问题。对于决策树中的每一个非叶子节点的子树，我们将它替换成一个叶子节点，该叶子节点的类别用大多数原则来确定，这样就产生了一个新的相对简化决策树，然后比较这两个决策树在验证集中的表现。如果新的决策树在验证集中的正确率较高，那么该子树就可以替换成叶子节点，从而达到决策树剪枝的目的。</p>
<p>PEP：这个算法和REP差不多，和REP不同之处在于：PEP不需要新的验证集，并且PEP是自上而下剪枝的。由于我们还是用生成决策树时相同的训练样本，那么对于每个节点剪枝后的错分率一定是会上升的，因此在计算错分率时需要加一个惩罚因子0.5。</p>
<p>CPC：CCP算法为子树 $T_i$ 定义了代价和复杂度，以及一个衡量代价与复杂度之间关系的参数 $\alpha$ 。代价指的是在剪枝过程中因子树 $T_i$ 被叶节点替代而增加的错分样本;复杂度表示剪枝后子树 $T_i$ 减少的叶结点数; 从下到上计算每一个非叶节点的 $\alpha$ 值，然后每一次都剪掉具有最小值的子树 ${T_0}{T_1} \cdots {T_n}$ ，最后得到,其中是 $T_0$ 完整的数， $T_n$ 表示根节点，然后根据真实的错误率在 ${T_0}{T_1} \cdots {T_n}$ 中选择一个最好的。</p>
<p>MEP：此方法的基本思路是采用自底向上的方式，对于树中每个非叶节点。首先计算该节点的误差,然后，计算该节点每个分支的误差,并且加权相加，权为每个分支拥有的训练样本比例。如果大于,则保留该子树；否则就剪裁。</p>
<p><img src="https://img-blog.csdnimg.cn/373937826586452cad330f80876e589a.png" alt="img"><br>详细的结果如上图所示</p>
<h3 id="C4-5采用的剪枝方法是什么？"><a href="#C4-5采用的剪枝方法是什么？" class="headerlink" title="C4.5采用的剪枝方法是什么？"></a>C4.5采用的剪枝方法是什么？</h3><p>C4.5 采用的悲观剪枝方法，用递归的方式从低往上针对每一个非叶子节点，评估用一个最佳叶子节点去代替这课子树是否有益。如果剪枝后与剪枝前相比其错误率是保持或者下降，则这棵子树就可以被替换掉。C4.5 通过训练数据集上的错误分类数量来估算未知样本上的错误率。</p>
<h3 id="CART是如何处理类别不平衡问题的？-1"><a href="#CART是如何处理类别不平衡问题的？-1" class="headerlink" title="CART是如何处理类别不平衡问题的？"></a>CART是如何处理类别不平衡问题的？</h3><p>CART 的一大优势在于：无论训练数据集有多失衡，它都可以将其自动消除，而不需要建模人员采取其他操作。</p>
<p>CART 使用了一种先验机制，其作用相当于对类别进行加权。这种先验机制嵌入于 CART 算法判断分裂优劣的运算里，在 CART 默认的分类模式中，总是要计算每个节点关于根节点的类别频率的比值，这就相当于对数据自动重加权，对类别进行均衡。</p>
<h3 id="说一下ID3、C4-5和CART三者之间的差异？"><a href="#说一下ID3、C4-5和CART三者之间的差异？" class="headerlink" title="说一下ID3、C4.5和CART三者之间的差异？"></a>说一下ID3、C4.5和CART三者之间的差异？</h3><p>划分标准的差异：ID3 使用信息增益偏向特征值多的特征，C4.5 使用信息增益率克服信息增益的缺点，偏向于特征值小的特征，CART 使用基尼指数克服 C4.5 需要求 log 的巨大计算量，偏向于特征值较多的特征。<br>使用场景的差异：ID3 和 C4.5 都只能用于分类问题，CART 可以用于分类和回归问题；ID3 和 C4.5 是多叉树，速度较慢，CART 是二叉树，计算速度很快；<br>样本数据的差异：ID3 只能处理离散数据且缺失值敏感，C4.5 和 CART 可以处理连续性数据且有多种方式处理缺失值；从样本量考虑的话，小样本建议 C4.5、大样本建议 CART。C4.5 处理过程中需对数据集进行多次扫描排序，处理成本耗时较高，而 CART 本身是一种大样本的统计方法，小样本处理下泛化误差较大 ；<br>样本特征的差异：ID3 和 C4.5 层级之间只使用一次特征，CART 可多次重复使用特征；<br>剪枝策略的差异：ID3 没有剪枝策略，C4.5 是通过悲观剪枝策略来修正树的准确性，而 CART 是通过代价复杂度剪枝。</p>
<h3 id="拥有很多特征的决策树最后没有用到的特征一定是无用吗？"><a href="#拥有很多特征的决策树最后没有用到的特征一定是无用吗？" class="headerlink" title="拥有很多特征的决策树最后没有用到的特征一定是无用吗？"></a>拥有很多特征的决策树最后没有用到的特征一定是无用吗？</h3><p>不是无用的，从两个角度考虑:</p>
<p>一是特征替代性，如果可以已经使用的特征A和特征B可以提点特征C，特征C可能就没有被使用，但是如果把特征C单独拿出来进行训练，依然有效.</p>
<p>其二，决策树的每一条路径就是计算条件概率的条件，前面的条件如果包含了后面的条件，只是这个条件在这棵树中是无用的，如果把这个条件拿出来也是可以帮助分析数据.</p>
<p>决策树需要进行归一化处理吗？<br>概率模型不需要归一化，因为他们不关心变量的值，而是关心变量的分布和变量之间的条件概率。决策树是一种概率模型，数值缩放，不影响分裂点位置，对树模型的结构不造成影响。所以一般不对其进行归一化处理。</p>
<p>按照特征值进行排序的，排序的顺序不变，那么所属的分支以及分裂点就不会有不同。</p>
<p>树模型是不能进行梯度下降的，因为构建树模型（回归树）寻找最优点时是通过寻找最优分裂点完成的，因此树模型是阶跃的，阶跃点是不可导的，并且求导没意义，也就不需要归一化。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/89901519">https://zhuanlan.zhihu.com/p/89901519</a><br><a target="_blank" rel="noopener" href="https://ask.csdn.net/questions/377838">https://ask.csdn.net/questions/377838</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/404072623">https://zhuanlan.zhihu.com/p/404072623</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/481321311">https://zhuanlan.zhihu.com/p/481321311</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/2abc638490e3">https://www.jianshu.com/p/2abc638490e3</a></p>
</blockquote>
<h2 id="提升树"><a href="#提升树" class="headerlink" title="提升树"></a>提升树</h2><h3 id="简单介绍下GBDT的基本原理？"><a href="#简单介绍下GBDT的基本原理？" class="headerlink" title="简单介绍下GBDT的基本原理？"></a>简单介绍下GBDT的基本原理？</h3><p>GBDT是一种基于boosting集成思想的加法模型，训练时采用前向分布算法进行贪婪的学习，每次迭代都学习一棵CART树来拟合之前 t-1 棵树的预测结果与训练样本真实值的残差。</p>
<h3 id="什么是梯度提升？"><a href="#什么是梯度提升？" class="headerlink" title="什么是梯度提升？"></a>什么是梯度提升？</h3><p>首先，梯度提升是一种基于函数梯度信息的Boosting方法，与梯度下降有异曲同工之妙。<br>在每一轮迭代时，我们生成一个基学习器，基学习器的拟合目标是当前模型Loss的负梯度。<br>当训练完成后，我们将该基学习器加入至模型。<br>重复上述，继续训练基学习器，直至迭代次数达到目标。<br>梯度提升的优化原理伪代码如下(图中Loss的负梯度使用了残差，即MSE的负梯度)：</p>
<h3 id="为什么用Loss的负梯度来拟合下一棵树？"><a href="#为什么用Loss的负梯度来拟合下一棵树？" class="headerlink" title="为什么用Loss的负梯度来拟合下一棵树？"></a>为什么用Loss的负梯度来拟合下一棵树？</h3><p>将函数进行泰勒展开，使Loss朝着当前最小化的方向优化，在函数空间上求解出下一棵树拟合的目标，即Loss的负梯度。梯度下降法通过不断的迭代优化参数，让参数朝着下降速度最快的方向不断下降，逐步达到Loss最小化的目标</p>
<h3 id="为什么GBDT的树深度较RF通常都比较浅？"><a href="#为什么GBDT的树深度较RF通常都比较浅？" class="headerlink" title="为什么GBDT的树深度较RF通常都比较浅？"></a>为什么GBDT的树深度较RF通常都比较浅？</h3><p>对于机器学习来说，泛化误差可以理解为两部分，分别是偏差（bias）和方差（variance）；偏差指的是算法的期望预测与真实预测之间的偏差程度，反应了模型本身的拟合能力；方差度量了同等大小的训练集的变动导致学习性能的变化，刻画了数据扰动所导致的影响。当模型越复杂时，拟合的程度就越高，模型的训练偏差就越小；但此时如果换一组数据可能模型的变化就会很大，即模型的方差很大，所以模型过于复杂的时候会导致过拟合。</p>
<p>对于RF来说由于并行训练很多不同的分类器的目的就是降低这个方差（variance）。所以对于每个基分类器来说，目标就是如何降低这个偏差（bias），所以我们会采用深度很深甚至不剪枝的决策树。而对于GBDT来说由于利用的是残差逼近的方式，即在上一轮的基础上更加拟合原数据，所以可以保证偏差（bias），所以对于每个基分类器来说，问题就在于如何选择 variance 更小的分类器，即更简单的分类器，所以我们选择了深度很浅的决策树。</p>
<h3 id="GBDT构建的分类树和回归树的区别是什么？"><a href="#GBDT构建的分类树和回归树的区别是什么？" class="headerlink" title="GBDT构建的分类树和回归树的区别是什么？"></a>GBDT构建的分类树和回归树的区别是什么？</h3><p>GBDT构建CART树，无论是分类还是回归，都是使用的回归树，因为分类树无法处理连续值。那么接下来说区别：</p>
<p>1.CART里分类节点分裂时特征选择用gini, 回归用均方差mse，度量目标是对于划分特征A，对应划分点s两边的数据集D1和D2，求出使D1和D2各自集合的均方差最小，同时D1和D2的均方差之和最小。</p>
<p>2.对于决策树建立后做预测的方式，CART分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。回归树输出不是类别，采用叶子节点的均值或者中位数来预测输出结果。</p>
<h3 id="GBDT构建回归和分类的第一颗树是什么？"><a href="#GBDT构建回归和分类的第一颗树是什么？" class="headerlink" title="GBDT构建回归和分类的第一颗树是什么？"></a>GBDT构建回归和分类的第一颗树是什么？</h3><p>对于回归树：<br> ${F_0} = avg(y)$ </p>
<p>对应分类树<br> ${F_0}(x) = \log \frac{{P(Y = 1|x)}}{{1 - P(Y = 1|x)}}$<br>其中， $P(Y = 1|x)$ 是训练样本中 $Y=1$ 的比例，利用先验信息来初始化学习器。</p>
<h3 id="GBDT如何进行多分类的学习？"><a href="#GBDT如何进行多分类的学习？" class="headerlink" title="GBDT如何进行多分类的学习？"></a>GBDT如何进行多分类的学习？</h3><p>多分类的伪代码如下：<br><img src="https://img-blog.csdnimg.cn/ab0ec907d1ca4655ae9f66716cdb5978.png" alt="img"></p>
<p>根据上面的伪代码具体到多分类这个任务上面来，我们假设总体样本共有  $K$  类。来了一个样本  $x$  ，我们需要使用GBDT来判断 $x$ 属于样本的哪一类。</p>
<p>第一步我们在训练的时候，是针对样本 $x$ 每个可能的类都训练一个分类回归树。举例说明，目前样本有三类，也就是 $K=3$  ，样本 $x$ 属于第二类。那么针对该样本的分类标签，其实可以用一个三维向量 [0,1,0]来表示。 0表示样本不属于该类， 1表示样本属于该类。由于样本已经属于第二类了，所以第二类对应的向量维度为 1 ，其它位置为 0 。</p>
<p>针对样本有三类的情况，我们实质上在每轮训练的时候是同时训练三颗树。第一颗树针对样本  $x$  的第一类，输入为  $(x,0)$  。第二颗树输入针对样本  $x$ 的第二类，输入为  $(x,1)$  。第三颗树针对样本 $x$ 的第三类，输入为  $(x,0) $ 。这里每颗树的训练过程其实就CART树的生成过程。在此我们参照CART生成树的步骤即可解出三颗树，以及三颗树对  $x$  类别的预测值  $F_{1}(x), F_{2}(x), F_{3}(x)$  , 那么在此类训练中，我们仿照多分类的逻辑回归 ，使用Softmax 来产生概率，则属于类别 1 的概率为：</p>
 $$
{p_1}(x) = \frac{{\exp ({F_1}(x))}}{{\sum\limits_{k = 1}^3 {\exp ({F_k}(x))} }}
$$ 
<p>并且我们可以针对类别 1 求出残差  ${\tilde y_1} = 0 - {p_1}(x)$  ；类别 2  求出残差  ${\tilde y_2} = 0 - {p_2}(x)$ ；类别  3  求出残差  ${\tilde y_3} = 0 - {p_3}(x)$ 。</p>
<p>然后开始第二轮训练，针对第一类输入为  $(x,{\tilde y_1})$ , 针对第二类输入为  $(x,{\tilde y_2})$  ，针对第三类输入为  $(x,{\tilde y_3})$ 。继续训练出三颗树。一直迭代M轮。每轮构建3颗树。</p>
<h3 id="GBDT常用损失函数有哪些？"><a href="#GBDT常用损失函数有哪些？" class="headerlink" title="GBDT常用损失函数有哪些？"></a>GBDT常用损失函数有哪些？</h3><p>MSE(Mean Square Error)均方误差<br>RMSE(Root Mean Square Error)均方根误差<br>MAE(Mean Absolute Error)平均绝对误差<br>Huber Loss(MAE和MSE结合)</p>
<h3 id="为什么GBDT不适合使用高维稀疏特征？"><a href="#为什么GBDT不适合使用高维稀疏特征？" class="headerlink" title="为什么GBDT不适合使用高维稀疏特征？"></a>为什么GBDT不适合使用高维稀疏特征？</h3><p>高维稀疏的ID类特征会使树模型的训练变得极为低效，且容易过拟合。</p>
<p>树模型训练过程是一个贪婪选择特征的算法，要从候选特征集合中选择一个使分裂后收益函数增益最大的特征来分裂，按照高维的ID特征做分裂时，子树数量非常多，计算量会非常大，训练会非常慢。<br>同时，按ID分裂得到的子树的泛化能力比较弱，由于只包含了对应ID值的样本，样本稀疏时也很容易过拟合。</p>
<h3 id="GBDT算法的优缺点？"><a href="#GBDT算法的优缺点？" class="headerlink" title="GBDT算法的优缺点？"></a>GBDT算法的优缺点？</h3><p>优点：<br>预测阶段的计算速度快，树与树之间可并行化计算（注意预测时可并行）；<br>在分布稠密的数据集上，泛化能力和表达能力都很好；<br>采用决策树作为弱分类器使得GBDT模型具有：</p>
<ol>
<li>较好的解释性和鲁棒性；</li>
<li>能够自动发现特征间的高阶关系；</li>
<li>不需要对数据进行特殊的预处理，如归一化等。</li>
</ol>
<p>缺点：<br>GBDT在高维稀疏的数据集上表现不佳；<br>训练过程需要串行训练，只能在决策树内部采用一些局部并行的手段提高训练速度。</p>
<h3 id="GBDT有哪些参数？"><a href="#GBDT有哪些参数？" class="headerlink" title="GBDT有哪些参数？"></a>GBDT有哪些参数？</h3><ul>
<li>GBDT框架参数</li>
</ul>
<p>n_estimators:代表弱学习器的最大个数，即最多训练多少棵树。这个值过大导致过拟合，过小导致欠拟合.默认值为100.</p>
<p>learning_rate：每个弱学习器都有一个权重参数，默认值0.1，取值范围0-1。 learning_rate和n_estimators同时决定着模型的拟合效果，因此要同时调整，建议从一个小一点的学习率开始。</p>
<p>subsample:子采样比例，默认1.0，是不放回的采样，与随机森林的有放回采样不一样。如果为1.0，表示每轮采用全部数据生成决策树，容易过拟合，方差容易比较大。但是如果过小，容易造成高偏差，所以这个值需要这种，建议0.5-0.8之间。</p>
<p>init:初始学习器的值，在有一定先验知识的情况下可以自己设定，但是一般不用。</p>
<p>loss：损失函数的选择，对于分类和回归是有区别的。<br>分类：可选项有{‘deviance’,’exponential’}，”deviance”对数似然损失函数和’exponential’指数损失函数,默认对数似然损失函数，对于二分类以及多分类问题采用对数似然损失函数比较好，这种损失函数用的也比较多。而指数损失函数，让我们想到的是Adaboost,即改变本轮错误训练的数据在下一轮训练中的权值，使错误分类的样本得到更多重视。<br>回归：可选项有{‘ls’, ‘lad’, ‘huber’, ‘quantile’},ls是均方，lad是绝对误差，huber是抗噪音损失函数。当残差大于delta，应当采用L1（对较大的异常值不那么敏感）来最小化，而残差小于超参数，则用L2来最小化。本质上，Huber损失是绝对误差，只是在误差很小时，就变为平方误差。它对数据中的异常点没有平方误差损失那么敏感。它在0也可微分。使用MAE训练神经网络最大的一个问题就是不变的大梯度，这可能导致在使用梯度下降快要结束时，错过了最小点。而对于MSE，梯度会随着损失的减小而减小，使结果更加精确。在这种情况下，Huber损失就非常有用。它会由于梯度的减小而落在最小值附近。比起MSE，它对异常点更加鲁棒。因此，Huber损失结合了MSE和MAE的优点。但是，Huber损失的问题是我们可能需要不断调整超参数delta。</p>
<p>alpha:这个参数只有GradientBoostingRegressor有，当我们使用Huber损失”huber”和分位数损失“quantile”时，需要指定分位数的值。默认是0.9，如果噪音点较多，可以适当降低这个分位数的值。</p>
<ul>
<li>弱学习器参数</li>
</ul>
<p>max_features：划分时考虑的特征数量。当特征数量并不多，小于50，可以None,即默认使用全部特征。也可以是如下几个。</p>
<p>max_depth：每棵子树的深度，默认为3.如果数据量和特征都不多，可以不管这个参数。但是当较大时，建议限制深度，10-100之间。</p>
<p>min_samples_split：子树继续划分的条件，默认为2.当一个节点内的样本数量少于该值时，该节点不再拆分，当作叶节点。当数据量小不用管，数据量大可以增大该值。</p>
<p>min_samples_leaf：叶子节点最少的样本数，默认1.如果叶节点的样本数少于该值，会和兄弟节点一起被剪纸，相当于不需要对上层的样本再做细分，因为叶节点中只有一个样本，分支意义不大。当数量级大，可以增大这个值。由此可见gbdt生成的树不是完全二叉树，是有可能出现左右子树高度不同的情况的。</p>
<p>min_weight_fraction_leaf：限制了叶子节点所有样本权重和的最小值。如果小于这个值，则会和兄弟节点一起被剪枝。默认是0，即不考虑。如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。</p>
<p>max_leaf_nodes：最大叶子节点数量，默认为None,在限制的叶节点数之内生成最优决策树，可以防止过拟合。当数量级较大，可以限制这个数。</p>
<p>min_impurity_split：最小基尼不纯度，如果某个节点的基尼不纯度小于该值，则不再划分，视为叶节点，默认1e-7，一般不修改。</p>
<h3 id="GBDT如何调参？"><a href="#GBDT如何调参？" class="headerlink" title="GBDT如何调参？"></a>GBDT如何调参？</h3><ol>
<li><p>先对提升框架内的，迭代次数和学习率做调整，选一个较小的学习率，对迭代次数网格化调参。</p>
</li>
<li><p>接下来对决策树调参，先一起调整max_depth和min_samples_split，根据输出的最优值将max_depth定下俩，后续再调整最小划分样本数。</p>
</li>
<li><p>再对内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf一起调参。看二者的最优值是否在边界上，如果在边界上，就进一步改变参数范围再网格化调餐。</p>
</li>
<li><p>再对max_features和subsample进行网格化。</p>
</li>
<li><p>最后可以通过，减小学习率，增大迭代次数，增加泛化能力，防止过拟合。保持两者的乘积基本不变，但步长设定过小，会导致拟合效果反而变差，应适当减小学习率。</p>
</li>
</ol>
<h3 id="关于Shrinkage的原理是什么？"><a href="#关于Shrinkage的原理是什么？" class="headerlink" title="关于Shrinkage的原理是什么？"></a>关于Shrinkage的原理是什么？</h3><p>Shrinkage（缩减）的思想认为，每次走一小步逐渐逼近结果的效果，要比每次迈一大步很快逼近结果的方式更容易避免过拟合。在GBDT中同样利用了Shrinkage的思想，通过对初始树除外的每一棵树给予一个较小的学习率，让整个模型换慢迭代逼近结果，以避免过拟合。</p>
<h3 id="GBDT为什么使用cart回归树而不是使用分类树"><a href="#GBDT为什么使用cart回归树而不是使用分类树" class="headerlink" title="GBDT为什么使用cart回归树而不是使用分类树?"></a>GBDT为什么使用cart回归树而不是使用分类树?</h3><p>GBDT主要是利用残差逼近的方式，这就意味每棵树的值是连续的可叠加的，这一点和回归树输出连续值不谋而合，如果采用分类树，那么残差逼近进行叠加就会使得这种叠加没有意义，比如男+男+女=到底是男是女。这个是GBDT基本原理决定的。</p>
<h3 id="GBDT哪些部分可以并行？"><a href="#GBDT哪些部分可以并行？" class="headerlink" title="GBDT哪些部分可以并行？"></a>GBDT哪些部分可以并行？</h3><p>1、计算每个样本的负梯度；<br>2、分裂挑选最佳特征及其分割点时，对特征计算相应的误差及均值时；<br>3、更新每个样本的负梯度时；<br>4、最后预测过程中，每个样本将之前的所有树的结果累加的时候。</p>
<h3 id="GBDT与RF的区别？"><a href="#GBDT与RF的区别？" class="headerlink" title="GBDT与RF的区别？"></a>GBDT与RF的区别？</h3><p>相同点：<br>1、GBDT与RF都是采用多棵树组合作为最终结果；这是两者共同点。<br>不同点：<br>1、RF的树可以是回归树也可以是分类树，而GBDT只能是回归树。<br>2、RF中树是独立的，相互之间不影响，可以并行；而GBDT树之间有依赖，是串行。<br>3、RF最终的结果是有多棵树表决决定，而GBDT是有多棵树叠加组合最终的结果。<br>4、RF对异常值不敏感，原因是多棵树表决，而GBDT对异常值比较敏感，原因是当前的错误会延续给下一棵树。<br>5、RF是通过减少模型的方差来提高性能，而GBDT是减少模型的偏差来提高性能的。</p>
<h3 id="GBDT和AdaBoost的异同？"><a href="#GBDT和AdaBoost的异同？" class="headerlink" title="GBDT和AdaBoost的异同？"></a>GBDT和AdaBoost的异同？</h3><p>相似之处：<br>都是基于Boosting思想的融合算法<br>默认的基分类器都是决策树<br>Adaboost其实是GBDT的一个特例</p>
<p>不同点：<br>Adaboost的基分类器可以选择更多的算法，而GBDT只能选决策树<br>GBDT的模型提升方法与Adaboost不同，Adaboost是通过不断加强对错判断数据的权重学习来提升模型的预测效果，而GBDT则是通过不断降低模型误差的思想来提升模型的预测效果。</p>
<h3 id="为什么GBDT中要拟合残差？"><a href="#为什么GBDT中要拟合残差？" class="headerlink" title="为什么GBDT中要拟合残差？"></a>为什么GBDT中要拟合残差？</h3><p>首先，GBDT拟合的不是残差，而是负梯度。只是当损失函数为平方损失的时候，负梯度正好为残差。</p>
<h3 id="GBDT是否需要进行归一化操作？"><a href="#GBDT是否需要进行归一化操作？" class="headerlink" title="GBDT是否需要进行归一化操作？"></a>GBDT是否需要进行归一化操作？</h3><p>概率模型不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率，如决策树、rf。而像adaboost、svm、lr、KNN、KMeans之类的最优化问题就需要归一化。</p>
<h3 id="为什么树模型不需要归一化？"><a href="#为什么树模型不需要归一化？" class="headerlink" title="为什么树模型不需要归一化？"></a>为什么树模型不需要归一化？</h3><p>因为数值缩放不影响分裂点位置，对树模型的结构不造成影响，而且是不能进行梯度下降的，因为构建树模型（回归树）寻找最优点时是通过寻找最优分裂点完成的，因此树模型是阶跃的，阶跃点是不可导的，并且求导没意义，也就不需要归一化 。</p>
<h3 id="GBDT的优缺点是什么？"><a href="#GBDT的优缺点是什么？" class="headerlink" title="GBDT的优缺点是什么？"></a>GBDT的优缺点是什么？</h3><ul>
<li><p>GBDT主要的优点有：<br>可以灵活处理各种类型的数据，包括连续值和离散值。<br>在相对少的调参时间情况下，预测的准确率也可以比较高。这个是相对SVM来说的。<br>使用一些健壮的损失函数，对异常值的鲁棒性非常强。比如 Huber损失函数和Quantile损失函数。<br>预测阶段的计算速度快， 树与树之间可并行化计算。所有的树一旦建好，用它来预测时是并行的，最终的预测值就是所有树的预测值之和。​​​​​​​<br>在分布稠密的数据集上， 泛化能力和表达能力都很好， 这使得GBDT在Kaggle的众多竞赛中， 经常名列榜首。<br>采用决策树作为弱分类器使得GBDT模型具有较好的解释性和鲁棒性，能够自动发现特征间的高阶关系， 并且也不需要对数据进行特殊的预处理如归一化等。</p>
</li>
<li><p>GBDT的主要缺点有：<br>由于弱学习器之间存在依赖关系，难以并行训练数据。不过可以通过自采样的SGBT来达到部分并行。<br>GBDT在高维稀疏的数据集上， 表现不如支持向量机或者神经网络。<br>GBDT在处理文本分类特征问题上， 相对其他模型的优势不如它在处理数值特征时明显。<br>训练过程需要串行训练， 只能在决策树内部采用一些局部并行的手段提高训练速度。</p>
</li>
</ul>
<h3 id="GBDT的预测结果有负数，为啥？"><a href="#GBDT的预测结果有负数，为啥？" class="headerlink" title="GBDT的预测结果有负数，为啥？"></a>GBDT的预测结果有负数，为啥？</h3><p>这里不是严格意义上说GBDT的预测结果一定为负数，而指的是训练集的结果中GBDT拟合的label都为正数，而在测试集中却出现了负数的情况。<br>是可能会出现负值的，出现的情况原因可能有如下：<br>如果在loss函数中没有加对负数输出的惩罚项（regularization），就有可能得到负数输出。<br>首先要看得到负数的的输入值是否在training data中出现过，如果没出现过，并且这种数据点很少，可以认为这些是outlier。也可以把负数变为0。<br>training data里很多输出接近于0，testing里出现一些接近于0的负数也很正常。<br>样本较少，特征较少的情况可能会出现，因为GBDT是加法模型，然后下一轮都是上一轮预测值和实际值的残差作为label继续拟合，最后将结果相加，这样最后可能会出现负值。<br>我说个比较简单的理解思路，GBDT你拟合的是残差，这个残差可正可负，第一棵树得到的预测值偏大，那么后续拟合的就是负值，如果拟合的不好，多棵树相加的结果还是一个负数(越界的数)。</p>
<h3 id="为什么GBDT的树深度较RF通常都比较浅？-1"><a href="#为什么GBDT的树深度较RF通常都比较浅？-1" class="headerlink" title="为什么GBDT的树深度较RF通常都比较浅？"></a>为什么GBDT的树深度较RF通常都比较浅？</h3><p>对于机器学习来说，泛化误差可以理解为两部分，分别是偏差（bias）和方差（variance）；偏差指的是算法的期望预测与真实预测之间的偏差程度，反应了模型本身的拟合能力；方差度量了同等大小的训练集的变动导致学习性能的变化，刻画了数据扰动所导致的影响。当模型越复杂时，拟合的程度就越高，模型的训练偏差就越小；但此时如果换一组数据可能模型的变化就会很大，即模型的方差很大，所以模型过于复杂的时候会导致过拟合。</p>
<p>对于RF来说由于并行训练很多不同的分类器的目的就是降低这个方差（variance）。所以对于每个基分类器来说，目标就是如何降低这个偏差（bias），所以我们会采用深度很深甚至不剪枝的决策树。</p>
<p>而对于GBDT来说由于利用的是残差逼近的方式，即在上一轮的基础上更加拟合原数据，所以可以保证偏差（bias），所以对于每个基分类器来说，问题就在于如何选择 variance 更小的分类器，即更简单的分类器，所以我们选择了深度很浅的决策树。</p>
<h3 id="RF算法思想？"><a href="#RF算法思想？" class="headerlink" title="RF算法思想？"></a>RF算法思想？</h3><p>随机森林使用多个CART决策树作为弱学习期，不同决策树之间没有关联。当我们进行分类任务时，新的输入样本进入，就让森林中的每一棵决策树分别进行判断和分类，每个决策树会得到一个自己的分类结果，决策树的分类结果中哪一个分类最多，那么随机森林就会把这个结果当作最终的结果。</p>
<h3 id="RF的建立过程说一下？"><a href="#RF的建立过程说一下？" class="headerlink" title="RF的建立过程说一下？"></a>RF的建立过程说一下？</h3><p>第一步：原始训练集中有N个样本，且每个样本有M维特征。从数据集D中有放回的随机抽取x个样本组成训练子集（bootstrap方法），一共进行w次采样，即生成w个训练子集。</p>
<p>第二步：每个训练子集形成一棵决策树，一共w棵决策树。而每一次未被抽到的样本则组成了w个oob（用来做预估）。</p>
<p>第三步：对于单个决策树，树的每个节点处从M个特征中随机挑选m（n &lt; M） 个特征， 按照节点不纯度最小原则进行分裂。每棵树都一直这样分裂下去，直到该节点的所有训练样例都属于同一类。在决策树的分裂过程中不需要剪枝。</p>
<p>第四步：根据生成的多个决策树分类起对需要进行预测的数据进行预测。根据每棵决策树的投票结果，如果是分类树的话，最后取票数最高的一个类别；如果是回归树的话，利用简单的平均得到最终结果。</p>
<h3 id="RF为什么要有放回的抽样？"><a href="#RF为什么要有放回的抽样？" class="headerlink" title="RF为什么要有放回的抽样？"></a>RF为什么要有放回的抽样？</h3><p>保证样本集间有重叠，若不放回，每个训练样本集及其分布都不一样，可能导致训练的各决策树差异性很大，最终多数表决无法“求同”。</p>
<h3 id="为什RF的训练效率优于bagging"><a href="#为什RF的训练效率优于bagging" class="headerlink" title="为什RF的训练效率优于bagging?"></a>为什RF的训练效率优于bagging?</h3><p>因为在个体决策树的构建过程中，Bagging使用的是“确定型”决策树，Bagging在选择划分属性时要对每棵树对所有特征进行考察，而随机森林仅仅考察一个特征子集。</p>
<h3 id="RF需要剪枝吗？"><a href="#RF需要剪枝吗？" class="headerlink" title="RF需要剪枝吗？"></a>RF需要剪枝吗？</h3><p>不需要，后剪枝是为了避免过拟合，随机森林选择变量与树的数量，已经避免了过拟合，没必要去剪枝了。一般随机森林要控制的是树的规模，而不是树的置信度，剩下的每棵树需要做的就是尽可能的在自己所对应的数据（特征）集情况下尽可能的做到最好的预测结果。剪枝的作用其实被集成方法消解了，所以作用不大。</p>
<h3 id="RF需要交叉验证吗？"><a href="#RF需要交叉验证吗？" class="headerlink" title="RF需要交叉验证吗？"></a>RF需要交叉验证吗？</h3><p>随机森林是不需要的，它属于bagging集成算法，采用Bootstrap，理论和实践可以发现Bootstrap每次约有1/3的样本不会出现在Bootstrap所采集的样本集合中。故没有参加决策树的建立，这些数据称为袋外数据oob，歪点子来了，这些袋外数据可以用于取代测试集误差估计方法，可用于模型的验证。</p>
<h3 id="RF为什么不能用全样本取训练m棵决策树？"><a href="#RF为什么不能用全样本取训练m棵决策树？" class="headerlink" title="RF为什么不能用全样本取训练m棵决策树？"></a>RF为什么不能用全样本取训练m棵决策树？</h3><p>随机森林的基学习器是同构的，如果用全样本去训练m棵决策树的话，基模型之间的多样性减少，互相相关的程度增加，不能够有效起到减少方差的作用，对于模型的泛化能力是有害的。随机森林思想就是取一组高方差、低偏差的决策树，并将它们转换成低方差、低偏差的新模型。</p>
<h3 id="RF和GBDT的区别"><a href="#RF和GBDT的区别" class="headerlink" title="RF和GBDT的区别"></a>RF和GBDT的区别</h3><p>相同点：</p>
<ul>
<li>都是由多棵树组成，最终的结果都是由多棵树一起决定。</li>
</ul>
<p>不同点：</p>
<ul>
<li>集成学习：RF属于bagging思想，而GBDT是boosting思想</li>
<li>偏差-方差权衡：RF不断的降低模型的方差，而GBDT不断的降低模型的偏差<br>训练样本：RF每次迭代的样本是从全部训练集中有放回抽样形成的，而GBDT每次使用全部样本</li>
<li>并行性：RF的树可以并行生成，而GBDT只能顺序生成(需要等上一棵树完全生成)</li>
<li>最终结果：RF最终是多棵树进行多数表决（回归问题是取平均），而GBDT是加权融合</li>
<li>数据敏感性：RF对异常值不敏感，而GBDT对异常值比较敏感</li>
<li>泛化能力：RF不易过拟合，而GBDT容易过拟合</li>
</ul>
<h3 id="随机森林算法训练时主要需要调整哪些参数？"><a href="#随机森林算法训练时主要需要调整哪些参数？" class="headerlink" title="随机森林算法训练时主要需要调整哪些参数？"></a>随机森林算法训练时主要需要调整哪些参数？</h3><p><strong>n_estimators:</strong>随机森林建立子树的数量。<br>较多的子树一般可以让模型有更好的性能，但同时让你的代码变慢。需要选择最佳的随机森林子树数量</p>
<p><strong>max_features：</strong>随机森林允许单个决策树使用特征的最大数量。<br>增加max_features一般能提高模型的性能，因为在每个节点上，我们有更多的选择可以考虑。然而，这未必完全是对的，因为它降低了单个树的多样性，而这正是随机森林独特的优点。但是，可以肯定，你通过增加max_features会降低算法的速度。因此，你需要适当的平衡和选择最佳max_features。</p>
<p>max_depth： 决策树最大深度</p>
<p>默认决策树在建立子树的时候不会限制子树的深度</p>
<p><strong>min_samples_split：</strong>内部节点再划分所需最小样本数<br>内部节点再划分所需最小样本数，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。</p>
<p>min_samples_leaf： 叶子节点最少样本</p>
<p>这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。</p>
<p>max_leaf_nodes： 最大叶子节点数</p>
<p>通过限制最大叶子节点数，可以防止过拟合，默认是”None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。</p>
<p>min_impurity_split： 节点划分最小不纯度<br>这个值限制了决策树的增长，如果某节点的不纯度（基于基尼系数，均方差）小于这个阈值，则该节点不再生成子节点。即为叶子节点。一般不推荐改动默认值1e-7。</p>
<h3 id="RF为什么比Bagging效率高？"><a href="#RF为什么比Bagging效率高？" class="headerlink" title="RF为什么比Bagging效率高？"></a>RF为什么比Bagging效率高？</h3><p>Bagging无随机特征，使得训练决策树时效率更低</p>
<h3 id="RF的优缺点？"><a href="#RF的优缺点？" class="headerlink" title="RF的优缺点？"></a>RF的优缺点？</h3><p>优点</p>
<ol>
<li>训练可以高度并行化，对于大数据时代的大样本训练速度有优势。个人觉得这是的最主要的优点。</li>
<li>由于可以随机选择决策树节点划分特征，这样在样本特征维度很高的时候，仍然能高效的训练模型。</li>
<li>在训练后，可以给出各个特征对于输出的重要性</li>
<li>由于采用了随机采样，训练出的模型的方差小，泛化能力强。</li>
<li>相对于Boosting系列的Adaboost和GBDT， RF实现比较简单。</li>
<li>对部分特征缺失不敏感。</li>
</ol>
<p>缺点</p>
<ol>
<li>在某些噪音比较大的样本集上，RF模型容易陷入过拟合。</li>
<li>取值划分比较多的特征容易对RF的决策产生更大的影响，从而影响拟合的模型的效果</li>
</ol>
<h3 id="简单介绍一下XGBoost？"><a href="#简单介绍一下XGBoost？" class="headerlink" title="简单介绍一下XGBoost？"></a>简单介绍一下XGBoost？</h3><p>首先需要说一说GBDT，它是一种基于boosting增强策略的加法模型，训练的时候采用前向分布算法进行贪婪的学习，每次迭代都学习一棵CART树来拟合之前 t-1 棵树的预测结果与训练样本真实值的残差。<br>XGBoost对GBDT进行了一系列优化，比如损失函数进行了二阶泰勒展开、目标函数加入正则项、支持并行和默认缺失值处理等，在可扩展性和训练速度上有了巨大的提升，但其核心思想没有大的变化。</p>
<h3 id="XGBoost与GBDT的联系和区别有哪些？"><a href="#XGBoost与GBDT的联系和区别有哪些？" class="headerlink" title="XGBoost与GBDT的联系和区别有哪些？"></a>XGBoost与GBDT的联系和区别有哪些？</h3><p>（1）GBDT是机器学习算法，XGBoost是该算法的工程实现。<br>（2）正则项：在使用CART作为基分类器时，XGBoost显式地加入了正则项来控制模型的复杂度，有利于防止过拟合，从而提高模型的泛化能力。<br>（3）导数信息：GBDT在模型训练时只使用了代价函数的一阶导数信息，XGBoost对代价函数进行二阶泰勒展开，可以同时使用一阶和二阶导数。<br>（4）基分类器：传统的GBDT采用CART作为基分类器，XGBoost支持多种类型的基分类器，比如线性分类器。<br>（5）子采样：传统的GBDT在每轮迭代时使用全部的数据，XGBoost则采用了与随机森林相似的策略，支持对数据进行采样。<br>（6）缺失值处理：传统GBDT没有设计对缺失值进行处理，XGBoost能够自动学习出缺失值的处理策略。<br>（7）并行化：传统GBDT没有进行并行化设计，注意不是tree维度的并行，而是特征维度的并行。XGBoost预先将每个特征按特征值排好序，存储为块结构，分裂结点时可以采用多线程并行查找每个特征的最佳分割点，极大提升训练速度。  </p>
<h3 id="为什么XGBoost泰勒二阶展开后效果就比较好呢？"><a href="#为什么XGBoost泰勒二阶展开后效果就比较好呢？" class="headerlink" title="为什么XGBoost泰勒二阶展开后效果就比较好呢？"></a>为什么XGBoost泰勒二阶展开后效果就比较好呢？</h3><ul>
<li>从为什么会想到引入泰勒二阶的角度来说（可扩展性）：XGBoost官网上有说，当目标函数是MSE时，展开是一阶项（残差）+二阶项的形式，而其它目标函数，如logistic loss的展开式就没有这样的形式。为了能有个统一的形式，所以采用泰勒展开来得到二阶项，这样就能把MSE推导的那套直接复用到其它自定义损失函数上。简短来说，就是为了统一损失函数求导的形式以支持自定义损失函数。至于为什么要在形式上与MSE统一？是因为MSE是最普遍且常用的损失函数，而且求导最容易，求导后的形式也十分简单。所以理论上只要损失函数形式与MSE统一了，那就只用推导MSE就好了。</li>
<li>从二阶导本身的性质，也就是从为什么要用泰勒二阶展开的角度来说（精准性）：二阶信息本身就能让梯度收敛更快更准确。这一点在优化算法里的牛顿法中已经证实。可以简单认为一阶导指引梯度方向，二阶导指引梯度方向如何变化。简单来说，相对于GBDT的一阶泰勒展开，XGBoost采用二阶泰勒展开，可以更为精准的逼近真实的损失函数。  </li>
</ul>
<h3 id="XGBoost对缺失值是怎么处理的？"><a href="#XGBoost对缺失值是怎么处理的？" class="headerlink" title="XGBoost对缺失值是怎么处理的？"></a>XGBoost对缺失值是怎么处理的？</h3><p>在普通的GBDT策略中，对于缺失值的方法是先手动对缺失值进行填充，然后当做有值的特征进行处理，但是这样人工填充不一定准确，而且没有什么理论依据。</p>
<ul>
<li>在特征k上寻找最佳 split point 时，不会对该列特征 missing 的样本进行遍历，而只对该列特征值为 non-missing 的样本上对应的特征值进行遍历，通过这个技巧来减少了为稀疏离散特征寻找 split point 的时间开销。</li>
</ul>
<ul>
<li>在逻辑实现上，为了保证完备性，会将该特征值missing的样本分别分配到左叶子结点和右叶子结点，两种情形都计算一遍后，选择分裂后增益最大的那个方向（左分支或是右分支），作为预测时特征值缺失样本的默认分支方向。</li>
</ul>
<ul>
<li>如果在训练中没有缺失值而在预测中出现缺失，那么会自动将缺失值的划分方向放到右子结点。</li>
</ul>
<h3 id="XGBoost为什么快？"><a href="#XGBoost为什么快？" class="headerlink" title="XGBoost为什么快？"></a>XGBoost为什么快？</h3><ul>
<li><p>分块并行：训练前每个特征按特征值进行排序并存储为Block结构，后面查找特征分割点时重复使用，并且支持并行查找每个特征的分割点</p>
</li>
<li><p>候选分位点：每个特征采用常数个分位点作为候选分割点</p>
</li>
<li><p>CPU cache 命中优化： 使用缓存预取的方法，对每个线程分配一个连续的buffer，读取每个block中样本的梯度信息并存入连续的Buffer中。</p>
</li>
<li><p>Block 处理优化：Block预先放入内存；Block按列进行解压缩；将Block划分到不同硬盘来提高吞吐</p>
</li>
</ul>
<h3 id="XGBoost防止过拟合的方法"><a href="#XGBoost防止过拟合的方法" class="headerlink" title="XGBoost防止过拟合的方法"></a>XGBoost防止过拟合的方法</h3><p>XGBoost在设计时，为了防止过拟合做了很多优化，具体如下：  </p>
<ul>
<li>目标函数添加正则项：叶子节点个数+叶子节点权重的L2正则化  </li>
<li>列抽样：训练的时候只用一部分特征（不考虑剩余的block块即可）  </li>
<li>子采样：每轮计算可以不使用全部样本，使算法更加保守  </li>
<li>shrinkage: 可以叫学习率或步长，为了给后面的训练留出更多的学习空间  </li>
</ul>
<h3 id="XGBoost为什么若模型决策树的叶子节点值越大，越容易过拟合呢？"><a href="#XGBoost为什么若模型决策树的叶子节点值越大，越容易过拟合呢？" class="headerlink" title="XGBoost为什么若模型决策树的叶子节点值越大，越容易过拟合呢？"></a>XGBoost为什么若模型决策树的叶子节点值越大，越容易过拟合呢？</h3><p>xgb最终的决策就是wx,如果某个w太大，则显然w对应叶子结点对最终的输出起到绝大部分的贡献，那么如果第一个叶子结点对应的基树拟合的过头，很容易导致整体的输出方差增大引发过拟合。更小的w表示更小的模型复杂度，因此来说w小点是好的。</p>
<h3 id="XGBoost为什么可以并行训练？"><a href="#XGBoost为什么可以并行训练？" class="headerlink" title="XGBoost为什么可以并行训练？"></a>XGBoost为什么可以并行训练？</h3><ul>
<li>XGBoost的并行，并不是说每棵树可以并行训练，XGBoost本质上仍然采用boosting思想，每棵树训练前需要等前面的树训练完成才能开始训练。  </li>
<li>XGBoost的并行，指的是特征维度的并行：在训练之前，每个特征按特征值对样本进行预排序，并存储为Block结构，在后面查找特征分割点时可以重复使用，而且特征已经被存储为一个个block结构，那么在寻找每个特征的最佳分割点时，可以利用多线程对每个block并行计算。</li>
</ul>
<h3 id="XGBoost中叶子结点的权重如何计算出来"><a href="#XGBoost中叶子结点的权重如何计算出来" class="headerlink" title="XGBoost中叶子结点的权重如何计算出来"></a>XGBoost中叶子结点的权重如何计算出来</h3><p>利用一元二次函数求最值的知识，当目标函数达到最小值Obj<em>时，每个叶子结点的权重为wj</em>。<br> $$
w_j^* = -G_j/(H_j+\lambda)
$$ </p>
<h3 id="XGBoost中的一棵树的停止生长条件"><a href="#XGBoost中的一棵树的停止生长条件" class="headerlink" title="XGBoost中的一棵树的停止生长条件"></a>XGBoost中的一棵树的停止生长条件</h3><ul>
<li><p>当新引入的一次分裂所带来的增益Gain&lt;0时，放弃当前的分裂。这是训练损失和模型结构复杂度的博弈过程。</p>
</li>
<li><p>当树达到最大深度时，停止建树，因为树的深度太深容易出现过拟合，这里需要设置一个超参数max_depth。</p>
</li>
<li><p>当引入一次分裂后，重新计算新生成的左、右两个叶子结点的样本权重和。如果任一个叶子结点的样本权重低于某一个阈值，也会放弃此次分裂。这涉及到一个超参数:最小样本权重和，是指如果一个叶子节点包含的样本数量太少也会放弃分裂，防止树分的太细。</p>
</li>
</ul>
<h3 id="Xboost中的min-child-weight是什么意思"><a href="#Xboost中的min-child-weight是什么意思" class="headerlink" title="Xboost中的min_child_weight是什么意思"></a>Xboost中的min_child_weight是什么意思</h3><p>一般来说，我们定义的不带正则项的损失函数是这个<br> $$
\frac{1}{2} (y_i-\hat y_i^2)
$$<br>那么hi=1，Hj即叶子节点上的样本数，min_child_weight就是叶子上的最小样本数，不最小样本总数啊，只是在这个情况下是。</p>
<h3 id="Xgboost中的gamma是什么意思"><a href="#Xgboost中的gamma是什么意思" class="headerlink" title="Xgboost中的gamma是什么意思"></a>Xgboost中的gamma是什么意思</h3><p>指的是叶节点需要分裂需要的最小损失减少量，也就是<img src="https://img-blog.csdn.net/20180819171358821?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI0NTE5Njc3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="image">公式中的r。</p>
<h3 id="Xgboost中的参数有哪些？"><a href="#Xgboost中的参数有哪些？" class="headerlink" title="Xgboost中的参数有哪些？"></a>Xgboost中的参数有哪些？</h3><ol>
<li>通用参数：宏观函数控制</li>
</ol>
<ul>
<li>booster[默认gbtree]<br>选择每次迭代的模型，有两种选择：<br>gbtree：基于树的模型<br>gbliner：线性模型</li>
<li>silent[默认0]<br>当这个参数值为1时，静默模式开启，不会输出任何信息。<br>一般这个参数就保持默认的0，因为这样能帮我们更好地理解模型。</li>
<li>nthread[默认值为最大可能的线程数]<br>这个参数用来进行多线程控制，应当输入系统的核数。<br>如果你希望使用CPU全部的核，那就不要输入这个参数，算法会自动检测它。</li>
</ul>
<ol>
<li>Booster参数：控制每一步的booster(tree/regression)<br>尽管有两种booster可供选择，我这里只介绍tree booster，因为它的表现远远胜过linear booster，所以linear booster很少用到。</li>
</ol>
<ul>
<li>eta[默认0.3]<br>和GBM中的 learning rate 参数类似。<br>通过减少每一步的权重，可以提高模型的鲁棒性。<br>典型值为0.01-0.2。</li>
<li>min_child_weight[默认1]<br>决定最小叶子节点样本权重和。<br>和GBM的 min_child_leaf 参数类似，但不完全一样。XGBoost的这个参数是最小样本权重的和，而GBM参数是最小样本总数。<br>这个参数用于避免过拟合。当它的值较大时，可以避免模型学习到局部的特殊样本。<br>但是如果这个值过高，会导致欠拟合。这个参数需要使用CV来调整。</li>
<li>max_depth[默认6]<br>和GBM中的参数相同，这个值为树的最大深度。<br>这个值也是用来避免过拟合的。max_depth越大，模型会学到更具体更局部的样本。<br>需要使用CV函数来进行调优。<br>典型值：3-10</li>
<li>max_leaf_nodes<br>树上最大的节点或叶子的数量。<br>可以替代max_depth的作用。因为如果生成的是二叉树，一个深度为n的树最多生成n 2 n^2n<br>2个叶子。如果定义了这个参数，GBM会忽略max_depth参数。</li>
<li>gamma[默认0]<br>在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。Gamma指定了节点分裂所需的最小损失函数下降值。<br>这个参数的值越大，算法越保守。这个参数的值和损失函数息息相关，所以是需要调整的。</li>
<li>max_delta_step[默认0]<br>这参数限制每棵树权重改变的最大步长。如果这个参数的值为0，那就意味着没有约束。如果它被赋予了某个正值，那么它会让这个算法更加保守。<br>通常，这个参数不需要设置。但是当各类别的样本十分不平衡时，它对逻辑回归是很有帮助的。<br>这个参数一般用不到，但是你可以挖掘出来它更多的用处。</li>
<li>subsample[默认1]<br>和GBM中的subsample参数一模一样。这个参数控制对于每棵树，随机采样的比例。<br>减小这个参数的值，算法会更加保守，避免过拟合。但是，如果这个值设置得过小，它可能会导致欠拟合。<br>典型值：0.5-1</li>
<li>colsample_bytree[默认1]<br>和GBM里面的max_features参数类似。用来控制每棵随机采样的列数的占比(每一列是一个特征)。<br>典型值：0.5-1</li>
<li>colsample_bylevel[默认1]<br>用来控制树的每一级的每一次分裂，对列数的采样的占比。<br>我个人一般不太用这个参数，因为subsample参数和colsample_bytree参数可以起到相同的作用。但是如果感兴趣，可以挖掘这个参数更多的用处。</li>
<li>lambda[默认1]<br>权重的L2正则化项。(和Ridge regression类似)。<br>这个参数是用来控制XGBoost的正则化部分的。虽然大部分数据科学家很少用到这个参数，但是这个参数在减少过拟合上还是可以挖掘出更多用处的。</li>
<li>alpha[默认1]<br>权重的L1正则化项。(和Lasso regression类似)。<br>可以应用在很高维度的情况下，使得算法的速度更快。</li>
<li>scale_pos_weight[默认1]<br>在各类别样本十分不平衡时，把这个参数设定为一个正值，可以使算法更快收敛。</li>
</ul>
<ol>
<li>学习目标参数：控制训练目标的表现<br>这个参数用来控制理想的优化目标和每一步结果的度量方法。</li>
</ol>
<ul>
<li>objective[默认reg:linear]<br>这个参数定义需要被最小化的损失函数。最常用的值有：<br>binary:logistic 二分类的逻辑回归，返回预测的概率(不是类别)。<br>multi:softmax 使用softmax的多分类器，返回预测的类别(不是概率)。<br>在这种情况下，你还需要多设一个参数：num_class(类别数目)。<br>multi:softprob 和multi:softmax参数一样，但是返回的是每个数据属于各个类别的概率。</li>
<li>eval_metric[默认值取决于objective参数的取值]<br>对于有效数据的度量方法。<br>对于回归问题，默认值是rmse，对于分类问题，默认值是error。</li>
<li>seed(默认0)<br>随机数的种子<br>设置它可以复现随机数据的结果，也可以用于调整参数</li>
</ul>
<h3 id="xgboost本质上是树模型，能进行线性回归拟合么"><a href="#xgboost本质上是树模型，能进行线性回归拟合么" class="headerlink" title="xgboost本质上是树模型，能进行线性回归拟合么"></a>xgboost本质上是树模型，能进行线性回归拟合么</h3><p>Xgboost中可以使用的，gbliner这个参数，那么它就使用线性基学习器来进行学习了。</p>
<h3 id="Xgboos是如何调参的"><a href="#Xgboos是如何调参的" class="headerlink" title="Xgboos是如何调参的"></a>Xgboos是如何调参的</h3><p>一般来说主要调节的几个参数有如下</p>
<ul>
<li>max_depth</li>
<li>learning_rate</li>
<li>n_estimators</li>
<li>min_child_weight</li>
<li>subsample</li>
<li>colsample_bytree</li>
</ul>
<p>XGBoost的作者把所有的参数分成了三类：<br>1、通用参数：宏观函数控制。<br>2、Booster参数：控制每一步的booster(tree/regression)。<br>3、学习目标参数：控制训练目标的表现。  </p>
<p>调参主要由一下步骤</p>
<ol>
<li>确定数据的的情况，设置好相应的参数</li>
<li>调参方法1：<ol>
<li>选择较高的学习速率(learning rate)。一般情况下，学习速率的值为0.1。但是，对于不同的问题，理想的学习速率有时候会在0.05到0.3之间波动。选择对应于此学习速率的理想决策树数量。XGBoost有一个很有用的函数“cv”，这个函数可以在每一次迭代中使用交叉验证，并返回理想的决策树数量。</li>
<li>对于给定的学习速率和决策树数量，进行决策树特定参数调优(max_depth, min_child_weight, gamma, subsample, colsample_bytree)。在确定一棵树的过程中，我们可以选择不同的参数，待会儿我会举例说明。</li>
<li>xgboost的正则化参数的调优。(lambda, alpha)。这些参数可以降低模型的复杂度，从而提高模型的表现。4. 降低学习速率，确定理想参数。</li>
</ol>
</li>
<li>调参方法2：<br> 使用网格搜索</li>
<li>调参方法3：<br> 使用随机搜索</li>
<li>调参方法4：<br> 使用贝叶斯调参方法</li>
</ol>
<h3 id="为什么xgboost-gbdt在调参时为什么树的深度很少就能达到很高的精度？"><a href="#为什么xgboost-gbdt在调参时为什么树的深度很少就能达到很高的精度？" class="headerlink" title="为什么xgboost/gbdt在调参时为什么树的深度很少就能达到很高的精度？"></a>为什么xgboost/gbdt在调参时为什么树的深度很少就能达到很高的精度？</h3><p>Boosting主要关注降低偏差，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成；Bagging主要关注降低方差，因此它在不剪枝的决策树、神经网络等学习器上效用更为明显。</p>
<p>gbdt属于boosting的方法，其主要关注的是减少偏差，多棵树进行叠加后可以保证较高的精度。</p>
<h3 id="为什么常规的gbdt和xgboost不适用于类别特别多的特征"><a href="#为什么常规的gbdt和xgboost不适用于类别特别多的特征" class="headerlink" title="为什么常规的gbdt和xgboost不适用于类别特别多的特征?"></a>为什么常规的gbdt和xgboost不适用于类别特别多的特征?</h3><p>one-hot coding是类别特征的一种通用解决方法，然而在树模型里面，这并不是一个比较好的方案，尤其当类别特征维度很高的时候。主要的问题是：  </p>
<ul>
<li>可能无法在这个类别特征上进行切分<br>使用one-hot coding的话，意味着在每一个决策节点上只能用 one-vs-rest (例如是不是狗，是不是猫，等等) 的切分方式。当特征纬度高时，每个类别上的数据都会比较少，这时候产生的切分不平衡，切分增益（split gain）也会很小（比较直观的理解是，不平衡的切分和不切分几乎没有区别）。</li>
<li>会影响决策树的学习<br>因为就算可以在这个类别特征进行切分，也会把数据切分到很多零散的小空间上，如图1左所示。而决策树学习时利用的是统计信息，在这些数据量小的空间上，统计信息不准确，学习会变差。但如果使用图1右边的切分方法，数据会被切分到两个比较大的空间，进一步的学习也会更好。<br><img src="https://pic2.zhimg.com/80/v2-17fc885c67ae576937533c7bda71a83f_720w.jpg?source=1940ef5c" alt="image"></li>
</ul>
<h3 id="简述一下Adaboost原理"><a href="#简述一下Adaboost原理" class="headerlink" title="简述一下Adaboost原理"></a>简述一下Adaboost原理</h3><p>Adaboost算法利用同一种基分类器（弱分类器），基于分类器的错误率分配不同的权重参数，最后累加加权的预测结果作为输出。</p>
<p>Adaboost算法流程：<br>样本赋予权重，得到第一个分类器。<br>计算该分类器的错误率，根据错误率赋予分类器权重（注意这里是分类器的权重）。<br>增加分错样本的权重，减小分对样本的权重（注意这里是样本的权重）。<br>然后再用新的样本权重训练数据，得到新的分类器。<br>多次迭代，直到分类器错误率为0或者整体弱分类器错误为0，或者到达迭代次数。<br>将所有弱分类器的结果加权求和，得到一个较为准确的分类结果。错误率低的分类器获得更高的决定系数，从而在对数据进行预测时起关键作用。</p>
<h3 id="AdaBoost的优点和缺点"><a href="#AdaBoost的优点和缺点" class="headerlink" title="AdaBoost的优点和缺点"></a>AdaBoost的优点和缺点</h3><p>优点</p>
<ol>
<li>Adaboost提供一种框架，在框架内可以使用各种方法构建子分类器。可以使用简单的弱分类器，不用对特征进行筛选，也不存在过拟合的现象。</li>
<li>Adaboost算法不需要弱分类器的先验知识，最后得到的强分类器的分类精度依赖于所有弱分类器。无论是应用于人造数据还是真实数据，Adaboost都能显著的提高学习精度。</li>
<li>Adaboost算法不需要预先知道弱分类器的错误率上限，且最后得到的强分类器的分类精度依赖于所有弱分类器的分类精度，可以深挖分类器的能力。</li>
<li>Adaboost可以根据弱分类器的反馈，自适应地调整假定的错误率，执行的效率高。</li>
<li>Adaboost对同一个训练样本集训练不同的弱分类器，按照一定的方法把这些弱分类器集合起来，构造一个分类能力很强的强分类器，即“三个臭皮匠赛过一个诸葛亮””。</li>
</ol>
<p>缺点</p>
<ol>
<li>在Adaboost训练过程中，Adaboost会使得难于分类样本的权值呈指数增长，训练将会过于偏向这类困难的样本，导致Adaboost算法易受噪声干扰。</li>
<li>Adaboost依赖于弱分类器，而弱分类器的训练时间往往很长。</li>
</ol>
<h3 id="Adaboost对噪声敏感吗？"><a href="#Adaboost对噪声敏感吗？" class="headerlink" title="Adaboost对噪声敏感吗？"></a>Adaboost对噪声敏感吗？</h3><p>在Adaboost训练过程中，Adaboost会使得难于分类样本的权值呈指数增长，训练将会过于偏向这类困难的样本，导致Adaboost算法易受噪声干扰。</p>
<h3 id="怎么处理类别特征在树模型下？"><a href="#怎么处理类别特征在树模型下？" class="headerlink" title="怎么处理类别特征在树模型下？"></a>怎么处理类别特征在树模型下？</h3><ul>
<li>可以使用lightGBM模型</li>
<li>可以用embedding</li>
<li>其他的编码方法，比如binary coding</li>
</ul>
<h3 id="LGBM简单介绍下？"><a href="#LGBM简单介绍下？" class="headerlink" title="LGBM简单介绍下？"></a>LGBM简单介绍下？</h3><p>LightGBM是微软2017年新提出的，比Xgboost更强大、速度更快的模型，性能上有很大的提升，与传统算法相比具有的优点：        </p>
<ol>
<li>更快的训练效率  </li>
<li>低内存使用        </li>
<li>更高的准确率        </li>
<li>支持并行化学习        </li>
<li>可处理大规模数据          </li>
<li>原生支持类别特征，不需要对类别特征再进行0-1编码这类的</li>
</ol>
<h3 id="LGBM相比于之前的GBDT做了哪些改进？"><a href="#LGBM相比于之前的GBDT做了哪些改进？" class="headerlink" title="LGBM相比于之前的GBDT做了哪些改进？"></a>LGBM相比于之前的GBDT做了哪些改进？</h3><p>对训练效率上进行了大量的改进，主要还是比GBDT快很多，GBDT的训练受到特征数量和数据量的双重影响，所以LightGBM就是从这几个方面入手来对GBDT进行改进。</p>
<ul>
<li><p>提出了GOSS算法</p>
</li>
<li><p>进行特征绑定将大量的可以合并的特征进行合并以加快计算。</p>
</li>
<li><p>通过leaf-wise策略来生长树。</p>
</li>
<li><p>采用直方图来优化最优分割点寻找的过程</p>
</li>
</ul>
<h3 id="简单介绍下直方图算法？"><a href="#简单介绍下直方图算法？" class="headerlink" title="简单介绍下直方图算法？"></a>简单介绍下直方图算法？</h3><p>直方图算法的基本思想是先把连续的浮点特征值离散化成k个整数，同时构造一个宽度为k的直方图。在遍历数据的时候，根据离散化后的值作为索引在直方图中累积统计量，当遍历一次数据后，直方图累积了需要的统计量，然后根据直方图的离散值，遍历寻找最优的分割点</p>
<p>使用直方图算法有很多优点。首先，最明显就是内存消耗的降低，直方图算法不仅不需要额外存储预排序的结果，而且可以只保存特征离散化后的值，而这个值一般用 8 位整型存储就足够了，内存消耗可以降低为原来的1/8。 </p>
<h3 id="Histogram-算法的优缺点"><a href="#Histogram-算法的优缺点" class="headerlink" title="Histogram 算法的优缺点"></a>Histogram 算法的优缺点</h3><p>Histogram算法并不是完美的。由于特征被离散化后，找到的并不是很精确的分割点，所以会对结果产生影响。但在实际的数据集上表明，离散化的分裂点对最终的精度影响并不大，甚至会好一些。原因在于decision tree本身就是一个弱学习器，采用Histogram算法会起到正则化的效果，有效地防止模型的过拟合。</p>
<p>时间上的开销由原来的O(#data <em> #features)降到O(k </em> #features)。由于离散化，#bin远小于#data，因此时间上有很大的提升。</p>
<h3 id="介绍下GOSS算法？"><a href="#介绍下GOSS算法？" class="headerlink" title="介绍下GOSS算法？"></a>介绍下GOSS算法？</h3><p>该技术是去掉了很大一部分梯度很小的数据，只使用剩下的去估计信息增益，避免低梯度长尾部分的影响。由于梯度大的数据在计算信息增益的时候更重要，所以GOSS在小很多的数据上仍然可以取得相当准确的估计值。</p>
<h3 id="传统树模型如何处理离散特征？"><a href="#传统树模型如何处理离散特征？" class="headerlink" title="传统树模型如何处理离散特征？"></a>传统树模型如何处理离散特征？</h3><p>一般使用独热编码的形式来处理，但是这样会存在问题，当类别的数量很多，会导致计算的复杂度增加，除此之外，还存在相关算法方面的问题。</p>
<ol>
<li><p>可能无法在这个类别特征上进行切分（即浪费了这个特征）。使用one-hot编码的话，意味着在每一个决策节点上只能使用one vs rest（例如是不是狗，是不是猫等）的切分方式。当类别值很多时，每个类别上的数据可能会比较少，这时候切分会产生不平衡，这意味着切分增益也会很小（比较直观的理解是，不平衡的切分和不切分没有区别）。</p>
</li>
<li><p>会影响决策树的学习。因为就算可以在这个类别特征进行切分，也会把数据切分到很多零碎的小空间上，如图1左边所示。而决策树学习时利用的是统计信息，在这些数据量小的空间上，统计信息不准确，学习会变差。但如果使用如图1右边的分裂方式，数据会被切分到两个比较大的空间，进一步的学习也会更好。</p>
</li>
</ol>
<p>图右边叶子节点的含义是X=A或者X=C放到左孩子，其余放到右孩子。</p>
<p><img src="https://img-blog.csdn.net/20181022170102610?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Fuc2h1YWlfYXcx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p>
<h3 id="LGBM如何处理离散特征？"><a href="#LGBM如何处理离散特征？" class="headerlink" title="LGBM如何处理离散特征？"></a>LGBM如何处理离散特征？</h3><p>为了解决one-hot编码处理类别特征的不足。LGBM采用了Many vs many的切分方式，实现了类别特征的最优切分。用Lightgbm可以直接输入类别特征，并产生如上面图右边的效果。在1个k维的类别特征中寻找最优切分，朴素的枚举算法的复杂度是 $2^k$ ，而LGBM实现了的算法复杂度为 $nlogn$ 。</p>
<p>算法流程瑞霞：在枚举分割点之前，先把直方图按每个类别的均值进行排序；然后按照均值的结果依次枚举最优分割点。其中计算的Sum(y)/Count(y)为类别的均值。当然，这个方法很容易过拟合，所以在LGBM中加入了很多对这个方法的约束和正则化。</p>
<h3 id="LGBM如何处理缺失值？"><a href="#LGBM如何处理缺失值？" class="headerlink" title="LGBM如何处理缺失值？"></a>LGBM如何处理缺失值？</h3><p>和 xgboost 的处理方式是一样，zero_as_missing=true 会将 0 也当作缺失值处理，因此在用的时候要注意，有的是偶缺失值和0不是一个意思。</p>
<h3 id="LGBM-与-XGBoost-的不同点？"><a href="#LGBM-与-XGBoost-的不同点？" class="headerlink" title="LGBM 与 XGBoost 的不同点？"></a>LGBM 与 XGBoost 的不同点？</h3><ol>
<li>由于在决策树在每一次选择节点特征的过程中，要遍历所有的属性的所有取值并选择一个较好的。XGBoost 使用的是近似算法，先对特征值进行预排序 Pre-sort，然后根据二阶梯度进行分桶，能够更精确的找到数据分隔点；但是复杂度较高。LightGBM 使用的是 histogram 算法，这种只需要将数据分割成不同的段即可，不需要进行预先的排序。占用的内存更低，数据分割的复杂度更低。</li>
<li>决策树生长策略，XGBoost 采用的是 Level-wise 的树生长策略，LightGBM 采用的是 leaf-wise 的生长策略，以最大信息增益为导向。后者进度更高，容易过拟合，所以要控制最大深度。</li>
<li>并行策略对比，XGBoost 的并行主要集中在特征并行上，而 LightGBM 的并行策略分特征并行，数据并行以及投票并行。</li>
<li>在树方面，提出了直方图算法寻找最佳分裂点，而且还采用Leaf-wise树生长策略。不过后面改进版的xgb也使用到了。</li>
<li>在样本数上，使用GOSS保留所有大梯度样本但随机采样小梯度样本，减少训练样本量。</li>
<li>在特征数上，使用EFB捆绑互斥特征，将特征变稠密。此外，作者还采用GS编码，在GBDT一类模型中，这是第一次能直接支持类别型特征，不需要提前独热编码后再输入至模型中。最后，同样地，LightGBM也跟XGBoost一样进行了工程优化，使得训练能高效并行且增加Cache命中率。</li>
</ol>
<h3 id="树模型怎么查看特征重要性？"><a href="#树模型怎么查看特征重要性？" class="headerlink" title="树模型怎么查看特征重要性？"></a>树模型怎么查看特征重要性？</h3><ol>
<li>通过OOB<br>OOB是怎么做到可以对特征重要性进行排序的呢，先用训练好的模型对OOB数据进行打分，计算出AUC或其他业务定义的评估指标；接着对OOB数据中的每个特征：(1) 随机shuffle当前特征的取值；(2) 重新对当前数据进行打分，计算评估指标；(3)计算指标变化率。按照上面方式，对每个特征都会得到一个变化率，最后按照变化率排序来量化特征重要性。  </li>
<li>通过Gini<br>说白了就是看看每个特征在随机森林中的每颗树上做了多大的贡献，然后取个平均值，最后比一比特征之间的贡献大小。对于生成的每棵树，计算每个分裂节点的Gini指数,特征 Xj 在节点m的重要性可以通过分裂前后的特征 GIm 的差值来表示。</li>
</ol>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><h3 id="参考-1"><a href="#参考-1" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/83901304">https://zhuanlan.zhihu.com/p/83901304</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/77473961">https://zhuanlan.zhihu.com/p/77473961</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/277638585/answer/522272201">https://www.zhihu.com/question/277638585/answer/522272201</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/359567100">https://www.zhihu.com/question/359567100</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_37933986/article/details/69681671">https://blog.csdn.net/weixin_37933986/article/details/69681671</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/68621766/answer/336096221">https://www.zhihu.com/question/68621766/answer/336096221</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/han_xiaoyang/article/details/52665396">https://blog.csdn.net/han_xiaoyang/article/details/52665396</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29649128">https://zhuanlan.zhihu.com/p/29649128</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/9423b3e41e14">https://www.jianshu.com/p/9423b3e41e14</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44507034/article/details/109757064">https://blog.csdn.net/weixin_44507034/article/details/109757064</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/266195966">https://www.zhihu.com/question/266195966</a><br><a target="_blank" rel="noopener" href="https://www.icode9.com/content-4-689535.html">https://www.icode9.com/content-4-689535.html</a><br><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844903798603776014">https://juejin.cn/post/6844903798603776014</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/maqunfi/article/details/82219999">https://blog.csdn.net/maqunfi/article/details/82219999</a><br> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/65597945">https://zhuanlan.zhihu.com/p/65597945</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/cranberrycookie/article/details/79834884">https://blog.csdn.net/cranberrycookie/article/details/79834884</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/Heitao5200/article/details/103758643">https://blog.csdn.net/Heitao5200/article/details/103758643</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/Daverain/article/details/96702696">https://blog.csdn.net/Daverain/article/details/96702696</a></p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%AF%84%E4%BC%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%AF%84%E4%BC%B0/" class="post-title-link" itemprop="url">模型选择与评估</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-23 22:37:18" itemprop="dateModified" datetime="2024-03-23T22:37:18+08:00">2024-03-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="模型选择与评估"><a href="#模型选择与评估" class="headerlink" title="模型选择与评估"></a>模型选择与评估</h1><h2 id="损失函数类"><a href="#损失函数类" class="headerlink" title="损失函数类"></a>损失函数类</h2><h3 id="代价函数，损失函数和目标函数的区别？"><a href="#代价函数，损失函数和目标函数的区别？" class="headerlink" title="代价函数，损失函数和目标函数的区别？"></a>代价函数，损失函数和目标函数的区别？</h3><p>损失函数（Loss Function ）是定义在单个样本上的，算的是一个样本的误差。<br>代价函数（Cost Function）是定义在整个训练集上的，是所有样本误差的平均，也就是损失函数的平均。<br>目标函数（Object Function）定义为：最终需要优化的函数。等于经验风险+结构风险（也就是代价函数 + 正则化项）。代价函数最小化，降低经验风险，正则化项最小化降低。<br>风险函数(risk function)，风险函数是损失函数的期望，这是由于我们输入输出的(X,Y)遵循一个联合分布，但是这个联合分布是未知的，所以无法计算。但是我们是有历史数据的，就是我们的训练集，f(x) 关于训练集的平均损失称作经验风险(empirical risk)，即，所以我们的目标就是最小化 称为经验风险最小化。</p>
<h3 id="误差、偏差和方差的区别是啥？"><a href="#误差、偏差和方差的区别是啥？" class="headerlink" title="误差、偏差和方差的区别是啥？"></a>误差、偏差和方差的区别是啥？</h3><p>噪声：描述了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。说人话，就是数据中的有些标签不是真的标签，也是有限噪声的标签。</p>
<p>偏差：是指预测结果与真实值之间的差异，排除噪声的影响，偏差更多的是针对某个模型输出的样本误差，偏差是模型无法准确表达数据关系导致，比如模型过于简单，非线性的数据关系采用线性模型建模，偏差较大的模型是错的模型。</p>
<p>方差：不是针对某一个模型输出样本进行判定，而是指多个(次)模型输出的结果之间的离散差异，注意这里写的是多个模型或者多次模型，即不同模型或同一模型不同时间的输出结果方差较大，方差是由训练集的数据不够导致，一方面量 (数据量) 不够，有限的数据集过度训练导致模型复杂，另一方面质(样本质量)不行，测试集中的数据分布未在训练集中，导致每次抽样训练模型时，每次模型参数不同，输出的结果都无法准确的预测出正确结果。</p>
<h3 id="常见的损失函数有哪些？"><a href="#常见的损失函数有哪些？" class="headerlink" title="常见的损失函数有哪些？"></a>常见的损失函数有哪些？</h3><ol>
<li>0-1损失函数<br>0-1损失是指，预测值和目标值不相等为1，否则为0</li>
<li>绝对值损失函数平方损失函数（squared loss）<br>实际结果和观测结果之间差距的平方和，一般用在线性回归中，可以理解为最小二乘法</li>
<li>对数损失函数（logarithmic loss）这个在逻辑回归中用到的</li>
<li>指数损失函数，这个在Adaboost中就有体现的</li>
<li>铰链损失函数，这个在SVM中用到过 </li>
</ol>
<h3 id="均方差损失函数和高斯假设的关系？"><a href="#均方差损失函数和高斯假设的关系？" class="headerlink" title="均方差损失函数和高斯假设的关系？"></a>均方差损失函数和高斯假设的关系？</h3><p>事先我们模型预测与真实值之间的误差是服从标准高斯分布也就是$\mu {\rm{ = }}0,\sigma {\rm{ = }}1$，我们给定一个输入$x_i$，则模型输出真实值$y_i$的概率为:<br>$$
p({y_i}|{x_i}) = \frac{1}{{\sqrt {2\pi } }}\exp ( - \frac{{{{({y_i} - {{\hat y}_i})}^2}}}{2})
$$<br>再假设各个样本点之间是相互独立的，那么最大似然函数可以写为：<br>$$
L(x,y) = \prod\limits_{i = 1}^N {\frac{1}{{\sqrt {2\pi } }}} \exp ( - \frac{{{{({y_i} - {{\hat y}_i})}^2}}}{2})
$$<br>为了计算方便，通常取对数似然函数，结果如下：<br>$$
\log L(x,y) =  - \frac{N}{2}\log 2\pi  - \frac{1}{2}\sum\limits_{i = 1}^N {{{({y_i} - {{\hat y}_i})}^2}}
$$<br>可以看到前面的一项是C，只与后面的结果有关，然后转化为最小化负对数似然 Negative Log-Likelihood<br>$$
- \log L(x,y) = \frac{1}{2}\sum\limits_{i = 1}^N {{{({y_i} - {{\hat y}_i})}^2}}
$$<br>这就是MSE的基本形式，也就是说在假设误差为高斯分布的情况下，最小化均方差损失函数与极大似然估计本质上是一致的。</p>
<h3 id="平均绝对误差损失函数和拉普拉斯假设的关系？"><a href="#平均绝对误差损失函数和拉普拉斯假设的关系？" class="headerlink" title="平均绝对误差损失函数和拉普拉斯假设的关系？"></a>平均绝对误差损失函数和拉普拉斯假设的关系？</h3><p>事先我们模型预测与真实值之间的误差是服从拉普拉斯分布也就是$\mu {\rm{ = }}0,b {\rm{ = }}1$，我们给定一个输入$x_i$，则模型输出真实值$y_i$的概率为:<br>$$
p({y_i}|{x_i}) = \frac{1}{2}\exp ( - |{y_i} - {{\hat y}_i}|)
$$<br>和上面的推导类似，最后可以得到如下的公式：<br>$$
- \log L(x,y) = \frac{1}{2}\sum\limits_{i = 1}^N {(|{y_i} - {{\hat y}_i}|)}
$$<br>这就是MAE我的基本形式，也就是说在假设误差为拉普拉斯分布的情况下，最小化均方差损失函数与极大似然估计本质上是一致的。</p>
<h3 id="均方差损失函数与平均绝对误差损失函数区别"><a href="#均方差损失函数与平均绝对误差损失函数区别" class="headerlink" title="均方差损失函数与平均绝对误差损失函数区别?"></a>均方差损失函数与平均绝对误差损失函数区别?</h3><p>通过上述分析我们可以发现，MSE损失相对于MAE会更加快速的收敛，但是MAE相比于异常点会更健壮。</p>
<p>当使用梯度下降算法时，MSE 损失的梯度为$-{ \hat y }$，而 MAE 损失的梯度为$\pm 1$，即 MSE 的梯度的值会随误差大小而变化，而 MAE 的梯度的则一直保持为 1，即便在绝对误差$|{y_i} - {\hat y_i}|$很小的时候 MAE 的梯度也同样保持为 1，这实际上是非常不利于模型的训练的，也就是我们看到的训练的时候呈现上下左右直线跳的现象。</p>
<p>从上述的损失函数计算公式中我们也可以看到，MSE的公式中有平方项，这样当数据中存在较大的异常值的话会导致较大的异常的梯度，但MAE就不会，梯度就是1，就是这么拽。</p>
<h3 id="mse对于异常样本的鲁棒性差的问题怎么解决？"><a href="#mse对于异常样本的鲁棒性差的问题怎么解决？" class="headerlink" title="mse对于异常样本的鲁棒性差的问题怎么解决？"></a>mse对于异常样本的鲁棒性差的问题怎么解决？</h3><ol>
<li>如果异常样本无意义，可以进行异常值的平滑或者直接删除。</li>
<li>如果异常样本有意义，需要模型把这些有意义的异常考虑进来，则从模型侧考虑使用表达能力更强的模型或复合模型或分群建模等；</li>
<li>在损失层面选择更鲁棒的损失函数例如smape</li>
</ol>
<h3 id="介绍你了解到的熵的相关知识点？"><a href="#介绍你了解到的熵的相关知识点？" class="headerlink" title="介绍你了解到的熵的相关知识点？"></a>介绍你了解到的熵的相关知识点？</h3><ul>
<li>信息量<br>度量一个事件的不确定性程度，不确定性越高则信息量越大，一般通过事件发生的概率来定义不确定性，信息量则是基于概率密度函数的log运算，用以下式子定义：$$
I(x) =  - \log p(x)
$$</li>
<li>信息熵<br>衡量的是一个事件集合的不确定性程度，就是事件集合中所有事件的不确定性的期望，公式定义如下：$$
H(X) =  - \sum\limits_{x \in X} {[p(x)\log p(x)]}
$$</li>
<li>相对熵(KL散度)<br>kl散度，从概统角度出发，表示用于两个概率分布的差异的非对称衡量，kl散度也可以从信息理论的角度出发，从这个角度出发的kl散度我们也可以称之为相对熵，实际上描述的是两个概率分布的信息熵的差值：$$
KL(P||Q) = \sum {P(x)\log \frac{{P(x)}}{{Q(x)}}}
$$
kl散度和余弦距离一样，不满足距离的严格定义；非负且不对称。</li>
<li>js散度<br>公式如下：$$
JS(P||Q) = \frac{1}{2}KL(P(x))||\frac{{P(x) + Q(x)}}{2} + \frac{1}{2}KL(Q(x))||\frac{{P(x) + Q(x)}}{2}
$$
js散度的范围是[0,1],相同则是0，相反为1。相较于KL，对相似度的判别更准确;同时，js散度满足对称性 JS(P||Q)=JS(Q||P)</li>
<li>交叉熵<br>公式如下：$$
H(P,Q) =  - \sum {p\log q = H(P) + {D_{kl}}(P||Q)}
$$
可见,交叉熵就是真值分布的信息熵与KL散度的和,而真值的熵是确定的,与模型的参数θ 无关,所以梯度下降求导时，优化交叉熵和优化kl散度（相对熵）是一样的；</li>
<li><p>联合熵<br>公式如下：</p>
$$
H(X,Y) =  - \sum\limits_{x,y} {p(x,y)\log p(x,y)}
$$
<p>联合熵实际上衡量的是两个事件集合，经过组合之后形成的新的大的事件集合的信息熵；</p>
</li>
<li><p>条件熵<br>公式如下：</p>
$$
H(Y|X) = H(X,Y) - H(X)
$$
<p>事件集合Y的条件熵=联合熵-事件集合X的信息熵，用来衡量在事件集合X已知的基础上，事件集合Y的不确定性的减少程度；</p>
</li>
</ul>
<h3 id="交叉熵的设计思想是什么？"><a href="#交叉熵的设计思想是什么？" class="headerlink" title="交叉熵的设计思想是什么？"></a>交叉熵的设计思想是什么？</h3><p>优化交叉熵等价于优化kl散度<br>$$
H(P,Q) =  - \sum {p\log q = H(P) + {D_{kl}}(P||Q)}
$$<br>这里的P是真实分布，它的信息熵 H（p）是一个定值，对于模型来说是一个不可优化的常数, 因此优化的时候可以忽略。</p>
<h3 id="怎么衡量两个分布的差异？"><a href="#怎么衡量两个分布的差异？" class="headerlink" title="怎么衡量两个分布的差异？"></a>怎么衡量两个分布的差异？</h3><p>使用KL散度或者JS散度</p>
<h3 id="Huber-Loss-有什么特点？"><a href="#Huber-Loss-有什么特点？" class="headerlink" title="Huber Loss 有什么特点？"></a>Huber Loss 有什么特点？</h3><p>首先看下huber loss的形状：</p>
<p><img src="https://pic2.zhimg.com/80/v2-68de6203f87d93fe9134c7c89745a31d_720w.jpg" alt="image"></p>
<p>Huber Loss 结合了 MSE 和 MAE 损失，在误差接近 0 时使用 MSE，使损失函数可导并且梯度更加稳定；在误差较大时使用 MAE 可以降低 outlier 的影响，使训练对 outlier 更加健壮。缺点是需要额外地设置一个超参数。</p>
<h3 id="为何使用Huber损失函数？"><a href="#为何使用Huber损失函数？" class="headerlink" title="为何使用Huber损失函数？"></a>为何使用Huber损失函数？</h3><p>使用MAE用于训练神经网络的一个大问题就是，它的梯度始终很大，这会导致使用梯度下降训练模型时，在结束时遗漏最小值。对于MSE，梯度会随着损失值接近其最小值逐渐减少，从而使其更准确。<br>在这些情况下，Huber损失函数真的会非常有帮助，因为它围绕的最小值会减小梯度。而且相比MSE，它对异常值更具鲁棒性。因此，它同时具备MSE和MAE这两种损失函数的优点。不过，Huber损失函数也存在一个问题，我们可能需要训练超参数δ，而且这个过程需要不断迭代。</p>
<h3 id="如何理解Hinger-Loss？"><a href="#如何理解Hinger-Loss？" class="headerlink" title="如何理解Hinger Loss？"></a>如何理解Hinger Loss？</h3><p>首先看下Hinger Loss的图像，如下： </p>
<p><img src="https://pic3.zhimg.com/80/v2-3c6aa9626ee8e4609b0d7c5712baf624_720w.jpg" alt="image"></p>
<p>可以看到，当x大于某个值的时候，loss为0，当x小于某个值的时候，那就需要算loss了，说明模型对小于阈值的样本进行了惩罚，而且越大惩罚的越厉害，对于大于阈值的样本不进行惩罚，总的来说就是该损失函数寻找一个边界，对具有可信的样本不惩罚，对不可信的样本或者超出决策边界的样本进行惩罚。</p>
<h3 id="交叉熵与最大似然估计的联系？"><a href="#交叉熵与最大似然估计的联系？" class="headerlink" title="交叉熵与最大似然估计的联系？"></a>交叉熵与最大似然估计的联系？</h3><p>交叉熵刻画的是实际输出（概率）与期望输出（概率）的距离，也就是交叉熵的值越小，两个概率分布就越接近，即拟合的更好。<br>最小化交叉熵即最小化KL散度，即最小化实际与预估之间的差距，这与最大似然的目的是一致的。即最大似然与交叉熵在目标上一致，只是由于正负号，而导致一个为最小化（交叉熵，前面有负号），一个为最大化（最大似然）</p>
<h3 id="分类问题为何用交叉熵而不用MSE？"><a href="#分类问题为何用交叉熵而不用MSE？" class="headerlink" title="分类问题为何用交叉熵而不用MSE？"></a>分类问题为何用交叉熵而不用MSE？</h3><p>首先来看两者的表达式<br>MSE的表达式如下：<br>$$
L = \frac{1}{N}\sum\limits_{i = 1}^N {||{y_i} - {{\hat y}_i}|{|^2}}
$$<br>交叉熵的表达式如下：<br>$$
L = \frac{1}{N}\sum\limits_{i = 1}^N {\sum\limits_{k = 1}^N {{y_i}^k\log {{\hat y}_i}^k} }
$$<br>可以看到，对于分类问题，实际的标签为0和1，那么交叉熵很多项是不用算的，举个例子， 实际标签是[1,0,0],模型预测得到的概率是[0.9,0.4,0.3],那么交叉熵损失函数的结果是 1log(0.9)+0log(0.4)+0log(0.3),而MSE则都得全部算一遍。<br>结论1：MSE无差别得关注全部类别上预测概率和真实概率的差.交叉熵关注的是正确类别的预测概率。<br>其次，我们在之前的文章中也说到了关于求解优化模型的时候的问题，MSE会收敛的慢一些，因为它求导的结果相比于交叉熵还多乘以一个sigmod函数，但是交叉熵梯度中不再含有sigmoid的导数，有的是sigmoid的值和实际值之间的差，也就满足了我们之前所说的错误越大，下降的越快的要求。<br>结论2：是交叉熵更有利于梯度更新。<br>MSE是假设数据符合高斯分布时,模型概率分布的负条件对数似然;交叉熵是假设模型分布为多项式分布时,模型分布的负条件对数似然。<br>还有一点要说明，MSE对残差大的样例惩罚更大些.，我们还举个例子看看，比如真实标签分别是(1, 0, 0).模型1的预测标签是(0.8, 0.2, 0),模型2的是(0.9, 0.1, 0). 但MSE-based算出来模型1的误差是MSE-based算出模型2的4倍,而交叉熵-based算出来模型1的误差是交叉熵-based算出来模型2的2倍左右.对于模型1和模型2输出的结果。其实也主要是由于MSE太苛刻了，想要把左右的值都预测的分毫不差，而交叉熵只关注正样本也也是就1的那些，计算那些损失函数就可以了，样本标签为0的压根不用算。</p>
<h3 id="类别不均衡情况下使用什么损失函数？"><a href="#类别不均衡情况下使用什么损失函数？" class="headerlink" title="类别不均衡情况下使用什么损失函数？"></a>类别不均衡情况下使用什么损失函数？</h3><p>可以使用Focal loss函数：为了解决正负样本严重失衡的问题，由 log loss 改进而来<br>$$
{L_{FL}} =  - \frac{1}{n}\sum\limits_{i = 1}^N {[\alpha {y_i}{{(1 - {{\hat y}_i})}^\gamma }\log {{\hat y}_i} + (1 - \alpha )(1 - {y_i}){{\hat y}_i}^\gamma \log (1 - {{\hat y}_i})]}
$$<br>基本思想：对于类别极度不平衡的情况下，网络如果在 log loss 下会倾向于之预测负样本，并且负样本的预测概率$ {{{\hat y}_i}} $ 也会非常的高，回传的梯度也很大。但是如果添加${(1 - {\hat y_i})^\gamma }$则会使预测概率大的样本得到的 loss 变小，而预测概率小的样本，loss 变得大，从而加强对正样本的关注度。可以改善目标不均衡的现象，对此情况比交叉熵要好很多。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/358103958">https://zhuanlan.zhihu.com/p/358103958</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/149093389">https://zhuanlan.zhihu.com/p/149093389</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/376387915">https://zhuanlan.zhihu.com/p/376387915</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/77686118">https://zhuanlan.zhihu.com/p/77686118</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/Scc_hy/article/details/84190080">https://blog.csdn.net/Scc_hy/article/details/84190080</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/391954665">https://zhuanlan.zhihu.com/p/391954665</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/collection/168981231">https://www.zhihu.com/collection/168981231</a></p>
</blockquote>
<h2 id="偏差与方差"><a href="#偏差与方差" class="headerlink" title="偏差与方差"></a>偏差与方差</h2><h3 id="什么是偏差和方差？"><a href="#什么是偏差和方差？" class="headerlink" title="什么是偏差和方差？"></a>什么是偏差和方差？</h3><p>不要看这个问题简单，但是问的时候，真的一下子你可能会答不上来。偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力;方差 度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。</p>
<h3 id="什么是噪声？"><a href="#什么是噪声？" class="headerlink" title="什么是噪声？"></a>什么是噪声？</h3><p>噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。噪声的存在是学习算法所无法解决的问题，数据的质量决定了学习的上限。假设在数据已经给定的情况下，此时上限已定，我们要做的就是尽可能的接近这个上限。举个简单的例子，对于一个预测性别的任务来说，特征中有胡子，标签为女性，这样的数据就是噪声数据，它反应的是数据质量的问题。</p>
<h3 id="泛化误差、偏差和方差的关系？"><a href="#泛化误差、偏差和方差的关系？" class="headerlink" title="泛化误差、偏差和方差的关系？"></a>泛化误差、偏差和方差的关系？</h3><p>关系如下：<br>$E = bia{s^2}(x) + {\mathop{\rm var}} (x) + {\varepsilon ^2}$<br>也就是说，泛化误差可以通过一系列公式分解运算证明：泛化误差为偏差、方差与噪声之和。证明过程如下：  </p>
<p><img src="https://s21.ax1x.com/2024/03/23/pFhIBZt.png" alt="image"></p>
<p>“偏差-方差分解”说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。给定学习任务，为了取得好的泛化性能，则需使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。</p>
<h3 id="偏差、方差与过拟合、欠拟合的关系？"><a href="#偏差、方差与过拟合、欠拟合的关系？" class="headerlink" title="偏差、方差与过拟合、欠拟合的关系？"></a>偏差、方差与过拟合、欠拟合的关系？</h3><p>一般来说，简单的模型会有一个较大的偏差和较小的方差，复杂的模型偏差较小方差较大。</p>
<p>欠拟合：模型不能适配训练样本，有一个很大的偏差。</p>
<p>举个例子：我们可能有本质上是多项式的连续非线性数据，但模型只能表示线性关系。在此情况下，我们向模型提供多少数据不重要，因为模型根本无法表示数据的基本关系，模型不能适配训练样本，有一个很大的偏差，因此我们需要更复杂的模型。那么，是不是模型越复杂拟合程度越高越好呢？也不是，因为还有方差。</p>
<p>过拟合：模型很好的适配训练样本，但在测试集上表现很糟，有一个很大的方差。</p>
<p>方差就是指模型过于拟合训练数据，以至于没办法把模型的结果泛化。而泛化正是机器学习要解决的问题，如果一个模型只能对一组特定的数据有效，换了数据就无效，我们就说这个模型过拟合。这就是模型很好的适配训练样本，但在测试集上表现很糟，有一个很大的方差。</p>
<h3 id="偏差、方差与模型复杂度的关系"><a href="#偏差、方差与模型复杂度的关系" class="headerlink" title="偏差、方差与模型复杂度的关系?"></a>偏差、方差与模型复杂度的关系?</h3><p>复杂度高的模型通常对训练数据有很好的拟合能力，但是对测试数据就不一定了。而复杂度太低的模型又不能很好的拟合训练数据，更不能很好的拟合测试数据。因此，模型复杂度和模型偏差和方差具有如下图所示关系  </p>
<p><img src="https://img-blog.csdnimg.cn/fe602ad1bce7467ab1b678783186098d.png" alt="image"></p>
<h3 id="请从偏差和方差的角度解释bagging和boosting的原理？"><a href="#请从偏差和方差的角度解释bagging和boosting的原理？" class="headerlink" title="请从偏差和方差的角度解释bagging和boosting的原理？"></a>请从偏差和方差的角度解释bagging和boosting的原理？</h3><p>偏差指的是算法的期望预测与真实值之间的偏差程度，反映了模型本身的拟合能力；方差度量了同等大小的训练集的变动导致学习性能的变化，刻画了数据扰动所导致的影响。</p>
<p>Bagging对样本重采样，对每一重采样得到的子样本集训练一个模型，最后取平均。由于子样本集的相似性以及使用的是同种模型，因此各模型有近似相等的bias和variance。由于$E[\frac{{\sum {{X_i}} }}{n}] = E[{X_i}]$，所以bagging后的bias和单个子模型的接近，一般来说不能显著降低bias。另一方面，若各子模型独立，则有$Var[\frac{{\sum {{X_i}} }}{n}] = \frac{{Var[{X_i}]}}{n}$，此时可以显著降低variance。若各子模型完全相同，则$Var[\frac{{\sum {{X_i}} }}{n}] = Var[{X_i}]$，此时不会降低variance。</p>
<p>bagging方法得到的各子模型是有一定相关性的，属于上面两个极端状况的中间态，因此可以一定程度降低variance。</p>
<p>boosting从优化角度来看，是用forward-stagewise这种贪心法去最小化损失函数,由于采取的是串行优化的策略，各子模型之间是强相关的，于是子模型之和并不能显著降低variance。所以说boosting主要还是靠降低bias来提升预测精度。</p>
<h3 id="为什么说bagging是减少variance，而boosting是减少bias"><a href="#为什么说bagging是减少variance，而boosting是减少bias" class="headerlink" title="为什么说bagging是减少variance，而boosting是减少bias?"></a>为什么说bagging是减少variance，而boosting是减少bias?</h3><p>boosting是把许多弱的分类器组合成一个强的分类器。弱的分类器bias高，而强的分类器bias低，所以说boosting起到了降低bias的作用。variance不是boosting的主要考虑因素。bagging是对许多强（甚至过强）的分类器求平均。在这里，每个单独的分类器的bias都是低的，平均之后bias依然低；而每个单独的分类器都强到可能产生overfitting的程度，也就是variance高，求平均的操作起到的作用就是降低这个variance。</p>
<h3 id="如何解决偏差、方差问题？"><a href="#如何解决偏差、方差问题？" class="headerlink" title="如何解决偏差、方差问题？"></a>如何解决偏差、方差问题？</h3><p>偏差和方差是无法完全避免的，只能尽量减少其影响。<br>(1) 在避免偏差时，需尽量选择正确的模型，一个非线性问题而我们一直用线性模型去解决，那无论如何，高偏差是无法避免的。<br>(2) 有了正确的模型，我们还要慎重选择数据集的大小，通常数据集越大越好，但大到数据集已经对整体所有数据有了一定的代表性后，再多的数据已经不能提升模型了，反而会带来计算量的增加。而训练数据太小一定是不好的，这会带来过拟合，模型复杂度太高，方差很大，不同数据集训练出来的模型变化非常大。<br>(3) 最后，要选择合适的模型复杂度，复杂度高的模型通常对训练数据有很好的拟合能力。</p>
<h3 id="训练集上预测误差大，在测试集上预测误差小的情况？"><a href="#训练集上预测误差大，在测试集上预测误差小的情况？" class="headerlink" title="训练集上预测误差大，在测试集上预测误差小的情况？"></a>训练集上预测误差大，在测试集上预测误差小的情况？</h3><p>模型恰好在验证数据上的泛化性能好，例如二分类问题中，测试集数据恰好是和分界超平面距离很远的样本或者是回归问题中，验证数据在模型的拟合曲面上。</p>
<h3 id="参考-1"><a href="#参考-1" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/38853908">https://zhuanlan.zhihu.com/p/38853908</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/27068705">https://www.zhihu.com/question/27068705</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/27068705/answer/416457469">https://www.zhihu.com/question/27068705/answer/416457469</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/collection/168981231">https://www.zhihu.com/collection/168981231</a></p>
</blockquote>
<h2 id="过拟合和欠拟合"><a href="#过拟合和欠拟合" class="headerlink" title="过拟合和欠拟合"></a>过拟合和欠拟合</h2><h3 id="什么是欠拟合？"><a href="#什么是欠拟合？" class="headerlink" title="什么是欠拟合？"></a>什么是欠拟合？</h3><p>欠拟合是指模型不能在训练集上获得足够低的误差。换句换说，就是模型复杂度低，模型在训练集上就表现很差，没法学习到数据背后的规律。</p>
<h3 id="什么是过拟合？"><a href="#什么是过拟合？" class="headerlink" title="什么是过拟合？"></a>什么是过拟合？</h3><p>过拟合是指训练误差和测试误差之间的差距太大。换句换说，就是模型复杂度高于实际问题，模型在训练集上表现很好，但在测试集上却表现很差。模型对训练集”死记硬背”（记住了不适用于测试集的训练集性质或特点），没有理解数据背后的规律，泛化能力差。</p>
<h3 id="如何解决欠拟合"><a href="#如何解决欠拟合" class="headerlink" title="如何解决欠拟合?"></a>如何解决欠拟合?</h3><ol>
<li>添加其他特征项。组合、泛化、相关性、上下文特征、平台特征等特征是特征添加的重要手段，有时候特征项不够会导致模型欠拟合。</li>
<li>添加多项式特征。例如将线性模型添加二次项或三次项使模型泛化能力更强。例如，FM（Factorization Machine）模型、FFM（Field-aware Factorization Machine）模型，其实就是线性模型，增加了二阶多项式，保证了模型一定的拟合程度。</li>
<li>可以增加模型的复杂程度。</li>
<li>减小正则化系数。正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数。</li>
</ol>
<h3 id="过拟合原因有哪些？"><a href="#过拟合原因有哪些？" class="headerlink" title="过拟合原因有哪些？"></a>过拟合原因有哪些？</h3><p>（1）建模样本选取有误，样本标签错误等，导致选取的样本数据不足以代表预定的分类规则<br>（2）样本噪音干扰过大，使得机器将学习了噪音，还认为是特征，从而扰乱了预设的分类规则<br>（3）假设的模型无法合理存在，或者说是假设成立的条件实际并不成立<br>（4）参数太多，模型复杂度过高<br>（5）对于tree-based模型，如果我们对于其深度与split没有合理的限制，有可能使节点只包含单纯的事件数据(event)或非事件数据(no event)，使其虽然可以完美匹配（拟合）训练数据，但是无法适应其他数据集<br>（6）对于神经网络模型：1.权值学习迭代次数太多(Overtraining)，2。BP算法使权值可能收敛过于复杂的决策面</p>
<h3 id="如何解决过拟合"><a href="#如何解决过拟合" class="headerlink" title="如何解决过拟合?"></a>如何解决过拟合?</h3><ol>
<li>重新清洗数据，数据不纯会导致过拟合，此类情况需要重新清洗数据。</li>
<li>增加训练样本数量。</li>
<li>降低模型复杂程度。</li>
<li>增大正则项系数。</li>
<li>采用dropout方法。  </li>
<li>early stopping。</li>
<li>减少迭代次数。</li>
<li>增大学习率。</li>
<li>添加噪声数据。</li>
<li>树结构中，可以对树进行剪枝。</li>
<li>减少特征项。</li>
</ol>
<p>欠拟合和过拟合这些方法，需要根据实际问题，实际模型，进行选择。</p>
<h3 id="为什么L1正则化会产生更稀疏？"><a href="#为什么L1正则化会产生更稀疏？" class="headerlink" title="为什么L1正则化会产生更稀疏？"></a>为什么L1正则化会产生更稀疏？</h3><p>L1中的参数更新如下所示：<br>$$
w \to w' = w - \frac{{\eta \lambda }}{n}{\mathop{\rm sgn}} (w) - \eta \frac{{\partial {C_0}}}{{\partial w}}
$$<br>其中$C_0$是损失函数，$n$是样本数，$\lambda$是正则参数，我们看这个参数更新的公式，发现</p>
<p>$w=0$, 时，$w=0$是不可导的。所以我们仅仅能依照原始的未经正则化的方法去更新$w=0$。<br>当 $w&gt;0$ 时，$sgn(w)&gt;0$, 则梯度下降时更新后的$w$变小。<br>当 $w&lt;0$ 时，$sgn(w)&lt;0$, 则梯度下降时更新后的$w$变大，换句换说，L1正则化使得权重$w$往0靠，使网络中的权重尽可能为0，也就相当于减小了网络复杂度，防止过拟合。</p>
<h3 id="为啥L1正则先验分布是Laplace分布，L2正则先验分布是Gaussian分布"><a href="#为啥L1正则先验分布是Laplace分布，L2正则先验分布是Gaussian分布" class="headerlink" title="为啥L1正则先验分布是Laplace分布，L2正则先验分布是Gaussian分布"></a>为啥L1正则先验分布是Laplace分布，L2正则先验分布是Gaussian分布</h3><p>L1正则先验分布是Laplace分布，L2正则先验分布是Gaussian分布。接下来从最大后验概率的角度进行推导和分析。在机器学习建模中，我们知道了$x$和$y$以后,需要对参数$w$进行建模。那么后验概率表达式如下:<br>$$
MAP = \log P(y|X,w)P(w) = \log P(y|X,w) + \log P(w)
$$<br>可以看出来后验概率函数为在似然函数的基础上增加了$logP(w)$，$P(w)$的意义是对权重系数$w$的概率分布的先验假设，在收集到训练样本$X$，$y$<br>后，则可根据$w$在$X$，$y$<br>下的后验概率对$w$进行修正，从而做出对的更好地估计。若假设$w$的先验分布为0均值的高斯分布，即 $w \sim N(0,{\sigma ^2})$,则有<br>$$
\log P(w) = \log \prod\limits_j {P({w_j}) = } \log \prod\limits_j {[\frac{1}{{\sqrt {2\pi } \sigma }}{e^{ - \frac{{{w_j}^2}}{{2{\sigma ^2}}}}}] =  - \frac{1}{{2{\sigma ^2}}}} \sum\limits_j {{w_j}^2 + C}
$$<br>可以看到，在高斯分布$logP(w)$下的效果等价于在代价函数中增加L2正则项。若假设服$w$从均值为0，参数为a的拉普拉斯分布，即$P({w_j}) = \frac{1}{{\sqrt {2a} }}{e^{\frac{{|{w_j}|}}{a}}}$，则有<br>$$
\log P(w) = \log \prod\limits_j {P({w_j}) = } \log \prod\limits_j {\frac{1}{{\sqrt {2a} }}{e^{\frac{{|{w_j}|}}{a}}}}  =  - \frac{1}{{2a}}\sum\limits_j {|{w_j}| + C} 
$$<br>可以看到，在拉普拉斯分布$logP(W)$下的效果等价在代价函数中增加L1正项。</p>
<p>L1正则化可通过假设权重w的先验分布为拉普拉斯分布，由最大后验概率估计导出。</p>
<p>L2正则化可通过假设权重w的先验分布为高斯分布，由最大后验概率估计导出。</p>
<h3 id="Lasso回归的求解方法有哪些？"><a href="#Lasso回归的求解方法有哪些？" class="headerlink" title="Lasso回归的求解方法有哪些？"></a>Lasso回归的求解方法有哪些？</h3><p>Lasso回归有时也叫做线性回归的L1正则化，和Ridge回归的主要区别就是在正则化项，Ridge回归用的是L2正则化，而Lasso回归用的是L1正则化。由于L1范数用的是绝对值之和，在零点处不可求导，所以使用非梯度下降法进行求解，如 坐标轴下降法（coordinate descent）和最小角回归法（ Least Angle Regression， LARS）。</p>
<ul>
<li><p>坐标轴下降法<br>坐标轴下降法坐标下降优化方法是一种非梯度优化算法，坐标下降算法每次选择一个维度进行参数更新，维度的选择可以是随机的或者是按顺序。当一轮更新结束后，更新步长的最大值少于预设阈值时，终止迭代。</p>
</li>
<li><p>最小角回归法<br>最小角回归法运用到了前向选择法（选取余弦距离最小的值进行投影，计算残差，迭代这个过程，直到残差达到我们的较小值或者已经遍历了整个变量）和前向梯度算法（选取余弦距离最小的值的样本方向进行移动一定距离，计算残差，重复这个迭代过程）的综合，做法就是取投影方向和前向梯度算法的残差方向形成的角的平分线方向，进行移动。对前向梯度算法和前向选择算法做了折中，保留了前向梯度算法一定程度的精确性，同时简化了前向梯度算法一步步迭代的过程。</p>
<h3 id="为什么L2正则化会产生更稠密解？"><a href="#为什么L2正则化会产生更稠密解？" class="headerlink" title="为什么L2正则化会产生更稠密解？"></a>为什么L2正则化会产生更稠密解？</h3><p>L2正则化通常被称为权重衰减（weight decay），就是在原始的损失函数后面再加上一个L2正则化项，即全部权重[公式]的平方和，再乘以λ/2n。则损失函数变为：</p>
$$
C = {C_0} + \frac{\lambda }{{2n}}\sum {{w_i}^2}
$$
<p>对应的梯度（导数）：  </p>
$$
\begin{array}{l}
\frac{{\partial C}}{{\partial w}} = \frac{{\partial {C_0}}}{{\partial w}} + \frac{\lambda }{n}w\\
\frac{{\partial C}}{{\partial b}} = \frac{{\partial {C_0}}}{{\partial b}}
\end{array}
$$
<p>能够发现L2正则化项对偏置 b 的更新没有影响，可是对于权重$w$的更新有影响：<br>参数的更新步骤如下：  </p>
$$
\begin{array}{l}
w \to w' = w - \frac{{\eta \lambda }}{n}w - \eta \frac{{\partial {C_0}}}{{\partial w}}\\
\;\;\;\;\;\;\;\;\;\;\;\; = (1 - \frac{{\eta \lambda }}{n})w - \eta \frac{{\partial {C_0}}}{{\partial w}}
\end{array}
$$
<p>这里的参数都是大于0的，所以 $1 - \frac{{\eta \lambda }}{n}<1$,因此在梯度下降过程中，权重$w$将逐渐减小，趋向于0但不等于0。这也就是权重衰减（weight decay）的由来。< p>
</1$,因此在梯度下降过程中，权重$w$将逐渐减小，趋向于0但不等于0。这也就是权重衰减（weight></p></li>
</ul>
<p>L2正则化起到使得权重参数$w$变小的效果，为什么能防止过拟合呢？因为更小的权重参数$w$意味着模型的复杂度更低，对训练数据的拟合刚刚好，不会过分拟合训练数据，从而提高模型的泛化能力。</p>
<h3 id="L1和L2的区别和联系？"><a href="#L1和L2的区别和联系？" class="headerlink" title="L1和L2的区别和联系？"></a>L1和L2的区别和联系？</h3><p>相同的点：<br>都可以用来解决过拟合问题的，提高模型的泛化能力。</p>
<p>不同的点：<br>l1-norm使用的是每个权重值的绝对值之和，l2-norm使用的是每个权重值的平方和；<br>l1-norm会得到稀疏解，可用于特征选择，l2-norm不会；<br>l1-norm下降速度更快。  </p>
<h3 id="为什么权重变小可以防止过拟合呢？"><a href="#为什么权重变小可以防止过拟合呢？" class="headerlink" title="为什么权重变小可以防止过拟合呢？"></a>为什么权重变小可以防止过拟合呢？</h3><p>还是借助上面的公式来说明下问题：</p>
<p>直观上：算法会在训练过程中梯度下降迭代时损失函数尽量的小，而这需要更多复杂的参数，就容易导致过拟合，加上L2之后，当参数变多变复杂时就会导致L2正则化项增大，从而导致损失函数增大，达到制约参数的目的。</p>
<p>模型复杂度：更小的权值w，从某种意义上说，表示网络的复杂度更低，对数据的拟合更好(这个法则也叫做奥卡姆剃刀)，而在实际应用中，也验证了这一点，L2正则化的效果往往好于未经正则化的效果。</p>
<p>数学方面：过拟合的时候，拟合函数a的系数往往非常大，为什么?如下图所示，过拟合，就是拟合函数需要顾忌每一个点，最终形成的拟合函数波动很大。在某些很小的区间里，函数值的变化很剧烈。这就意味着数据在某些小区间内的导数值(绝对值)非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大。而正则化是通过约束参数的大小，使其不要太大，所以可以在一定程度上减少过拟合情况。</p>
<h3 id="为什么增加样本可以减少过拟合？"><a href="#为什么增加样本可以减少过拟合？" class="headerlink" title="为什么增加样本可以减少过拟合？"></a>为什么增加样本可以减少过拟合？</h3><p>增加的数据主要会引入学习器没有看到过的样本，其中可能包括测试集的分布，这样让模型开开眼界，不会局限于当前数据的分布。<br>但是如果引入的数据和未来的样本完全不相似，例如不均衡学习中的许多上采样的方法，纯粹基于训练数据的一些加减计算，难以扩充和未来相似的样本，自然是不能缓解过拟合问题了。</p>
<h3 id="参考-2"><a href="#参考-2" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/72038532">https://zhuanlan.zhihu.com/p/72038532</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/64127398">https://zhuanlan.zhihu.com/p/64127398</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/495738409">https://zhuanlan.zhihu.com/p/495738409</a></p>
</blockquote>
<h2 id="检验方法"><a href="#检验方法" class="headerlink" title="检验方法"></a>检验方法</h2><h3 id="比较检验方法有哪些？"><a href="#比较检验方法有哪些？" class="headerlink" title="比较检验方法有哪些？"></a>比较检验方法有哪些？</h3><ol>
<li>假设检验——二项检验   </li>
<li>假设检验——t检验  </li>
<li>交叉验证t检验  </li>
<li>McNemar检验  </li>
<li>Friedman检验和Nemenyi后续检验 </li>
</ol>
<h3 id="什么是假设检验？"><a href="#什么是假设检验？" class="headerlink" title="什么是假设检验？"></a>什么是假设检验？</h3><p>假设检验是用来判断样本与样本，样本与总体的差异是由抽样误差引起还是本质差别造成的统计推断方法。其基本原理是先对总体的特征作出某种假设，然后通过抽样研究的统计推理，对此假设应该被拒绝还是接受作出推断。 </p>
<p>举两个例子：1.在产品的质量检验中经常会遇到的问题就是样本是否可以代替总体，这就涉及用样本来估计总体。2.你先后做了两批实验，得到两组数据，你想知道在这两试实验中合格率有无显著变化，那怎么做呢？这时你可以使用假设检验这种统计方法，来比较你的数据。可以先假设这两批实验合格率没有显著变化，然后用统计的方法推断假设成立的概率，如果是小概率事件，那么原假设不成立。</p>
<h3 id="简述假设检验的一般步骤？"><a href="#简述假设检验的一般步骤？" class="headerlink" title="简述假设检验的一般步骤？"></a>简述假设检验的一般步骤？</h3><ol>
<li>建立原假设和备择假设。</li>
<li>在原假设成立的前提下，选择合适统计量的抽样分布，计算统计量的值，常用的有Z 分布、T 分布、F 分布。</li>
<li>选定显著性水平，查相应分布表确定临界值，从而确定原假设的拒绝区间和接受区间。</li>
<li>对原假设做出判断和解释，如果统计量值大于临界值，拒绝原假设。反之，则接受</li>
</ol>
<h3 id="什么是置信区间？"><a href="#什么是置信区间？" class="headerlink" title="什么是置信区间？"></a>什么是置信区间？</h3><p>任何测量的数据都会存在误差，即使实验条件再精确也无法完全避免随机干扰的影响，所以科学实验往往要测量或实验多次，用取平均值之类的手段去取得结果。多次测量是个排除偶然因素的好办法，但再好的统计手段也不能把所有的偶然因素全部排除。所以，在科学实验中总是会在测量结果上加一个误差范围，这里的误差范围（区间）在统计概率中就叫做置信区间。</p>
<h3 id="为什么小样本用t检验？"><a href="#为什么小样本用t检验？" class="headerlink" title="为什么小样本用t检验？"></a>为什么小样本用t检验？</h3><p>从抽样研究所得的样本均数特点来看，只要样本量&gt;60，（无论总体是否服从正态分布）抽样研究的样本均数服从或者近似服从正态分布；而如果样本量较小（参考样本量&lt;100）,抽样分布随着样本量的减小，与正态分布的差别越来越大。此时需要用小样本理论来解释样本均数的分布——而t分布就是小样本理论的代表。因此，小样本的检验需要用到t检验。</p>
<h3 id="各中检验方法的适用范围是什么？"><a href="#各中检验方法的适用范围是什么？" class="headerlink" title="各中检验方法的适用范围是什么？"></a>各中检验方法的适用范围是什么？</h3><p>T检验又叫做student t检验，即Student’s t test，通常用于样本含量较小(一般n&lt;30)，总体标准差σ未知的正态分布。目的为：比较样本均数所代表的未知总体均数μ和已知总体均数μ0.</p>
<p>Z检验是通常用于大样本(也就是样本容量&gt;30)平均值差异性检验的方法。是用标准正态分布的理论来推断差异发生的概率，从而对两个平均数的差异进行比较，判断该差异是否显著。</p>
<p>卡方检验又叫做X2检验，简单来说就是，检验两个变量之间有没有关系。卡方检验属于非参数检验，通常是用来比较两个及两个以上样本率(构成比)，以及两个分类变量的关联性分析。基本思想为：比较理论频数和实际频数的吻合程度或者拟合优度问题。</p>
<p>F 检验是为检验方差是否有显著性差异。经常被叫做，联合假设检验(joint hypotheses test)，也可以叫做方差比率检验、方差齐性检验。F 检验为一种在零假设(null hypothesis, H0)情况之下，统计值服从F-分布的检验。</p>
<h3 id="相关性检验有那些标准？"><a href="#相关性检验有那些标准？" class="headerlink" title="相关性检验有那些标准？"></a>相关性检验有那些标准？</h3><p>相关分析是一种简单易行的测量定量数据之间的关系情况的分析方法。可以分析包括变量间的关系情况以及关系强弱程度等。相关系数常见有三类，分别是：  </p>
<ol>
<li>Pearson相关系数</li>
<li>Spearman等级相关系数</li>
<li>Kendall相关系数</li>
</ol>
<p>三种相关系数最常使用的是Pearson相关系数；当数据不满足正态性时，则使用Spearman相关系数，Kendall相关系数用于判断数据一致性，比如裁判打分。</p>
<h3 id="参考-3"><a href="#参考-3" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/409625718">https://zhuanlan.zhihu.com/p/409625718</a><br>机器学习-西瓜书<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/93182578">https://zhuanlan.zhihu.com/p/93182578</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_39875181/article/details/78612348">https://blog.csdn.net/weixin_39875181/article/details/78612348</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_37228052/article/details/121498111">https://blog.csdn.net/m0_37228052/article/details/121498111</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_48988106/article/details/121113200">https://blog.csdn.net/qq_48988106/article/details/121113200</a></p>
</blockquote>
<h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><h3 id="什么是模型的泛化能力？"><a href="#什么是模型的泛化能力？" class="headerlink" title="什么是模型的泛化能力？"></a>什么是模型的泛化能力？</h3><p>泛化能力：指模型对未知的、新鲜的数据的预测能力，通常是根据测试误差来衡量模型的泛化能力，测试误差越小，模型能力越强；<br>统计理论表明：如果训练集和测试集中的样本都是独立同分布产生的，则有 模型的训练误差的期望等于模型的测试误差的期望 。</p>
<h3 id="模型评估的方法主要有哪些？"><a href="#模型评估的方法主要有哪些？" class="headerlink" title="模型评估的方法主要有哪些？"></a>模型评估的方法主要有哪些？</h3><ul>
<li>留出法</li>
<li>交叉验证</li>
<li>自助法</li>
</ul>
<h3 id="Bootstrap原理以及抽样到的概率是啥？"><a href="#Bootstrap原理以及抽样到的概率是啥？" class="headerlink" title="Bootstrap原理以及抽样到的概率是啥？"></a>Bootstrap原理以及抽样到的概率是啥？</h3><p>63.2%原始数据元组将出现在自助样本中，而其他36.8%的元组将形成检验集。假设每个元组被选中的概率是 1/d, 因此未被选中的概率是（1-1/d）, 需要挑选 d 次，因此一个元组在 d 次都未被选中的概率是（1-1/d）^d。如果 d 很大，该概率近似为 e^(-1)=0.368。因此36.8%的元组将作为验证集。</p>
<h3 id="自助法优缺点？"><a href="#自助法优缺点？" class="headerlink" title="自助法优缺点？"></a>自助法优缺点？</h3><p>自助法的优点有：<br>在数据集比较小、难以有效划分训练/测试集时很有用：<br>能从初始数据集中产生多个不同的训练集，这对集成学习等方法而言有很大好处。  </p>
<p>但也存在如下缺点：<br>产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此在初始数据量足够时，留出法和折交叉验证法更常用。</p>
<h3 id="交叉验证的方法主要分为哪些？"><a href="#交叉验证的方法主要分为哪些？" class="headerlink" title="交叉验证的方法主要分为哪些？"></a>交叉验证的方法主要分为哪些？</h3><p>1.Holdout验证<br>严格意义上来说的话，这个不算是交叉验证，因为根本没有用到交叉。首先，我们随机的将样本数据分为两部分（比如：70%的训练集，30%的测试集），然后用训练集来训练模型，在测试集上验证模型及参数。<br>2.K折交叉验<br>也是经常会用到的一种方法。主要思想是将数据集划分为互斥的K个集合，用K-1个集合做训练，然后剩下的一个做验证，这里不做过多的解释。<br>3.留一交叉验证<br>假设有N个训练样本，它的思想是每次选择N-1个样本来训练数据，留一个样本来验证模型预测的好坏。此方法主要用于样本量非常少的情况，比如对于普通适中问题，当样本小于50时，我一般采用留一交叉验证。</p>
<h3 id="k折交叉验证中k取值多少有什么关系？"><a href="#k折交叉验证中k取值多少有什么关系？" class="headerlink" title="k折交叉验证中k取值多少有什么关系？"></a>k折交叉验证中k取值多少有什么关系？</h3><p>在理想情况下，可认为K折交叉验证可以降低模型的方差，从而提高模型的泛化能力，通俗地说，我们期望模型在训练集的多个子数据集上表现良好，要胜过单单在整个训练数据集上表现良好。（但实际上，由于我们所得到K折数据之间并非独立而存在相关性，K折交叉验证到底能降低多少方差还不确定，同时带来的偏差上升有多少也还存疑。）  </p>
<p><center>
<img src="https://img-blog.csdnimg.cn/3299c0ca2ff545b29de97f88ecaca511.png" width="80%">  
</center><br>完全不使用交叉验证是一种极端情况，即K=1的情况下。在这个情况下所有数据都被用于训练，因而过拟合导致低偏差、高方差(low bias and high variance)。留一法是K折的另一种极端情况，即K=n。随着K值的不断升高，单一模型评估时的方差逐渐加大而偏差减小。但从总体模型角度来看，反而是偏差升高了而方差降低了。所以当K值在1到n之间的游走，可以理解为一种方差和偏差妥协的结果。<br>2017年的一项研究给出了另一种经验式的选择方法，作者建议k=log(n) 且保证n/K&gt;3d ，n代表了数据量，d代表了特征数。<br>1、使用交叉验证的根本原因是数据集太小，而较小的K值会导致可用于建模的数据量太小，所以小数据集的交叉验证结果需要格外注意。建议选择较大的K值。<br>2、当模型稳定性较低时，增大K的取值可以给出更好的结果<br>3、相对而言，较大的K值的交叉验证结果倾向于更好。但同时也要考虑较大K值的计算开销。</p>
<h3 id="训练集、验证集合测试集的作用？"><a href="#训练集、验证集合测试集的作用？" class="headerlink" title="训练集、验证集合测试集的作用？"></a>训练集、验证集合测试集的作用？</h3><p>训练集：主要就是训练模型，理论上越大越好；<br>验证集：用于模型调试超参数。通常要求验证集比较大，避免模型会对验证集过拟合；<br>测试集：用于评估模型的泛化能力。理论上，测试集越大，评估结果就约精准。另外，测试集必须不包含训练样本，否则会影响对模型泛化能力的评估。<br>验证集和测试集的对比：</p>
<p>测试集通常用于对模型的预测能力进行评估，它是提供模型预测能力的无偏估计；如果不需要对模型预测能力的无偏估计，可以不需要测试集；<br>验证集主要是用于超参数的选择。</p>
<h3 id="划分数据集的比例选择方法"><a href="#划分数据集的比例选择方法" class="headerlink" title="划分数据集的比例选择方法?"></a>划分数据集的比例选择方法?</h3><p>对于小批量数据，数据的拆分的常见比例为：<br>如果未设置验证集，则将数据三七分：70% 的数据用作训练集、30% 的数据用作测试集。<br>如果设置验证集，则将数据划分为：60% 的数据用作训练集、20%的数据用过验证集、20% 的数据用作测试集。<br>对于大批量数据，验证集和测试集占总数据的比例会更小。<br>对于百万级别的数据，其中 1 万条作为验证集、1 万条作为测试集即可。<br>验证集的目的就是验证不同的超参数；测试集的目的就是比较不同的模型。<br>一方面它们要足够大，才足够评估超参数、模型。<br>另一方面，如果它们太大，则会浪费数据（验证集和训练集的数据无法用于训练）</p>
<h3 id="调参的方法有哪些？"><a href="#调参的方法有哪些？" class="headerlink" title="调参的方法有哪些？"></a>调参的方法有哪些？</h3><ul>
<li><strong>传统的手工调参</strong><br>在传统的调参过程中，我们通过训练算法手动检查随机超参数集，并选择符合我们目标的最佳参数集。没办法确保得到最佳的参数组合。这是一个不断试错的过程，所以，非常的耗时。</li>
<li><strong>网格搜索</strong><br>网格搜索是一种基本的超参数调优技术。它类似于手动调优，为网格中指定的所有给定超参数值的每个排列构建模型，评估并选择最佳模型。由于它尝试了超参数的每一个组合，并根据交叉验证得分选择了最佳组合，这使得GridsearchCV非常慢。</li>
<li><strong>随机搜索</strong><br>使用随机搜索代替网格搜索的动机是，在许多情况下，所有的超参数可能不是同等重要的。随机搜索从超参数空间中随机选择参数组合，参数由n_iter给定的固定迭代次数的情况下选择。实验证明，随机搜索的结果优于网格搜索。随机搜索的问题是它不能保证给出最好的参数组合。</li>
<li><strong>贝叶斯搜索</strong><br>贝叶斯优化属于一类优化算法，称为基于序列模型的优化(SMBO)算法。这些算法使用先前对损失 f 的观察结果，以确定下一个(最优)点来抽样 f。要在2维或3维的搜索空间中得到一个好的代理曲面需要十几个样本，增加搜索空间的维数需要更多的样本。</li>
</ul>
<p>在确定参数的最佳组合的保证和计算时间之间总是存在权衡。如果超参数空间(超参数个数)非常大，则使用随机搜索找到超参数的潜在组合，然后在该局部使用网格搜索(超参数的潜在组合)选择最优特征。</p>
<h3 id="参考-4"><a href="#参考-4" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.51cto.com/u_8985428/3866903">https://blog.51cto.com/u_8985428/3866903</a></p>
</blockquote>
<h2 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h2><h3 id="TP、FP、TN、FN具体指的是什么？"><a href="#TP、FP、TN、FN具体指的是什么？" class="headerlink" title="TP、FP、TN、FN具体指的是什么？"></a>TP、FP、TN、FN具体指的是什么？</h3><p>FN：False Negative,被判定为负样本，但事实上是正样本。<br>FP：False Positive,被判定为正样本，但事实上是负样本。<br>TN：True Negative,被判定为负样本，事实上也是负样本。<br>TP：True Positive,被判定为正样本，事实上也是证样本。</p>
<h3 id="ROC曲线和PR曲线的区别？"><a href="#ROC曲线和PR曲线的区别？" class="headerlink" title="ROC曲线和PR曲线的区别？"></a>ROC曲线和PR曲线的区别？</h3><p>ROC曲线的纵坐标是TPR，横坐标是FPR<br>PR曲线的纵坐标是Precision，纵坐标是Recall  </p>
<p>其中TPR、FPR以及Precision、Recall的计算方法如下：<br>$$
\begin{array}{l}
TPR = \frac{{TP}}{{TP + FN}}\\
FPR = \frac{{FP}}{{FP + TN}}\\
\Pr ecision = \frac{{TP}}{{TP + FP}}\\
{\mathop{\rm Re}\nolimits} call = \frac{{TP}}{{TP + FN}}
\end{array}
$$<br>注意看到TPR就是Recall。</p>
<h3 id="如何综合precision和recall指标？"><a href="#如何综合precision和recall指标？" class="headerlink" title="如何综合precision和recall指标？"></a>如何综合precision和recall指标？</h3><p>可以使用 F1评分（F1-Score）：查全率和查准率的调和平均数。<br>$$
F1 = \frac{{2PR}}{{P + R}}
$$<br>所谓调和平均数，考虑的是，赋予较小值更大的权重，避免较小值和较大值对结果产生较大影响。对于二分类的情况，则讲究的是不偏科。因为我们追求的就是更高的查全率和更高的查准率，即刚才思考中的情况4。因此F1评分相较于单一的查全率和查准率具备更好的评估效果。</p>
<h3 id="Precision和Recall的应用场景？"><a href="#Precision和Recall的应用场景？" class="headerlink" title="Precision和Recall的应用场景？"></a>Precision和Recall的应用场景？</h3><p>Precision适用于那些对预测结果很有信心的场景下，比如买股票，希望只要自己选择的标签为1股票，都是涨的；或者在推荐中给用户推荐的视频或者新闻等内容，用户肯定会消费的。</p>
<p>Recall适用于对标签也就是实际上的正样本有很大注意的场景，比如抓坏人，总是希望将坏人都抓回来，因此多抓了几个好人也没事，只要能把坏人抓回来就可以，而不关系自己抓的人中有多少被误伤的。</p>
<h3 id="如何判断一个学习器的性能比另一个好？"><a href="#如何判断一个学习器的性能比另一个好？" class="headerlink" title="如何判断一个学习器的性能比另一个好？"></a>如何判断一个学习器的性能比另一个好？</h3><p><img src="https://img-blog.csdnimg.cn/67c710b9e658406fa4e8458b508e7415.png" alt="image"></p>
<p>如果一个学习器的P-R曲线被另一个学习器的P-R曲线完全包住，则可认为后者的性能优于前者，例如上面的A和B优于学习器C。</p>
<h3 id="ROC曲线中，高于和低于对角线表示意义"><a href="#ROC曲线中，高于和低于对角线表示意义" class="headerlink" title="ROC曲线中，高于和低于对角线表示意义?"></a>ROC曲线中，高于和低于对角线表示意义?</h3><p>如果模型的roc曲线在对角线下方，则该模型比随机模型还差，高于对角线则表示模型比随机模型好，模型是有意义的。</p>
<p>ROC曲线下的面积就AUC，其中AUC大于0.5表示模型的排序能力是正向的，最起码比随机要好，如果小于0.5，说明模型的排序结果很差了。</p>
<h3 id="多分类AUC怎么算？"><a href="#多分类AUC怎么算？" class="headerlink" title="多分类AUC怎么算？"></a>多分类AUC怎么算？</h3><p>基于macro的策略：ovr的划分方式，分别计算每个类别的metrics然后再进行平均</p>
<p>基于micro的策略：所有类放在一起算metrics；</p>
<p>micro的评估方式，当类别非常不均衡时，micro的计算结果会被样本数量多的类别主导，此时需要使用macro</p>
<h3 id="ROC曲线和PR曲线的区别，适用场景，各自优缺点？"><a href="#ROC曲线和PR曲线的区别，适用场景，各自优缺点？" class="headerlink" title="ROC曲线和PR曲线的区别，适用场景，各自优缺点？"></a>ROC曲线和PR曲线的区别，适用场景，各自优缺点？</h3><p>roc曲线和正负样本的比例是没有关系的，roc聚焦于二分类模型整体对正负样本的预测能力，所以适用于评估模型整体的性能，如在rank算法中，如果主要关注正样本的预测能力而不care负样本的预测能力，则pr曲线更合适。</p>
<h3 id="准确率Accuracy的局限性是什么？"><a href="#准确率Accuracy的局限性是什么？" class="headerlink" title="准确率Accuracy的局限性是什么？"></a>准确率Accuracy的局限性是什么？</h3><p>说明下Accuracy的计算公式如下所示：<br>$$
A = \frac{{TP + FP}}{{TP + FN + TN + FP}}
$$<br>准确率是分类问题最简单也是最直接的评价标准，但存在明显的缺陷。如：当负样本数占99%时，分类器把所有样本都预测为负样本也可以获得99%的准确率。所以，当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。</p>
<h3 id="AUC的物理意义是啥"><a href="#AUC的物理意义是啥" class="headerlink" title="AUC的物理意义是啥?"></a>AUC的物理意义是啥?</h3><p>AUC是衡量排序能力的好坏，越大越好，值在0和1之间，AUC 的原始定义是 ROC 下的面积，计算起来比较麻烦。从ROC 的曲线可以看出， AUC的值 不会超过1。同时，对于相同的 FPR ，当 TPR 越大时，面积越大，即 AUC 越大。这也就是说，被模型预测为正的样本中，实际的正样本越多越好，实际的负样本越少越好。从另外一个角度来说， AUC的物理意义就是：随机选出一对正负样本，模型对正样本的打分大于对负样本打分的概率。<br>$$
AUC = \frac{{\sum {{r_i} - \frac{{P*(P + 1)}}{2}} }}{{P*N}}
$$<br>其中P表示正样本数量，N表示负样本数量, 以及r表示排序值。</p>
<h3 id="AUC为啥对正负样本比例不敏感？"><a href="#AUC为啥对正负样本比例不敏感？" class="headerlink" title="AUC为啥对正负样本比例不敏感？"></a>AUC为啥对正负样本比例不敏感？</h3><p>AUC的全称是 area under the curve，即曲线下的面积， 通常这里的曲线指的是受试者操作曲线(Receiver operating characteristic, ROC)。实际的模型的ROC曲线则是一条上凸的曲线，介于随机和理想的ROC曲线之间。而ROC曲线下的面积，即为AUC的表达式：<br>$$
% MathType!MTEF!2!1!+-
AUC{\rm{ = }}\int_{t =  - \infty }^\infty  {y(t)dx(t)} 
$$<br>可以证明得到如下的结果：AUC可以看做随机从正负样本中选取一对正负样本，其中正样本的得分大于负样本的概率，证明如下：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/429313a480ddf5eba4e73d98745d1743.png" alt="image"></p>
<h3 id="为啥很多工程上的评价指标使用ROC或AUC"><a href="#为啥很多工程上的评价指标使用ROC或AUC" class="headerlink" title="为啥很多工程上的评价指标使用ROC或AUC"></a>为啥很多工程上的评价指标使用ROC或AUC</h3><p>ROC和AUC是用来衡量模型的排序能力的，可能预测的precision和recall很差，但是AUC很好，在一些推荐排序的算法中，经常使用到AUC指标，说白了，就是AUC指关注排序的好坏，不关注精度啥的指标。</p>
<h3 id="PR和ROC的区别？"><a href="#PR和ROC的区别？" class="headerlink" title="PR和ROC的区别？"></a>PR和ROC的区别？</h3><ol>
<li>PR<br>P-R曲线就是精确率precision vs 召回率recall 曲线，以recall作为横坐标轴，precision作为纵坐标轴。当我们对样本预测后得到概率，通过置信度就可以对所有样本进行排序，再逐个样本的选择阈值，在该样本之前的都属于正例，该样本之后的都属于负例。得到的PR曲线大概长下面这个样子。P-R曲线肯定会经过（0,0）点，比如讲所有的样本全部判为负例，则TP=0，那么P=R=0，因此会经过（0,0）点，但随着阈值点左移，precision初始很接近1，recall很接近0，因此有可能从（0,0）上升的线和坐标重合，不易区分。如果最前面几个点都是负例，那么曲线会从（0,0）点开始逐渐上升，但曲线最终不会到（1,0）点。</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/a984c96b28b74f3d984265bb2a896107.png" alt="image"></p>
<ol>
<li>ROC<br>ROC的全称是Receiver Operating Characteristic Curve，中文名字叫“受试者工作特征曲线”，顾名思义，其主要的分析方法就是画这条特征曲线。该曲线的横坐标为假阳性率（False Positive Rate, FPR）,纵坐标为真阳性率（True Positive Rate, TPR）。  </li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/b6eec48f9c9a4748a6196f42d5e7cd06.png" alt="image"></p>
<p>根据上述的定义，ROC最直观的应用就是能反映模型在选取不同阈值的时候其敏感性（sensitivity, FPR）和其精确性（specificity, TPR）的趋势走向。不过，相比于上面说的P-R曲线（精确度和召回率），ROC曲线有一个巨大的优势就是，当正负样本的分布发生变化时，其形状能够基本保持不变，而P-R曲线的形状一般会发生剧烈的变化，因此该评估指标能降低不同测试集带来的干扰，更加客观的衡量模型本身的性能。</p>
<h3 id="为啥方差的计算公式分母为n-1"><a href="#为啥方差的计算公式分母为n-1" class="headerlink" title="为啥方差的计算公式分母为n-1?"></a>为啥方差的计算公式分母为n-1?</h3><p>首先我们解释下自由度的定义，自由度在英文中是这么解释的，In statistics, the number of degrees of freedom is the number of values in the final calculation of a statistic that are free to vary.通俗的来说就是，n个样本，如果在某种条件下，样本均值是先定的固定的，那么只剩个n-1样本的值是可以变化的，那么自由度就是n-1。</p>
<p>假设现在有3个样本，分别是${X_1}{X_2}{X_3}$。因为样本具有随机性，所以它们取值不定。但是假设出于某种原因，我们需要让样本均值固定，比如说是$\hat X$， 此时”有随机性”的样本只有2个。一旦均值固定了，只要知道其中的两个，剩下的一个肯定可以自动求出来。剩下的那个被求出来的就可以理解为被剥夺了一个自由度。所以就这个例子而言，3个样本最终”自由”的只有其中的 2 个。</p>
<p>实上，计算样本方差时，样本均值就需要给定。计算样本均值也就是维基百科里提到的 ‘intermediate step’。如果你去观察计算样本方差的一系列表达式，比如往往最常会被介绍的方差的无偏估计 （样本方差）$\frac{1}{{n - 1}}\sum\nolimits_{i = 1}^n {{{({X_i} - \hat X)}^2}}$.其实发现样本均值这一项都包含在内。考虑到方差是衡量数据偏差程度的统计量，计算一下样本均值作为中间步骤的中间量，也不失其合理性。于是，为计算样本方差，样本里原有的n个自由度，有一个自由度被分配给计算样本均值，剩下自由度即为n-1。</p>
<h3 id="为什么使用标准差？"><a href="#为什么使用标准差？" class="headerlink" title="为什么使用标准差？"></a>为什么使用标准差？</h3><p>方差是衡量随机变量或一组数据时离散程度的度量。方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。统计中的方差（样本方差）是各个样本数据和平均数之差的平方和的平均数。在许多实际问题中，研究方差即偏离程度有着重要意义。方差公式的计算公式如下：<br>$$
S^2_{N}=\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}
$$</p>
<p>标准差又称均方差，是方差的算数平方根，标准差的公式如下：<br>$$
S_{N}=\sqrt{\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}}
$$</p>
<p>样本标准差的计算公式为：<br>$$
S_{N}=\sqrt{\frac{1}{N-1}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}}
$$<br>可以看到标准差的概念是基于方差的，仅仅是求了一个平方根而已。那么为什么要造出标准差这样一个概念呢？简单来说，方差单位和数据的单位不一致，没法使用，虽然能很好的描述数据与均值的偏离程度，但是处理结果是不符合我们的直观思维的。而标准差和数据的单位一致，使用起来方便。内在原因就是方差开了一个平方，而标准差通过加了一个根号使得和均值的量纲（单位）保持了一致，在描述一个波动范围时标准差比方差更方便。</p>
<p>与方差相比，使用标准差来表示数据点的离散程度有3个好处：<br>1、表示离散程度的数字与样本数据点的数量级一致，更适合对数据样本形成感性认知。<br>2、表示离散程度的数字单位与样本数据的单位一致，更方便做后续的分析运算。<br>3、在样本数据大致符合正态分布的情况下，标准差具有方便估算的特性：68%的数据点落在平均值前后1个标准差的范围内、95%的数据点落在平均值前后2个标准差的范围内，而99%的数据点将会落在平均值前后3个标准差的范围内。</p>
<h3 id="回归问题的评价指标有哪些？"><a href="#回归问题的评价指标有哪些？" class="headerlink" title="回归问题的评价指标有哪些？"></a>回归问题的评价指标有哪些？</h3><p>回归问题五大评价指标分别为 </p>
<ul>
<li>皮尔逊相关系数</li>
<li>解释方差分数（explained_varience_score）</li>
<li>平均绝对误差（mean_absolute_error）</li>
<li>均方差(mean_square_error)</li>
<li>r2分数（r2_score） </li>
<li>调整r2分数（r2_score_adjust）</li>
</ul>
<h3 id="皮尔逊相关系数怎么算的？"><a href="#皮尔逊相关系数怎么算的？" class="headerlink" title="皮尔逊相关系数怎么算的？"></a>皮尔逊相关系数怎么算的？</h3><p>公式计算如下：<br>$$
{\rho _{X,Y}} = \frac{{Cov(X,Y)}}{{{\sigma _X}{\sigma _Y}}}
$$<br>主要有以下两个步骤：  </p>
<ol>
<li>计算协方差</li>
<li>计算标准差</li>
</ol>
<h3 id="参考-5"><a href="#参考-5" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/20534502/answer/2028365946">https://www.zhihu.com/question/20534502/answer/2028365946</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/13224ACMer/p/11799030.html">https://www.cnblogs.com/13224ACMer/p/11799030.html</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/386064764">https://zhuanlan.zhihu.com/p/386064764</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/dylan_young/article/details/121222221">https://blog.csdn.net/dylan_young/article/details/121222221</a></p>
</blockquote>
<h2 id="数据治理"><a href="#数据治理" class="headerlink" title="数据治理"></a>数据治理</h2><h3 id="机器学习中如何处理类别型特征？"><a href="#机器学习中如何处理类别型特征？" class="headerlink" title="机器学习中如何处理类别型特征？"></a>机器学习中如何处理类别型特征？</h3><p>类别型特征指的是如性别(男、女)，身高(高、矮)等非连续型的数据，这些数据需要经过处理才可以进入到算法模型中<br>在机器学习中，一般可以按照如下进行处理：  </p>
<ul>
<li>序号编码<br>序号编码（Ordinal Encoding）通常用于处理类别间具有大小关系的数据。如成绩有“高、中、低”，并且存在“高&gt;中&gt;低”的关系，可以按照大小关系赋予数值ID：3，2，1。</li>
<li>独热编码<br>独热编码（One-hot Encoding）通常用于处理类别间不具有大小关系的特征，每个类别对应一维编码，如大和小两个特征值可以变为[0,1]和[1,0]</li>
<li>二进制编码<br>二进制编码（Binary Encoding）是指使用二进制来表示映射关系的编码方式。<br>1）先将类别特征赋予一个数值型的唯一ID（十进制的整数）<br>2）将每个类别特征对应的数值型的唯一ID转换成二进制  </li>
</ul>
<h3 id="机器学习中的异常值如何处理？"><a href="#机器学习中的异常值如何处理？" class="headerlink" title="机器学习中的异常值如何处理？"></a>机器学习中的异常值如何处理？</h3><p>异常点的检测按照处理方式可以分为图形法和模型法。图形法主要是借助箱线图或者正态分布图来判断，而模型法主要是建立总体模型，偏离模型的鉴定为异常点。</p>
<ul>
<li>数据错误<br>不符合直观的数据，如升高为10m,这种数据需要去除，或者使用均值等方法填充。</li>
<li>箱线图<br>我们常用的分位点为上四分位数q1（数据的75%分位点所对应的值）、中位数（数据的50%分位点所对应的值）和下四分位数q3（数据的25%分位点所对应的值），上下四分位数差值被称为四分位差，即q1-q3。异常点为上须和下须之外的数据点，其中上须=q1+1.5<em>(q1-q3)，下须=q3-1.5</em>(q1-q3)。图中中间部分的两个点分别为中位数和均值，可以反映数据的集中趋势。</li>
<li>正态分布图<br>在数据服从正态分布的情况下，可以借助3∂原则来对异常值进行检测</li>
<li>模型方法<br>可以使用一些异常检测的方法来进行检测，如AutoEncoder等</li>
</ul>
<h3 id="缺失值的处理方法有哪些？"><a href="#缺失值的处理方法有哪些？" class="headerlink" title="缺失值的处理方法有哪些？"></a>缺失值的处理方法有哪些？</h3><ul>
<li>不做任何处理<br>不对丢失的数据做任何事情。一方面，有一些算法有处理缺失值的能力，此时我们可以将完全控制权交给算法来控制它如何响应数据，如xgboos等。另一方面，各种算法对缺失数据的反应不同。例如，一些算法基于训练损失减少来确定缺失数据的最佳插补值。</li>
<li>不使用时将其删除<br>排除具有缺失数据的记录是一个最简单的方法。但可能会因此而丢失一些关键数据点。</li>
<li>均值插补<br>使用这种方法，可以先计算列的非缺失值的均值，然后分别替换每列中的缺失值，并独立于其他列。最大的缺点是它只能用于数值数据。这是一种简单快速的方法，适用于小型数值数据集。但是，存在例如忽略特征相关性的事实的限制等。每次填补仅适用于其中某一独立的列。<br>此外，如果跳过离群值处理，几乎肯定会替换一个倾斜的平均值，从而降低模型的整体质量。</li>
<li>中位数插补<br>解决上述方法中的异常值问题的另一种插补技术是利用中值。排序时，它会忽略异常值的影响并更新该列中出现的中间值。</li>
<li>众数插补<br>这种方法可应用于具有有限值集的分类变量。有些时候，可以使用最常用的值来填补缺失值。</li>
<li>分类值的插补<br>当分类列有缺失值时，可以使用最常用的类别来填补空白。如果有很多缺失值，可以创建一个新类别来替换它们。</li>
<li>前一次观测结果<br>这是一种常见的统计方法，用于分析纵向重复测量数据时，一些后续观察缺失。</li>
<li>线性插值<br>这是一种近似于缺失值的方法，沿着直线将点按递增顺序连接起来。简而言之，它以与在它之前出现的值相同的升序计算未知值。因为线性插值是默认的方法，我们不需要在使用它的时候指定它。这种方法常用于时间序列数据集。</li>
<li>KNN 插补<br>一种基本的分类方法是 k 最近邻 (kNN) 算法。类成员是 k-NN 分类的结果。<br>项目的分类取决于它与训练集中的点的相似程度，该对象将进入其 k 个最近邻中成员最多的类。如果 k = 1，则该项目被简单地分配给该项目最近邻居的类。使用缺失数据找到与观测值最近的 k 邻域，然后根据邻域中的非缺失值对它们进行插补可能有助于生成关于缺失值的预测。</li>
</ul>
<h3 id="如何进行连续特征离散化？"><a href="#如何进行连续特征离散化？" class="headerlink" title="如何进行连续特征离散化？"></a>如何进行连续特征离散化？</h3><p>无监督学习方法：  </p>
<ol>
<li>等宽法</li>
<li>等频法</li>
<li>基于聚类的方法</li>
</ol>
<p>有监督学习方法：</p>
<ol>
<li>1R方法</li>
<li>基于信息熵的方法</li>
<li>基于卡方的方法</li>
</ol>
<h3 id="什么是特征工程？"><a href="#什么是特征工程？" class="headerlink" title="什么是特征工程？"></a>什么是特征工程？</h3><p>特征工程，是指用一系列工程化的方式从原始数据中筛选出更好的数据特征，以提升模型的训练效果。业内有一句广为流传的话是：数据和特征决定了机器学习的上限，而模型和算法是在逼近这个上限而已。由此可见，好的数据和特征是模型和算法发挥更大的作用的前提。</p>
<h3 id="特征工程的步骤有哪些？"><a href="#特征工程的步骤有哪些？" class="headerlink" title="特征工程的步骤有哪些？"></a>特征工程的步骤有哪些？</h3><p>一般包括三个子模块：特征构建-&gt;特征提取-&gt;特征选择</p>
<p>特征构建：根据原始数据构建新的特征，需要找出一些具有物理意义的特征。<br>特征提取：自动地构建新的特征，将原始特征转换为一组具有明显物理意义或者统计意义或核的特征。例如 Gabor、几何特征、纹理等。常用的方法有：PCA、ICA、LDA等。<br>特征选择：从特征集合中挑选一组最具统计意义的特征子集，把无关的特征删掉，从而达到降维的效果</p>
<h3 id="特征离散化有什么好处？"><a href="#特征离散化有什么好处？" class="headerlink" title="特征离散化有什么好处？"></a>特征离散化有什么好处？</h3><p>在工业界，很少直接将连续值作为逻辑回归模型的特征输入，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：  </p>
<ol>
<li>离散特征的增加和减少都很容易，易于模型的快速迭代；     </li>
<li>稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展；     </li>
<li>离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄&gt;30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；     </li>
<li>逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合；     </li>
<li>离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力；     </li>
<li>特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问；     </li>
<li>特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。</li>
</ol>
<h3 id="特征归一化有哪些方法？"><a href="#特征归一化有哪些方法？" class="headerlink" title="特征归一化有哪些方法？"></a>特征归一化有哪些方法？</h3><ol>
<li><p>线性归一化<br>也称min-max标准化、离差标准化；是对原始数据的线性变换，使得结果值映射到[0,1]之间。转换函数如下：</p>
$$
x' = \frac{{x - \min (x)}}{{\max (x) - \min (x)}}
$$
<p>这种归一化比较适用在数值较集中的情况。但是这种方法有一个缺陷，就是如果max和min不稳定的时候，很容易使得归一化的结果不稳定，易受极值影响，影响后续使用效果。所以在实际应用中，我们一般用经验常量来替代max和min。</p>
</li>
<li><p>标准差归一化<br>也叫Z-score标准化，这种方法给予原始数据的均值（mean，μ）和标准差（standard deviation，σ）进行数据的标准化。经过处理后的数据符合标准正态分布，即均值为0，标准差为1，转化函数为：</p>
$$
{x^*} = \frac{{x - u}}{\sigma }
$$
</li>
<li><p>非线性归一化<br>这种方法一般使用在数据分析比较大的场景，有些数值很大，有些很小，通过一些数学函数，将原始值进行映射。一般使用的函数包括log、指数、正切等，需要根据数据分布的具体情况来决定非线性函数的曲线。</p>
</li>
</ol>
<h3 id="特征选择有哪些方法？"><a href="#特征选择有哪些方法？" class="headerlink" title="特征选择有哪些方法？"></a>特征选择有哪些方法？</h3><p>筛选特征的方法：过滤式(filter)、包裹式(wrapper)、嵌入式(embedding)</p>
<ol>
<li>过滤式(filter)<br>先对数据集进行特征选择，其过程与后续学习器无关，即设计一些统计量来过滤特征，并不考虑后续学习器问题。如方差选择、卡方检验、互信息</li>
<li>包裹式(wrapper)<br>实际上就是一个分类器，如Las Vagas 算法；包裹式特征选择直接把最终将要使用的学习器的性能作为特征子集的评价原则。其目的就是为给定学习器选择最有利于其性能、量身定做的特征子集。</li>
<li>嵌入式(embedding)<br>实际上是学习器自主选择特征。如基于惩罚项的选择、基于树的选择GBDT；嵌入式特征选择是将特征选择与学习器训练过程融为一体，两者在同一个优化过程中完成的。即学习器训练过程中自动进行了特征选择。</li>
</ol>
<h3 id="特征筛选如何获取高相似性特征？"><a href="#特征筛选如何获取高相似性特征？" class="headerlink" title="特征筛选如何获取高相似性特征？"></a>特征筛选如何获取高相似性特征？</h3><p>在得到特征后，可以基于卡方或者皮尔逊等相关系数</p>
<h3 id="计算特征之间的相关性方法有哪些？"><a href="#计算特征之间的相关性方法有哪些？" class="headerlink" title="计算特征之间的相关性方法有哪些？"></a>计算特征之间的相关性方法有哪些？</h3><ol>
<li>pearson系数PLCC<br>对定距连续变量的数据进行计算。是介于-1和1之间的值</li>
<li>Spearman秩相关系数SRCC<br>该系数是度量两个变量之间的统计相关性的指标，用来评估当前单调函数来描述俩个变量之间的关系有多相关</li>
<li>Kendall（肯德尔等级）相关系数<br>该相关系数是一个用来测量两个随机变量相关性的统计值。</li>
</ol>
<h3 id="如何检查数据中的噪声？"><a href="#如何检查数据中的噪声？" class="headerlink" title="如何检查数据中的噪声？"></a>如何检查数据中的噪声？</h3><ol>
<li>通过寻找数据集中与其他观测值及均值差距最大的点作为异常</li>
<li>聚类方法检测：将类似的取值组织成“群”或“簇”，落在“簇”集合之外的值被视为离群点。</li>
</ol>
<h3 id="什么是组合特征？"><a href="#什么是组合特征？" class="headerlink" title="什么是组合特征？"></a>什么是组合特征？</h3><p>为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高级特征。例如，特征a有m个取值，特别b 有n个取值，将二者组合就有m*n个组成情况。这时需要学习的参数个数就是 m×n 个。一些常见的算法如FM就可以用来对高维系数特征的交叉进行学习，且在高维情况下可以高效。</p>
<h3 id="如何处理高维特征？"><a href="#如何处理高维特征？" class="headerlink" title="如何处理高维特征？"></a>如何处理高维特征？</h3><ol>
<li>高维连续特征<br>这种情况可以使用降维方法将维度降低下来然后进行模型的训练，或者对特征进行选择性的筛选得到重要特征后再进行算法开发。</li>
<li>高维离散特征<br>目前主流的方法是使用Embedding技术进行获取离散特征对应的稠密特征，然后在上层进行特征的融合。</li>
</ol>
<h2 id="不平衡问题"><a href="#不平衡问题" class="headerlink" title="不平衡问题"></a>不平衡问题</h2><h3 id="如何处理类别不均衡问题？"><a href="#如何处理类别不均衡问题？" class="headerlink" title="如何处理类别不均衡问题？"></a>如何处理类别不均衡问题？</h3><ol>
<li>采样<br>这里的采样可以分为上采样和下采样，简单说就是从类别少的多采样或者类别多的少采样。对于上采样，如SMOTE算法。</li>
<li>转化为One-class问题<br>把它看做一分类（One Class Learning）或异常检测（Novelty Detection）问题。这类方法的重点不在于捕捉类间的差别，而是为其中一类进行建模，经典的工作包括One-class SVM等</li>
<li>聚类+采样<br>对数据先进行聚类，再将大的簇进行随机欠采样或者小的簇进行数据生成，注意了，这里不是简单的上面所说的下采样，而是先聚类后再采样。</li>
<li>模型惩罚<br>简单说就是对分类器的小类样本数据增加权值，降低大类样本的权值。</li>
<li>换模型<br>使用一些如Bagging和Boosting的方法,</li>
</ol>
<h3 id="分类问题中如何解决正负样本比较大的情况？"><a href="#分类问题中如何解决正负样本比较大的情况？" class="headerlink" title="分类问题中如何解决正负样本比较大的情况？"></a>分类问题中如何解决正负样本比较大的情况？</h3><p>1.随机欠采样（RandomUnder-Sampling）<br>2.随机过采样（RandomOver-Sampling）<br>3.基于聚类的过采样（Cluster-BasedOver Sampling）<br>在这种情况下，K-均值聚类算法独立地被用于少数和多数类实例。这是为了识别数据集中的聚类。随后，每一个聚类都被过采样以至于相同类的所有聚类有着同样的实例数量，且所有的类有着相同的大小。<br>4.信息性过采样：合成少数类过采样技术（SMOTE）<br>这一技术可用来避免过拟合——当直接复制少数类实例并将其添加到主数据集时。从少数类中把一个数据子集作为一个实例取走，接着创建相似的新合成的实例。这些合成的实例接着被添加进原来的数据集。新数据集被用作样本以训练分类模型。<br>5.改进的合成少数类过采样技术（MSMOTE）<br>6.算法集成技术（AlgorithmicEnsemble Techniques）如 Bagging boosting  </p>
<h3 id="采样后如何计算指标？"><a href="#采样后如何计算指标？" class="headerlink" title="采样后如何计算指标？"></a>采样后如何计算指标？</h3><p>比如采样前的正负样本比例是100:1, 采样后是1:1，使用采样后的数据训练好的模型后，不是在1:1的数据上验证指标的好坏，而是要在原始的数据上验证precision和recall等。</p>
<h3 id="如果把不平衡的训练集采样到平衡，计算的AUC和Precision会右什么变化？"><a href="#如果把不平衡的训练集采样到平衡，计算的AUC和Precision会右什么变化？" class="headerlink" title="如果把不平衡的训练集采样到平衡，计算的AUC和Precision会右什么变化？"></a>如果把不平衡的训练集采样到平衡，计算的AUC和Precision会右什么变化？</h3><p>对于正负样本比为1：100，经过采样后训练得到的模型，在采样后的得到平衡的数据上，相比于之前的不平衡的情况，AUC不会变，这是我们在之前说到的，但是Precision会变大，因为正样本的比例变大了。</p>
<h3 id="class-weight的思想是什么？"><a href="#class-weight的思想是什么？" class="headerlink" title="class_weight的思想是什么？"></a>class_weight的思想是什么？</h3><p>就是简单的类权重，对于不平衡的问题的话，可以给不同比例的样本在损失函数函数上加以权重，保持后续在梯度更新上，模型的学习不会偏向于多类的样本，这点在sklearn中的很多模型中都自带的有参数设置。</p>
<h3 id="讲讲smote算法的原理"><a href="#讲讲smote算法的原理" class="headerlink" title="讲讲smote算法的原理?"></a>讲讲smote算法的原理?</h3><p>SMOTE的全称是Synthetic Minority Over-Sampling Technique 即“人工少数类过采样法”，非直接对少数类进行重采样，而是设计算法来人工合成一些新的少数样本。</p>
<p>主要步骤如下： </p>
<ol>
<li>选一个正样本</li>
<li>找到该正样本的K个近邻（假设K = 3）</li>
<li>随机从K个近邻中选出一个样本</li>
<li>在正样本和随机选出的这个近邻之间的连线上，随机找一点。这个点就是人工合成的新正样本了</li>
</ol>
<h3 id="smote的缺点以及为啥在业界用的不多？"><a href="#smote的缺点以及为啥在业界用的不多？" class="headerlink" title="smote的缺点以及为啥在业界用的不多？"></a>smote的缺点以及为啥在业界用的不多？</h3><p>SMOTE是基于距离的度量，然后生成少数类样本。这样生成的数据很大可能是噪音数据，是不利于学习的。<br>原因是：  </p>
<ol>
<li>如果小样本数据之间生成新的小样本数据，没有揭示太多信息，意义不大。  </li>
<li>如果小样本数据生成的数据散布在大样本数据里，则很有可能是噪音，意义也不大。</li>
</ol>
<p>而且工业界的数据量都特别大，对于这种方法需要进行合成数据的效率问题来说，是很难接受的。</p>
<h3 id="过采样和生成样本的区别？"><a href="#过采样和生成样本的区别？" class="headerlink" title="过采样和生成样本的区别？"></a>过采样和生成样本的区别？</h3><p>上采样不一定是生成具体的样本，例如简单的重复的进行数据的采样，通过这种采样来说它是不涉及样本生成的过程，但生成样本一定是一种上采样的过程。</p>
<h3 id="参考-6"><a href="#参考-6" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_38068876/article/details/122736423">https://blog.csdn.net/m0_38068876/article/details/122736423</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/457807729">https://zhuanlan.zhihu.com/p/457807729</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/91125751">https://zhuanlan.zhihu.com/p/91125751</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_46838716/article/details/124424903">https://blog.csdn.net/weixin_46838716/article/details/124424903</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/cc13186851239/article/details/114336039#69__76">https://blog.csdn.net/cc13186851239/article/details/114336039#69__76</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/36503570">https://zhuanlan.zhihu.com/p/36503570</a></p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">线性模型与经典算法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-23 22:38:11" itemprop="dateModified" datetime="2024-03-23T22:38:11+08:00">2024-03-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="线性模型与经典算法"><a href="#线性模型与经典算法" class="headerlink" title="线性模型与经典算法"></a>线性模型与经典算法</h1><h2 id="PLA-感知机"><a href="#PLA-感知机" class="headerlink" title="PLA(感知机)"></a>PLA(感知机)</h2><h3 id="简单介绍下感知机算法？"><a href="#简单介绍下感知机算法？" class="headerlink" title="简单介绍下感知机算法？"></a>简单介绍下感知机算法？</h3><p>感知机算法的全称是Perceptron Linear Algorithm，是由美国学者Fran Rosenblatt 在1957 年提出的一种线性的算法模型，它也是神经网络的算法的起源思想。感知机是一个接受输入并具有输出，感知机的信号流只有1或者0。公式如下所示：<br> $$
f(x)=sign(wx+b)
$$<br>其中sign是符号函数, 如果 $wx+b>0$ 则输出1，如果 $wx+b<0$ ，则输出0。< p>
<center>
<img src="https://img-blog.csdnimg.cn/fe982a7cac2145f3a4288e1385c0553b.png" width="70%">  
</center>

<p>其中  $w$  也即优化的参数。</p>
<h3 id="单层感知机可以实现异或运算吗？"><a href="#单层感知机可以实现异或运算吗？" class="headerlink" title="单层感知机可以实现异或运算吗？"></a>单层感知机可以实现异或运算吗？</h3><p>单层的感知机可以实现与门，与非门和或门，但是无法实现异或门。可以借助下图来形象的描述相关原因。<br>异或门的运算相当于找出一条直线将图中的圈和三角形分开，很显然是不能的。</p>
<center>
<img src="https://img-blog.csdnimg.cn/1b5bf1571bb04444958a732b46a7219f.png" width="70%">  
</center>

<h3 id="多层感知机可以解决异或问题吗？"><a href="#多层感知机可以解决异或问题吗？" class="headerlink" title="多层感知机可以解决异或问题吗？"></a>多层感知机可以解决异或问题吗？</h3><p>实现异或主要的划分曲面如下所示，使用一条曲线即可将圈和三角形分开，这在单层感知机是无法实现的，需要通过多层感知机叠加非线性实现异或。</p>
<center>
<img src="https://img-blog.csdnimg.cn/f22e5942df894829b16b520a8e72a56c.png" width="70%">  
</center>
通过组合感知机（叠加层就可以实现异或门。异或门可以使用通过组合与门、与非门、或门来实现。
<center>
<img src="https://img-blog.csdnimg.cn/3ecb0304269e4689b855c4110c6f96a8.png" width="70%">  
</center>

<h3 id="感知机损失函数是什么？"><a href="#感知机损失函数是什么？" class="headerlink" title="感知机损失函数是什么？"></a>感知机损失函数是什么？</h3><p>感知机线性方程表示为：<br> $$
wx+b=0
$$<br>损失函数只对于误分类的点计算值，也即当误分后有 $-y_{i}({wx_{i}+b})>0$ ，将误分点到直线的距离加起来即为损失函数<br> $$
{\rm{ - }}\frac{1}{{{\rm{||w||}}}}{y_i}(w{x_i} + b)
$$<br>则可以得到总的距离为<br> $$
-{\rm{ - }}\frac{1}{{{\rm{||w||}}}}\sum\limits_{{x_i} \in M} {{y_i}(w{x_i} + b)}
$$<br>不考虑 $||w||$ 的话，则损失函数可以写为<br> $$
-\sum\limits_{{x_i} \in M} {{y_i}(w{x_i} + b)}
$$ </p>
<h3 id="感知机损失函数为什么不考虑W的二范数？"><a href="#感知机损失函数为什么不考虑W的二范数？" class="headerlink" title="感知机损失函数为什么不考虑W的二范数？"></a>感知机损失函数为什么不考虑W的二范数？</h3><p>其实考虑了也没用，整体上来说感知机的任务是进行二分类工作，它最终并不关心得到的超平面离各点的距离有多少，只是可能考虑后得到的新的分界线和之前不考虑得到的有些不同，但是依然可以将所有的点分开的，</p>
<h3 id="感知机优化算法是怎么做的？"><a href="#感知机优化算法是怎么做的？" class="headerlink" title="感知机优化算法是怎么做的？"></a>感知机优化算法是怎么做的？</h3><p>使用SGD方法进行优化，优化更新的思路也是很简单的，如下所示，对损失函数进行求导，如下<br> $$
\begin{array}{l}
{\Delta _w}L(w,b) =  - \sum\limits_{{x_i} \in M} {{y_i}{x_i}} \\
{\Delta _b}L(w,b) =  - \sum\limits_{{x_i} \in M} {{y_i}} 
\end{array}
$$<br>其中参数的更新如下：<br> $$
\begin{array}{l}
w \leftarrow w - \eta *( - {y_i}*{x_i}) = w + \eta *({y_i}*{x_i})\\
b \leftarrow b - \eta *( - {y_i}) = b + \eta *{y_i}
\end{array}
$$<br>通过迭代期望损失函数 $L(w,b)$ 不断减小，直到为0。这种学习算法直观解释：当一个实例点被误分类，即位于分离超平面的错误一侧时，则调整 $w，b$ 的值，使分离超平面向该误分类点的一侧移动，以减少该误分类点与超平面的距离，直至超平面越过该误分类点使其被正确分类。</p>
<h3 id="感知机算法的解释唯一的吗？"><a href="#感知机算法的解释唯一的吗？" class="headerlink" title="感知机算法的解释唯一的吗？"></a>感知机算法的解释唯一的吗？</h3><p>感知机算法在采用了不同的初始值后，得到的解不同，因此无法得到唯一解，可能每次得到的解都不一样，但是每次的分割线可以将正负样本很好的分开，因为能将正负样本分开的线有无限多个，因此解是无穷的。</p>
<h3 id="感知机算法和SVM的区别？"><a href="#感知机算法和SVM的区别？" class="headerlink" title="感知机算法和SVM的区别？"></a>感知机算法和SVM的区别？</h3><p>感知机和SVM的区别：</p>
<ul>
<li><p>相同点<br>都是属于监督学习的一种分类器。</p>
</li>
<li><p>不同点</p>
</li>
</ul>
<ol>
<li>感知机追求最大程度正确划分，最小化错误，很容易造成过拟合。</li>
<li>支持向量机追求大致正确分类的同时，一定程度上避免过拟合。</li>
<li>感知机使用的学习策略是梯度下降法，而SVM采用的SMO算法。</li>
</ol>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_37762592/article/details/101760105">https://blog.csdn.net/weixin_37762592/article/details/101760105</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/163811629">https://zhuanlan.zhihu.com/p/163811629</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/touch_dream/article/details/63748923">https://blog.csdn.net/touch_dream/article/details/63748923</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/collection/709757854">https://www.zhihu.com/collection/709757854</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_34767784/article/details/115271164">https://blog.csdn.net/qq_34767784/article/details/115271164</a></p>
</blockquote>
<h2 id="LR（线性回归）"><a href="#LR（线性回归）" class="headerlink" title="LR（线性回归）"></a>LR（线性回归）</h2><h3 id="简单介绍下线性回归？"><a href="#简单介绍下线性回归？" class="headerlink" title="简单介绍下线性回归？"></a>简单介绍下线性回归？</h3><p>线性回归是⼀种预测模型，利⽤各个特征的数值去预测⽬标值。线性回归的主要思想是给每⼀个特征分配⼀个权值，最终的预测结果是每个特征值与权值的乘机之和再加上偏置。所以训练的⽬标是找到各个特征的最佳权值和偏置，使得误差最⼩。线性回归的假设前提是噪声符合正态分布。</p>
<h3 id="线性回归的5大假设是什么？"><a href="#线性回归的5大假设是什么？" class="headerlink" title="线性回归的5大假设是什么？"></a>线性回归的5大假设是什么？</h3><ol>
<li>特征和标签呈线性关系。</li>
<li>误差之间相互独⽴</li>
<li>⾃变量相互独⽴</li>
<li>误差项的⽅差应为常数</li>
<li>误差呈正态分布</li>
</ol>
<h3 id="线性回归要求因变量符合正态分布？"><a href="#线性回归要求因变量符合正态分布？" class="headerlink" title="线性回归要求因变量符合正态分布？"></a>线性回归要求因变量符合正态分布？</h3><p>是的。线性回归的假设前提是特征与预测值呈线性关系，误差项符合⾼斯-马尔科夫条件（零均值，零⽅差，不相关），这时候线性回归是⽆偏估计。噪声符合正态分布，那么因变量也符合分布。在进⾏线性回归之前，要求因变量近似符合正态分布，否则线性回归效果不佳（有偏估计）。</p>
<h3 id="线性回归为啥做分类不好？"><a href="#线性回归为啥做分类不好？" class="headerlink" title="线性回归为啥做分类不好？"></a>线性回归为啥做分类不好？</h3><p>线性回归的函数形式是 $y=wx+b$ ，其中特征的值 $y$ 是无法控制的，可能会导致算出来的预测值是大于1或者小于0的，因此做分类是不太适合的。</p>
<h3 id="线性回归的损失函数是什么？"><a href="#线性回归的损失函数是什么？" class="headerlink" title="线性回归的损失函数是什么？"></a>线性回归的损失函数是什么？</h3><p>⼀般使⽤最⼩⼆乘法，损失函数是各个样本真实值与预测值之差的平⽅和，需要找到合适的参数，也就是权重和偏置，使得这个误差平⽅和最⼩。<br> $$
Loss(\hat y, y) = \sum_i(wx_i+b-y)^2
$$ </p>
<h3 id="线性回归的求解方法有哪些？"><a href="#线性回归的求解方法有哪些？" class="headerlink" title="线性回归的求解方法有哪些？"></a>线性回归的求解方法有哪些？</h3><ul>
<li>公式法<br>损失函数对 $w$ 和 $b$ 进行求导，并令导数为0，得到最优的 $w$ 和 $b$ </li>
<li>优化法<br>可以通过梯度下降法进行求解</li>
</ul>
<h3 id="线性回归在业界用的不多的原因有哪些？"><a href="#线性回归在业界用的不多的原因有哪些？" class="headerlink" title="线性回归在业界用的不多的原因有哪些？"></a>线性回归在业界用的不多的原因有哪些？</h3><ol>
<li>容易过拟合</li>
<li>数据假设不符合线性</li>
<li>不能做复杂的特征工程，如特征交叉等</li>
</ol>
<h3 id="为什么进行线性回归前需要对特征进行离散化处理？"><a href="#为什么进行线性回归前需要对特征进行离散化处理？" class="headerlink" title="为什么进行线性回归前需要对特征进行离散化处理？"></a>为什么进行线性回归前需要对特征进行离散化处理？</h3><ol>
<li>离散化操作很easy，特征离散化之后易于模型的快速迭代。</li>
<li>稀疏矩阵计算快，省内存。</li>
<li>鲁棒性强。单个特征数值过⼤或者过⼩对结果的影响会被降低。</li>
<li>可以产⽣交叉特征（相当于⾮线性了）</li>
<li>模型的稳定性加强了。</li>
<li>简化了模型，相当于降低了过拟合的风险。</li>
</ol>
<h3 id="线性回归时如果数据量太大导致无法一次读进内存如何解决？"><a href="#线性回归时如果数据量太大导致无法一次读进内存如何解决？" class="headerlink" title="线性回归时如果数据量太大导致无法一次读进内存如何解决？"></a>线性回归时如果数据量太大导致无法一次读进内存如何解决？</h3><p>可以将输入特征向量 $X$ 进行拆分，分开进行计算，将一部分数据加载到内存中计算，然后得到结果后，再计算后面的数据，这样依次得到计算的结果。</p>
<h3 id="线性回归中的R方是什么意思？"><a href="#线性回归中的R方是什么意思？" class="headerlink" title="线性回归中的R方是什么意思？"></a>线性回归中的R方是什么意思？</h3><p>R平方值意义是趋势线拟合程度的指标，它的数值大小可以反映趋势线的估计值与对应的实际数据之间的拟合程度，拟合程度越高，趋势线的可靠性就越高。R平方值是取值范围在0～1之间的数值，当趋势线的 R 平方值等于 1 或接近 1 时，其可靠性最高，反之则可靠性较低。<br> $$
{R^2}{\rm{ = }}\frac{{SSR}}{{SST}} = \frac{{||\hat Y - \bar Y|{|^2}}}{{||Y - \bar Y|{|^2}}} = \frac{{Var(\hat y)}}{{Var(y)}} = 1 - \frac{{\sum\limits_i {{{({{\hat y}_i} - {y_i})}^2}} }}{{\sum\limits_i {{{({y_i} - \bar y)}^2}} }}
$$ </p>
<h3 id="解释下R方为0是什么意思？"><a href="#解释下R方为0是什么意思？" class="headerlink" title="解释下R方为0是什么意思？"></a>解释下R方为0是什么意思？</h3><p>R方=0：一种可能情况是”简单预测所有y值等于y平均值”，即所有 $\hat y_i$ 都等于 $\bar y$ （即真实y值的平均数），但也有其他可能。</p>
<h3 id="相关系数和R方的关系？"><a href="#相关系数和R方的关系？" class="headerlink" title="相关系数和R方的关系？"></a>相关系数和R方的关系？</h3><p>相关系数r，是指两个变量之间的相关关系，取值在-1~1之间。r为负数，则是指两个变量之间存在负相关关系，且越接近-1，负相关性越强，反之，为负数，则是指两个变量之间存在正相关关系，且越接近-1，正相关性越强。</p>
<p>R方指的拟合优度，即某个方程对一组数据拟合程度的大小，取值在0~1之间，越接近1，拟合程度就越大。</p>
<h3 id="线性回归中的多重共线性是什么意思？"><a href="#线性回归中的多重共线性是什么意思？" class="headerlink" title="线性回归中的多重共线性是什么意思？"></a>线性回归中的多重共线性是什么意思？</h3><p>多重共线性（Multicollinearity）是指线性回归模型中的特征存在较高的线性关系。</p>
<h3 id="多重共线性的危害有哪些？"><a href="#多重共线性的危害有哪些？" class="headerlink" title="多重共线性的危害有哪些？"></a>多重共线性的危害有哪些？</h3><ul>
<li>增大模型的不确定性，影响泛化能力</li>
<li>导致模型系数的值不稳定，甚至出现0和负数的情况，这样就没有通过系数值来判断特征的重要性了，无法解释单个变量对模型的影响</li>
<li>会对对非共线性变量的系数产生影响（做实验可以看出来）</li>
</ul>
<h3 id="多重共线性是如何影响算法结果的？"><a href="#多重共线性是如何影响算法结果的？" class="headerlink" title="多重共线性是如何影响算法结果的？"></a>多重共线性是如何影响算法结果的？</h3><p>为了找到最优化的系数，可以对损失函数求导，也就是如下：<br> $$
\frac{{\partial L}}{{\partial w}} = \frac{{\partial {{(y - Xw)}^2}}}{{\partial w}} =  \cdots  = {({X^T}X)^{ - 1}}{X^T}y
$$<br>我们假设 ${X^T}X$ 是可逆的，以便能够估计 $w$  。 但是，如果 $X$ 的列彼此线性相关（存在多重共线性），则 ${X^T}X$ 是不可逆的，由于回归模型中存在共线性，所以很难解释模型的系数 。</p>
<h3 id="共线性变量的处理有哪些方法？"><a href="#共线性变量的处理有哪些方法？" class="headerlink" title="共线性变量的处理有哪些方法？"></a>共线性变量的处理有哪些方法？</h3><ul>
<li>删除共线变量<br>可以通过启发式的方法将变量加入到模型中，看模型的效果，然后确定删除哪个</li>
<li>加正则项<br>正则本身就可以限制模型的复杂度，如使用L2算法</li>
</ul>
<h3 id="线性回归优缺点？"><a href="#线性回归优缺点？" class="headerlink" title="线性回归优缺点？"></a>线性回归优缺点？</h3><p>优点：实现简单，建模快，是许多非线性模型的基础<br>缺点：模型简单所以难以拟合复杂数据，对非线性的数据难以运用</p>
<h3 id="请简单说下Lasso和Ridge的区别？"><a href="#请简单说下Lasso和Ridge的区别？" class="headerlink" title="请简单说下Lasso和Ridge的区别？"></a>请简单说下Lasso和Ridge的区别？</h3><p>Lasso和Ridge都是用来在线性回归中防止过拟合的手段。</p>
<ul>
<li>Lasso<br>在损失函数中加⼊ $w$ 的L1范数， $w$ 容易落到坐标轴上，即Lasso回归容易得到稀疏矩阵</li>
<li>Ridge<br>在原来的损失函数基础上加⼊ $w$ 参数的平⽅和乘以 $\lambda$ （加⼊ $w$ 的L2范数） 。相当于增加了⼀个约束项，在这个约束之下求损失函数的最小值。</li>
</ul>
<h3 id="Ridge回归和Lasso回归的使用场景"><a href="#Ridge回归和Lasso回归的使用场景" class="headerlink" title="Ridge回归和Lasso回归的使用场景"></a>Ridge回归和Lasso回归的使用场景</h3><ol>
<li>解决普通线性回归过拟合的问题；</li>
<li>解决⽅程求解法中⾮满秩矩阵⽆法求解的问题；</li>
<li>约束参数</li>
</ol>
<h3 id="参考-1"><a href="#参考-1" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/Ooman/p/11350095.html">https://www.cnblogs.com/Ooman/p/11350095.html</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_52589734/article/details/116060443">https://blog.csdn.net/weixin_52589734/article/details/116060443</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/Noob_daniel/article/details/76087829">https://blog.csdn.net/Noob_daniel/article/details/76087829</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41761357/article/details/111589392">https://blog.csdn.net/weixin_41761357/article/details/111589392</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/151636748?utm_source=wechat_session&amp;ivk_sa=1024320u">https://zhuanlan.zhihu.com/p/151636748?utm_source=wechat_session&amp;ivk_sa=1024320u</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/143132259?from=singlemessage">https://zhuanlan.zhihu.com/p/143132259?from=singlemessage</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/443658898">https://zhuanlan.zhihu.com/p/443658898</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/32021302/answer/1012441825">https://www.zhihu.com/question/32021302/answer/1012441825</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/146478349">https://zhuanlan.zhihu.com/p/146478349</a></p>
</blockquote>
<h2 id="LR（逻辑回归）"><a href="#LR（逻辑回归）" class="headerlink" title="LR（逻辑回归）"></a>LR（逻辑回归）</h2><h3 id="简单介绍下LR算法？"><a href="#简单介绍下LR算法？" class="headerlink" title="简单介绍下LR算法？"></a>简单介绍下LR算法？</h3><p>逻辑回归（Logistic Regression）属于机器学习 — 监督学习 — 分类的一个算法，它在数据服从伯努利分布的假设下，通过极大似然的方法，运用梯度下降法来求解参数，从而达到将数据二分类的目的。</p>
<h3 id="LR是如何做分类的？"><a href="#LR是如何做分类的？" class="headerlink" title="LR是如何做分类的？"></a>LR是如何做分类的？</h3><p> 逻辑回归中，对于每个 x，其条件概率 y 的确是一个连续的变量。而逻辑回归中可以设定一个阈值，y 值大于这个阈值的是一类，y 值小于这个阈值的是另外一类。至于阈值的选择，通常是根据实际情况来确定，一般情况下选取 0.5 作为阈值来划分。</p>
<h3 id="LR的损失函数怎么来的？"><a href="#LR的损失函数怎么来的？" class="headerlink" title="LR的损失函数怎么来的？"></a>LR的损失函数怎么来的？</h3><p> LR的损失函数可以通过极大似然函数推导得到，极大化似然函数就是最小化损失函数，其中损失函数就是LogLoss，就是极大似然函数取负后的结果。<br> 似然函数的形式是：<br>  $$
L(w) = \prod\limits_{i = 1}^n {{{[p({x_i})]}^{{y_i}}}{{[1 - p({x_i})]}^{1 - {y_{i}}}}}
 $$<br> 损失函数如下：<br>   $$
L(w) = -\prod\limits_{i = 1}^n {{{[p({x_i})]}^{{y_i}}}{{[1 - p({x_i})]}^{1 - {y_{i}}}}}
 $$ </p>
<h3 id="LR如何解决地维不可分？"><a href="#LR如何解决地维不可分？" class="headerlink" title="LR如何解决地维不可分？"></a>LR如何解决地维不可分？</h3><p> 这个问题类似于SVM如何解决低维不可分，如果低维不可分的话，可以使用一些核函数，进行特征空间的映射，到高维后再进行划分即可。</p>
<h3 id="LR的优缺点是什么？"><a href="#LR的优缺点是什么？" class="headerlink" title="LR的优缺点是什么？"></a>LR的优缺点是什么？</h3><p>优点：  </p>
<ol>
<li>形式简单，模型的可解释性非常好。从特征的权重可以看到不同的特征对最后结果的影响，某个特征的权重值比较高，那么这个特征最后对结果的影响会比较大。  </li>
<li>模型效果不错。在工程上是可以接受的（作为 baseline），如果特征工程做的好，效果不会太差，并且特征工程可以并行开发，大大加快开发的速度。  </li>
<li>训练速度较快。分类的时候，计算量仅仅只和特征的数目相关。并且逻辑回归的分布式优化 SGD 发展比较成熟。方便调整输出结果，通过调整阈值的方式。<br>缺点：  </li>
<li>准确率欠佳。因为形式非常的简单，而现实中的数据非常复杂，因此，很难达到很高的准确性。  </li>
<li>很难处理数据不平衡的问题。举个例子：如果我们对于一个正负样本非常不平衡的问题比如正负样本比 10000:1。我们把所有样本都预测为正也能使损失函数的值比较小。但是作为一个分类器，它对正负样本的区分能力不会很好。  </li>
<li>无法自动的进行特征筛选。  </li>
<li>只能处理二分类问题。</li>
</ol>
<h3 id="LR在训练模型中出现了强相关特征怎么办？"><a href="#LR在训练模型中出现了强相关特征怎么办？" class="headerlink" title="LR在训练模型中出现了强相关特征怎么办？"></a>LR在训练模型中出现了强相关特征怎么办？</h3><p>如果在损失函数最终收敛的情况下，其实就算有很多特征高度相关也不会影响分类器的效果。但是对特征本身来说的话，假设只有一个特征，在不考虑采样的情况下，你现在将它重复 N 遍。训练以后完以后，数据还是这么多，但是这个特征本身重复了 N 遍，实质上将原来的特征分成了 N 份，每一个特征都是原来特征权重值的百分之一。</p>
<h3 id="为什么在进入LR模型前要将强相关特征去除？"><a href="#为什么在进入LR模型前要将强相关特征去除？" class="headerlink" title="为什么在进入LR模型前要将强相关特征去除？"></a>为什么在进入LR模型前要将强相关特征去除？</h3><ol>
<li>加快训练速度<br>特征少了的话，无疑训练速度是会加快的</li>
<li>增加模型的可解释性<br>如果出现了强相关特征A和B，最后得到的A的特征重要性和B的特征重要性可能是不准的，在分析的时候很难解释清楚。</li>
</ol>
<h3 id="逻辑回归与朴素贝叶斯有什么区别"><a href="#逻辑回归与朴素贝叶斯有什么区别" class="headerlink" title="逻辑回归与朴素贝叶斯有什么区别?"></a>逻辑回归与朴素贝叶斯有什么区别?</h3><ol>
<li>逻辑回归是判别模型， 朴素贝叶斯是生成模型，所以生成和判别的所有区别它们都有。  </li>
<li>朴素贝叶斯属于贝叶斯派，逻辑回归是最大似然频率派，两种概率哲学间的区别。  </li>
<li>朴素贝叶斯需要条件独立假设。逻辑回归需要求特征参数间是线性的。 </li>
</ol>
<h3 id="LR与NB有什么区别？"><a href="#LR与NB有什么区别？" class="headerlink" title="LR与NB有什么区别？"></a>LR与NB有什么区别？</h3><p>逻辑回归与朴素贝叶斯区别有以下几个方面：  </p>
<ol>
<li>逻辑回归是判别模型， 朴素贝叶斯是生成模型，所以生成和判别的所有区别它们都有。</li>
<li>朴素贝叶斯属于贝叶斯，逻辑回归是最大似然，两种概率哲学间的区别。</li>
<li>朴素贝叶斯需要条件独立假设。</li>
<li>逻辑回归需要求特征参数间是线性的。</li>
</ol>
<h3 id="线性回归和LR的区别"><a href="#线性回归和LR的区别" class="headerlink" title="线性回归和LR的区别?"></a>线性回归和LR的区别?</h3><ol>
<li>线性回归主要来做预测，逻辑回归分类</li>
<li>线性回归y范围实数集，逻辑回归为0,1</li>
<li>线性回归函数为拟合函数，逻辑回归为预测函数</li>
<li>线性回归的参数计算方式为最小二乘法，逻辑回归为极大似然估计</li>
</ol>
<h3 id="为什么LR的输出值可以作为概率？"><a href="#为什么LR的输出值可以作为概率？" class="headerlink" title="为什么LR的输出值可以作为概率？"></a>为什么LR的输出值可以作为概率？</h3><p>因为 sigmoid 函数是伯努利分布的联系函数的反函数，它将线性函数映射到了伯努利分布的期望上，而伯努利分布的期望本身就是概率，因此，我们最终从LR得到的输出，可以代表概率，也正是因为它代表概率，才落在(0,1)之间。</p>
<h3 id="LR和最大熵模型之间的关系到底是什么？"><a href="#LR和最大熵模型之间的关系到底是什么？" class="headerlink" title="LR和最大熵模型之间的关系到底是什么？"></a>LR和最大熵模型之间的关系到底是什么？</h3><p>逻辑斯谛回归是最大熵模型的一个特例，只需将逻辑斯谛回归模型所隐含的模型约束条件引入到最大熵模型中即可导出逻辑斯谛回归模型。最大熵原理是概率模型学习的一种通用准则，可有效避免模型的过拟合。逻辑斯谛回归和最大熵模型都是对数线性模型。</p>
<h3 id="LR的并行化计算方法？"><a href="#LR的并行化计算方法？" class="headerlink" title="LR的并行化计算方法？"></a>LR的并行化计算方法？</h3><ol>
<li>仅按照样本划分<br>可以在样本的层次上进行拆分，对每一个分类错误的样本的计算进行并行化，然后将最终的结果相加再平均即可。</li>
<li>仅按照特征划分<br>按列并行的意思就是将同一样本的特征也分布到不同的机器中去。</li>
<li>按照特征和样本同时划分<br>就是将特征拆分为多个独立的块，每个块算好后进行合并，然后得到最后的梯度值。</li>
</ol>
<h3 id="为什么LR适合稀疏矩阵？"><a href="#为什么LR适合稀疏矩阵？" class="headerlink" title="为什么LR适合稀疏矩阵？"></a>为什么LR适合稀疏矩阵？</h3><p>稀疏矩阵用在LR上，可以大大减少时间复杂度，比如对元素为0的部分，可以直接忽略其乘法运算，并且通过一些方式，也可以仅仅存储不等于0的元素，大大减少空间复杂度。</p>
<p>因此并非是说LR适合稀疏矩阵，而是考虑到现实情境，为了增加非线性，导致了矩阵为稀疏的，反过来，因为LR的特性，特征矩阵即使是很大且稀疏的，也可以快速运算。</p>
<h3 id="LR为什么选择0-5作为分类的阈值？"><a href="#LR为什么选择0-5作为分类的阈值？" class="headerlink" title="LR为什么选择0.5作为分类的阈值？"></a>LR为什么选择0.5作为分类的阈值？</h3><p>我们用来训练的样本数据，通常是从总体中进行抽样得到，因此其正反例的分布也大致符合总体的分布，如果样本数据平衡，那么我们可以假设总体数据平衡，那么设置0.5为阈值便是合理的。</p>
<h3 id="LR都有哪些正则化？"><a href="#LR都有哪些正则化？" class="headerlink" title="LR都有哪些正则化？"></a>LR都有哪些正则化？</h3><ul>
<li>L0<br>L0正则化的想法十分直接，既然我们希望模型不要使用所有特征，那么只要让正则化项代表权重为非0的个数就好了</li>
<li>L1<br>L1正则加入的先验知识是，模型的权重符合拉普拉斯分布，且平均值为0</li>
<li>L2<br>这里的正则加入的先验知识是，模型的权重符合正态分布，且平均值为0</li>
</ul>
<h3 id="LR能否用于非线性分类？"><a href="#LR能否用于非线性分类？" class="headerlink" title="LR能否用于非线性分类？"></a>LR能否用于非线性分类？</h3><p>关于Logistic Regression能否用于非线性分类，这是毫无悬念的，是肯定可以的，只要用一个kernel trick来帮忙就行了，对，就是我们在SVM中常常用到的核函数。在这种情况下，logistic regression模型就不能再表示成 ${w^T}x + b$ 的形式（primal form），而只能表示成 {% raw%}$\sum\limits_i {{a_i} < {x_i},{x_j} >  + b}${% endraw %} 的形式（dual form）。逻辑回归本质上是线性回归模型，关于系数是线性函数，分离平面无论是线性还是非线性的，逻辑回归其实都可以进行分类。对于非线性的，需要自己去定义一个非线性映射。</p>
<h3 id="LR如何并行化？"><a href="#LR如何并行化？" class="headerlink" title="LR如何并行化？"></a>LR如何并行化？</h3><p>并行的方法可以对矩阵进行行分块并行化计算最后合并，注意的是这里随机梯度下降原则不并行话，因为只计算一个样本点的梯度，没必要并行。如果对于类似点击率这种问题，矩阵的特征数目达到上亿维，还可以对列进行分块，就是行列都分块来算，最后结果再合并。算完梯度后直接就可以更新参数值了。</p>
<p>整体上划分的话，有三种并行方法，分别是：</p>
<ol>
<li>按样本并行</li>
<li>按特征并行</li>
<li>按样本和特征并行</li>
</ol>
<h3 id="SVM和LR区别？"><a href="#SVM和LR区别？" class="headerlink" title="SVM和LR区别？"></a>SVM和LR区别？</h3><p>相同点：  </p>
<ol>
<li>LR和SVM都是判别模型。  </li>
<li>LR和SVM都线性模型。(加核的话就是非线性了)  </li>
<li>LR和SVM都是分类算法。(SVM也可以用来做回归)  </li>
<li>LR和SVM都是监督学习算法。  </li>
</ol>
<p>不同点:  </p>
<ol>
<li>损失函数不同<br>LR采用log损失，SVM采用合页(hinge)损失</li>
<li>异常值敏感不同<br>LR对异常值敏感，SVM对异常值不敏感</li>
<li>效率不同<br>大数据和多维特征的情况下，LR优势更明显</li>
<li>模型构建出发点<br>LR是经验风险最小化，SVM是结构风险最小化</li>
</ol>
<h3 id="为什么LR模型损失数使用交叉熵不用MSE？"><a href="#为什么LR模型损失数使用交叉熵不用MSE？" class="headerlink" title="为什么LR模型损失数使用交叉熵不用MSE？"></a>为什么LR模型损失数使用交叉熵不用MSE？</h3><p>LR的基本表达形式如下：<br> $$
{h_\theta }(x) = g({\theta ^T}x) = \frac{1}{{1 + {e^{ - {\theta ^T}x}}}}
$$<br>使用交叉熵作为损失函数的梯度下降更新求导的结果如下：首先得到损失函数如下：<br> $$
C = \frac{1}{n}\sum {[yIn\hat y + (1 - y)In(1 - \hat y)]}
$$<br>计算梯度如下：<br> $$
\frac{{\partial C}}{{\partial w}} = \frac{1}{n}\sum {x(\sigma (z) - y)}
$$<br>如果我们使用MSE作为损失函数的话，那损失函数以及求导的结果如下所示：<br> $$
\begin{array}{l}
C = \frac{{{{(y - \hat y)}^2}}}{2}\\
\frac{{\partial C}}{{\partial w}} = (y - \hat y)\sigma '(z)(x)
\end{array}
$$<br>可以看到使用MSE作为损失函数的话，它的梯度是和sigmod函数的导数有关的，如果当前模型的输出接近0或者1时，导数 $\sigma '(z)$ 就会非常小，接近0，使得求得的梯度很小，损失函数收敛的很慢。但是我们使用交叉熵的话就不会出现这样的情况，它的导数就是一个差值，误差大的话更新的就快，误差小的话就更新的慢点，这正是我们想要的。因此，我们需要用交叉熵而不是MSE作为损失函数。</p>
<h3 id="为什么做LR之前要做归一化？"><a href="#为什么做LR之前要做归一化？" class="headerlink" title="为什么做LR之前要做归一化？"></a>为什么做LR之前要做归一化？</h3><center>
<img src="https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzMzOC8xYmUxOGRkY2ViZTFiZmY1NzhiY2ZkZGQ2OWVjNDVhMi5wbmc=" width="70%">  
</center>
特征两个不一样，则W权重中的每一个wi的梯度更新量差异很大，量纲大的特征对应的权重w的梯度更新的量纲也大。导致梯度中的偏导差异极大，使得模型收敛很慢甚至无法收敛。


### LR损失函数中为啥要加1/N
1/N（N表示样本数量）可以融合到learning rate里去理解，torch的损失函数里面也设计了 对loss进行平均和对loss进行求和，平均不求和的差异就在于每一个step对参数w的梯度更新量的差异为N（样本数量）倍，数据量很大时，会导致梯度更新量非常大，权重的变化会非常的剧烈，收敛困难，所以用1/N，不过其实learning rate缩小n倍达到的效果是一样的。梯度表达式前面的以乘数的形式存在的常数项对梯度下降法的收敛没有任何的影响，本质上可以理解为learning rate的变化。

### LR使用梯度下降法的时候的停止条件是什么？
1、达到最大迭代次数
2、权重的更新值小于设定的阈值
3、设置了早停机制

### LR是线性模型还是非线性模型？
经过sigmoid之后称为非线性的值，所以从决策平面的来说逻辑回归是线性模型，从输出来看逻辑回归是非线性模型，不过一般是从决策平面来定义线性和非线性的，所以我们还是将逻辑回归视为线性模型。

### 请从多个角度解释下LR？
- 从广义线性模型（GLM）角度出发
以二分类逻辑回归为例：二分类问题的逻辑回归，是在假设先验分布p（y）为伯努利分布情况下（由于伯努利分布属于指数分布族），根据GLM规则对后验分布p（y|x）进行建模的结果。

- 从对数几率的角度出发
逻辑回归的建模基础为：假设新样本分为正类别的概率的对数几率（或logit函数）是输入数据x的线性函数。（这一角度和GLM感觉有点类似）

- 从最大熵模型的角度
最大熵模型是逻辑回归的一般形式，逻辑回归是最大熵模型的一个代表。

三种不同角度都不约而同指向了逻辑回归。最开始接触逻辑回归时觉得其很是别扭，现在深感存在即合理。

### 为什么LR要用极大似然法来进行参数估计？
极大似然估计是一种参数估计的方法，它是频率学派最经典的方法之一，认为真实发生的结果的概率应该是最大的，那么相应的参数，也应该是能让这个状态发生的概率最大的参数。简单说就是如果事件发生了被我们观测到了，那么这个事件对应发生的概率一定是最大的才能被我们观测到否则就不会被我们观测到，所以当前的状态是这个事件发生概率最大的结果。

### 参考
> https://zhuanlan.zhihu.com/p/441128484
> https://blog.csdn.net/qq_37430422/article/details/105289993
> https://zhuanlan.zhihu.com/p/391954665
> https://www.zhihu.com/collection/168981231
> https://blog.csdn.net/OliverLee456/article/details/86300850

## KNN
### 简单介绍下KNN？
邻近算法，或者说K最邻近（KNN，K-NearestNeighbor）分类算法是数据挖掘分类技术中最简单的方法之一。所谓K最近邻，就是K个最近的邻居的意思，说的是每个样本都可以用它最接近的K个邻近值来代表。近邻算法就是将数据集合中每一个记录进行分类的方法。
<center>
<img src="https://img-blog.csdnimg.cn/296cd0203a9a4749a8fe338deac0366c.png
" width="90%">  
</center>

<h3 id="KNN的实现方式有哪些？"><a href="#KNN的实现方式有哪些？" class="headerlink" title="KNN的实现方式有哪些？"></a>KNN的实现方式有哪些？</h3><ol>
<li>Kd tree<br>大家了解最多的可能就是Kd tree了，基本思想是对样本在笛卡尔空间进行矩形划分，虽然Kd tree 的方法对于低维度 (D&lt;20) 近邻搜索非常快, 当D增长到很大时, 效率变低: 这就是所谓的“维度灾难” 的一种体现。</li>
<li>ball tree<br>因为使用kd tree最近邻预测时，矩形与目标点和树上点构成的圆于相交，时常会因为菱角相交导致一些，无关多余的搜索，球树就是在kd树这个缺点上进行改进而生，通过将特征点转化为球状分割，从而减少无效相交。通过这种方法构建的树要比 Kd tree消耗更多的时间, 但是这种数据结构对于高结构化的数据是非常有效的, 即使在高维度上也是一样。</li>
</ol>
<h3 id="KNN的决策边界是怎样的？"><a href="#KNN的决策边界是怎样的？" class="headerlink" title="KNN的决策边界是怎样的？"></a>KNN的决策边界是怎样的？</h3><p>KNN的决策边界一般不是线性的，而且随着K的变小，模型容易过拟合，此时的模型复杂度很高且决策边界崎岖，但是如果K取的过大，这时与目标点较远的样本点也会对预测起作用，就会导致欠拟合，此时模型变得简单，决策边界变平滑。如下图所示：</p>
<center>
<img src="https://img-blog.csdnimg.cn/86f18b5de0814cbbb3a53049b815cc8c.png
" width="90%">  
</center>


<h3 id="KD树与一维二叉查找树之间的区别"><a href="#KD树与一维二叉查找树之间的区别" class="headerlink" title="KD树与一维二叉查找树之间的区别?"></a>KD树与一维二叉查找树之间的区别?</h3><p>二叉查找树：数据存放在树中的每个结点（根结点、中间结点、叶子结点）中；<br>Kd-Tree：数据只存放在叶子结点，而根结点和中间结点存放一些空间划分信息（例如划分维度、划分值）</p>
<h3 id="KD树的构建过程是怎样的？"><a href="#KD树的构建过程是怎样的？" class="headerlink" title="KD树的构建过程是怎样的？"></a>KD树的构建过程是怎样的？</h3><ol>
<li><p>在K维数据集合中选择具有最大方差的维度k，然后在该维度上选择中值m为pivot对该数据集合进行划分，得到两个子集合；同时创建一个树结点node，用于存储；</p>
</li>
<li><p>对两个子集合重复上一步骤的过程，直至所有子集合都不能再划分为止；如果某个子集合不能再划分时，则将该子集合中的数据保存到叶子结点（leaf node）。</p>
</li>
</ol>
<h3 id="高维情况下KD树查找性能如何优化？"><a href="#高维情况下KD树查找性能如何优化？" class="headerlink" title="高维情况下KD树查找性能如何优化？"></a>高维情况下KD树查找性能如何优化？</h3><p>Kd-tree在维度较小时（例如：K≤30），算法的查找效率很高，然而当Kd-tree用于对高维数据（例如：K≥100）进行索引和查找时，就面临着维数灾难（curse of dimension）问题，查找效率会随着维度的增加而迅速下降。</p>
<p>在此情况下，我们可以使用优化后的算法BBF来处理，其主要的思路如下所示：<br>bbf算法的思想比较简单，通过对回溯可能需要的路过的结点加入队列，并按照查找点到该结点确定的超平面的距离进行排序，然后每次首先遍历的是优先级最高（即距离最短的结点），直到队列为空算法结束。同时bbf算法也设立了一个时间限制，如果算法运行时间超过该限制，不管是不是为空，一律停止运行，返回当前的最近邻点作为结果。</p>
<p>bbf的算法流程如下：<br>输入：kd树，查找点x<br>输出：kd树种距离查找点最近的点以及最近的距离<br>流程：<br>（1）若kd树为空，则设定两者距离为无穷大，返回；如果kd树非空，则将kd树的根节点加入到优先级队列中；<br>（2）从优先级队列中出队当前优先级最大的结点，计算当前的该点到查找点的距离是否比最近邻距离小，如果是则更新最近邻点和最近邻距离。如果查找点在切分维坐标小于当前点的切分维坐标，则把他的右孩子加入到队列中，同时检索它的左孩子，否则就把他的左孩子加入到队列中，同时检索它的右孩子。这样一直重复检索，并加入队列，直到检索到叶子节点。然后在从优先级队列中出队优先级最大的结点；<br>（3）重复（1）和（2）中的操作，直到优先级队列为空，或者超出规定的时间，返回当前的最近邻结点和距离。</p>
<h3 id="KNN数据需要归一化吗？"><a href="#KNN数据需要归一化吗？" class="headerlink" title="KNN数据需要归一化吗？"></a>KNN数据需要归一化吗？</h3><p>KNN对数据纲量敏感，所以数据要先归一化。因为KNN使用的方差来反映“距离”，纲量对方差计算影响较大。</p>
<h3 id="KNN的K设置的过大会有什么问题"><a href="#KNN的K设置的过大会有什么问题" class="headerlink" title="KNN的K设置的过大会有什么问题?"></a>KNN的K设置的过大会有什么问题?</h3><p>如果选择的K很大，相当于使用所有数据中标签多的样本进行预测，其可以减少学习的估计误差，会使学习的近似误差增大，如果考虑到极端情况，当k和整个样本的数量是一样的话，那么KNN的分类结果就是属于类别最多的那一类。<br>如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，<br>其优点是可以减少学习的估计误差，<br>但缺点是学习的近似误差会增大。</p>
<p>我们考虑一种极端的情况，当k和整个样本数量一样的，KNN的分类结果总是取决于样本类别数量最多的那一类。这时模型的误差最大化。</p>
<h3 id="KD树建立过程中切分维度的顺序是否可以优化？"><a href="#KD树建立过程中切分维度的顺序是否可以优化？" class="headerlink" title="KD树建立过程中切分维度的顺序是否可以优化？"></a>KD树建立过程中切分维度的顺序是否可以优化？</h3><p>先对各个维度计算方差，选取最大方差的维度作为候选划分维度(方差越大，表示此维度上数据越分散)；对split维度上的值进行排序，选取中间的点为node-data；按照split维度的node-data对空间进行一次划分；对上述子空间递归以上操作，直到空间只包含一个数据点。分而治之，且循环选取坐标轴。从方差大的维度来逐步切分，可以取得更好的切分效果及树的平衡性。</p>
<h3 id="KNN为什么使用欧氏距离？"><a href="#KNN为什么使用欧氏距离？" class="headerlink" title="KNN为什么使用欧氏距离？"></a>KNN为什么使用欧氏距离？</h3><p>⼀般⽤欧式距离⽽⾮曼哈顿距离的原因：欧式距离可适⽤于不同空间，表⽰不同空间点之间的距离；曼哈顿距离则只计算⽔平或垂直距离，有维度的限制</p>
<h3 id="KNN中K是怎么选的？"><a href="#KNN中K是怎么选的？" class="headerlink" title="KNN中K是怎么选的？"></a>KNN中K是怎么选的？</h3><p>在实际应用中，K值一般取一个比较小的数值，例如采用交叉验证法（简单来说，就是一部分样本做训练集，一部分做测试集）来选择最优的K值。</p>
<p>1.如果选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合；<br>2.如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。<br>3.K=N，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。还有一些类似的用贝叶斯方法以及bootstrap方法也可以用来做。</p>
<h3 id="KNN的优缺点有哪些？"><a href="#KNN的优缺点有哪些？" class="headerlink" title="KNN的优缺点有哪些？"></a>KNN的优缺点有哪些？</h3><p>优点</p>
<ol>
<li>简单，易于理解，易于实现。</li>
<li>只需保存训练样本和标记，无需估计参数，无需训练。</li>
<li>不易受小错误概率的影响。经理论证明，最近邻的渐进错误率最坏时不超过两倍的贝叶斯错误率，最好时接近或达到贝叶斯错误率。</li>
</ol>
<p>缺点</p>
<ol>
<li>K的选择不固定。</li>
<li>预测结果容易受含噪声数据的影响。</li>
<li>当样本不平衡时，新样本的类别偏向训练样本中数量占优的类别，容易导致预测错误。</li>
<li>具有较高的计算复杂度和内存消耗，因为对每一个待分类的文本，都要计算它到全体已知样本的距离，才能求得它的K个最近邻。</li>
</ol>
<h3 id="如何进行分组计算来解决KNN计算量过大的问题？"><a href="#如何进行分组计算来解决KNN计算量过大的问题？" class="headerlink" title="如何进行分组计算来解决KNN计算量过大的问题？"></a>如何进行分组计算来解决KNN计算量过大的问题？</h3><p>先将样本按照距离分组，再计算每组内的质心，然后计算未知样本到每个质心的距离，最后选择一组或几组，在里面使用KNN。本质上就是先预处理一下，将对计算结果没有用大样本不参与后面的计算，然后在有用的样本内计算。</p>
<h3 id="KNN对不平衡样本的预测有哪些问题？"><a href="#KNN对不平衡样本的预测有哪些问题？" class="headerlink" title="KNN对不平衡样本的预测有哪些问题？"></a>KNN对不平衡样本的预测有哪些问题？</h3><p>会把少数类别往多类别上预测，造成预测结果的不准，假设在训练中有100:1的负正样本比例，对于某个待预测的点来说，其周围一定范围内有50个负样本，2个正样本，这时候可能会预测出为负，但这样是不合理的，因为样本的比例差别太大。解决该方法的可以使用加权的方法，对少类别的样本进行加权，并通过实验来确定最优的权重。</p>
<h3 id="KNN分类和Kmeans的区别？"><a href="#KNN分类和Kmeans的区别？" class="headerlink" title="KNN分类和Kmeans的区别？"></a>KNN分类和Kmeans的区别？</h3><p>KNN属于监督学习，类别是已知的，通过对已知分类的数据进行训练和学习，找到这些不同类的特征，再对未分类的数据进行分类。Kmeans属于非监督学习，事先不知道数据会分为几类，通过聚类分析将数据聚合成几个群体。聚类不需要对数据进行训练和学习。</p>
<h3 id="参考-2"><a href="#参考-2" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.csdn.net/tags/MtTaUg5sMzA1NzktYmxvZwO0O0OO0O0O.html">https://www.csdn.net/tags/MtTaUg5sMzA1NzktYmxvZwO0O0OO0O0O.html</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/cc13186851239/article/details/114377737">https://blog.csdn.net/cc13186851239/article/details/114377737</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42546127/article/details/103290498">https://blog.csdn.net/qq_42546127/article/details/103290498</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/abcaaf754f92">https://www.jianshu.com/p/abcaaf754f92</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/377747470">https://zhuanlan.zhihu.com/p/377747470</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/lhanchao/article/details/52535694">https://blog.csdn.net/lhanchao/article/details/52535694</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/521545516">https://zhuanlan.zhihu.com/p/521545516</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_46838716/article/details/124520422">https://blog.csdn.net/weixin_46838716/article/details/124520422</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/zsmjqtmd/article/details/124187905">https://blog.csdn.net/zsmjqtmd/article/details/124187905</a></p>
</blockquote>
<h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h2><h3 id="请简单介绍下SVM？"><a href="#请简单介绍下SVM？" class="headerlink" title="请简单介绍下SVM？"></a>请简单介绍下SVM？</h3><p>SVM是一类有监督的分类算法，它的大致思想是：假设样本空间上有两类点，我们希望找到一个划分超平面，将这两类样本分开，而划分超平面应该选择泛化能力最好的，也就是能使得两类样本中距离它最近的样本点距离最大。</p>
<center>
<img src="https://img-blog.csdnimg.cn/b0ab29eee88348a2819e85794815cb7d.png" width="70%">  
</center>

<h3 id="为什么SVM要引入核函数？"><a href="#为什么SVM要引入核函数？" class="headerlink" title="为什么SVM要引入核函数？"></a>为什么SVM要引入核函数？</h3><p>当样本在原始空间线性不可分时，可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。核函数就是这么一个映射的函数，而引入这样的映射后，所要求解的对偶问题的求解中，无需求解真正的映射函数，而只需要知道其核函数。核函数的定义：K(x,y)=&lt;ϕ(x),ϕ(y)&gt;，即在特征空间的内积等于它们在原始样本空间中通过核函数 K 计算的结果。一方面数据变成了高维空间中线性可分的数据，另一方面不需要求解具体的映射函数，只需要给定具体的核函数即可，这样使得求解的难度大大降低。</p>
<h3 id="SVM-为什么采用间隔最大化"><a href="#SVM-为什么采用间隔最大化" class="headerlink" title="SVM 为什么采用间隔最大化?"></a>SVM 为什么采用间隔最大化?</h3><p>当训练的数据线性可分的时候，可能会存在无限个超平面能够将正负样本分开，采用间隔最大化的做法，可以保证这个超平面是唯一的，就是距离正负样本都是最大的。</p>
<h3 id="SVM中的核函数有哪些？"><a href="#SVM中的核函数有哪些？" class="headerlink" title="SVM中的核函数有哪些？"></a>SVM中的核函数有哪些？</h3><ul>
<li>Linear Kernel线性核</li>
<li>Polynomial Kernel多项式核</li>
<li>Exponential Kernel指数核</li>
<li>Gaussian Kernel高斯核</li>
<li>Laplacian Kernel拉普拉斯核</li>
<li>ANOVA Kernel</li>
<li>Sigmoid Kernel</li>
</ul>
<h3 id="SVM核函数之间的区别"><a href="#SVM核函数之间的区别" class="headerlink" title="SVM核函数之间的区别?"></a>SVM核函数之间的区别?</h3><p>主要在项目中用到的是：  </p>
<ol>
<li>线性核<br>表示简单且计算速度快，可以用于线性可分的情况下</li>
<li>多项式核<br>可解决非线性问题，可通过主观设置幂数来实现总结的预判，对于大数量级的幂数，不太适用比较多的参数要选择</li>
<li>高斯核<br>主要用于线性不可分的情形，参数多，分类结果非常依赖于参数。有很多人是通过训练数据的交叉验证来寻找合适的参数，不过这个过程比较耗时。</li>
</ol>
<h3 id="不同数据量和特征的情况下怎么选择核函数？"><a href="#不同数据量和特征的情况下怎么选择核函数？" class="headerlink" title="不同数据量和特征的情况下怎么选择核函数？"></a>不同数据量和特征的情况下怎么选择核函数？</h3><ol>
<li>当特征维数 d 超过样本数 m 时 (文本分类问题通常是这种情况), 使用线性核;</li>
<li>当特征维数 d 比较小，样本数 m 中等时, 使用RBF核;</li>
<li>当特征维数 d 比较小，样本数 m 特别大时, 支持向量机性能通常不如深度神经网络。</li>
</ol>
<h3 id="SVM中的函数间隔和几何间隔是什么？"><a href="#SVM中的函数间隔和几何间隔是什么？" class="headerlink" title="SVM中的函数间隔和几何间隔是什么？"></a>SVM中的函数间隔和几何间隔是什么？</h3><p>函数间隔 ： 对于在超平面上的点，  $wx+b=0$ 恒成立。而超平面之外的点，可以认为距离越远，  $wx+b$ 的绝对值越大，同时分类成功的概率也越高，表达式为：<br> $$
{\gamma _i} = {y_i}(w{x_i} + b)
$$ </p>
<p>几何间隔 ： 顾名思义，几何间隔就是两条平行线之间的距离，表达式为：<br> $$
{\gamma _i} = {y_i}(\frac{w}{{||w||}}{x_i} + \frac{b}{{||w||}})
$$ </p>
<h3 id="SVM为什么引入对偶问题？"><a href="#SVM为什么引入对偶问题？" class="headerlink" title="SVM为什么引入对偶问题？"></a>SVM为什么引入对偶问题？</h3><ol>
<li>对偶问题将原始问题中的约束转为了对偶问题中的等式约束，对偶问题往往更加容易求解。  </li>
<li>可以很自然的引用核函数（拉格朗日表达式里面有内积，而核函数也是通过内积进行映射的）。  </li>
<li>在优化理论中，目标函数 f(x) 会有多种形式：如果目标函数和约束条件都为变量 x 的线性函数，称该问题为线性规划；如果目标函数为二次函数，约束条件为线性函数，称该最优化问题为二次规划；如果目标函数或者约束条件均为非线性函数，称该最优化问题为非线性规划。每个线性规划问题都有一个与之对应的对偶问题，对偶问题有非常良好的性质，以下列举几个：<br> a, 对偶问题的对偶是原问题；<br> b, 无论原始问题是否是凸的，对偶问题都是凸优化问题；<br> c, 对偶问题可以给出原始问题一个下界；<br> d, 当满足一定条件时，原始问题与对偶问题的解是完全等价的。</li>
</ol>
<h3 id="SVM中系数求解是怎么做的？"><a href="#SVM中系数求解是怎么做的？" class="headerlink" title="SVM中系数求解是怎么做的？"></a>SVM中系数求解是怎么做的？</h3><p>SMO（Sequential Minimal Optimization）算法。有多个拉拉格朗日乘子，每次只选择其中两个乘子做优化，其他因子被认为是常数。将N个变量的求解问题，转换成两个变量的求解问题，并且目标函数是凸的。</p>
<h3 id="讲一下SVM中松弛变量和惩罚系数？"><a href="#讲一下SVM中松弛变量和惩罚系数？" class="headerlink" title="讲一下SVM中松弛变量和惩罚系数？"></a>讲一下SVM中松弛变量和惩罚系数？</h3><p>松弛变量和惩罚因子是为了把线性可分SVM拓展为线性不可分SVM的。只有被决策面分类错误的点（线性不可分点）才会有松弛变量，然后惩罚因子是对线性不可分点的惩罚。 增大惩罚因子，模型泛化性能变弱，惩罚因子无穷大时，退化为线性可分SVM（硬间隔）； 减少惩罚因子，模型泛化性能变好。</p>
<h3 id="SVM在大数据情况下怎么办？"><a href="#SVM在大数据情况下怎么办？" class="headerlink" title="SVM在大数据情况下怎么办？"></a>SVM在大数据情况下怎么办？</h3><p>原理上，SVM使用非线性特征映射将低维特征映射到高维，并通过kernel trick直接计算高维特征之间的内积，避免显式计算非线性特征映射，然后在高维特征空间中做线性分类。用 $\phi$ 表示非线性映射，它对应的核函数是，使得 $\left\langle {\phi (x),\phi (y)} \right\rangle  = k(x,y)$ 。</p>
<p>由于使用数据集的核矩阵（Kernel Matrix）描述样本之间的相似性，矩阵元素的个数随着数据规模增大成平方增长。这样要随着数据规模增大，SVM的计算变得无法处理。但是问题总是有解决方法的，2007年，Ali 等人在 NIPS发表Random Features for Large-Scale Kernel Machines，提出使用随机特征映射的方法处理大规模核函数的方法。其基本思想是，构造一个“随机”映射  直接将数据映射到高维空间，使得在这空间上的内积可以近似等于核函数。</p>
<h3 id="SVM为啥不加正则？"><a href="#SVM为啥不加正则？" class="headerlink" title="SVM为啥不加正则？"></a>SVM为啥不加正则？</h3><p>对于SVM的original问题的表达形式如下：<br> $$
\begin{array}{l}
{\min _{w,b,\xi }} = \frac{1}{2}{\left\| w \right\|^2} + C\sum\limits_{i = 1}^N {{\xi _i}} \;\;\;\;\;\;\\
s.t.\;\;{y_i}(w{x_i} + b) \ge 1 - {\xi _i},i = 1,2, \cdots N\\
\;\;\;\;\;\;{\xi _i} > 0,\;\;\;i = 1,2, \cdots N
\end{array}
$$<br>上面的这三个小等式可以由下面的一个式子来表示<br> $$
\begin{array}{l}
{\min _{w,b,\xi }} = \frac{1}{2}{\left\| w \right\|^2} + C\sum\limits_{i = 1}^N {{{[1 - {y_i}(w{x_i} + b)]}_ + }} \\
\;\;\;\;\;\;\;\;\;\;\; = \;\frac{1}{2}{\left\| w \right\|^2} + C\sum\limits_{i = 1}^N {{{[\xi ]}_ + }} \;\;\;\;\;
\end{array}
$$<br>尾部的+号表示的意思是这个是一个合页损失函数，如下所示:<br> $$
{[z]_ + } = \left\{ \begin{array}{l}
z,z > 0\\
0,z \le 0
\end{array} \right.
$$<br>可以从中看到，这就是一个加了正则化的合页损失函数的形式，因此是不需要加正则的。</p>
<h3 id="SVM和FM的区别？"><a href="#SVM和FM的区别？" class="headerlink" title="SVM和FM的区别？"></a>SVM和FM的区别？</h3><p>1.SVM的二元特征交叉参数是独立的，而FM的二元特征交叉参数是两个k维的向量vi、vj，交叉参数就不是独立的，而是相互影响的。<br>2.FM可以在原始形式下进行优化学习，而基于kernel的非线性SVM通常需要在对偶形式下进行。<br>3.FM的模型预测与训练样本独立，而SVM则与部分训练样本有关，即支持向量。</p>
<h3 id="说说为什么svm中的某核能映射到无穷维"><a href="#说说为什么svm中的某核能映射到无穷维" class="headerlink" title="说说为什么svm中的某核能映射到无穷维"></a>说说为什么svm中的某核能映射到无穷维</h3><p>SVM使用的核函数大致是那么几种，线性，多项式，高斯核。<br>高斯核函数可以映射到无穷维，表达式如下：<br> $$
K({x_1},{x_2}) = \exp ( - \frac{{||{x_1} - {x_2}|{|^2}}}{{2{\sigma ^2}}})
$$<br>展开后变成<br> $$
K({x_1},{x_2}) = \exp ( - \frac{{||{x_1} - {x_2}|{|^2}}}{{2{\sigma ^2}}}) = 1 + ( - \frac{{||{x_1} - {x_2}|{|^2}}}{{2{\sigma ^2}}}) + \frac{{ - {{(\frac{{||{x_1} - {x_2}|{|^2}}}{{2{\sigma ^2}}})}^2}}}{{2}} + \frac{{ - {{(\frac{{||{x_1} - {x_2}|{|^2}}}{{2{\sigma ^2}}})}^3}}}{{3}} + .... + \frac{{ - {{(\frac{{||{x_1} - {x_2}|{|^2}}}{{2{\sigma ^2}}})}^n}}}{{n}}
$$<br>这就可以映射到无穷维了。</p>
<h3 id="SVM如何多分类？"><a href="#SVM如何多分类？" class="headerlink" title="SVM如何多分类？"></a>SVM如何多分类？</h3><p>经典的支持向量机算法只给出了二类分类的算法，而在数据挖掘的实际应用中，一般要解决多类的分类问题。可以通过多个二类支持向量机的组合来解决。主要有一对多组合模式、一对一组合模式和SVM决策树；再就是通过构造多个分类器的组合来解决。主要原理是克服SVM固有的缺点，结合其他算法的优势，解决多类问题的分类精度。如：与粗集理论结合，形成一种优势互补的多类问题的组合分类器。</p>
<h3 id="为什么SVM对缺失数据敏感？"><a href="#为什么SVM对缺失数据敏感？" class="headerlink" title="为什么SVM对缺失数据敏感？"></a>为什么SVM对缺失数据敏感？</h3><p>这里说的缺失数据是指缺失某些特征数据，向量数据不完整。SVM 没有处理缺失值的策略。而 SVM 希望样本在特征空间中线性可分，所以特征空间的好坏对SVM的性能很重要。缺失特征数据将影响训练结果的好坏。</p>
<h3 id="SVM的优缺点是什么？"><a href="#SVM的优缺点是什么？" class="headerlink" title="SVM的优缺点是什么？"></a>SVM的优缺点是什么？</h3><ul>
<li>优点：  </li>
</ul>
<ol>
<li>由于SVM是一个凸优化问题，所以求得的解一定是全局最优而不是局部最优。</li>
<li>不仅适用于线性线性问题还适用于非线性问题(用核技巧)。</li>
<li>拥有高维样本空间的数据也能用SVM，这是因为数据集的复杂度只取决于支持向量而不是数据集的维度，这在某种意义上避免了“维数灾难”。</li>
<li>理论基础比较完善。</li>
</ol>
<ul>
<li>缺点：  </li>
</ul>
<ol>
<li>二次规划问题求解将涉及m阶矩阵的计算(m为样本的个数), 因此SVM不适用于超大数据集。(SMO算法可以缓解这个问题)。当样本数量比较大时，效果通常不如神经网络。</li>
<li>用SVM解决多分类问题存在困难</li>
<li>对缺失数据敏感，对参数和核函数的选择敏感</li>
</ol>
<h3 id="说一下一下SVR的原理？"><a href="#说一下一下SVR的原理？" class="headerlink" title="说一下一下SVR的原理？"></a>说一下一下SVR的原理？</h3><p>传统回归模型的损失是计算模型输出f(x)和真实值y之间的差别，当且仅当f(x)=y时，损失才为零；但是SVR假设我们能容忍f(x)和y之间有一定的偏差，仅当f(x)和y之间的偏差大于该值时才计算损失。</p>
<h3 id="参考-3"><a href="#参考-3" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/43827793">https://zhuanlan.zhihu.com/p/43827793</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/81890745">https://zhuanlan.zhihu.com/p/81890745</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/cc13186851239/article/details/114336039">https://blog.csdn.net/cc13186851239/article/details/114336039</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/Elford/article/details/121493152">https://blog.csdn.net/Elford/article/details/121493152</a><br><a target="_blank" rel="noopener" href="https://www.csdn.net/tags/NtjaQg0sMDI3MDEtYmxvZwO0O0OO0O0O.html">https://www.csdn.net/tags/NtjaQg0sMDI3MDEtYmxvZwO0O0OO0O0O.html</a></p>
</blockquote>
<h2 id="NB"><a href="#NB" class="headerlink" title="NB"></a>NB</h2><h3 id="朴素贝叶斯算法优缺点？"><a href="#朴素贝叶斯算法优缺点？" class="headerlink" title="朴素贝叶斯算法优缺点？"></a>朴素贝叶斯算法优缺点？</h3><p>朴素贝叶斯的主要优点有：</p>
<ol>
<li>朴素贝叶斯模型有稳定的分类效率。</li>
<li>对小规模的数据表现很好，能处理多分类任务，适合增量式训练，尤其是数据量超出内存时，可以一批批的去增量训练。</li>
<li>对缺失数据不太敏感，算法也比较简单，常用于文本分类。</li>
</ol>
<p>朴素贝叶斯的主要缺点有：　　　</p>
<ol>
<li>理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型给定输出类别的情况下,假设属性之间相互独立，这个假设在实际应用中往往是不成立的，在属性个数比较多或者属性之间相关性较大时，分类效果不好。而在属性相关性较小时，朴素贝叶斯性能最为良好。对于这一点，有半朴素贝叶斯之类的算法通过考虑部分关联性适度改进。</li>
<li>需要知道先验概率，且先验概率很多时候取决于假设，假设的模型可以有很多种，因此在某些时候会由于假设的先验模型的原因导致预测效果不佳。</li>
<li>由于我们是通过先验和数据来决定后验的概率从而决定分类，所以分类决策存在一定的错误率。</li>
<li>对输入数据的表达形式很敏感。</li>
</ol>
<h3 id="什么是贝叶斯决策论？"><a href="#什么是贝叶斯决策论？" class="headerlink" title="什么是贝叶斯决策论？"></a>什么是贝叶斯决策论？</h3><p>贝叶斯决策论是基于先验概率求解后验概率的方法，其核心是寻找一个判别准则使得条件风险达到最小。而在最小化分类错误率的目标下，贝叶斯最优分类器又可以转化为求后验概率达到最大的类别标记，即 h*（x) = argmaxP(i|x)。</p>
<h3 id="贝叶斯公式是啥？"><a href="#贝叶斯公式是啥？" class="headerlink" title="贝叶斯公式是啥？"></a>贝叶斯公式是啥？</h3><p>贝叶斯定理由英国数学家贝叶斯 ( Thomas Bayes 1702-1761 ) 发展，用来描述两个条件概率之间的关系，比如 P(A|B) 和 P(B|A)。按照乘法法则，可以立刻导出：P(A∩B) = P(A)<em>P(B|A)=P(B)</em>P(A|B)。如上公式也可变形为：P(A|B)=P(B|A)*P(A)/P(B)。</p>
<h3 id="朴素怎么理解？"><a href="#朴素怎么理解？" class="headerlink" title="朴素怎么理解？"></a>朴素怎么理解？</h3><p>朴素贝叶斯分类是一种十分简单的分类算法，其思想是朴素的，即：对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此待分类项属于哪个类别。</p>
<p>之所以被称为“朴素”， 是因为它假定所有的特征在数据集中的作用是同样重要和独立的，正如我们所知，这个假设在现实世界中是很不真实的，因此，说是很“朴素的”。</p>
<h3 id="贝叶斯学派和频率学派的区别？"><a href="#贝叶斯学派和频率学派的区别？" class="headerlink" title="贝叶斯学派和频率学派的区别？"></a>贝叶斯学派和频率学派的区别？</h3><p>直至今日，关于统计推断的主张和想法，大体可以纳入到两个体系之内，其一叫频率学派，其特征是把需要推断的参数θ视作固定且未知的常数，而样本X是随机的，其着眼点在样本空间，有关的概率计算都是针对X的分布。另一派叫做贝叶斯学派，他们把参数θ视作随机变量，而样本X是固定的，其着眼点在参数空间，重视参数θ的分布，固定的操作模式是通过参数的先验分布结合样本信息得到参数的后验分布。</p>
<h3 id="什么是拉普拉斯平滑？"><a href="#什么是拉普拉斯平滑？" class="headerlink" title="什么是拉普拉斯平滑？"></a>什么是拉普拉斯平滑？</h3><p>零概率问题：在计算事件的概率时，如果某个事件在观察样本库（训练集）中没有出现过，会导致该事件的概率结果是0。这是不合理的，不能因为一个事件没有观察到，就被认为该事件一定不可能发生（即该事件的概率为0）。</p>
<p>拉普拉斯平滑(Laplacian smoothing) 是为了解决零概率的问题。<br> $$
{\varphi _j} = \frac{{\sum\nolimits_{i = 1}^m {I({z^{(i)}} = j)}  + 1}}{m}
$$ </p>
<p>法国数学家 拉普拉斯 最早提出用 加1 的方法，估计没有出现过的现象的概率。<br>理论假设：假定训练样本很大时，每个分量x的计数加1造成的估计概率变化可以忽略不计，但可以方便有效的避免零概率问题。</p>
<h3 id="朴素的缺点为什么有较好的表现效果？"><a href="#朴素的缺点为什么有较好的表现效果？" class="headerlink" title="朴素的缺点为什么有较好的表现效果？"></a>朴素的缺点为什么有较好的表现效果？</h3><ol>
<li>对于分类任务来说，只要各个条件概率之间的排序正确，那么就可以通过比较概率大小来进行分类，不需要知道精确的概率值(朴素贝叶斯分类的核心思想是找出后验概率最大的那个类，而不是求出其精确的概率)</li>
<li>如果属性之间的相互依赖对所有类别的影响相同，或者相互依赖关系可以互相抵消，那么属性条件独立性的假设在降低计算开销的同时不会对分类结果产生不良影响。</li>
</ol>
<h3 id="朴素贝叶斯中有没有超参数可以调？"><a href="#朴素贝叶斯中有没有超参数可以调？" class="headerlink" title="朴素贝叶斯中有没有超参数可以调？"></a>朴素贝叶斯中有没有超参数可以调？</h3><p>朴素贝叶斯是没有超参数可以调的，所以它不需要调参，朴素贝叶斯是根据训练集进行分类，分类出来的结果基本上就是确定了的，拉普拉斯估计器不是朴素贝叶斯中的参数，不能通过拉普拉斯估计器来对朴素贝叶斯调参。</p>
<h3 id="朴素贝叶斯中有多少种模型？"><a href="#朴素贝叶斯中有多少种模型？" class="headerlink" title="朴素贝叶斯中有多少种模型？"></a>朴素贝叶斯中有多少种模型？</h3><p>朴素贝叶斯含有3种模型，分别是</p>
<ul>
<li>高斯模型<br>对连续型数据进行处理</li>
<li>多项式模型<br>对离散型数据进行处理，计算数据的条件概率(使用拉普拉斯估计器进行平滑的一个模型)</li>
<li>伯努利模型<br>伯努利模型的取值特征是布尔型，即出现为ture,不出现为false,在进行文档分类时，就是一个单词有没有在一个文档中出现过。</li>
</ul>
<h3 id="朴素贝叶斯有哪些应用吗？"><a href="#朴素贝叶斯有哪些应用吗？" class="headerlink" title="朴素贝叶斯有哪些应用吗？"></a>朴素贝叶斯有哪些应用吗？</h3><p>现实生活中朴素贝叶斯算法应用广泛，如文本分类，垃圾邮件的分类，信用评估，钓鱼网站检测等等。</p>
<h3 id="朴素贝叶斯对异常值敏不敏感？"><a href="#朴素贝叶斯对异常值敏不敏感？" class="headerlink" title="朴素贝叶斯对异常值敏不敏感？"></a>朴素贝叶斯对异常值敏不敏感？</h3><p>朴素贝叶斯对异常值不敏感。所以在进行数据处理时，我们可以不去除异常值，因为保留异常值可以保持朴素贝叶斯算法的整体精度，而去除异常值则可能在进行预测的过程中由于失去部分异常值导致模型的泛化能力下降。</p>
<h3 id="朴素贝叶斯对缺失值敏不敏感？"><a href="#朴素贝叶斯对缺失值敏不敏感？" class="headerlink" title="朴素贝叶斯对缺失值敏不敏感？"></a>朴素贝叶斯对缺失值敏不敏感？</h3><p>朴素贝叶斯是一种对缺失值不敏感的分类器，朴素贝叶斯算法能够处理缺失的数据，在算法的建模时和预测时数据的属性都是单独处理的。因此如果一个数据实例缺失了一个属性的数值，在建模时将被忽略，不影响类条件概率的计算，在预测时，计算数据实例是否属于某类的概率时也将忽略缺失属性，不影响最终结果。</p>
<h3 id="朴素贝叶斯是高方差还是低方差模型？"><a href="#朴素贝叶斯是高方差还是低方差模型？" class="headerlink" title="朴素贝叶斯是高方差还是低方差模型？"></a>朴素贝叶斯是高方差还是低方差模型？</h3><p>朴素贝叶斯是低方差模型，可以看它的假设是独立同分布的，是一个简单的算法模型，而对于简单的模型来说，则恰恰相反，简单模型的偏差会更大，相对的，方差就会较小。(偏差是模型输出值与真实值的误差，也就是模型的精准度，方差是预测值与模型输出期望的的误差，即模型的稳定性，也就是数据的集中性的一个指标)</p>
<h3 id="朴素贝叶斯为什么适合增量计算？"><a href="#朴素贝叶斯为什么适合增量计算？" class="headerlink" title="朴素贝叶斯为什么适合增量计算？"></a>朴素贝叶斯为什么适合增量计算？</h3><p>因为朴素贝叶斯在训练过程中实际只需要计算出各个类别的概率和各个特征的类条件概率，这些概率值可以快速的根据增量数据进行更新，无需重新全量训练，所以其十分适合增量计算，该特性可以使用在超出内存的大量数据计算和按小时级等获取的数据计算中。</p>
<h3 id="朴素贝叶斯与-LR-区别？"><a href="#朴素贝叶斯与-LR-区别？" class="headerlink" title="朴素贝叶斯与 LR 区别？"></a>朴素贝叶斯与 LR 区别？</h3><ol>
<li>朴素贝叶斯是生成模型,LR是判别模型</li>
<li>朴素贝叶斯是基于很强的条件独立假设(在已知分类Y的条件下，各个特征变量取值是相互独立的)，而 LR 则对此没有要求</li>
<li>朴素贝叶斯适用于数据集少的情景，而LR适用于大规模数据集。</li>
</ol>
<h3 id="高度相关的特征对朴素贝叶斯有什么影响？"><a href="#高度相关的特征对朴素贝叶斯有什么影响？" class="headerlink" title="高度相关的特征对朴素贝叶斯有什么影响？"></a>高度相关的特征对朴素贝叶斯有什么影响？</h3><p>假设有两个特征高度相关，相当于该特征在模型中发挥了两次作用(计算两次条件概率)，使得朴素贝叶斯获得的结果向该特征所希望的方向进行了偏移，影响了最终结果的准确性，所以朴素贝叶斯算法应先处理特征，把相关特征去掉。</p>
<h3 id="参考-4"><a href="#参考-4" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43868020/article/details/106602799">https://blog.csdn.net/weixin_43868020/article/details/106602799</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/jaffe507/article/details/105197631">https://blog.csdn.net/jaffe507/article/details/105197631</a></p>
</blockquote>
<h2 id="LDA-线性判别分析"><a href="#LDA-线性判别分析" class="headerlink" title="LDA(线性判别分析)"></a>LDA(线性判别分析)</h2><h3 id="请简单介绍下LDA？"><a href="#请简单介绍下LDA？" class="headerlink" title="请简单介绍下LDA？"></a>请简单介绍下LDA？</h3><p>线性判别分析(LDA)是机器学习中常见的降维方法之一，它是一种有监督的线性的降维方法，主要思想是在给定训练集的情况下，将样本投影到一条直线上，使得同类的样本的投影尽可能的接近、异类样本的投影尽可能的远。</p>
<center>
<img src="https://img-blog.csdnimg.cn/addb57d34c264961adf843623d552ecd.png" width="70%">  
</center>

<h3 id="LDA和PCA的联系和区别？"><a href="#LDA和PCA的联系和区别？" class="headerlink" title="LDA和PCA的联系和区别？"></a>LDA和PCA的联系和区别？</h3><p>相同点：</p>
<ol>
<li>两者均可以对数据进行降维。  </li>
<li>两者在降维时均使用了矩阵特征分解的思想。  </li>
<li>两者都假设数据符合高斯分布。  </li>
</ol>
<p>不同点：</p>
<ol>
<li>LDA是有监督的降维方法，而PCA是无监督的降维方法  </li>
<li>LDA降维最多降到类别数k-1的维数，而PCA没有这个限制。  </li>
<li>LDA除了可以用于降维，还可以用于分类。  </li>
<li>LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。这点可以从下图形象的看出，在某些数据分布下LDA比PCA降维较优。  </li>
</ol>
<h3 id="LDA的优缺点？"><a href="#LDA的优缺点？" class="headerlink" title="LDA的优缺点？"></a>LDA的优缺点？</h3><p>LDA算法的主要优点有：</p>
<ol>
<li>在降维过程中可以使用类别的先验知识经验，而像PCA这样的无监督学习则无法使用类别先验知识。</li>
<li>LDA在样本分类信息依赖均值而不是方差的时候，比PCA之类的算法较优。</li>
</ol>
<p>LDA算法的主要缺点有：</p>
<ol>
<li>LDA不适合对非高斯分布样本进行降维，PCA也有这个问题。</li>
<li>LDA降维最多降到类别数k-1的维数，如果我们降维的维度大于k-1，则不能使用LDA。当然目前有一些LDA的进化版算法可以绕过这个问题。</li>
<li>LDA在样本分类信息依赖方差而不是均值的时候，降维效果不好。</li>
<li>LDA可能过度拟合数据。</li>
</ol>
<h3 id="LDA算法步骤简单说一下？"><a href="#LDA算法步骤简单说一下？" class="headerlink" title="LDA算法步骤简单说一下？"></a>LDA算法步骤简单说一下？</h3><p>输入：数据集 {% raw%}$D{\rm{ = \{ (}}{x_1}{\rm{,}}{{\rm{y}}_1}{\rm{),(}}{x_2}{\rm{,}}{{\rm{y}}_2}{\rm{)}},{\rm{(}}{x_3}{\rm{,}}{{\rm{y}}_3}{\rm{)}} \cdots {\rm{(}}{x_m}{\rm{,}}{{\rm{y}}_m}{\rm{)\} }}${% endraw %}  ，其中任意样本 {% raw%}$x_i${% endraw %} 为 {% raw%}$n${% endraw %} 维向量， {% raw%}${y_i} \in \{ {C_1},{C_2}, \cdots ,{C_k}\}${% endraw %} ，降维到的维度 $d$ 。</p>
<p>输出：降维后的样本集 $\hat D$ </p>
<ol>
<li>计算类内散度矩阵 $S_w$ </li>
<li>计算类间散度矩阵 $S_b$ </li>
<li>计算矩阵  $S^{-1} wS_b$ </li>
<li>计算的最大的 $d$ 个特征值和对应的 $d$ 个特征向量 $w_1,w_2 \cdots w_n$ 得到投影矩阵 $w$ </li>
<li>对样本集中的每一个样本特征 $x_i$ ,转化为新的样本，得到输出样本集</li>
</ol>
<h3 id="协方差为什么可以反映类内方差？"><a href="#协方差为什么可以反映类内方差？" class="headerlink" title="协方差为什么可以反映类内方差？"></a>协方差为什么可以反映类内方差？</h3><p>协方差的表达式如下所示：<br> $$
\begin{array}{l}
{\mathop{\rm cov}}  = \frac{1}{n}\sum {(Y - \bar Y)} (Y - \bar Y)\\
{\mathop{\rm cov}}  = \frac{1}{n}\sum {(X - \bar X)} (X - \bar X)
\end{array}
$$<br>可以看到协方差的公式和方差十分相近，甚至可以说方差是协方差的一种特例。我们知道方差可以用来度量数据的离散程度， $（X - \bar X）$ 越大，表示数据距离样本中心越远，数据越离散，数据的方差越大。同样我们观察，协方差的公式， $（X - \bar X）$ 和  $（Y - \bar Y）$  越大，表示数据距离样本中心越远，数据分布越分散，协方差越大。相反他们越小表示数据距离样本中心越近，数据分布越集中，协方差越小。</p>
<p>所以协方差不仅是反映了变量之间的相关性，同样反映了多维样本分布的离散程度（一维样本使用方差），协方差越大（对于负相关来说是绝对值越大），表示数据的分布越分散。所以上面的“欲使同类样例的投影点尽可能接近，可以让同类样本点的协方差矩阵尽可能小”就可以理解了。</p>
<h3 id="特征的辨识信息不是均值，LDA还可以用吗？"><a href="#特征的辨识信息不是均值，LDA还可以用吗？" class="headerlink" title="特征的辨识信息不是均值，LDA还可以用吗？"></a>特征的辨识信息不是均值，LDA还可以用吗？</h3><p>LDA在样本分类信息依赖方差而不是均值的时候，降维效果不好；LDA是有监督学习，它既可以用作数据降维，又可以用于分类，但要保证不同类别数据的投影中心尽可能远；有辨识的信息即分类依据，如果有辨识的信息不是平均值，那么就无法保证投影后的异类数据点中心尽可能远，LDA就会失败。</p>
<h3 id="解释一下LDA的目标函数？"><a href="#解释一下LDA的目标函数？" class="headerlink" title="解释一下LDA的目标函数？"></a>解释一下LDA的目标函数？</h3><p>LDA的目标函数包括两个部分，分别是类内方差和类间的距离，目标函数如下所示：<br> $$
J(w) = \frac{{|{{\tilde u}_1} - {{\tilde u}_2}{|^2}}}{{{{\tilde s}^2}_1 + {{\tilde s}^2}_2}}
$$<br>分子表示不同类别均值之差，分母表示不同类别方差之和，因此我们的目标就是最大化 $J(w)$ 即可</p>
<h3 id="LDA需要对数据归一化吗？"><a href="#LDA需要对数据归一化吗？" class="headerlink" title="LDA需要对数据归一化吗？"></a>LDA需要对数据归一化吗？</h3><p>LDA 假设输入变量是数值型且正态分布，并且它们具有相同的方差（分布）。如果不是这种情况，则可能需要将数据转换为具有高斯分布并在建模之前对数据进行标准化或归一化。</p>
<h3 id="参考-5"><a href="#参考-5" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_25990967/article/details/123465182">https://blog.csdn.net/qq_25990967/article/details/123465182</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/a6232ca325ed">https://www.jianshu.com/p/a6232ca325ed</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/wj-1314/p/10234256.html">https://www.cnblogs.com/wj-1314/p/10234256.html</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/468965293">https://zhuanlan.zhihu.com/p/468965293</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/13ec606fdd5f?ivk_sa=1024320u">https://www.jianshu.com/p/13ec606fdd5f?ivk_sa=1024320u</a></p>
</blockquote>
<h2 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h2><h3 id="简单介绍下FM？"><a href="#简单介绍下FM？" class="headerlink" title="简单介绍下FM？"></a>简单介绍下FM？</h3><p>FM即Factor Machine，因⼦分解机，算法可进行回归和二分类预测，它的特点是考虑了特征之间的相互作用，是一种非线性模型，目前FM算法是推荐领域被验证的效果较好的推荐方案之一，在诸多电商、广告、直播厂商的推荐领域有广泛应用。</p>
<h3 id="为什么使用FM？"><a href="#为什么使用FM？" class="headerlink" title="为什么使用FM？"></a>为什么使用FM？</h3><p>在实际的工业界场景中，经常遇到类似点击率预测这种工程问题，其特征高维稀疏且需要考虑特征交叉，FM则提出了二阶特征交叉的思路用于完成LR不能进行特征交叉的缺陷，且对每个稀疏的特征学习相应的隐向量来缓解高维特征情况下的参数学习问题。</p>
<h3 id="FM的公式是什么样的？"><a href="#FM的公式是什么样的？" class="headerlink" title="FM的公式是什么样的？"></a>FM的公式是什么样的？</h3><p>表达式如下：<br> $$
y = {w_0} + \sum\limits_{i = 1}^n {{w_i}{x_i} + \sum\limits_{i = 1}^{n - 1} {\sum\limits_{j = i + 1}^n {{w_{ij}}{x_i}{x_j}} } }
$$<br>其中 $w_0$  为初始权值，或者理解为偏置项， $w_i$  为每个特征 $x_i$ 对应的权值。可以看到<br>，FM的表达式只是在线性表达式后面加入了新的交叉项特征及对应的权值。</p>
<h3 id="FM公式是如何化简的？"><a href="#FM公式是如何化简的？" class="headerlink" title="FM公式是如何化简的？"></a>FM公式是如何化简的？</h3><p>FM的简化主要体现在交叉特征系数的矩阵上，也就 $w_{ij}$ 这个参数上，FM为了简化计算，使用了隐向量的乘积来近似 $w_{ij}$ ，其中计算过程如下所示，最终的结果可以通过“两两相乘求和就等于先求和再平方减去先平方再求和””这个思路，将N方的复杂度降低到KN的复杂度，其中K为隐含向量的维度，其中简化的过程如下所示：<br> $$
[\begin{array}{l}
\sum\limits_{i = 1}^{n - 1} {\sum\limits_{j = i + 1}^n {{w_{ij}}{x_i}{x_j}} }  \approx \sum\limits_{i = 1}^{n - 1} {\sum\limits_{j = i + 1}^n { < {v_i}.{v_j} > {x_i}{x_j}} } \\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; = \frac{1}{2}\sum\limits_{i = 1}^n {\sum\limits_{j = 1}^n { < {v_i}.{v_j} > {x_i}{x_j}} }  - \frac{1}{2}\sum\limits_{i = 1}^n { < {v_i},{v_j} > } {x_i}{x_i}\\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; = \frac{1}{2}(\sum\limits_{i = 1}^n {\sum\limits_{j = 1}^n {\sum\limits_{f = 1}^k {{v_{i,f}}{v_{j,f}}} {x_i}{x_j}} }  - \sum\limits_{i = 1}^n {\sum\limits_{f = 1}^k {{v_{i,f}}{v_{i,f}}} } {x_i}{x_i})\\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; = \frac{1}{2}\sum\limits_{f = 1}^k {((\sum\limits_{i = 1}^n {{v_{i,f}}{x_i}} )(\sum\limits_{j = 1}^n {{v_{j,f}}{x_j}} ) - \sum\limits_{i = 1}^n {{v^2}_{i,f}{x_i}^2} )} \\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; = \frac{1}{2}\sum\limits_{f = 1}^k {({{(\sum\limits_{i = 1}^n {{v_{i,f}}{x_i}} )}^2} - \sum\limits_{i = 1}^n {{v^2}_{i,f}{x_i}^2} )} 
\end{array}
$$<br>在实际的实现中，我们也不会对向量的每一位进行for循环计算，在tensorflow或pytorch里，我们直接可以计算出整个向量的结果。</p>
<h3 id="FM为什么要引入隐向量？"><a href="#FM为什么要引入隐向量？" class="headerlink" title="FM为什么要引入隐向量？"></a>FM为什么要引入隐向量？</h3><p>为了用两个隐向量的內积模拟二次项的参数，从而极大降低参数个数，并且缓解二次项稀疏的问题。</p>
<p>假设有1万个特征，特征的两两组合，那么二次项就有  $C_{10000}^2$ 这么权重。</p>
<p>而加入隐向量后，可以看公式的等号右边：中括号内只有 $N$ 的复杂度，中括外边是 $k$ 的复杂度，因此总的复杂度就降到了  $kN$  。考虑到 $k$ 是隐向量的维度，可以根据效果和复杂度来人为指定，是远远小于特征数的，比如取 $k$ 为16，则 $kN=160000$ ，参数量是小来很多。</p>
<h3 id="FM如何做优化的？"><a href="#FM如何做优化的？" class="headerlink" title="FM如何做优化的？"></a>FM如何做优化的？</h3><p>FM使用随机梯度下降法进行参数的更新，其中导数的计算如下所示：<br> $$
\frac{{\partial y}}{{\partial \theta }} = \left\{ \begin{array}{l}
1,\;\;\;if\;\theta \;is\;{w_0}\\
{x_i},\;\;if\;\theta \;is\;{w_i}\\
{x_i}\sum\nolimits_{j = 1}^n {{v_{j,f}}{x_j} - {v_{i,f}}{x_i}^2} ,\;if\;\theta \;is\;{v_{i,f}}
\end{array} \right.
$$ </p>
<h3 id="FM和SVM的区别？"><a href="#FM和SVM的区别？" class="headerlink" title="FM和SVM的区别？"></a>FM和SVM的区别？</h3><p>FM和SVM最大的不同，在于特征组合时权重的计算方法</p>
<ol>
<li>SVM的二元特征交叉参数是独立的，而FM的二元特征交叉参数是两个k维的向量 $v_i, v_j$  ，交叉参数不是独立的，而是互相影响的</li>
<li>FM可以在原始形式下进行优化学习，而基于kernel的非线性SVM通常需要在对偶形式下进行</li>
<li>FM的模型预测与训练样本独立，而SVM则与部分训练样本有关，即支持向量</li>
</ol>
<h3 id="FM和FFM的区别？"><a href="#FM和FFM的区别？" class="headerlink" title="FM和FFM的区别？"></a>FM和FFM的区别？</h3><ol>
<li>FFM将特征按照事先的规则分为多个filed，特征 $x_i$ 属于某个特定的场 $f$ </li>
<li>当两个特征 $x_i, x_j$ 组合时，用对方对应的filed对应的隐向量做内积</li>
</ol>
<h3 id="FM和LR的区别？"><a href="#FM和LR的区别？" class="headerlink" title="FM和LR的区别？"></a>FM和LR的区别？</h3><ol>
<li>FM学习的是特征的隐向量，没有出现的特征组合也可以通过隐向量内积得到，打破了特征之间的独立性。</li>
<li>LR学习的是组合特征的权重，没有出现过的特征组合，权重无法学习。对于稀疏样本 $ x_i*x_j $ 的组合不一定存在，LR就无法学习 $w_{ij}$  </li>
</ol>
<h3 id="FFM中的F是什么意思？"><a href="#FFM中的F是什么意思？" class="headerlink" title="FFM中的F是什么意思？"></a>FFM中的F是什么意思？</h3><p>FFM(Field Factorization Machine)是在FM的基础上引入了“场（Field）”的概念而形成的新模型。在FM中的特征 与其他特征的交叉时，特征 使用的都是同一个隐向量 。而FFM将特征按照事先的规则分为多个场(Field)，特征属于某个特定的场F。每个特征将被映射为多个隐向量 ，每个隐向量对应一个场。当两个特征 ,组合时，用对方对应的场对应的隐向量做内积。说白了就是一个特征的embedding不是[1,n]维的了，是[k,n]维了，其中k是场的数量。</p>
<h3 id="FFM现实使用中存在哪些问题？"><a href="#FFM现实使用中存在哪些问题？" class="headerlink" title="FFM现实使用中存在哪些问题？"></a>FFM现实使用中存在哪些问题？</h3><ol>
<li>参数交大导致模型很大，如果我们的任务有100个特征域，FFM模型的参数量就是FM模型的大约100倍。在现实任务中，特征数量n是个很大的数值，特征域几十上百也很常见，这样的话，参数量会爆炸的。</li>
<li>正因为FFM模型参数量太大，所以在训练FFM模型的时候，很容易过拟合，需要采取早停等防止过拟合的手段。而根据经验，FFM模型的k值可以取得小一些，一般在几千万训练数据规模下，取8到10能取得较好的效果，当然，k具体取哪个数值，这其实跟具体训练数据规模大小有关系，理论上，训练数据集合越大，越不容易过拟合，这个k值可以设置得越大些。</li>
</ol>
<h3 id="FM算法的优缺点是什么？"><a href="#FM算法的优缺点是什么？" class="headerlink" title="FM算法的优缺点是什么？"></a>FM算法的优缺点是什么？</h3><p>优点：</p>
<ol>
<li>支持非常稀疏的特征，适用在高维稀疏的情况下</li>
<li>FM的计算时间复杂度为线性的，并且可以直接优化原问题的参数</li>
</ol>
<p>缺点：</p>
<ol>
<li>在稠密特征的情况下，效果可能和LR差不多</li>
<li>特征组合也只能到二阶，三阶往上效率就变低了</li>
</ol>
<h3 id="FM如何用于多路召回？"><a href="#FM如何用于多路召回？" class="headerlink" title="FM如何用于多路召回？"></a>FM如何用于多路召回？</h3><ol>
<li>基于离线数据训练号FM模型，得到各个特征维度的embedding</li>
<li>对于某个用户 $u$ ，我们可以把属于这个用户子集合的特征，查询离线训练好的FM模型对应的特征embedding向量，然后将 $n$ 个用户子集合的特征embedding向量累加，形成用户兴趣向量 $U$ ，这个向量维度和每个特征的维度是相同的</li>
<li>当用户登陆或者刷新页面时，可以根据用户ID取出其对应的兴趣向量embedding，然后和Faiss中存储的物料embedding做内积计算，按照得分由高到低返回得分Top K的物料作为召回结果。 </li>
</ol>
<h3 id="参考-6"><a href="#参考-6" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/298277108">https://zhuanlan.zhihu.com/p/298277108</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/GFDGFHSDS/article/details/104782245/">https://blog.csdn.net/GFDGFHSDS/article/details/104782245/</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/Super_Json/article/details/105324546">https://blog.csdn.net/Super_Json/article/details/105324546</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/58160982">https://zhuanlan.zhihu.com/p/58160982</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/zwqjoy/article/details/118145249">https://blog.csdn.net/zwqjoy/article/details/118145249</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/Su_Mo/article/details/11699324">https://blog.csdn.net/Su_Mo/article/details/11699324</a></p>
</blockquote>
</0$></p>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" class="post-title-link" itemprop="url">集成学习</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-23 20:48:02" itemprop="dateModified" datetime="2024-03-23T20:48:02+08:00">2024-03-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="集成学习方法"><a href="#集成学习方法" class="headerlink" title="集成学习方法"></a>集成学习方法</h1><h2 id="bagging"><a href="#bagging" class="headerlink" title="bagging"></a>bagging</h2><h3 id="bagging和boosting区别"><a href="#bagging和boosting区别" class="headerlink" title="bagging和boosting区别"></a>bagging和boosting区别</h3><p>Bagging：即自助法，无放回的采样，学习到多个基模型，然后进行融合。<br>Boosting是一族可以将弱分类器提升为强分类器的算法，首先基于初始数据集训练基模型，然后再根据基学习期的表现对样本分布进行调整，使得错误的样本得到较大的关注，基于调整后的数据训练模型，训练得到多个模型，然后将模型的结果加权即可。 </p>
<p>区别如下：<br>Bagging和Boosting的区别：<br>1）样本选择上<br>Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。<br>Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。<br>2）样例权重<br>Bagging：使用均匀取样，每个样例的权重相等Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。<br>3）预测函数<br>Bagging：所有预测函数的权重相等。Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。<br>4）并行计算<br>Bagging：各个预测函数可以并行生成Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。  </p>
<p>详细见：<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/81340270">https://zhuanlan.zhihu.com/p/81340270</a></p>
<h3 id="为啥adboost不容易过拟合？"><a href="#为啥adboost不容易过拟合？" class="headerlink" title="为啥adboost不容易过拟合？"></a>为啥adboost不容易过拟合？</h3><p>在解决这个问题之前，我们需要先了解一下隐马科夫模型Adboost的定义是什么？Adaboost算法是一种提升方法，将多个弱分类器，组合成强分类器。AdaBoost，是英文”Adaptive Boosting“（自适应增强）的缩写，由Yoav Freund和Robert Schapire在1995年提出。它的自适应在于：前一个弱分类器分错的样本的权值（样本对应的权值）会得到加强，权值更新后的样本再次被用来训练下一个新的弱分类器。在每轮训练中，用总体（样本总体）训练新的弱分类器，产生新的样本权值、该弱分类器的话语权，一直迭代直到达到预定的错误率或达到指定的最大迭代次数。</p>
<p>对于过拟合问题，如今找到的能解释只有Margin理论能解释的还不错，这个理论是从泛化错误 &lt; 训练Margin项 + 学习算法容量相关项到泛化错误 &lt; 训练Margin项最小值 + 学习算法容量相关项进行发展，国内的一些学者 周志华 王立威 等也做了相关的研究。Margin理论讨论的主要是学习算法在训练样本上的信心.通过其他一些在variance-bias 分解实验中也观察到，AdaBoost不仅是减少了bias，同时也减少了variance，variance的减少往往与算法容量减少有关。有兴趣的小伙伴可以看一下参考文献。</p>
<p><a target="_blank" rel="noopener" href="https://jeremykun.com/2015/09/21/the-boosting-margin-or-why-boosting-doesnt-overfit/">https://jeremykun.com/2015/09/21/the-boosting-margin-or-why-boosting-doesnt-overfit/</a></p>
<h3 id="为什么随机森林的泛化能力较强？"><a href="#为什么随机森林的泛化能力较强？" class="headerlink" title="为什么随机森林的泛化能力较强？"></a>为什么随机森林的泛化能力较强？</h3><p>随机森林的泛化误差界与单个决策树的分类强度<code>$s$</code>成负相关，与决策树之间的相关性<code>$\rho$</code>成正相关，分类强度<code>$\rho$</code>越大且相关性<code>$s$</code>越小，泛化误差界越小，可以看到随机森林中的随机性可以保证<code>$\rho$</code>越小，如果每棵树的越大的话，泛化误差会收敛到一个small界，这个界当然越小越好，就是泛化误差越小。</p>
<h3 id="解释下stacking技术？"><a href="#解释下stacking技术？" class="headerlink" title="解释下stacking技术？"></a>解释下stacking技术？</h3><p>Stacking是通过一个元分类器或者元回归器来整合多个分类模型或回归模型的集成学习技术。基础模型利用整个训练集做训练，元模型将基础模型的特征作为特征进行训练。</p>
<h3 id="为什么bagging减少方差"><a href="#为什么bagging减少方差" class="headerlink" title="为什么bagging减少方差"></a>为什么bagging减少方差</h3><p>当融合多棵树的结果的时候，最后的方差是<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\rho \sigma^2 +(1-\rho)\frac&#123;\sigma^2&#125;&#123;B&#125;</span><br></pre></td></tr></table></figure><br>可以看到 <code>$\rho$</code>越小，<code>$B$</code>越大，方差越小<br>详细可以看<br><a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/380023/how-can-we-explain-the-fact-that-bagging-reduces-the-variance-while-retaining-t">https://stats.stackexchange.com/questions/380023/how-can-we-explain-the-fact-that-bagging-reduces-the-variance-while-retaining-t</a><br>推导在<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/373404605">https://zhuanlan.zhihu.com/p/373404605</a></p>
<h3 id="什么场景下采用bagging集成方法"><a href="#什么场景下采用bagging集成方法" class="headerlink" title="什么场景下采用bagging集成方法"></a>什么场景下采用bagging集成方法</h3><p>学习算法不稳定：if small changes to the training set cause large changes in the learned classifier.（也就是说如果训练集稍微有所改变就会导致分类器性能比较大大变化那么我们可以采用bagging这种集成方法）If the learning algorithm is unstable, then Bagging almost always improves performance.(当学习算法不稳定的时候，Bagging这种方法通常可以改善模型的性能)</p>
<p>详细见<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/81340270">https://zhuanlan.zhihu.com/p/81340270</a></p>
<h3 id="bagging和dropout区别"><a href="#bagging和dropout区别" class="headerlink" title="bagging和dropout区别"></a>bagging和dropout区别</h3><p>dropout训练与bagging训练不太一样，bagging的各个子模型之间是完全独立的，而在dropout里，这些参数是共享的。每个模型集成父神经网络参数的不同子集，参数共享使得在有限可用内存下表示指数级数量的模型变得可能，在bagging的情况下，每一个模型在其训练集上训练到收敛，而在dropout情况下，通常大部分的模型都没有显式的训练，因为父神经网络很大，大到宇宙毁灭都不可能采样完所有的网络，在每一个步骤中，我们训练一小部分网络，参数共享会使得剩余的网络也有好的参数设定。<br>详细见<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/149575988">https://zhuanlan.zhihu.com/p/149575988</a></p>
<h3 id="bagging和boosting的区别"><a href="#bagging和boosting的区别" class="headerlink" title="bagging和boosting的区别"></a>bagging和boosting的区别</h3><p>1）样本选择上：<br>Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的.<br>Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化.而权值是根据上一轮的分类结果进行调整.<br>2）样例权重：<br>Bagging：使用均匀取样，每个样例的权重相等.<br>Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大.<br><strong>3）预测函数：</strong><br>Bagging：所有预测函数的权重相等.<br>Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重.<br>4）并行计算：<br>Bagging：各个预测函数可以并行生.<br>Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果.</p>
<h3 id="为什么说bagging是减少variance，而boosting是减少bias"><a href="#为什么说bagging是减少variance，而boosting是减少bias" class="headerlink" title="为什么说bagging是减少variance，而boosting是减少bias?"></a>为什么说bagging是减少variance，而boosting是减少bias?</h3><p>boosting是把许多弱的分类器组合成一个强的分类器。弱的分类器bias高，而强的分类器bias低，所以说boosting起到了降低bias的作用。variance不是boosting的主要考虑因素。bagging是对许多强（甚至过强）的分类器求平均。在这里，每个单独的分类器的bias都是低的，平均之后bias依然低；而每个单独的分类器都强到可能产生overfitting的程度，也就是variance高，求平均的操作起到的作用就是降低这个variance。</p>
<h3 id="请从偏差和方差的角度解释bagging和boosting的原理"><a href="#请从偏差和方差的角度解释bagging和boosting的原理" class="headerlink" title="请从偏差和方差的角度解释bagging和boosting的原理"></a>请从偏差和方差的角度解释bagging和boosting的原理</h3><p>偏差指的是算法的期望预测与真实值之间的偏差程度，反映了模型本身的拟合能力；方差度量了同等大小的训练集的变动导致学习性能的变化，刻画了数据扰动所导致的影响。</p>
<p>Bagging对样本重采样，对每一重采样得到的子样本集训练一个模型，最后取平均。由于子样本集的相似性以及使用的是同种模型，因此各模型有近似相等的bias和variance。由于<code>$E[\frac{{\sum {{X_i}} }}{n}] = E[{X_i}]$</code>，所以bagging后的bias和单个子模型的接近，一般来说不能显著降低bias。另一方面，若各子模型独立，则有<code>$Var[\frac{{\sum {{X_i}} }}{n}] = \frac{{Var[{X_i}]}}{n}$</code>，此时可以显著降低variance。若各子模型完全相同，则<code>$Var[\frac{{\sum {{X_i}} }}{n}] = Var[{X_i}]$</code>，此时不会降低variance。</p>
<p>bagging方法得到的各子模型是有一定相关性的，属于上面两个极端状况的中间态，因此可以一定程度降低variance。</p>
<p>boosting从优化角度来看，是用forward-stagewise这种贪心法去最小化损失函数,由于采取的是串行优化的策略，各子模型之间是强相关的，于是子模型之和并不能显著降低variance。所以说boosting主要还是靠降低bias来提升预测精度。</p>
<h3 id="详细说明下决策数如何计算特征重要性的？"><a href="#详细说明下决策数如何计算特征重要性的？" class="headerlink" title="详细说明下决策数如何计算特征重要性的？"></a>详细说明下决策数如何计算特征重要性的？</h3><p>对于简单的的决策数，sklearn中是使用基尼指数来计算的，也就是基尼不纯度，决策数首先要构造好后才可以计算特征重要性，当然，我们在构建数的过程中已近计算好了特征重要性的一些值，如基尼指数，最后我们得到特征重要性的话，就直接将基尼指数做些操作就可以了。在sklearn中，feature_importances_应当就是这个Gini importance，也是就<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">N_t / N * (impurity - N_t_R / N_t * right_impurity</span><br><span class="line">                    - N_t_L / N_t * left_impurity)</span><br></pre></td></tr></table></figure></p>
<h3 id="softmax的这个小细节问题吗"><a href="#softmax的这个小细节问题吗" class="headerlink" title="softmax的这个小细节问题吗?"></a>softmax的这个小细节问题吗?</h3><p>在我们的softmax计算过程中会遇到上溢下溢的问题，这点我们可以从softmax的函数中看到。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f(x) = \frac&#123;&#123;\exp (x)&#125;&#125;&#123;&#123;\sum\limits_&#123;i = 1&#125;^k &#123;\exp (x)&#125; &#125;&#125;</span><br></pre></td></tr></table></figure><br>可以看到我们的分子和分母都是指数函数，当<code>$x$</code>取值过大时会导致数据溢出，当<code>$x$</code>都很小的时候，分母为0，举个例子，当x=[10000,5000,2000]的时候，超过了计算机所能存储的最大范围，就会发生溢出。当x=[-10000,-1000,-34343]的时候，分母很小很小，基本为0，导致计算结果为nan.</p>
<p>那如何解决呢，只要将x进行变换就可以,将原数组变成x-max(x)。对于x=[10000,5000,2000]，则变成x=[0,-5000,-8000]，这样分母最少为1，分子不用说没问题也不会溢出。为啥减去一个max(x)就可以呢，我们看如下的公式：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\frac&#123;&#123;\exp (x - a)&#125;&#125;&#123;&#123;\sum\limits_&#123;i = 1&#125;^k &#123;\exp (x - a)&#125; &#125;&#125; = \frac&#123;&#123;\exp (x)\exp ( - a)&#125;&#125;&#123;&#123;\exp ( - a)\sum\limits_&#123;i = 1&#125;^k &#123;\exp (x)&#125; &#125;&#125;</span><br></pre></td></tr></table></figure><br>这样就可以啦。</p>
<h3 id="adaboost为什么不容易过拟合？"><a href="#adaboost为什么不容易过拟合？" class="headerlink" title="adaboost为什么不容易过拟合？"></a>adaboost为什么不容易过拟合？</h3><p>这里需要用到一个理论来说一下。<br>Margin理论讨论的主要是学习算法在训练样本上的信心，学习算法的容量是不是随着训练轮数的增加而增加呢，其实并不一定，近来有工作表明，有差异的学习器的组合，能够起到正则化的作用，也就是减少学习算法容量（Diversity regularized ensemble pruning. ECML’12; On the Generalization Error Bounds of Neural Networks under Diversity-Inducing Mutual Angular Regularization）。在许多variance-bias 分解实验中也观察到，AdaBoost不仅是减少了bias，同时也减少了variance，variance的减少往往与算法容量减少有关。</p>
<p>详细见<br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/41047671/answer/127832345">https://www.zhihu.com/question/41047671/answer/127832345</a></p>
<h3 id="Random-Forest可以用来做聚类？"><a href="#Random-Forest可以用来做聚类？" class="headerlink" title="Random Forest可以用来做聚类？"></a>Random Forest可以用来做聚类？</h3><p>其实随机森林是可以用来做聚类的，对于没有标签的特征，随机森林通过生成数据来实现聚类。其主要的步骤如下：</p>
<p>第一步：生成假冒数据和临时标签。</p>
<p>我们先给原数据集增加一列，名叫“标签”，原生数据每一行的标签都是“1”。下面生成一些假数据，假数据的每一列都是从原生数据中根据其经验分布随机产生的，人工合成的数据的标签是“0”。举个例子，</p>
<p>标签 身高 体重 年龄</p>
<p>1 184 158 25</p>
<p>1 170 162 37</p>
<p>1 165 132 45</p>
<p>1 110 78 9</p>
<p>1 145 100 14</p>
<p>1 … … …</p>
<p>上面是原生数据，下面我们开始制造虚假数据</p>
<p>标签 身高 体重 年龄</p>
<p>1 184 158 25</p>
<p>1 170 162 37</p>
<p>1 165 132 45</p>
<p>1 110 78 9</p>
<p>1 145 100 14</p>
<p>1 … … …</p>
<p>0 170 100 9</p>
<p>0 110 162 37</p>
<p>0 165 158 14</p>
<p>每行假数据的每一个元素都是从它所在的那一列中随机抽取的，列和列之间的抽取是独立的。这样一来，人工合成的假数据就破坏了原有数据的结构性。现在我们的数据集和标签就生成完了。</p>
<p>第二步：用该数据集训练Random Forest并获得样本间的临近性(proximity)。</p>
<p>假设原生样本有N行，我们再生成M个假数据。现在我们就有了带标签的样本之后就可以用它训练出一个Random Forest。Random Forest在训练的同时，可以返回样本之间的临近性(proximity，两个样本出现在树杈同一节点的频率越高，它们就越临近)。我们就有了一个(N+M)x(N+M)的临近矩阵（这是个对称矩阵）。把与假数据相关的M行、M列去掉，我们就得到了NxN的矩阵，矩阵的第i行第j列的数值就是原生数据中第i个样本和第j个样本之间的临近性。</p>
<p>第三步：根据每个样本点两两之间的临近性来聚类。</p>
<p>这个是最后一步，在其中可以用两两之间的临近性当做两两之间的距离，然后再利用常规的聚类算法，比如层次聚类法(Hierarchical clustering)，就可以完成对原样本的聚类。</p>
<h3 id="组合弱学习器的算法？"><a href="#组合弱学习器的算法？" class="headerlink" title="组合弱学习器的算法？"></a>组合弱学习器的算法？</h3><p>为了建立一个集成学习方法，我们首先要选择待聚合的基础模型。在大多数情况下（包括在众所周知的 bagging 和 boosting 方法中），我们会使用单一的基础学习算法，这样一来我们就有了以不同方式训练的同质弱学习器。这样得到的集成模型被称为「同质的」。然而，也有一些方法使用不同种类的基础学习算法：将一些异质的弱学习器组合成「异质集成模型」。很重要的一点是：我们对弱学习器的选择应该和我们聚合这些模型的方式相一致。如果我们选择具有低偏置高方差的基础模型，我们应该使用一种倾向于减小方差的聚合方法；而如果我们选择具有低方差高偏置的基础模型，我们应该使用一种倾向于减小偏置的聚合方法。</p>
<p>bagging，该方法通常考虑的是同质弱学习器，相互独立地并行学习这些弱学习器，并按照某种确定性的平均过程将它们组合起来。boosting，该方法通常考虑的也是同质弱学习器。它以一种高度自适应的方法顺序地学习这些弱学习器（每个基础模型都依赖于前面的模型），并按照某种确定性的策略将它们组合起来。stacking，该方法通常考虑的是异质弱学习器，并行地学习它们，并通过训练一个「元模型」将它们组合起来，根据不同弱模型的预测结果输出一个最终的预测结果。</p>
<p>详细见<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/6588817">https://zhuanlan.zhihu.com/p/6588817</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" class="post-title-link" itemprop="url">非监督学习</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-23 20:48:13" itemprop="dateModified" datetime="2024-03-23T20:48:13+08:00">2024-03-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h1><h2 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h2><h3 id="什么是非监督学习？"><a href="#什么是非监督学习？" class="headerlink" title="什么是非监督学习？"></a>什么是非监督学习？</h3><p>非监督学习是机器学习任务的一种。它从无标记的训练数据中推断结论。最典型的无监督学习就是聚类分析，它可以在探索性数据分析阶段用于发现隐藏的模式或者对数据进行分组。一句话：给定数据，寻找隐藏的结构。</p>
<h3 id="常见的非监督学习包括哪些？"><a href="#常见的非监督学习包括哪些？" class="headerlink" title="常见的非监督学习包括哪些？"></a>常见的非监督学习包括哪些？</h3><p>无监督学习算法有几种类型，以下是其中最重要的12种:</p>
<ol>
<li>聚类算法<br>k-means聚类是一种流行的聚类算法，它将数据划分为k组。</li>
<li>降维算法<br>降低了数据的维数，使其更容易可视化和处理主成分分析(PCA)是一种降维算法，将数据投影到低维空间，PCA可以用来将数据降维到其最重要的特征。</li>
<li>异常检测算法<br>支持向量机是可以用于异常检测(示例)。异常检测算法用于检测数据集中的异常点，异常检测的方法有很多，但大多数可以分为有监督和无监督两种。监督方法需要标记数据集，而无监督方法不需要。无监督异常检测算法通常基于密度估计，试图找到数据空间中密集的区域外的点。一个简单的方法是计算每个点到k个最近邻居的平均距离。距离相邻点非常远的点很可能是异常点。还有很多基于密度的异常检测算法，包括局部离群因子(Local Outlier Factor,LOF)和支持向量数据描述(Support Vector Domain Description,SVDD)。这些算法比简单的k近邻方法更复杂，通常可以检测到更细微的异常。大多数异常检测算法都需要进行调整，例如指定一个参数来控制算法对异常的敏感程度。如果参数过低，算法可能会漏掉一些异常。如果设置过高，算法可能会产生误报(将正常点识别为异常点)。</li>
<li>分割算法<br>分割算法可以将图像分割为前景和背景。这些算法可以在不需要人工监督的情况下自动将数据集分割成有意义的组。这个领域中比较知名的一个算法是k-means算法。该算法通过最小化组内距离平方和将数据点分成k组。另一种流行的分割算法是mean shift算法。该算法通过迭代地将每个数据点移向其局部邻域的中心来实现。mean shift对异常值具有较强的鲁棒性，可以处理密度不均匀的数据集。但是在大型数据集上运行它的计算成本可能很高。高斯混合模型(GMM)是一种可用于分割的概率模型。以前gmm需要大量的计算来训练，但最近的研究进展使其更快。gmm非常灵活，可以用于任何类型的数据。但是它们有时并不能总是产生最好的结果。对于简单的数据集，k-means是一个很好的选择，而gmm则更适合于复杂的数据集。mean shift可以用于任何一种情况，但在大型数据集上计算的成本会很高。</li>
<li>去噪算法<br>小波变换可以用于图像去噪。但是各种来源可能会产生噪声，包括数据损坏、缺失值和异常值。去噪算法通过减少数据中的噪声量来提高无监督学习模型的准确性。现有的去噪算法有多种，包括主成分分析(PCA)、独立成分分析(ICA)和非负矩阵分解(NMF)。</li>
<li>链接预测算法预测数据点之间的未来连接<br>例如，网络中两个节点之间的未来交互，链接预测可用于预测哪些人将成为社交网络中的朋友。 更常用的链接预测算法之一是优先连接算法，它预测如果两个节点有许多现有连接，则它们更有可能被连接。另一种流行的链路预测算法是局部路径算法，它预测如果两个节点共享一个共同的邻居，那么它们更有可能被关联。该算法可以捕获“结构等价”的概念，因此在生物网络中经常使用。最后，random walk with restart算法也是一种链路预测算法，它模拟网络上的一个随机走动的人，在随机节点处重新启动步行者。然后，步行者到达特定节点的概率被用来衡量两个节点之间存在连接的可能性。</li>
<li>强化学习算法<br>通过反复试验来进行学习Q-learning是基于值的学习算法的一个例子;它实现简单并且通用。但是Q-learning有时会收敛到次优解。另一个例子是TD learning，它在计算上Q-learning学习要求更高，但通常可以找到更好的解决方案。</li>
<li>生成模型<br>算法使用训练数据生成新的数据自编码器是生成模型，可用于从图像数据集创建独特的图像。在机器学习中，生成模型是一种捕捉一组数据的统计属性的模型。这些模型可以用来生成新的数据，就像它们所用的训练的数据一样。生成模型用于各种任务，如无监督学习，数据压缩和去噪。生成模型有很多种，比如隐马尔可夫模型和玻尔兹曼机。每种模型都有其优缺点，并且适用于不同的任务。隐马尔可夫模型擅长对顺序数据建模，而玻尔兹曼机器更擅长对高维数据建模。通过在无标记数据上训练它们，生成模型可以用于无监督学习。一旦模型经过训练，就可以用来生成新的数据。然后这些生成的数据可以由人类或其他机器学习算法进行标记。这个过程可以重复，直到生成模型学会生成数据，就像想要的输出。</li>
</ol>
<h3 id="非监督学习的主要特点？"><a href="#非监督学习的主要特点？" class="headerlink" title="非监督学习的主要特点？"></a>非监督学习的主要特点？</h3><ol>
<li><p>无标签</p>
</li>
<li><p>无反馈</p>
</li>
<li><p>寻找隐藏的结构</p>
</li>
</ol>
<h3 id="什么是非监督学习的功能？"><a href="#什么是非监督学习的功能？" class="headerlink" title="什么是非监督学习的功能？"></a>什么是非监督学习的功能？</h3><ol>
<li>求数据的集群 </li>
<li>求出数据的低维表达</li>
<li>查找数据有趣的方向</li>
<li>有趣的坐标和相关性</li>
<li>发现显著的观测值和数据集清理</li>
</ol>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/24448657/answer/616164140">https://www.zhihu.com/question/24448657/answer/616164140</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/23194489/answer/41744596">https://www.zhihu.com/question/23194489/answer/41744596</a></p>
</blockquote>
<h2 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a>聚类算法</h2><h3 id="介绍下Kmeans算法？"><a href="#介绍下Kmeans算法？" class="headerlink" title="介绍下Kmeans算法？"></a>介绍下Kmeans算法？</h3><p>是一直监督的学习方法，主要用于聚类，通过方法将数据分为K个类。</p>
<h3 id="聚类算法的分类"><a href="#聚类算法的分类" class="headerlink" title="聚类算法的分类"></a>聚类算法的分类</h3><p>聚类算法一般可以用基于划分、基于层次、基于密度、基于网格、基于模型、基于图等方式来进行分类。</p>
<h3 id="Kmeans如何选择初始点？"><a href="#Kmeans如何选择初始点？" class="headerlink" title="Kmeans如何选择初始点？"></a>Kmeans如何选择初始点？</h3><p>常见的方法是随机的选取初始质心，但是这样簇的质量常常很差。处理选取初始质心问题的一种常用技术是：多次运行，每次使用一组不同的随机初始质心，然后选取具有最小SSE（误差的平方和）的簇集。这种策略简单，但是效果可能不好，这取决于数据集和寻找的簇的个数。</p>
<p>第二种有效的方法是，取一个样本，并使用层次聚类技术对它聚类。从层次聚类中提取K个簇，并用这些簇的质心作为初始质心。该方法通常很有效，但仅对下列情况有效：（1）样本相对较小，例如数百到数千（层次聚类开销较大）；（2）K相对于样本大小较小</p>
<p>第三种选择初始质心的方法，随机地选择第一个点，或取所有点的质心作为第一个点。然后，对于每个后继初始质心，选择离已经选取过的初始质心最远的点。使用这种方法，确保了选择的初始质心不仅是随机的，而且是散开的。但是，这种方法可能选中离群点。此外，求离当前初始质心集最远的点开销也非常大。为了克服这个问题，通常<br>该方法用于点样本。由于离群点很少（多了就不是离群点了），它们多半不会在随机样本中出现。计算量也大幅减少。</p>
<h3 id="大体流程描述一下"><a href="#大体流程描述一下" class="headerlink" title="大体流程描述一下"></a>大体流程描述一下</h3><ol>
<li>随机选择k个点作为中心点</li>
<li>分簇：利用定义好的距离（可以是欧式或者其他）对比每个点到k个点哪个近，则为哪个簇</li>
<li>更新：将第k个簇取平均得到新的中心点</li>
<li>循环23步骤直到中心点不变（可以设定收敛的最小误差或者设置迭代轮数）</li>
</ol>
<h3 id="Kmeans有哪些不同距离度量方式？"><a href="#Kmeans有哪些不同距离度量方式？" class="headerlink" title="Kmeans有哪些不同距离度量方式？"></a>Kmeans有哪些不同距离度量方式？</h3><ul>
<li><p>欧几里得距离</p>
</li>
<li><p>曼哈顿距离</p>
</li>
<li><p>余弦距离</p>
</li>
</ul>
<h3 id="如何选取k？"><a href="#如何选取k？" class="headerlink" title="如何选取k？"></a>如何选取k？</h3><ol>
<li><p>手肘法<br>核心指标是SSE误差平方和，外面是对k求和，里面是对簇求和，求和内容是每个样本和他所属簇的均值的差的平方。核心思想就是随着聚类数k增大，样本划分更加精细，SSE会越来越小，曲线呈现下降趋势，找到一个点是骤降的，即下降幅度最大，也即是最后是在手肘地方</p>
</li>
<li><p>Gap Static<br>不需要像上述手肘一样还需要画出来去判断，只需计算值，当这个值最大时，它所对应的k就是最好的，方便批量化作业</p>
</li>
<li><p>根据业务选取</p>
</li>
</ol>
<h3 id="为什么会产生空簇？"><a href="#为什么会产生空簇？" class="headerlink" title="为什么会产生空簇？"></a>为什么会产生空簇？</h3><p>这就要从簇中元素的分配说起。设当前的簇数为n，那么依次计算n个簇的质心，然后依次遍历所有元素，将其分配到到距其最近的一个质心簇中。在这个分配过程中，就可能存在没有一个点被分配到该质心中，这就产生了空簇。</p>
<h3 id="如何对空簇进行处理？"><a href="#如何对空簇进行处理？" class="headerlink" title="如何对空簇进行处理？"></a>如何对空簇进行处理？</h3><p>如果可以减少聚类的类数，那么就可以尝试直接放弃该空簇。<br>重新运行算法再次随机分类<br>将离其所属簇最远的点分配给空簇</p>
<h3 id="K-means对异常值是否敏感？为什么？"><a href="#K-means对异常值是否敏感？为什么？" class="headerlink" title="K-means对异常值是否敏感？为什么？"></a>K-means对异常值是否敏感？为什么？</h3><p>K-means对异常值较为敏感，因为一个集合内的元素均值易受到一个极大值的影响。当存在异常值的情况下，均值所计算出来的中心位置很可能不能够反映真实的类别中心。</p>
<h3 id="如何评估聚类效果？"><a href="#如何评估聚类效果？" class="headerlink" title="如何评估聚类效果？"></a>如何评估聚类效果？</h3><p>聚类往往不像分类一样有一个最优化目标和学习过程，聚类更像一个统计方法，将相似的数据和不相似的数据分开。所以，评估聚类效果可以从以下维度下手：</p>
<p>（1）聚类趋势（对数据进行评估）<br>霍普金斯统计量(Hopkins Statistic)评估给定数据集是否存在有意义的可聚类的非随机结构。如果一个数据集是由随机的均匀的点生成的，虽然也可以产生聚类结果，但该结果没有意义，聚类的前提是需要数据非均匀分布的。</p>
<p>（2）判断聚类的簇数是否为最佳<br>可用业务分析法、观察法、Gap Statistic方法等找到最佳的分类数与实际簇数做比较（见第四点）。</p>
<p>（3）聚类质量<br>因为是无监督学习，所以一般通过评估类的分离情况来决定聚类质量。类内越紧密，类间距离越小则质量越高。</p>
<h3 id="Kmeans优缺点？"><a href="#Kmeans优缺点？" class="headerlink" title="Kmeans优缺点？"></a>Kmeans优缺点？</h3><ul>
<li><p>优点<br>时间复杂度低，NKt，样本数乘以簇数乘以迭代轮数，接近线性</p>
</li>
<li><p>缺点</p>
</li>
</ul>
<ol>
<li>对数值敏感（因此需要做预处理、归一化处理），对异常值敏感（因此需要做离散点处理）</li>
<li>k难以选取</li>
<li>聚类效果依赖于中心初始化</li>
<li>局部最优</li>
</ol>
<h3 id="Kmeans-相比于Kmeans做的优化？"><a href="#Kmeans-相比于Kmeans做的优化？" class="headerlink" title="Kmeans++相比于Kmeans做的优化？"></a>Kmeans++相比于Kmeans做的优化？</h3><p>假设已经选取了n个初始聚类中心，则在选择n+1个聚类中心时，距离当前n个聚类中心越远的点会有更好的概率被选择为第n+1类聚类的中心。聚类中心当然是互相隔离的越远越好，之后的算法步骤同于k-means。（第一个点仍然是随机初始化）</p>
<h3 id="Kmeans和EM算法的联系？"><a href="#Kmeans和EM算法的联系？" class="headerlink" title="Kmeans和EM算法的联系？"></a>Kmeans和EM算法的联系？</h3><p>Kmeans等价于用EM算法求解以下含隐变量的最大似然问题，（c就是取的k，从1到K）。</p>
<p>E步求上述给定x和mui下c的条件概率期望，这里条件概率可以定义为如果分到最小类则为1，到其他类距离比最小的大，则为0。求期望也即是使P概率最大化。相当于先固定好了质心mui，然后将每个点找到离它最近的簇c。</p>
<p>M步，更新mui参数，此时是每个簇c已确定，对应于kmeans里更新聚类中心。</p>
<h3 id="介绍西喜爱DBSCAN算法？"><a href="#介绍西喜爱DBSCAN算法？" class="headerlink" title="介绍西喜爱DBSCAN算法？"></a>介绍西喜爱DBSCAN算法？</h3><p>DBSCAN（Density-Based Spatial Clustering of Applications with Noise），具有噪声的基于密度的聚类方法）是一种基于密度的空间聚类算法。 该算法将具有足够密度的区域划分为簇，并在具有噪声的空间数据库中发现任意形状的簇，它将簇定义为密度相连的点的最大集合。</p>
<h3 id="DBSCAN算法流程是什么样的？"><a href="#DBSCAN算法流程是什么样的？" class="headerlink" title="DBSCAN算法流程是什么样的？"></a>DBSCAN算法流程是什么样的？</h3><p>（1）从数据集中任选一个未访问过的点作为初始点，这个点称为“种子“，”。以该初始点为圆心，以e为半径画一个圆，圆形区域即为该点的邻域<br>（2）如果在该初始点的邻域中至少含有MinPts个点，则该点是一个核心对象（core object），聚类开始，该点成为新聚类中的第一个点。否则，该点将被标记为噪声点（noise）。在这两种情况下，这一点都被标记为“已访问（visited）”。<br>（3）对于新聚类中的第一个点，其距离内的点都成为同一聚类中的一部分。<br>（4）若核心对象邻域内的点满足步骤（2）的条件，则成为新的核心对象，并吸纳其距离内的点为同一聚类中的一部分，不断重复此过程，直到该聚类附近的所有点都已被访问。<br>（5）当完成当前的聚类时，重新检索下一个新的未访问点，重复步骤（1）~（4），直到所有点都被标记为“已访问”。</p>
<h3 id="DBSCAN中的参数如何确定？"><a href="#DBSCAN中的参数如何确定？" class="headerlink" title="DBSCAN中的参数如何确定？"></a>DBSCAN中的参数如何确定？</h3><p>DBSCAN也是一种较为常用的算法，DBSCAN中重要的参数是Eps和MinPts，那么这两个参数该如何确定呢？</p>
<p>(1)  Eps的值可以使用绘制k-距离曲线(k-distance graph)方法得当，在k-距离曲线图明显拐点位置为对应较好的参数。若参数设置过小，大部分数据不能聚类；若参数设置过大，多个簇和大部分对象会归并到同一个簇中。</p>
<p>K-距离：K距离的定义在DBSCAN算法原文中给出了详细解说，给定K邻域参数k,对于数据中的每个点，计算对应的第k个最近邻域距离，并将数据集所有点对应的最近邻域距离按照降序方式排序，称这幅图为排序的k距离图，选择该图中第一个谷值点位置对应的k距离值设定为Eps。一般将k值设为4。</p>
<p>(2)  MinPts的选取有一个指导性的原则（a rule of thumb），MinPts≥dim+1,其中dim表示待聚类数据的维度。MinPts设置为1是不合理的，因为设置为1，则每个独立点都是一个簇，MinPts≤2时，与层次距离最近邻域结果相同，因此，MinPts必须选择大于等于3的值。若该值选取过小，则稀疏簇中结果由于密度小于MinPts，从而被认为是边界点儿不被用于在类的进一步扩展；若该值过大，则密度较大的两个邻近簇可能被合并为同一簇。因此，该值是否设置适当会对聚类结果造成较大影响。</p>
<h3 id="DBSCAN的主要参数是？"><a href="#DBSCAN的主要参数是？" class="headerlink" title="DBSCAN的主要参数是？"></a>DBSCAN的主要参数是？</h3><p>邻域半径R和最少点数目minpoints</p>
<h3 id="解释下密度直达，密度可达，密度相连，非密度相连的关系？"><a href="#解释下密度直达，密度可达，密度相连，非密度相连的关系？" class="headerlink" title="解释下密度直达，密度可达，密度相连，非密度相连的关系？"></a>解释下密度直达，密度可达，密度相连，非密度相连的关系？</h3><p>如果P为核心点，Q在P的R邻域内，那么称P到Q密度直达。任何核心点到其自身密度直达，密度直达不具有对称性，如果P到Q密度直达，那么Q到P不一定密度直达。</p>
<p>如果存在核心点P2，P3，……，Pn，且P1到P2密度直达，P2到P3密度直达，……，P(n-1)到Pn密度直达，Pn到Q密度直达，则P1到Q密度可达。密度可达也不具有对称性。</p>
<p>如果存在核心点S，使得S到P和Q都密度可达，则P和Q密度相连。密度相连具有对称性，如果P和Q密度相连，那么Q和P也一定密度相连。密度相连的两个点属于同一个聚类簇。</p>
<p>如果两个点不属于密度相连关系，则两个点非密度相连。非密度相连的两个点属于不同的聚类簇，或者其中存在噪声点。</p>
<h3 id="DBSCAN算法优缺点"><a href="#DBSCAN算法优缺点" class="headerlink" title="DBSCAN算法优缺点"></a>DBSCAN算法优缺点</h3><p>和传统的 k-means 算法相比，DBSCAN 算法不需要输入簇数 k 而且可以发现任意形状的聚类簇，同时，在聚类时可以找出异常点。</p>
<p>DBSCAN 算法的主要优点如下。</p>
<p>1）可以对任意形状的稠密数据集进行聚类，而 k-means 之类的聚类算法一般只适用于凸数据集。</p>
<p>2）可以在聚类的同时发现异常点，对数据集中的异常点不敏感。</p>
<p>3）聚类结果没有偏倚，而 k-means 之类的聚类算法的初始值对聚类结果有很大影响。</p>
<p>DBSCAN 算法的主要缺点如下。</p>
<p>1）样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差，这时用 DBSCAN 算法一般不适合。</p>
<p>2）样本集较大时，聚类收敛时间较长，此时可以对搜索最近邻时建立的 KD 树或者球树进行规模限制来进行改进。</p>
<p>3）调试参数比较复杂时，主要需要对距离阈值 Eps，邻域样本数阈值 MinPts 进行联合调参，不同的参数组合对最后的聚类效果有较大影响。</p>
<p>4）对于整个数据集只采用了一组参数。如果数据集中存在不同密度的簇或者嵌套簇，则 DBSCAN 算法不能处理。为了解决这个问题，有人提出了 OPTICS 算法。</p>
<p>5）DBSCAN 算法可过滤噪声点，这同时也是其缺点，这造成了其不适用于某些领域，如对网络安全领域中恶意攻击的判断。</p>
<h3 id="解释下你知道的聚类算法以及他们之间的区别？"><a href="#解释下你知道的聚类算法以及他们之间的区别？" class="headerlink" title="解释下你知道的聚类算法以及他们之间的区别？"></a>解释下你知道的聚类算法以及他们之间的区别？</h3><p>各个聚类算法的对比如下：<br><img src="https://img-blog.csdnimg.cn/be63d6ad2f5f4406b9fe884f0be62f66.png" alt="img"></p>
<h3 id="介绍下层次聚类算法"><a href="#介绍下层次聚类算法" class="headerlink" title="介绍下层次聚类算法?"></a>介绍下层次聚类算法?</h3><p>根据层次分解的顺序是自底向上的还是自上向下的，层次聚类算法分为凝聚的层次聚类算法和分裂的层次聚类算法。　凝聚型层次聚类的策略是先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到所有对象都在一个簇中，或者某个终结条件被满足。绝大多数层次聚类属于凝聚型层次聚类，它们只是在簇间相似度的定义上有所不同。</p>
<p>算法流程主要如下所示：<br>(1) 将每个对象看作一类，计算两两之间的最小距离；<br>(2) 将距离最小的两个类合并成一个新类；<br>(3) 重新计算新类与所有类之间的距离；<br>(4) 重复(2)、(3)，直到所有类最后合并成一类。 </p>
<h3 id="参考-1"><a href="#参考-1" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/542290564">https://zhuanlan.zhihu.com/p/542290564</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/Chenzhi_2016/article/details/79451201">https://blog.csdn.net/Chenzhi_2016/article/details/79451201</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_43550820/article/details/108802267">https://blog.csdn.net/qq_43550820/article/details/108802267</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44507034/article/details/110010543">https://blog.csdn.net/weixin_44507034/article/details/110010543</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/hansome_hong/article/details/107596543">https://blog.csdn.net/hansome_hong/article/details/107596543</a></p>
</blockquote>
<h2 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h2><h3 id="降维的必要性和目的是什么？"><a href="#降维的必要性和目的是什么？" class="headerlink" title="降维的必要性和目的是什么？"></a>降维的必要性和目的是什么？</h3><p>降维的必要性：</p>
<p>多重共线性和预测变量之间相互关联。多重共线性会导致解空间的不稳定，从而可能导致结果的不连贯。<br>高维空间本身具有稀疏性。一维正态分布有68%的值落于正负标准差之间，而在十维空间上只有2%。<br>过多的变量，对查找规律造成冗余麻烦。<br>仅在变量层面上分析可能会忽略变量之间的潜在联系。例如几个预测变量可能落入仅反映数据某一方面特征的一个组内。</p>
<p>降维的目的：</p>
<p>减少预测变量的个数。<br>确保这些变量是相互独立的。<br>提供一个框架来解释结果。相关特征，特别是重要特征更能在数据中明确的显示出来；如果只有两维或者三维的话，更便于可视化展示。<br>数据在低维下更容易处理、更容易使用。<br>去除数据噪声。<br>降低算法运算开销。</p>
<h3 id="PCA介绍下？"><a href="#PCA介绍下？" class="headerlink" title="PCA介绍下？"></a>PCA介绍下？</h3><p>PCA(Principal Component Analysis)是一种常用的数据分析方法。PCA通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。数据降维是无监督学习的另外一个常见问题。</p>
<h3 id="PCA算法流程？"><a href="#PCA算法流程？" class="headerlink" title="PCA算法流程？"></a>PCA算法流程？</h3><ol>
<li>对所有的样本进行中心化</li>
<li>计算样本的协方差矩阵</li>
<li>求出协方差矩阵的特征值及对应的特征向量</li>
<li>将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P</li>
<li>Y=PX即为降维到k维后的数据</li>
</ol>
<h3 id="PCA如何解决非线性降维？"><a href="#PCA如何解决非线性降维？" class="headerlink" title="PCA如何解决非线性降维？"></a>PCA如何解决非线性降维？</h3><p>想解决非线性问题，就需要做一些调整。PCA也是一种线性变换。核主成分分析（Kernel PCA）可以处理非线性问题。数据先通过核函数（kernel function）转换成一个新空间，然后再用PCA处理。</p>
<h3 id="降维之后的维度怎么确定？"><a href="#降维之后的维度怎么确定？" class="headerlink" title="降维之后的维度怎么确定？"></a>降维之后的维度怎么确定？</h3><p>可以利用交叉验证，再选择一个很简单的分类器，来选择比较好的 k‘ 的值<br>可以设置一个比重阈值 t，比如 95%，然后选择满足阈值的最小的 k‘：</p>
<h3 id="LDA和PCA区别？"><a href="#LDA和PCA区别？" class="headerlink" title="LDA和PCA区别？"></a>LDA和PCA区别？</h3><p>相同点<br>(1) 两者的作用是用来降维的<br>(2) 两者都假设符合高斯分布  </p>
<p>不同点<br>(1) LDA是有监督的降维方法，PCA是无监督的。<br>(2) LDA降维最多降到类别数K-1的维数，PCA没有这个限制。<br>(3) LDA更依赖均值，如果样本信息更依赖方差的话，效果将没有PCA好。<br>(4) LDA可能会过拟合数据。</p>
<h3 id="PCA算法优缺点？"><a href="#PCA算法优缺点？" class="headerlink" title="PCA算法优缺点？"></a>PCA算法优缺点？</h3><p>PCA算法的主要优点有：</p>
<ul>
<li>仅仅需要以方差衡量信息量，不受数据集以外的因素影响。　</li>
<li>各主成分之间正交，可消除原始数据成分间的相互影响的因素。<br>计算方法简单，主要运算是特征值分解，易于实现。    </li>
</ul>
<p>PCA算法的主要缺点有：<br>主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的解释性强。<br>方差小的非主成分也可能含有对样本差异的重要信息，因降维丢弃可能对后续数据处理有影响。</p>
<h3 id="PCA和SVD的联系和区别？"><a href="#PCA和SVD的联系和区别？" class="headerlink" title="PCA和SVD的联系和区别？"></a>PCA和SVD的联系和区别？</h3><ol>
<li>两者都是矩阵分解的技术，一个直接分解SVD，一个是对协方差矩阵操作后分解PCA</li>
<li>奇异值和特征向量存在关系，即有<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\lambda _i&#125; = &#123;s_i&#125;^2/(n - 1)</span><br></pre></td></tr></table></figure></li>
<li>SVD可以获取另一个方向上的主成分，而PCA只能获得单个方向上的主成分，PCA只与SVD的右奇异向量的压缩效果相同</li>
<li>通过SVD可以得到PCA相同的结果，但是SVD通常比直接使用PCA更稳定。因为在PCA求协方差时很可能会丢失一些精度。例如Lauchli矩阵</li>
</ol>
<h3 id="除了PCA你还知道哪些降维方法"><a href="#除了PCA你还知道哪些降维方法" class="headerlink" title="除了PCA你还知道哪些降维方法"></a>除了PCA你还知道哪些降维方法</h3><p>当然PCA是众所周知的降维方法，SVD也是一种，除此之外，还有如LDA、LLE以及LE。</p>
<ul>
<li>PCA<br>PCA也就是主成份分析，Principal Component Analysis(PCA)是现如今最流行的无监督线性降维方法之一了，其主要思想是数据经过某种投影，或者说乘以一个矩阵之后，得到的新的矩阵在所投影的维度上数据的方差最大，以此使用较少的数据维度，同时保留住较多的原数据点的特性。PCA的目标主要如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathop &#123;\max &#125;\limits_w \frac&#123;1&#125;&#123;m&#125;\sum\limits_&#123;i = 1&#125;^m &#123;&#123;&#123;(&#123;w^T&#125;(&#123;x_i&#125; - \bar x))&#125;^2&#125;&#125;</span><br></pre></td></tr></table></figure>
PCA追求的是在降维之后能够最大化保持数据的内在信息，并通过衡量在投影方向上的数据方差的大小来衡量该方向的重要性。但是这样投影以后对数据 的区分作用并不大，反而可能使得数据点揉杂在一起无法区分。这也是PCA存在的最大一个问题，这导致使用PCA在很多情况下的分类效果并不好。具体可以看下图所示，若使用PCA将数据点投影至一维空间上时，PCA会选择2轴，这使得原本很容易区分的两簇点被揉杂在一起变得无法区分；而这时若选择1轴将会得 到很好的区分结果。而下面所说的LDA就将数据映射到轴1上的。<br><img src="https://img-blog.csdnimg.cn/ab9392f7a7dc4931b59295671a2a9cbb.png" alt="image"><br>(2) LDA<br>Linear Discriminant Analysis(也有叫做Fisher Linear Discriminant)是一种有监督的（supervised）线性降维算法。与PCA保持数据信息不同，LDA是为了使得降维后的数据点尽可能地容易被区分，如上图投影导轴1上，这里的公式推导就不说明。<br>(3) LLE<br>上面说到了线性降维方法，当然还有非线性降维方法，这里介绍下LLE，也就是局部线性嵌入，它能够使降维后的数据较好地保持原有流形结构 。LLE可以说是流形学习方法最经典的工作之一。很多后续的流形学习、降维方法都与LLE有密切联系。下图给了一个典型的例子，看到降维后数据还保持了流形的结构。<br><img src="https://www.icode9.com/i/ll/?i=20200316212600332.png?,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODA1Mzg4Nw==,size_1,color_FFFFFF,t_70#pic_center" alt="image"><br>(4) LE<br>Laplacian Eigenmaps 是用局部的角度去构建数据之间的关系。具体来讲，拉普拉斯特征映射是一种基于图的降维算法，它希望相互间有关系的点（在图中相连的点）在降维后的空间中尽可能的靠近，从而在降维后仍能保持原有的数据结构。 如果两个数据实例i和j很相似，那么i和j在降维后目标子空间中应该尽量接近。Laplacian Eigenmaps可以反映出数据内在的流形结构。<br>拉普拉斯特征映射通过构建邻接矩阵为W的图来重构数据流形的局部结构特征。其主要思想是，如果两个数据实例i和j很相似，那么i和j在降维后目标子空间中应该尽量接近。<br><img src="https://img-blog.csdnimg.cn/20191215213534273.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDgwMTM2NA==,size_16,color_FFFFFF,t_70" alt="image"></li>
</ul>
<h3 id="介绍下LDA算法？"><a href="#介绍下LDA算法？" class="headerlink" title="介绍下LDA算法？"></a>介绍下LDA算法？</h3><p>LDA是一种特征抽取的技术，用于分类任务的降维方法，其目标是向最大化类间差异，最小化类内差异的方向投影。</p>
<h3 id="LDA的优缺点？"><a href="#LDA的优缺点？" class="headerlink" title="LDA的优缺点？"></a>LDA的优缺点？</h3><p>LDA算法的主要优点有：</p>
<ol>
<li><p>在降维过程中可以使用类别的先验知识经验，而像PCA这样的无监督学习则无法使用类别先验知识。</p>
</li>
<li><p>LDA在样本分类信息依赖均值而不是方差的时候，比PCA之类的算法较优。</p>
</li>
</ol>
<p>LDA算法的主要缺点有：</p>
<ol>
<li><p>LDA不适合对非高斯分布样本进行降维，PCA也有这个问题。</p>
</li>
<li><p>LDA降维最多降到类别数k-1的维数，如果我们降维的维度大于k-1，则不能使用LDA。当然目前有一些LDA的进化版算法可以绕过这个问题。</p>
</li>
<li><p>LDA在样本分类信息依赖方差而不是均值的时候，降维效果不好。</p>
</li>
<li><p>LDA可能过度拟合数据。</p>
</li>
</ol>
<h3 id="LDA和PCA的异同？"><a href="#LDA和PCA的异同？" class="headerlink" title="LDA和PCA的异同？"></a>LDA和PCA的异同？</h3><p>首先我们看看相同点：</p>
<ol>
<li><p>两者均可以对数据进行降维。</p>
</li>
<li><p>两者在降维时均使用了矩阵特征分解的思想。</p>
</li>
<li><p>两者都假设数据符合高斯分布。</p>
</li>
</ol>
<p>我们接着看看不同点：</p>
<ol>
<li><p>LDA是有监督的降维方法，而PCA是无监督的降维方法</p>
</li>
<li><p>LDA降维最多降到类别数k-1的维数，而PCA没有这个限制。</p>
</li>
<li><p>LDA除了可以用于降维，还可以用于分类。</p>
</li>
<li><p>LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。</p>
</li>
</ol>
<h3 id="协方差与相关系数的区别和联系是什么？"><a href="#协方差与相关系数的区别和联系是什么？" class="headerlink" title="协方差与相关系数的区别和联系是什么？"></a>协方差与相关系数的区别和联系是什么？</h3><p>协方差：</p>
<p>协方差表示的是两个变量的总体的误差，这与只表示一个变量误差的方差不同。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。</p>
<p>相关系数：</p>
<p>研究变量之间线性相关程度的量，取值范围是[-1,1]。相关系数也可以看成协方差：一种剔除了两个变量量纲影响、标准化后的特殊协方差。</p>
<h3 id="参考-2"><a href="#参考-2" class="headerlink" title="参考"></a>参考</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/32412043">https://zhuanlan.zhihu.com/p/32412043</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/u013719780/article/details/51767341">https://blog.csdn.net/u013719780/article/details/51767341</a><br><a target="_blank" rel="noopener" href="https://www.it610.com/article/1535554599291744256.htm">https://www.it610.com/article/1535554599291744256.htm</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/57156916/">https://zhuanlan.zhihu.com/p/57156916/</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43758551/article/details/88691607">https://blog.csdn.net/weixin_43758551/article/details/88691607</a></p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Tom</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">17</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Tom</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
