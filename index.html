<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="fonts.lug.ustc.edu.cn/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"lilitom.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="算法工程师的日常">
<meta property="og:url" content="https://lilitom.github.io/index.html">
<meta property="og:site_name" content="算法工程师的日常">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Tom">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://lilitom.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>算法工程师的日常</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">算法工程师的日常</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益 404</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lilitom.github.io/2024/03/19/deep_learning/ch1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/deep_learning/ch1/" class="post-title-link" itemprop="url">数学基础面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-24 17:41:48" itemprop="dateModified" datetime="2024-03-24T17:41:48+08:00">2024-03-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>数学基础</h1>
<p>深度学习通常又需要哪些数学的基础？深度学习里的数学到底难在哪里？通常初学者都会有这些问题，在网络推荐及书本推荐里，经常看到会列出一系列数学科目，比如微积分、线性代数、概率论、复变函数、数值计算、优化理论、信息论等等。这些数学知识有相关性，但实际上按照这样的知识范围来学习，学习成本会很久，而且会很枯燥，本章我们通过选举一些数学基础里容易混淆的一些概念做以介绍，帮助大家更好的理清这些易混淆概念之间的关系。</p>
<h2 id="1-1-向量和矩阵">1.1 向量和矩阵</h2>
<h3 id="1-1-1-标量、向量、矩阵、张量之间的联系">1.1.1 标量、向量、矩阵、张量之间的联系</h3>
<p><strong>标量（scalar）</strong><br>
一个标量表示一个单独的数，它不同于线性代数中研究的其他大部分对象（通常是多个数的数组）。我们用斜体表示标量。标量通常被赋予小写的变量名称。</p>
<p><strong>向量（vector）</strong><br>
​一个向量表示一组有序排列的数。通过次序中的索引，我们可以确定每个单独的数。通常我们赋予向量粗体的小写变量名称，比如xx。向量中的元素可以通过带脚标的斜体表示。向量 $X$ 的第一个元素是 $X_1$ ，第二个元素是 $X_2$ ，以此类推。我们也会注明存储在向量中的元素的类型（实数、虚数等）。</p>
<p><strong>矩阵（matrix）</strong><br>
​矩阵是具有相同特征和纬度的对象的集合，表现为一张二维数据表。其意义是一个对象表示为矩阵中的一行，一个特征表示为矩阵中的一列，每个特征都有数值型的取值。通常会赋予矩阵粗体的大写变量名称，比如 $A$ 。</p>
<p><strong>张量（tensor）</strong><br>
​在某些情况下，我们会讨论坐标超过两维的数组。一般地，一个数组中的元素分布在若干维坐标的规则网格中，我们将其称之为张量。使用  $A$  来表示张量“A”。张量 $A$ 中坐标为 $(i,j,k)$ 的元素记作 $A_{(i,j,k)}$ 。</p>
<p><strong>四者之间关系</strong></p>
<blockquote>
<p>标量是0阶张量，向量是一阶张量。举例：<br>
​标量就是知道棍子的长度，但是你不会知道棍子指向哪儿。<br>
​向量就是不但知道棍子的长度，还知道棍子指向前面还是后面。<br>
​张量就是不但知道棍子的长度，也知道棍子指向前面还是后面，还能知道这棍子又向上/下和左/右偏转了多少。</p>
</blockquote>
<h3 id="1-1-2-张量与矩阵的区别">1.1.2 张量与矩阵的区别</h3>
<ul>
<li>从代数角度讲， 矩阵它是向量的推广。向量可以看成一维的“表格”（即分量按照顺序排成一排）， 矩阵是二维的“表格”（分量按照纵横位置排列）， 那么 $n$ 阶张量就是所谓的 $n$ 维的“表格”。 张量的严格定义是利用线性映射来描述。</li>
<li>从几何角度讲， 矩阵是一个真正的几何量，也就是说，它是一个不随参照系的坐标变换而变化的东西。向量也具有这种特性。</li>
<li>张量可以用3×3矩阵形式来表达。</li>
<li>表示标量的数和表示向量的三维数组也可分别看作1×1，1×3的矩阵。</li>
</ul>
<h3 id="1-1-3-矩阵和向量相乘结果">1.1.3 矩阵和向量相乘结果</h3>
<p>若使用爱因斯坦求和约定（Einstein summation convention），矩阵 $A$ ,  $B$ 相乘得到矩阵 $C$ 可以用下式表示：</p>
 $$ a_{ik}*b_{kj}=c_{ij} \tag{1.3-1} $$  
<p>其中， $a_{ik}$ ,  $b_{kj}$ ,  $c_{ij}$ 分别表示矩阵 $A, B, C$ 的元素， $k$ 出现两次，是一个哑变量（Dummy Variables）表示对该参数进行遍历求和。<br>
而矩阵和向量相乘可以看成是矩阵相乘的一个特殊情况，例如：矩阵 $B$ 是一个 $n \times 1$ 的矩阵。</p>
<h3 id="1-1-4-向量和矩阵的范数归纳">1.1.4 向量和矩阵的范数归纳</h3>
<p><strong>向量的范数(norm)</strong><br>
​	定义一个向量为： $\vec{a}=[-5, 6, 8, -10]$ 。任意一组向量设为 $\vec{x}=(x_1,x_2,...,x_N)$ 。其不同范数求解如下：</p>
<ul>
<li>向量的1范数：向量的各个元素的绝对值之和，上述向量 $\vec{a}$ 的1范数结果就是：29。</li>
</ul>
 $$
\Vert\vec{x}\Vert_1=\sum_{i=1}^N\vert{x_i}\vert
$$ 
<ul>
<li>向量的2范数：向量的每个元素的平方和再开平方根，上述 $\vec{a}$ 的2范数结果就是：15。</li>
</ul>
 $$
\Vert\vec{x}\Vert_2=\sqrt{\sum_{i=1}^N{\vert{x_i}\vert}^2}
$$ 
<ul>
<li>向量的负无穷范数：向量的所有元素的绝对值中最小的：上述向量 $\vec{a}$ 的负无穷范数结果就是：5。</li>
</ul>
 $$
\Vert\vec{x}\Vert_{-\infty}=\min{|{x_i}|}
$$ 
<ul>
<li>向量的正无穷范数：向量的所有元素的绝对值中最大的：上述向量 $\vec{a}$ 的正无穷范数结果就是：10。</li>
</ul>
 $$
\Vert\vec{x}\Vert_{+\infty}=\max{|{x_i}|}
$$ 
<ul>
<li>向量的p范数：</li>
</ul>
 $$
L_p=\Vert\vec{x}\Vert_p=\sqrt[p]{\sum_{i=1}^{N}|{x_i}|^p}
$$ 
<p><strong>矩阵的范数</strong></p>
<p>定义一个矩阵 $A=[-1, 2, -3; 4, -6, 6]$ 。 任意矩阵定义为： $A_{m\times n}$ ，其元素为  $a_{ij}$ 。</p>
<p>矩阵的范数定义为</p>
 $$
\Vert{A}\Vert_p :=\sup_{x\neq 0}\frac{\Vert{Ax}\Vert_p}{\Vert{x}\Vert_p}
$$ 
<p>当向量取不同范数时, 相应得到了不同的矩阵范数。</p>
<ul>
<li>
<p><strong>矩阵的1范数（列范数）</strong>：矩阵的每一列上的元</p>
<p>素绝对值先求和，再从中取个最大的,（列和最大），上述矩阵 $A$ 的1范数先得到 $[5,8,9]$ ，再取最大的最终结果就是：9。</p>
</li>
</ul>
 $$
\Vert A\Vert_1=\max_{1\le j\le n}\sum_{i=1}^m|{a_{ij}}|
$$ 
<ul>
<li><strong>矩阵的2范数</strong>：矩阵 $A^TA$ 的最大特征值开平方根，上述矩阵 $A$ 的2范数得到的最终结果是：10.0623。</li>
</ul>
 $$
\Vert A\Vert_2=\sqrt{\lambda_{max}(A^T A)}
$$ 
<p>其中，  $\lambda_{max}(A^T A)$  为  $A^T A​$  的特征值绝对值的最大值。</p>
<ul>
<li><strong>矩阵的无穷范数（行范数）</strong>：矩阵的每一行上的元素绝对值先求和，再从中取个最大的，（行和最大），上述矩阵 $A$ 的行范数先得到 $[6；16]$ ，再取最大的最终结果就是：16。</li>
</ul>
 $$
\Vert A\Vert_{\infty}=\max_{1\le i \le m}\sum_{j=1}^n |{a_{ij}}|
$$ 
<ul>
<li>
<p><strong>矩阵的核范数</strong>：矩阵的奇异值（将矩阵svd分解）之和，这个范数可以用来低秩表示（因为最小化核范数，相当于最小化矩阵的秩——低秩），上述矩阵A最终结果就是：10.9287。</p>
</li>
<li>
<p><strong>矩阵的L0范数</strong>：矩阵的非0元素的个数，通常用它来表示稀疏，L0范数越小0元素越多，也就越稀疏，上述矩阵 $A$ 最终结果就是：6。</p>
</li>
<li>
<p><strong>矩阵的L1范数</strong>：矩阵中的每个元素绝对值之和，它是L0范数的最优凸近似，因此它也可以表示稀疏，上述矩阵 $A$ 最终结果就是：22。</p>
</li>
<li>
<p><strong>矩阵的F范数</strong>：矩阵的各个元素平方之和再开平方根，它通常也叫做矩阵的L2范数，它的优点在于它是一个凸函数，可以求导求解，易于计算，上述矩阵A最终结果就是：10.0995。</p>
</li>
</ul>
 $$
\Vert A\Vert_F=\sqrt{(\sum_{i=1}^m\sum_{j=1}^n{| a_{ij}|}^2)}
$$ 
<ul>
<li><strong>矩阵的L21范数</strong>：矩阵先以每一列为单位，求每一列的F范数（也可认为是向量的2范数），然后再将得到的结果求L1范数（也可认为是向量的1范数），很容易看出它是介于L1和L2之间的一种范数，上述矩阵 $A$ 最终结果就是：17.1559。</li>
<li><strong>矩阵的 p范数</strong></li>
</ul>
 $$
\Vert A\Vert_p=\sqrt[p]{(\sum_{i=1}^m\sum_{j=1}^n{| a_{ij}|}^p)}
$$ 
<h3 id="1-1-5-如何判断一个矩阵为正定">1.1.5 如何判断一个矩阵为正定</h3>
<p>判定一个矩阵是否为正定，通常有以下几个方面：</p>
<ul>
<li>顺序主子式全大于0；</li>
<li>存在可逆矩阵 $C$ 使 $C^TC$ 等于该矩阵；</li>
<li>正惯性指数等于 $n$ ；</li>
<li>合同于单位矩阵 $E$ （即：规范形为 $E$ ）</li>
<li>标准形中主对角元素全为正；</li>
<li>特征值全为正；</li>
<li>是某基的度量矩阵。</li>
</ul>
<h2 id="1-2-导数和偏导数">1.2 导数和偏导数</h2>
<h3 id="1-2-1-导数偏导计算">1.2.1 导数偏导计算</h3>
<p><strong>导数定义</strong>:</p>
<p>导数(derivative)代表了在自变量变化趋于无穷小的时候，函数值的变化与自变量的变化的比值。几何意义是这个点的切线。物理意义是该时刻的（瞬时）变化率。<br>
​</p>
<p><em>注意</em>：在一元函数中，只有一个自变量变动，也就是说只存在一个方向的变化率，这也就是为什么一元函数没有偏导数的原因。在物理学中有平均速度和瞬时速度之说。平均速度有</p>
 $$
v=\frac{s}{t}
$$ 
<p>其中 $v$ 表示平均速度， $s$ 表示路程， $t$ 表示时间。这个公式可以改写为</p>
 $$
\bar{v}=\frac{\Delta s}{\Delta t}=\frac{s(t_0+\Delta t)-s(t_0)}{\Delta t}
$$ 
<p>其中 $\Delta s$ 表示两点之间的距离，而 $\Delta t$ 表示走过这段距离需要花费的时间。当 $\Delta t$ 趋向于0（ $\Delta t \to 0$ ）时，也就是时间变得很短时，平均速度也就变成了在 $t_0$ 时刻的瞬时速度，表示成如下形式：</p>
 $$
v(t_0)=\lim_{\Delta t \to 0}{\bar{v}}=\lim_{\Delta t \to 0}{\frac{\Delta s}{\Delta t}}=\lim_{\Delta t \to 0}{\frac{s(t_0+\Delta t)-s(t_0)}{\Delta t}}
$$ 
<p>实际上，上式表示的是路程 $s$ 关于时间 $t$ 的函数在 $t=t_0$ 处的导数。一般的，这样定义导数：如果平均变化率的极限存在，即有</p>
 $$
\lim_{\Delta x \to 0}{\frac{\Delta y}{\Delta x}}=\lim_{\Delta x \to 0}{\frac{f(x_0+\Delta x)-f(x_0)}{\Delta x}}
$$ 
<p>则称此极限为函数  $y=f(x)$  在点  $x_0$  处的导数。记作  $f'(x_0)$  或  $y'\vert_{x=x_0}$  或  $\frac{dy}{dx}\vert_{x=x_0}$  或  $\frac{df(x)}{dx}\vert_{x=x_0}$ 。</p>
<p>通俗地说，导数就是曲线在某一点切线的斜率。</p>
<p><strong>偏导数</strong>:</p>
<p>既然谈到偏导数(partial derivative)，那就至少涉及到两个自变量。以两个自变量为例， $z=f(x,y)​$ ，从导数到偏导数，也就是从曲线来到了曲面。曲线上的一点，其切线只有一条。但是曲面上的一点，切线有无数条。而偏导数就是指多元函数沿着坐标轴的变化率。</p>
<p><em>注意</em>：直观地说，偏导数也就是函数在某一点上沿坐标轴正方向的的变化率。</p>
<p>设函数 $z=f(x,y)​$ 在点 $(x_0,y_0)​$ 的领域内有定义，当 $y=y_0​$ 时， $z​$ 可以看作关于 $x​$ 的一元函数 $f(x,y_0)​$ ，若该一元函数在 $x=x_0​$ 处可导，即有</p>
 $$
\lim_{\Delta x \to 0}{\frac{f(x_0+\Delta x,y_0)-f(x_0,y_0)}{\Delta x}}=A
$$ 
<p>函数的极限 $A$ 存在。那么称 $A$ 为函数 $z=f(x,y)$ 在点 $(x_0,y_0)$ 处关于自变量 $x$ 的偏导数，记作 $f_x(x_0,y_0)$ 或 $\frac{\partial z}{\partial x}\vert_{y=y_0}^{x=x_0}$ 或 $\frac{\partial f}{\partial x}\vert_{y=y_0}^{x=x_0}$ 或 $z_x\vert_{y=y_0}^{x=x_0}$ 。</p>
<p>偏导数在求解时可以将另外一个变量看做常数，利用普通的求导方式求解，比如 $z=3x^2+xy$ 关于 $x$ 的偏导数就为 $z_x=6x+y$ ，这个时候 $y$ 相当于 $x$ 的系数。</p>
<p>某点 $(x_0,y_0)$ 处的偏导数的几何意义为曲面 $z=f(x,y)$ 与面 $x=x_0$ 或面 $y=y_0$ 交线在 $y=y_0$ 或 $x=x_0$ 处切线的斜率。</p>
<h3 id="1-2-2-导数和偏导数有什么区别？">1.2.2 导数和偏导数有什么区别？</h3>
<p>导数和偏导没有本质区别，如果极限存在，都是当自变量的变化量趋于0时，函数值的变化量与自变量变化量比值的极限。</p>
<blockquote>
<ul>
<li>一元函数，一个 $y$ 对应一个 $x$ ，导数只有一个。</li>
<li>二元函数，一个 $z$ 对应一个 $x$ 和一个 $y$ ，有两个导数：一个是 $z$ 对 $x$ 的导数，一个是 $z$ 对 $y$ 的导数，称之为偏导。</li>
<li>求偏导时要注意，对一个变量求导，则视另一个变量为常数，只对改变量求导，从而将偏导的求解转化成了一元函数的求导。</li>
</ul>
</blockquote>
<h2 id="1-3-特征值和特征向量">1.3 特征值和特征向量</h2>
<h3 id="1-3-1-特征值分解与特征向量">1.3.1 特征值分解与特征向量</h3>
<ul>
<li>
<p>特征值分解可以得到特征值(eigenvalues)与特征向量(eigenvectors)；</p>
</li>
<li>
<p>特征值表示的是这个特征到底有多重要，而特征向量表示这个特征是什么。</p>
<p>如果说一个向量 $\vec{v}$ 是方阵 $A$ 的特征向量，将一定可以表示成下面的形式：</p>
</li>
</ul>
 $$
A\nu = \lambda \nu
$$ 
 $\lambda$ 为特征向量 $\vec{v}$ 对应的特征值。特征值分解是将一个矩阵分解为如下形式： 
 $$
A=Q\sum Q^{-1}
$$ 
<p>其中， $Q$ 是这个矩阵 $A$ 的特征向量组成的矩阵， $\sum$ 是一个对角矩阵，每一个对角线元素就是一个特征值，里面的特征值是由大到小排列的，这些特征值所对应的特征向量就是描述这个矩阵变化方向（从主要的变化到次要的变化排列）。也就是说矩阵 $A$ 的信息可以由其特征值和特征向量表示。</p>
<h3 id="1-3-2-奇异值与特征值有什么关系">1.3.2 奇异值与特征值有什么关系</h3>
<p>那么奇异值和特征值是怎么对应起来的呢？我们将一个矩阵 $A$ 的转置乘以 $A$ ，并对 $A^TA​$ 求特征值，则有下面的形式：</p>
 $$
(A^TA)V = \lambda V
$$ 
<p>这里 $V​$ 就是上面的右奇异向量，另外还有：</p>
 $$
\sigma_i = \sqrt{\lambda_i}, u_i=\frac{1}{\sigma_i}AV
$$ 
<p>这里的 $\sigma​$ 就是奇异值， $u​$ 就是上面说的左奇异向量。【证明那个哥们也没给】<br>
​奇异值 $\sigma​$ 跟特征值类似，在矩阵 $\sum​$ 中也是从大到小排列，而且 $\sigma​$ 的减少特别的快，在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上了。也就是说，我们也可以用前 $r​$ （ $r​$ 远小于 $m、n​$ ）个的奇异值来近似描述矩阵，即部分奇异值分解：</p>
 $$
A_{m\times n}\approx U_{m \times r}\sum_{r\times r}V_{r \times n}^T
$$ 
<p>右边的三个矩阵相乘的结果将会是一个接近于 $A$ 的矩阵，在这儿， $r$ 越接近于 $n$ ，则相乘的结果越接近于 $A$ 。</p>
<h2 id="1-4-概率分布与随机变量">1.4 概率分布与随机变量</h2>
<h3 id="1-4-1-机器学习为什么要使用概率">1.4.1 机器学习为什么要使用概率</h3>
<p>事件的概率是衡量该事件发生的可能性的量度。虽然在一次随机试验中某个事件的发生是带有偶然性的，但那些可在相同条件下大量重复的随机试验却往往呈现出明显的数量规律。<br>
​机器学习除了处理不确定量，也需处理随机量。不确定性和随机性可能来自多个方面，使用概率论来量化不确定性。<br>
​概率论在机器学习中扮演着一个核心角色，因为机器学习算法的设计通常依赖于对数据的概率假设。</p>
<blockquote>
<p>​	例如在机器学习（Andrew Ng）的课中，会有一个朴素贝叶斯假设就是条件独立的一个例子。该学习算法对内容做出假设，用来分辨电子邮件是否为垃圾邮件。假设无论邮件是否为垃圾邮件，单词x出现在邮件中的概率条件独立于单词y。很明显这个假设不是不失一般性的，因为某些单词几乎总是同时出现。然而，最终结果是，这个简单的假设对结果的影响并不大，且无论如何都可以让我们快速判别垃圾邮件。</p>
</blockquote>
<h3 id="1-4-2-变量与随机变量有什么区别">1.4.2 变量与随机变量有什么区别</h3>
<p><strong>随机变量</strong>（random variable）</p>
<p>表示随机现象（在一定条件下，并不总是出现相同结果的现象称为随机现象）中各种结果的实值函数（一切可能的样本点）。例如某一时间内公共汽车站等车乘客人数，电话交换台在一定时间内收到的呼叫次数等，都是随机变量的实例。<br>
​随机变量与模糊变量的不确定性的本质差别在于，后者的测定结果仍具有不确定性，即模糊性。</p>
<p><strong>变量与随机变量的区别：</strong><br>
​当变量的取值的概率不是1时,变量就变成了随机变量；当随机变量取值的概率为1时,随机变量就变成了变量。</p>
<blockquote>
<p>比如：<br>
​	当变量 $x$ 值为100的概率为1的话,那么 $x=100$ 就是确定了的,不会再有变化,除非有进一步运算.<br>
​	当变量 $x$ 的值为100的概率不为1,比如为50的概率是0.5,为100的概率是0.5,那么这个变量就是会随不同条件而变化的,是随机变量,取到50或者100的概率都是0.5,即50%。</p>
</blockquote>
<h3 id="1-4-3-随机变量与概率分布的联系">1.4.3 随机变量与概率分布的联系</h3>
<p>一个随机变量仅仅表示一个可能取得的状态，还必须给定与之相伴的概率分布来制定每个状态的可能性。用来描述随机变量或一簇随机变量的每一个可能的状态的可能性大小的方法，就是 <strong>概率分布(probability distribution)</strong>.</p>
<p>随机变量可以分为离散型随机变量和连续型随机变量。</p>
<p>相应的描述其概率分布的函数是</p>
<p>概率质量函数(Probability Mass Function, PMF):描述离散型随机变量的概率分布，通常用大写字母  $P$ 表示。</p>
<p>概率密度函数(Probability Density Function, PDF):描述连续型随机变量的概率分布，通常用小写字母 $p$ 表示。</p>
<h3 id="1-4-4-离散型随机变量和概率质量函数">1.4.4 离散型随机变量和概率质量函数</h3>
<p>PMF 将随机变量能够取得的每个状态映射到随机变量取得该状态的概率。</p>
<ul>
<li>一般而言， $P(x)​$  表示时 $X=x​$ 的概率.</li>
<li>有时候为了防止混淆，要明确写出随机变量的名称 $P(​$ x $=x)​$</li>
<li>有时候需要先定义一个随机变量，然后制定它遵循的概率分布x服从 $P(​$ x​ $)​$</li>
</ul>
<p>PMF 可以同时作用于多个随机变量，即联合概率分布(joint probability distribution)  $P(X=x,Y=y)$ *表示  $X=x$ 和 $Y=y$ 同时发生的概率，也可以简写成  $P(x,y)$ .</p>
<p>如果一个函数 $P​$ 是随机变量  $X​$  的 PMF， 那么它必须满足如下三个条件</p>
<ul>
<li>
$P​$ 的定义域必须是的所有可能状态的集合
</li>
<li>
$∀x∈​$ x,  $0 \leq P(x) \leq 1 ​$ . 
</li>
<li>
$∑_{x∈X} P(x)=1$ . 我们把这一条性质称之为 归一化的(normalized)
</li>
</ul>
<h3 id="1-4-5-连续型随机变量和概率密度函数">1.4.5 连续型随机变量和概率密度函数</h3>
<p>如果一个函数 $p​$ 是x的PDF，那么它必须满足如下几个条件</p>
<ul>
<li>
$p$ 的定义域必须是x的所有可能状态的集合。
</li>
<li>
$∀x∈X,p(x)≥0$ . 注意，我们并不要求 $ p(x)≤1$ ，因为此处  $p(x)$ 不是表示的对应此状态具体的概率，而是概率的一个相对大小(密度)。具体的概率，需要积分去求。
</li>
<li>
$∫p(x)dx=1$ , 积分下来，总和还是1，概率之和还是1.
</li>
</ul>
<p>注：PDF $p(x)$ 并没有直接对特定的状态给出概率，给出的是密度，相对的，它给出了落在面积为  $δx$ 的无线小的区域内的概率为 $ p(x)δx$ . 由此，我们无法求得具体某个状态的概率，我们可以求得的是 某个状态  $x$  落在 某个区间 $[a,b]$ 内的概率为 $ \int_{a}^{b}p(x)dx$ .</p>
<h3 id="1-4-6-举例理解条件概率">1.4.6 举例理解条件概率</h3>
<p>条件概率公式如下：</p>
 $$
P(A|B) = P(A\cap B) / P(B)
$$ 
<p>说明：在同一个样本空间 $\Omega$ 中的事件或者子集 $A$ 与 $B$ ，如果随机从 $\Omega$ 中选出的一个元素属于 $B$ ，那么下一个随机选择的元素属于 $A$  的概率就定义为在 $B$ 的前提下 $A$ 的条件概率。条件概率文氏图示意如图1.1所示。<br>
<img src="conditional_probability.jpg" alt="条件概率"></p>
<p>图1.1 条件概率文氏图示意</p>
<p>根据文氏图，可以很清楚地看到在事件B发生的情况下，事件A发生的概率就是 $P(A\bigcap B)$ 除以 $P(B)$ 。<br>
​举例：一对夫妻有两个小孩，已知其中一个是女孩，则另一个是女孩子的概率是多少？（面试、笔试都碰到过）<br>
​<strong>穷举法</strong>：已知其中一个是女孩，那么样本空间为男女，女女，女男，则另外一个仍然是女生的概率就是1/3。<br>
​<strong>条件概率法</strong>： $P(女|女)=P(女女)/P(女)$ ,夫妻有两个小孩，那么它的样本空间为女女，男女，女男，男男，则 $P(女女)$ 为1/4， $P（女）= 1-P(男男)=3/4$ ,所以最后 $1/3$ 。<br>
这里大家可能会误解，男女和女男是同一种情况，但实际上类似姐弟和兄妹是不同情况。</p>
<h3 id="1-4-7-联合概率与边缘概率联系区别">1.4.7 联合概率与边缘概率联系区别</h3>
<p><strong>区别：</strong><br>
​联合概率：联合概率指类似于 $P(X=a,Y=b)$ 这样，包含多个条件，且所有条件同时成立的概率。联合概率是指在多元的概率分布中多个随机变量分别满足各自条件的概率。<br>
​边缘概率：边缘概率是某个事件发生的概率，而与其它事件无关。边缘概率指类似于 $P(X=a)$ ， $P(Y=b)$ 这样，仅与单个随机变量有关的概率。</p>
<p><strong>联系：</strong><br>
​联合分布可求边缘分布，但若只知道边缘分布，无法求得联合分布。</p>
<h3 id="1-4-8-条件概率的链式法则">1.4.8 条件概率的链式法则</h3>
<p>由条件概率的定义，可直接得出下面的乘法公式：<br>
​乘法公式 设 $A, B$ 是两个事件，并且 $P(A) > 0$ , 则有</p>
 $$
P(AB) = P(B|A)P(A)
$$ 
<p>推广</p>
 $$
P(ABC)=P(C|AB)P(B|A)P(A)
$$ 
<p>一般地，用归纳法可证：若 $P(A_1A_2...A_n)>0$ ，则有</p>
 $$
P(A_1A_2...A_n)=P(A_n|A_1A_2...A_{n-1})P(A_{n-1}|A_1A_2...A_{n-2})...P(A_2|A_1)P(A_1)
=P(A_1)\prod_{i=2}^{n}P(A_i|A_1A_2...A_{i-1})
$$ 
<p>任何多维随机变量联合概率分布，都可以分解成只有一个变量的条件概率相乘形式。</p>
<h3 id="1-4-9-独立性和条件独立性">1.4.9 独立性和条件独立性</h3>
<p><strong>独立性</strong><br>
​两个随机变量 $x$ 和 $y$ ，概率分布表示成两个因子乘积形式，一个因子只包含 $x$ ，另一个因子只包含 $y$ ，两个随机变量相互独立(independent)。<br>
​条件有时为不独立的事件之间带来独立，有时也会把本来独立的事件，因为此条件的存在，而失去独立性。<br>
​举例： $P(XY)=P(X)P(Y)$ , 事件 $X$ 和事件 $Y$ 独立。此时给定 $Z$ ，</p>
 $$
P(X,Y|Z) \not = P(X|Z)P(Y|Z)
$$ 
<p>事件独立时，联合概率等于概率的乘积。这是一个非常好的数学性质，然而不幸的是，无条件的独立是十分稀少的，因为大部分情况下，事件之间都是互相影响的。</p>
<p><strong>条件独立性</strong><br>
​给定 $Z$ 的情况下, $X$ 和 $Y$ 条件独立，当且仅当</p>
 $$
X\bot Y|Z \iff P(X,Y|Z) = P(X|Z)P(Y|Z)
$$ 
 $X$ 和 $Y$ 的关系依赖于 $Z$ ，而不是直接产生。  
<blockquote>
<p><strong>举例</strong>定义如下事件：</p>
 $X$ ：明天下雨；  
 $Y$ ：今天的地面是湿的；  
 $Z$ ：今天是否下雨；  
 $Z$ 事件的成立，对 $X$ 和 $Y$ 均有影响，然而，在 $Z$ 事件成立的前提下，今天的地面情况对明天是否下雨没有影响。 
</blockquote>
<h2 id="1-5-常见概率分布">1.5 常见概率分布</h2>
<h3 id="1-5-1-Bernoulli分布">1.5.1 Bernoulli分布</h3>
<p><strong>Bernoulli分布</strong>(伯努利分布，0-1分布)是单个二值随机变量分布, 单参数 $\phi$ ∈[0,1]控制, $\phi$ 给出随机变量等于1的概率. 主要性质有:</p>
 $$
\begin{align*}
P(x=1) &= \phi \\
P(x=0) &= 1-\phi  \\
概率质量函数：P(x=x) &= \phi^x(1-\phi)^{1-x} \\
\end{align*}
$$ 
<p>其期望和方差为：</p>
 $$
\begin{align*}
E_x[x] &= \phi \\
Var_x(x) &= \phi{(1-\phi)}
\end{align*}
$$ 
<p><strong>适用范围</strong>: <strong>伯努利分布</strong>适合对<strong>离散型</strong>随机变量建模.</p>
<p><strong>Multinoulli分布</strong>也叫<strong>范畴分布</strong>, 是单个<em>k</em>值随机分布,经常用来表示<strong>对象分类的分布</strong>. 其中 $k$ 是有限值.Multinoulli分布由向量 $\vec{p}\in[0,1]^{k-1}$ 参数化,每个分量 $p_i$ 表示第 $i$ 个状态的概率, 且 $p_k=1-1^Tp$ .这里 $1^T$ 表示元素全为1的列向量的转置，其实就是对于向量p中除了k的概率之和。可以重写为 $p_k=1-\sum_{0}^{k-1}p_i$  。</p>
<p>补充二项分布、多项分布：</p>
<p>二项分布，通俗点硬币抛多次。二项分布(Binomial distribution)是<strong>n重伯努利试验</strong>成功次数的离散概率分布。</p>
<p>多项式分布(Multinomial Distribution)是二项式分布的推广。二项式做n次伯努利实验，规定了每次试验的结果只有两个，如果现在还是做n次试验，只不过每次试验的结果可以有多m个，且m个结果发生的概率互斥且和为1，则发生其中一个结果X次的概率就是多项式分布。</p>
<h3 id="1-5-2-高斯分布">1.5.2 高斯分布</h3>
<p>高斯也叫正态分布(Normal Distribution), 概率度函数如下:</p>
 $$
N(x;\mu,\sigma^2) = \sqrt{\frac{1}{2\pi\sigma^2}}exp\left ( -\frac{1}{2\sigma^2}(x-\mu)^2 \right )
$$ 
<p>其中,  $\mu​$ 和 $\sigma​$ 分别是均值和标准差, 中心峰值x坐标由 $\mu​$ 给出, 峰的宽度受 $\sigma​$ 控制, 最大点在 $x=\mu​$ 处取得, 拐点为 $x=\mu\pm\sigma​$</p>
<p>正态分布中，±1 $\sigma$ 、±2 $\sigma$ 、±3 $\sigma$ 下的概率分别是68.3%、95.5%、99.73%，这3个数最好记住。</p>
<p>此外, 令 $\mu=0,\sigma=1​$ 高斯分布即简化为标准正态分布:</p>
 $$
N(x;\mu,\sigma^2) = \sqrt{\frac{1}{2\pi}}exp\left ( -\frac{1}{2}x^2 \right )
$$ 
<p>对概率密度函数高效求值:</p>
 $$
N(x;\mu,\beta^{-1})=\sqrt{\frac{\beta}{2\pi}}exp\left(-\frac{1}{2}\beta(x-\mu)^2\right)
$$ 
<p>其中， $\beta=\frac{1}{\sigma^2}$ 通过参数 $\beta∈（0，\infty）​$ 来控制分布精度。</p>
<h3 id="1-5-3-何时采用正态分布">1.5.3 何时采用正态分布</h3>
<p>问: 何时采用正态分布?<br>
答: 缺乏实数上分布的先验知识, 不知选择何种形式时, 默认选择正态分布总是不会错的, 理由如下:</p>
<ol>
<li>中心极限定理告诉我们, 很多独立随机变量均近似服从正态分布, 现实中很多复杂系统都可以被建模成正态分布的噪声, 即使该系统可以被结构化分解.</li>
<li>正态分布是具有相同方差的所有概率分布中, 不确定性最大的分布, 换句话说, 正态分布是对模型加入先验知识最少的分布.</li>
</ol>
<p>正态分布的推广:<br>
正态分布可以推广到 $R^n$ 空间, 此时称为<strong>多位正态分布</strong>, 其参数是一个正定对称矩阵 $\Sigma​$ :</p>
 $$
N(x;\vec\mu,\Sigma)=\sqrt{\frac{1}{(2\pi)^ndet(\Sigma)}}exp\left(-\frac{1}{2}(\vec{x}-\vec{\mu})^T\Sigma^{-1}(\vec{x}-\vec{\mu})\right)
$$ 
<p>对多为正态分布概率密度高效求值:</p>
 $$
N(x;\vec{\mu},\vec\beta^{-1}) = \sqrt{det(\vec\beta)}{(2\pi)^n}exp\left(-\frac{1}{2}(\vec{x}-\vec\mu)^T\beta(\vec{x}-\vec\mu)\right)
$$ 
<p>此处， $\vec\beta$ 是一个精度矩阵。</p>
<h3 id="1-5-4-指数分布">1.5.4 指数分布</h3>
<p>深度学习中, 指数分布用来描述在 $x=0​$ 点处取得边界点的分布, 指数分布定义如下:</p>
 $$
p(x;\lambda)=\lambda I_{x\geq 0}exp(-\lambda{x})
$$ 
<p>指数分布用指示函数 $I_{x\geq 0}​$ 来使 $x​$ 取负值时的概率为零。</p>
<h3 id="1-5-5-Laplace-分布（拉普拉斯分布）">1.5.5 Laplace 分布（拉普拉斯分布）</h3>
<p>一个联系紧密的概率分布是 Laplace 分布（Laplace distribution），它允许我们在任意一点  $\mu$ 处设置概率质量的峰值</p>
 $$
Laplace(x;\mu;\gamma)=\frac{1}{2\gamma}exp\left(-\frac{|x-\mu|}{\gamma}\right)
$$ 
<h3 id="1-5-6-Dirac分布和经验分布">1.5.6 Dirac分布和经验分布</h3>
<p>Dirac分布可保证概率分布中所有质量都集中在一个点上. Diract分布的狄拉克 $\delta​$ 函数(也称为<strong>单位脉冲函数</strong>)定义如下:</p>
 $$
p(x)=\delta(x-\mu), x\neq \mu
$$ 
 $$
\int_{a}^{b}\delta(x-\mu)dx = 1, a < \mu < b
$$ 
<p>Dirac 分布经常作为 经验分布（empirical distribution）的一个组成部分出现</p>
 $$
\hat{p}(\vec{x})=\frac{1}{m}\sum_{i=1}^{m}\delta(\vec{x}-{\vec{x}}^{(i)})
$$ 
<p>, 其中, m个点 $x^{1},...,x^{m}$ 是给定的数据集, <strong>经验分布</strong>将概率密度 $\frac{1}{m}​$ 赋给了这些点.</p>
<p>当我们在训练集上训练模型时, 可以认为从这个训练集上得到的经验分布指明了<strong>采样来源</strong>.</p>
<p><strong>适用范围</strong>: 狄拉克δ函数适合对<strong>连续型</strong>随机变量的经验分布.</p>
<blockquote></blockquote>
<h2 id="1-6-期望、方差、协方差、相关系数">1.6 期望、方差、协方差、相关系数</h2>
<h3 id="1-6-1-期望">1.6.1 期望</h3>
<p>在概率论和统计学中，数学期望（或均值，亦简称期望）是试验中每次可能结果的概率乘以其结果的总和。它反映随机变量平均取值的大小。</p>
<ul>
<li>线性运算：  $E(ax+by+c) = aE(x)+bE(y)+c$</li>
<li>推广形式：  $E(\sum_{k=1}^{n}{a_ix_i+c}) = \sum_{k=1}^{n}{a_iE(x_i)+c}$</li>
<li>函数期望：设 $f(x)$ 为 $x$ 的函数，则 $f(x)$ 的期望为
<ul>
<li>离散函数：  $E(f(x))=\sum_{k=1}^{n}{f(x_k)P(x_k)}$</li>
<li>连续函数：  $E(f(x))=\int_{-\infty}^{+\infty}{f(x)p(x)dx}$</li>
</ul>
</li>
</ul>
<blockquote>
<p>注意：</p>
<ul>
<li>函数的期望大于等于期望的函数（Jensen（詹森）不等式，即 $E(f(x))\geqslant f(E(x))$</li>
<li>一般情况下，乘积的期望不等于期望的乘积。</li>
<li>如果 $X$ 和 $Y$ 相互独立，则 $E(xy)=E(x)E(y)​$ 。</li>
</ul>
</blockquote>
<h3 id="1-6-2-方差">1.6.2 方差</h3>
<p>概率论中方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。方差是一种特殊的期望。定义为：</p>
 $$
Var(x) = E((x-E(x))^2)
$$ 
<blockquote>
<p>方差性质：</p>
<p>1） $Var(x) = E(x^2) -E(x)^2$<br>
2）常数的方差为0;<br>
3）方差不满足线性性质;<br>
4）如果 $X$ 和 $Y$ 相互独立,  $Var(ax+by)=a^2Var(x)+b^2Var(y)$</p>
</blockquote>
<h3 id="1-6-3-协方差">1.6.3 协方差</h3>
<p>协方差是衡量两个变量线性相关性强度及变量尺度。  两个随机变量的协方差定义为：</p>
 $$
Cov(x,y)=E((x-E(x))(y-E(y)))
$$ 
<p>方差是一种特殊的协方差。当 $X=Y$ 时， $Cov(x,y)=Var(x)=Var(y)$ 。</p>
<blockquote>
<p>协方差性质：</p>
<p>1）独立变量的协方差为0。<br>
2）协方差计算公式：</p>
</blockquote>
 $$
Cov(\sum_{i=1}^{m}{a_ix_i}, \sum_{j=1}^{m}{b_jy_j}) = \sum_{i=1}^{m} \sum_{j=1}^{m}{a_ib_jCov(x_iy_i)}
$$ 
<blockquote>
<p>3）特殊情况：</p>
</blockquote>
 $$
Cov(a+bx, c+dy) = bdCov(x, y)
$$ 
<h3 id="1-6-4-相关系数">1.6.4 相关系数</h3>
<p>相关系数是研究变量之间线性相关程度的量。两个随机变量的相关系数定义为：</p>
 $$
Corr(x,y) = \frac{Cov(x,y)}{\sqrt{Var(x)Var(y)}}
$$ 
<blockquote>
<p>相关系数的性质：<br>
1）有界性。相关系数的取值范围是 [-1,1]，可以看成无量纲的协方差。<br>
2）值越接近1，说明两个变量正相关性（线性）越强。越接近-1，说明负相关性越强，当为0时，表示两个变量没有相关性。</p>
</blockquote>
<h2 id="参考文献">参考文献</h2>
<p>[1]Ian，Goodfellow，Yoshua，Bengio，Aaron…深度学习[M]，人民邮电出版，2017</p>
<p>[2]周志华.机器学习[M].清华大学出版社，2016.</p>
<p>[3]同济大学数学系.高等数学（第七版）[M]，高等教育出版社，2014.</p>
<p>[4]盛骤，试式千，潘承毅等编. 概率论与数理统计（第4版）[M]，高等教育出版社，2008</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lilitom.github.io/2024/03/19/deep_learning/ch10/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/deep_learning/ch10/" class="post-title-link" itemprop="url">强化学习面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-24 10:13:59" itemprop="dateModified" datetime="2024-03-24T10:13:59+08:00">2024-03-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>强化学习</h1>
<h2 id="10-1-强化学习的主要特点？">10.1 强化学习的主要特点？</h2>
<p>其他许多机器学习算法中学习器都是学得怎样做，而RL是在尝试的过程中学习到在特定的情境下选择哪种行动可以得到最大的回报。在很多场景中，当前的行动不仅会影响当前的rewards，还会影响之后的状态和一系列的rewards。RL最重要的3个特定在于：<br>
(1)	基本是以一种闭环的形式；<br>
(2)	不会直接指示选择哪种行动（actions）；<br>
(3)	一系列的actions和奖励信号（reward signals）都会影响之后较长的时间。</p>
<h3 id="10-1-1-定义">10.1.1 定义</h3>
<p>强化学习是机器学习的一个重要分支，是多学科多领域交叉的一个产物，它的本质是解决 decision making 问题，即自动进行决策，并且可以做连续决策。<br>
它主要包含四个元素，agent，环境状态，行动，奖励, 强化学习的目标就是获得最多的累计奖励。<br>
我们列举几个形象的例子：<br>
小孩想要走路，但在这之前，他需要先站起来，站起来之后还要保持平衡，接下来还要先迈出一条腿，是左腿还是右腿，迈出一步后还要迈出下一步。<br>
小孩就是 agent，他试图通过采取行动（即行走）来操纵环境（行走的表面），并且从一个状态转变到另一个状态（即他走的每一步），当他完成任务的子任务（即走了几步）时，孩子得到奖励（给巧克力吃），并且当他不能走路时，就不会给巧克力。</p>
<p><img src="10-1.png" alt></p>
<p>上图中agent代表自身，如果是自动驾驶，agent就是车；如果你玩游戏它就是你当前控制的游戏角色，如马里奥，马里奥往前走时环境就一直在发生变化，有小怪物或者障碍物出现，它需要通过跳跃来进行躲避，就是要做action（如向前走和跳起的动作）；无人驾驶的action就是车左转、右转或刹车等等，它无时无刻都在与环境产生交互，action会反馈给环境，进而改变环境，如果自动驾驶的车行驶目标是100米，它向前开了10米，那环境就发生了变化，所以每次产生action都会导致环境改变，环境的改变会反馈给自身（agent），就是这样的一个循环；反馈又两种方式：1、做的好（reward）即正反馈，2、做得不好（punishment惩罚）即负反馈。Agent可能做得好，也可能做的不好，环境始终都会给它反馈，agent会尽量去做对自身有利的决策，通过反反复复这样的一个循环，agent会越来越做的好，就像孩子在成长过程中会逐渐明辨是非，这就是强化学习。</p>
<h2 id="10-2-强化学习应用实例">10.2 强化学习应用实例</h2>
<p>（1）Manufacturing</p>
<p>例如一家日本公司 Fanuc，工厂机器人在拿起一个物体时，会捕捉这个过程的视频，记住它每次操作的行动，操作成功还是失败了，积累经验，下一次可以更快更准地采取行动。</p>
<p><img src="10-2.png" alt></p>
<p>（2）Inventory Management</p>
<p>在库存管理中，因为库存量大，库存需求波动较大，库存补货速度缓慢等阻碍使得管理是个比较难的问题，可以通过建立强化学习算法来减少库存周转时间，提高空间利用率。</p>
<p>（3）Dynamic pricing</p>
<p>强化学习中的 Q-learning 可以用来处理动态定价问题。</p>
<p>（4）Customer Delivery</p>
<p>制造商在向各个客户运输时，想要在满足客户的所有需求的同时降低车队总成本。通过 multi-agents 系统和 Q-learning，可以降低时间，减少车辆数量。</p>
<p>（5）ECommerce Personalization</p>
<p>在电商中，也可以用强化学习算法来学习和分析顾客行为，定制产品和服务以满足客户的个性化需求。</p>
<p>（6）Ad Serving</p>
<p>例如算法 LinUCB （属于强化学习算法 bandit 的一种算法），会尝试投放更广范围的广告，尽管过去还没有被浏览很多，能够更好地估计真实的点击率。<br>
再如双 11 推荐场景中，阿里巴巴使用了深度强化学习与自适应在线学习，通过持续机器学习和模型优化建立决策引擎，对海量用户行为以及百亿级商品特征进行实时分析，帮助每一个用户迅速发现宝贝，提高人和商品的配对效率。还有，利用强化学习将手机用户点击率提升了 10-20%。</p>
<p>（7）Financial Investment Decisions</p>
<p>例如这家公司 <a target="_blank" rel="noopener" href="http://Pit.ai">Pit.ai</a>，应用强化学习来评价交易策略，可以帮助用户建立交易策略，并帮助他们实现其投资目标。</p>
<p>（8）Medical Industry</p>
<p>动态治疗方案（DTR）是医学研究的一个主题，是为了给患者找到有效的治疗方法。 例如癌症这种需要长期施药的治疗，强化学习算法可以将患者的各种临床指标作为输入 来制定治疗策略。</p>
<h2 id="10-3-强化学习和监督式学习、非监督式学习的区别">10.3 强化学习和监督式学习、非监督式学习的区别</h2>
<p>在机器学习中，我们比较熟知的是监督式学习，非监督学习，此外还有一个大类就是强化学习：<br>
当前的机器学习算法可以分为3种：有监督的学习（Supervised Learning）、无监督的学习（Unsupervised Learning）和强化学习（Reinforcement Learning），结构图如下所示：</p>
<p><img src="10-3.png" alt></p>
<h3 id="10-3-1-强化学习和监督式学习的区别：">10.3.1 强化学习和监督式学习的区别：</h3>
<p>监督式学习就好比你在学习的时候，有一个导师在旁边指点，他知道怎么是对的怎么是错的，但在很多实际问题中，例如 chess，go，这种有成千上万种组合方式的情况，不可能有一个导师知道所有可能的结果。</p>
<p>而这时，强化学习会在没有任何标签的情况下，通过先尝试做出一些行为得到一个结果，通过这个结果是对还是错的反馈，调整之前的行为，就这样不断的调整，算法能够学习到在什么样的情况下选择什么样的行为可以得到最好的结果。</p>
<p>就好比你有一只还没有训练好的小狗，每当它把屋子弄乱后，就减少美味食物的数量（惩罚），每次表现不错时，就加倍美味食物的数量（奖励），那么小狗最终会学到一个知识，就是把客厅弄乱是不好的行为。</p>
<p>两种学习方式都会学习出输入到输出的一个映射，监督式学习出的是之间的关系，可以告诉算法什么样的输入对应着什么样的输出，强化学习出的是给机器的反馈 reward function，即用来判断这个行为是好是坏。<br>
另外强化学习的结果反馈有延时，有时候可能需要走了很多步以后才知道以前的某一步的选择是好还是坏，而监督学习做了比较坏的选择会立刻反馈给算法。</p>
<p>而且强化学习面对的输入总是在变化，每当算法做出一个行为，它影响下一次决策的输入，而监督学习的输入是独立同分布的。</p>
<p>通过强化学习，一个 agent 可以在探索和开发（exploration and exploitation）之间做权衡，并且选择一个最大的回报。</p>
<p>exploration 会尝试很多不同的事情，看它们是否比以前尝试过的更好。</p>
<p>exploitation 会尝试过去经验中最有效的行为。</p>
<p>一般的监督学习算法不考虑这种平衡，就只是是 exploitative。</p>
<h3 id="10-3-2-强化学习和非监督式学习的区别：">10.3.2 强化学习和非监督式学习的区别：</h3>
<p>非监督式不是学习输入到输出的映射，而是模式。例如在向用户推荐新闻文章的任务中，非监督式会找到用户先前已经阅读过类似的文章并向他们推荐其一，而强化学习将通过向用户先推荐少量的新闻，并不断获得来自用户的反馈，最后构建用户可能会喜欢的文章的“知识图”。</p>
<p>对非监督学习来说，它通过对没有概念标记的训练例进行学习，以发现训练例中隐藏的结构性知识。这里的训练例的概念标记是不知道的，因此训练样本的歧义性最高。对强化学习来说，它通过对没有概念标记、但与一个延迟奖赏或效用（可视为延迟的概念标记）相关联的训练例进行学习，以获得某种从状态到行动的映射。这里本来没有概念标记的概<br>
念，但延迟奖赏可被视为一种延迟概念标记，因此其训练样本的歧义性介于监督学习和非监督学习之间。</p>
<p>需要注意的是，监督学习和非监督学习从一开始就是相对的，而强化学习在提出时并没有从训练样本歧义性的角度考虑其与监督学习和非监督学习的区别，因此，一些早期的研究中把强化学习视为一种特殊的非监督学习。事实上，对强化学习的定位到目前仍然是有争议的，有的学者甚至认为它是与“从例子中学习”同一级别的概念。</p>
<p>从训练样本歧义性角度进行的分类体系，在近几年可望有一些扩展，例如多示例学习（multi-instancelearning）等从训练样本歧义性方面来看很特殊的新的学习框架有可能会进入该体系。但到目前为止，没有任何新的框架得到了公认的地位。另外，半监督学习（semi-supervisedlearning）也有一定希望，它的障碍是半监督学习中的歧义性并不是与生俱来的，而是人为的，即用户期望用未标记的样本来辅助对已标记样本的学习。这与监督学习、非监督学习、强化学习等天生的歧义性完全不同。半监督学习中人为的歧义性在解决工程问题上是需要的、有用的（对大量样本进行标记的代价可能是极为昂贵的），但可能不太会导致方法学或对学习问题视点的大的改变。</p>
<p><strong>强化学习和前二者的本质区别</strong>:没有前两者具有的明确数据概念，它不知道结果，只有目标。数据概念就是大量的数据，有监督学习、无监督学习需要大量数据去训练优化你建立的模型，就像猫狗识别，用n多张猫狗图片去训练模型，经过训练优化后，你用一张崭新的猫狗图片让模型作出判断，这个模型就知道是猫还是狗。</p>
<h2 id="10-4-强化学习主要有哪些算法？">10.4 强化学习主要有哪些算法？</h2>
<p>强化学习不需要监督信号,可以在模型未知的环境中平衡探索和利用, 其主要算法有蒙特卡罗强化学习, 时间差分(temporal difference: TD)学习, 策略梯度等。典型的深度强化学习算法特点及性能比较如下图所示：</p>
<p><img src="10-4.png" alt></p>
<p>除了上述深度强化学习算法，还有深度迁移强化学习、分层深度强化学习、深度记忆强化学习以及多智能体强化学习等算法。</p>
<h2 id="10-5-深度迁移强化学习算法">10.5 深度迁移强化学习算法</h2>
<p>传统深度强化学习算法每次只能解决一种游戏任务, 无法在一次训练中完成多种任务. 迁移学习和强化学习的结合也是深度强化学习的一种主要思路。</p>
<p>Parisotto等提出了一种基于行为模拟的深度迁移强化学习算法. 该算法通过监督信号的指导, 使得单一的策略网络学习各自的策略, 并将知识迁移到新任务中. Rusa等提出策略蒸馏(policy distillation)深度迁移强化学习算法. 策略蒸馏算法中分为学习网络和指导网络, 通过这两个网络Q值的偏差来确定目标函数,引导学习网络逼近指导网络的值函数空间. 此后,Rusa等又提出了一种基于渐进神经网络(progressive neural networks, PNN)的深度迁移强化学习算法.PNN是一种把神经网络和神经网络连起来的算法. 它在一系列序列任务中, 通过渐进的方式来存储知识和提取特征, 完成了对知识的迁移. PNN最终实现多个独立任务的训练, 通过迁移加速学习过程, 避免灾难性遗忘. Fernando 等提出了路径网络(PathNet)[45].PathNet可以说是PNN的进阶版. PathNet把网络中每一层都看作一个模块, 把构建一个网络看成搭积木,也就是复用积木. 它跟PNN非常类似, 只是这里不再有列, 而是不同的路径. PathNet将智能体嵌入到神经网络中, 其中智能体的任务是为新任务发现网络中可以复用的部分. 智能体是网络之中的路径, 其决定了反向传播过程中被使用和更新的参数范围. 在一系列的Atari强化学习任务上, PathNet都实现了正迁移, 这表明PathNet在训练神经网络上具有通用性应用能力.PathNet也可以显著提高A3C算法超参数选择的鲁棒性. Schaul等提出了一种通用值函数逼近器(universalvalue function approximators, UVFAs)来泛化状态和目标空间．UVFAs可以将学习到的知识迁移到环境动态特性相同但目标不同的新任务中.</p>
<h2 id="10-6-分层深度强化学习算法">10.6 分层深度强化学习算法</h2>
<p>分层强化学习可以将最终目标分解为多个子任务来学习层次化的策略, 并通过组合多个子任务的策略形成有效的全局策略. Kulkarni等提出了分层DQN(hierarchical deep Q-network, h–DQN) 算法. h–DQN基于时空抽象和内在激励分层, 通过在不同的时空尺度上设置子目标对值函数进行层次化处理. 顶层的值函数用于确定宏观决策, 底层的值函数用于确定具体行动．Krishnamurthy等在h–DQN的基础上提出了基于内部选择的分层深度强化学习算法. 该模型结合时空抽象和深度神经网络, 自动地完成子目标的学习, 避免了特定的内在激励和人工设定中间目标,加速了智能体的学习进程, 同时也增强了模型的泛化能力. Kulkarni等基于后续状态表示法提出了深度后续强化学习(deep successor reinforcement learning,DSRL)．DSRL通过阶段性地分解子目标和学习子目标策略, 增强了对未知状态空间的探索, 使得智能体更加适应那些存在延迟反馈的任务．Vezhnevets等受封建(feudal)强化学习算法的启发, 提出一种分层深度强化学习的架构FeUdal网络(FuNs)[49]. FuNs框架使用一个管理员模块和一个工人模块. 管理员模块在较低的时间分辨率下工作, 设置抽象目标并传递给工人模块去执行. FuNs框架创造了一个稳定的自然层次结构, 并且允许两个模块以互补的方式学习. 实验证明, FuNs有助于处理长期信用分配和记忆任务,在Atari视频游戏和迷宫游戏中都取得了不错的效果。</p>
<h2 id="10-7-深度记忆强化学习算法">10.7 深度记忆强化学习算法</h2>
<p>传统的深度强化学习模型不具备记忆、认知、推理等高层次的能力, 尤其是在面对状态部分可观察和延迟奖赏的情形时. Junhyuk等通过在传统的深度强化学习模型中加入外部的记忆网络部件和反馈控制机制, 提出反馈递归记忆Q网络(feedback recurrent memory Q-network, FRMQN)). FRMQN模型具备了一定的记忆与推理功能, 通过反馈控制机制,FRMQN整合过去存储的有价值的记忆和当前时刻的上下文状态, 评估动作值函数并做出决策. FRMQN初步模拟了人类的主动认知与推理能力, 并完成了一些高层次的认知任务. 在一些未经过训练的任务中,FRMQN模型表现出了很强的泛化能力．Blundell等设计出一种模型无关的情节控制算法(model-free episode control, MFEC). MFEC可以快速存储和回放状态转移序列, 并将回放的序列整合到结构化知识系统中, 使得智能体在面对一些复杂的决策任务时, 能快速达到人类玩家的水平．MFEC通过反向经验回放, 使智能体拥有初步的情节记忆. 实验表明, 基于MFEC算法的深度强化学习不仅可以在Atari游戏中学习到有效策略, 还可以处理一些三维场景的复杂任务. Pritzel等在MFEC的基础上进一步提出了神经情节控制(neural episodic control, NEC),有效提高了深度强化学习智能体的记忆能力和学习效率[53]. NEC能快速吸收新经验并依据新经验来采取行动. 价值函数包括价值函数渐变状态表示和价值函数快速更新估计两部分. 大量场景下的研究表明,NEC的学习速度明显快于目前最先进的通用深度强化学习智能体.</p>
<h2 id="10-8-多智能体深度强化学习算法">10.8 多智能体深度强化学习算法</h2>
<p>在一些复杂场景中, 涉及到多智能体的感知决策问题, 这时需要将单一模型扩展为多个智能体之间相互合作、通信及竞争的多智能体深度强化学习系统.Foerster等提出了一种称为分布式深度递归Q网络(deep distributed recurrent Q-networks, DDRQN) 的模型, 解决了状态部分可观测状态下的多智能体通信与合作的挑战性难题[54]. 实验表明, 经过训练的DDRQN模型最终在多智能体之间达成了一致的通信协1536 控制理论与应用第34 卷议, 成功解决了经典的红蓝帽子问题.让智能体学会合作与竞争一直以来都是人工智能领域内的一项重要研究课题, 也是实现通用人工智能的必要条件. Lowe等提出了一种用于合作–竞争混合环境的多智能体actor-critic 算法(multi-agent deepdeterministic policy gradient, MADDPG)[55]. MADDPG对DDPG强化学习算法进行了延伸, 可实现多智能体的集中式学习和分布式执行, 让智能体学习彼此合作和竞争. 在多项测试任务中, MADDPG的表现都优于DDPG.</p>
<h2 id="10-9-强化学习开源框架">10.9 强化学习开源框架</h2>
<p>谷歌TensorFlow Agents —TensorFlow的加强版,它提供许多工具，通过强化学习可以实现各类智能应用程序的构建与训练。这个框架能够将OpoenAI Gym接口扩展至多个并行环境，并允许各代理立足TensorFlow之内实现以执行批量计算。其面向OpoenAI Gy环境的批量化接口可与TensorFlow实现全面集成，从而高效执行各类算法。该框架还结合有BatchPPO，一套经过优化的近端策略优化算法实现方案。其核心组件包括一个环境打包器，用于在外部过程中构建OpenAI Gym环境; 一套批量集成，用于实现TensorFlow图步并以强化学习运算的方式重置函数; 外加用于将TensorFlow图形批处理流程与强化学习算法纳入训练特内单一却步的组件。</p>
<p>Roboschool：Roboschool 提供开源软件以通过强化学习构建并训练机器人模拟。其有助于在同一环境当中对多个代理进行强化学习训练。通过多方训练机制，您可以训练同一代理分别作为两方玩家（因此能够自我对抗）、使用相同算法训练两套代理，或者设置两种算法进行彼此对抗。Roboschool由OpenAI开发完成，这一非营利性组织的背后赞助者包括Elon Musk、Sam Altman、Reid Hoffman以及Peter Thiel。其与OpenAI Gym相集成，后者是一套用于开发及评估强化学习算法的开源工具集。OpenAI Gym与TensorFlow、Theano以及其它多种深度学习库相兼容。OpenAI Gym当中包含用于数值计算、游戏以及物理引擎的相关代码。Roboschool基于Bullet物理引擎，这是一套开源许可物理库，并被其它多种仿真软件——例如Gazebo与Virtual Robot Experimentation Platform（简称V-REP）所广泛使用。其中包含多种强化学习算法，具体以怨报德 异步深度强化学习方法、Actor-Critic with Experience Replay、Actor- Critic using Kronecker-Factored Trust Region、深度确定性策略梯度、近端策略优化以及信任域策略优化等等。</p>
<p>Coach：英特尔公司的开源强化学习框架，可以对游戏、机器人以及其它基于代理的智能应用进行智能代理的建模、训练与评估。Coach 提供一套模块化沙箱、可复用组件以及用于组合新强化学习算法并在多种应用领域内训练新智能应用的Python API。该框架利用OpenAI Gym作为主工具，负责与不同强化学习环境进行交换。其还支持其它外部扩展，具体包括Roboschool、gym-extensions、PyBullet以及ViZDoom。Coach的环境打包器允许用户向其中添加自定义强化学习环境，从而解决其它学习问题。该框架能够在桌面计算机上高效训练强化学习代理，并利用多核CPU处理相关任务。其能够为一部分强化学习算法提供单线程与多线程实现能力，包括异步优势Actor-Critic、深度确定性策略梯度、近端策略优化、直接未来预测以及规范化优势函数。所有算法皆利用面向英特尔系统作出优化的TensorFLow完成，其中部分算法亦适用于英特尔的Neon深度学习框架。Coach 当中包含多种强化学习代理实现方案，具体包括从单线程实现到多线程实现的转换。其能够开发出支持单与多工作程序（同步或异步）强化学习实现方法的新代理。此外，其还支持连续与离散操作空间，以及视觉观察空间或仅包含原始测量指标的观察空间。</p>
<h2 id="10-10-深度强化学习算法小结">10.10 深度强化学习算法小结</h2>
<p>基于值函数概念的DQN及其相应的扩展算法在离散状态、离散动作的控制任务中已经表现了卓越的性能, 但是受限于值函数离散型输出的影响, 在连续型控制任务上显得捉襟见肘. 基于策略梯度概念的,以DDPG, TRPO等为代表的策略型深度强化学习算法则更适用于处理基于连续状态空间的连续动作的控制输出任务, 并且算法在稳定性和可靠性上具有一定的理论保证, 理论完备性较强. 采用actor-critic架构的A3C算法及其扩展算法, 相比于传统DQN算法, 这类算法的数据利用效率更高, 学习速率更快, 通用性、可扩展应用性更强, 达到的表现性能更优, 但算法的稳定性无法得到保证. 而其他的如深度迁移强化学习、分层深度强化学习、深度记忆强化学习和多智能体深度强化学习等算法都是现在的研究热点, 通过这些算法能应对更为复杂的场景问题、系统环境及控制任务, 是目前深度强化学习算法研究的前沿领域.</p>
<p>展望未来，人工智能开发者们需要尽可能掌握上述框架以及其中所使用的各类强化学习算法。此外，还需要强化自身对于多代理强化学习架构的理解，因为其中多种框架都大量利用前沿博弈论研究成果。最后，还需要熟悉深度强化学习知识。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lilitom.github.io/2024/03/19/deep_learning/ch11/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/deep_learning/ch11/" class="post-title-link" itemprop="url">迁移学习面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-24 10:14:01" itemprop="dateModified" datetime="2024-03-24T10:14:01+08:00">2024-03-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>迁移学习</h1>
<p>​	本章主要简明地介绍了迁移学习的基本概念、迁移学习的必要性、研究领域和基本方法。重点介绍了几大类常用的迁移学习方法：数据分布自适应方法、特征选择方法、子空间学习方法、以及目前最热门的深度迁移学习方法。除此之外，我们也结合最近的一些研究成果对未来迁移学习进行了一些展望。并提供了一些迁移学习领域的常用学习资源，以方便感兴趣的读者快速开始学习。</p>
<h2 id="11-1-迁移学习基础知识">11.1 迁移学习基础知识</h2>
<h3 id="11-1-1-什么是迁移学习？">11.1.1 什么是迁移学习？</h3>
<p>找到目标问题的相似性，迁移学习任务就是从相似性出发，将旧领域(domain)学习过的模型应用在新领域上。</p>
<h3 id="11-1-2-为什么需要迁移学习？">11.1.2 为什么需要迁移学习？</h3>
<ol>
<li><strong>大数据与少标注的矛盾</strong>：虽然有大量的数据，但往往都是没有标注的，无法训练机器学习模型。人工进行数据标定太耗时。</li>
<li><strong>大数据与弱计算的矛盾</strong>：普通人无法拥有庞大的数据量与计算资源。因此需要借助于模型的迁移。</li>
<li><strong>普适化模型与个性化需求的矛盾</strong>：即使是在同一个任务上，一个模型也往往难以满足每个人的个性化需求，比如特定的隐私设置。这就需要在不同人之间做模型的适配。</li>
<li><strong>特定应用（如冷启动）的需求</strong>。</li>
</ol>
<h3 id="11-1-3-迁移学习的基本问题有哪些？">11.1.3 迁移学习的基本问题有哪些？</h3>
<p>基本问题主要有3个：</p>
<ul>
<li><strong>How to transfer</strong>： 如何进行迁移学习？（设计迁移方法）</li>
<li><strong>What to transfer</strong>： 给定一个目标领域，如何找到相对应的源领域，然后进行迁移？（源领域选择）</li>
<li><strong>When to transfer</strong>： 什么时候可以进行迁移，什么时候不可以？（避免负迁移）</li>
</ul>
<h3 id="11-1-4-迁移学习有哪些常用概念？">11.1.4 迁移学习有哪些常用概念？</h3>
<ul>
<li>基本定义
<ul>
<li><strong>域(Domain)</strong>：数据特征和特征分布组成，是学习的主体
<ul>
<li><strong>源域 (Source domain)</strong>：已有知识的域</li>
<li><strong>目标域 (Target domain)</strong>：要进行学习的域</li>
</ul>
</li>
<li><strong>任务 (Task)</strong>：由目标函数和学习结果组成，是学习的结果</li>
</ul>
</li>
<li>按特征空间分类
<ul>
<li><strong>同构迁移学习（Homogeneous TL）</strong>： 源域和目标域的特征空间相同， $D_s=D_t$</li>
<li><strong>异构迁移学习（Heterogeneous TL）</strong>：源域和目标域的特征空间不同， $D_s\ne D_t$</li>
</ul>
</li>
<li>按迁移情景分类
<ul>
<li><strong>归纳式迁移学习（Inductive TL）</strong>：源域和目标域的学习任务不同</li>
<li><strong>直推式迁移学习（Transductive TL)</strong>：源域和目标域不同，学习任务相同</li>
<li><strong>无监督迁移学习（Unsupervised TL)</strong>：源域和目标域均没有标签</li>
</ul>
</li>
<li>按迁移方法分类
<ul>
<li><strong>基于实例的迁移 (Instance based TL)</strong>：通过权重重用源域和目标域的样例进行迁移</li>
<li><strong>基于特征的迁移 (Feature based TL)</strong>：将源域和目标域的特征变换到相同空间</li>
<li><strong>基于模型的迁移 (Parameter based TL)</strong>：利用源域和目标域的参数共享模型</li>
<li><strong>基于关系的迁移 (Relation based TL)</strong>：利用源域中的逻辑网络关系进行迁移</li>
</ul>
</li>
</ul>
<p><img src="1542972502781.png" alt="1542972502781"></p>
<p><img src="1542974131814.png" alt="1542974131814"></p>
<h3 id="11-1-5-迁移学习与传统机器学习有什么区别？">11.1.5 迁移学习与传统机器学习有什么区别？</h3>
<table>
<thead>
<tr>
<th></th>
<th>迁移学习</th>
<th>传统机器学习</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据分布</td>
<td>训练和测试数据不需要同分布</td>
<td>训练和测试数据同分布</td>
</tr>
<tr>
<td>数据标签</td>
<td>不需要足够的数据标注</td>
<td>足够的数据标注</td>
</tr>
<tr>
<td>建模</td>
<td>可以重用之前的模型</td>
<td>每个任务分别建模</td>
</tr>
</tbody>
</table>
<p><img src="1542973960796.png" alt="1542973960796"></p>
<h3 id="11-1-6-迁移学习的核心及度量准则？">11.1.6 迁移学习的核心及度量准则？</h3>
<p><strong>迁移学习的总体思路可以概括为</strong>：开发算法来最大限度地利用有标注的领域的知识，来辅助目标领域的知识获取和学习。</p>
<p><strong>迁移学习的核心是</strong>：找到源领域和目标领域之间的相似性，并加以合理利用。这种相似性非常普遍。比如，不同人的身体构造是相似的；自行车和摩托车的骑行方式是相似的；国际象棋和中国象棋是相似的；羽毛球和网球的打球方式是相似的。这种相似性也可以理解为不变量。以不变应万变，才能立于不败之地。</p>
<p>**有了这种相似性后，下一步工作就是， 如何度量和利用这种相似性。**度量工作的目标有两点：一是很好地度量两个领域的相似性，不仅定性地告诉我们它们是否相似，更定量地给出相似程度。二是以度量为准则，通过我们所要采用的学习手段，增大两个领域之间的相似性，从而完成迁移学习。</p>
<p><strong>一句话总结： 相似性是核心，度量准则是重要手段。</strong></p>
<h3 id="11-1-7-迁移学习与其他概念的区别？">11.1.7 迁移学习与其他概念的区别？</h3>
<ol>
<li>迁移学习与多任务学习关系：
<ul>
<li><strong>多任务学习</strong>：多个相关任务一起协同学习；</li>
<li><strong>迁移学习</strong>：强调信息复用，从一个领域(domain)迁移到另一个领域。</li>
</ul>
</li>
<li>迁移学习与领域自适应：<strong>领域自适应</strong>：使两个特征分布不一致的domain一致。</li>
<li>迁移学习与协方差漂移：<strong>协方差漂移</strong>：数据的条件概率分布发生变化。</li>
</ol>
<p>Reference：</p>
<ol>
<li><a href="https%EF%BC%9A//github.com/jindongwang/transferlearning-tutorial">王晋东，迁移学习简明手册</a></li>
<li>Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., &amp; Vaughan, J. W. (2010). A theory of learning from different domains. Machine learning, 79(1-2), 151-175.</li>
<li>Tan, B., Song, Y., Zhong, E. and Yang, Q., 2015, August. Transitive transfer learning. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 1155-1164). ACM.</li>
</ol>
<h3 id="11-1-8-什么是负迁移？产生负迁移的原因有哪些？">11.1.8 什么是负迁移？产生负迁移的原因有哪些？</h3>
<p>负迁移(Negative Transfer)指的是，在源域上学习到的知识，对于目标域上的学习产生负面作用。</p>
<p>产生负迁移的原因主要有：</p>
<ul>
<li>数据问题：源域和目标域压根不相似，谈何迁移？</li>
<li>方法问题：源域和目标域是相似的，但是，迁移学习方法不够好，没找到可迁移的成分。</li>
</ul>
<p>负迁移给迁移学习的研究和应用带来了负面影响。在实际应用中，找到合理的相似性，并且选择或开发合理的迁移学习方法，能够避免负迁移现象。</p>
<h3 id="11-1-9-迁移学习的基本思路？">11.1.9 迁移学习的基本思路？</h3>
<p>迁移学习的总体思路可以概括为：开发算法来最大限度地利用有标注的领域的知识，来辅助目标领域的知识获取和学习。</p>
<ol>
<li>找到目标问题的相似性，迁移学习任务就是从相似性出发，将旧领域(domain)学习过的模型应用在新领域上。</li>
<li>迁移学习，是指利用数据、任务、或模型之间的相似性，将在旧领域学习过的模型，应用于新领域的一种学习过程。</li>
<li>迁移学习<strong>最有用的场合</strong>是，如果你尝试优化任务B的性能，通常这个任务数据相对较少。<br>
例如，在放射科中你知道很难收集很多射线扫描图来搭建一个性能良好的放射科诊断系统，所以在这种情况下，你可能会找一个相关但不同的任务，如图像识别，其中你可能用 1 百万张图片训练过了，并从中学到很多低层次特征，所以那也许能帮助网络在任务在放射科任务上做得更好，尽管任务没有这么多数据。</li>
<li>迁移学习什么时候是有意义的？它确实可以<strong>显著提高</strong>你的<strong>学习任务的性能</strong>，但我有时候也见过有些场合使用迁移学习时，任务实际上数据量比任务要少， 这种情况下增益可能不多。</li>
</ol>
<blockquote>
<p>什么情况下可以使用迁移学习？</p>
<p>假如两个领域之间的区别特别的大，<strong>不可以直接采用迁移学习</strong>，因为在这种情况下效果不是很好。在这种情况下，推荐使用[3]的工作，在两个相似度很低的domain之间一步步迁移过去（踩着石头过河）。</p>
</blockquote>
<blockquote>
<ol>
<li>迁移学习主要解决方案有哪些？</li>
<li>除直接看infer的结果的Accurancy以外，如何衡量迁移学习学习效果？</li>
<li>对抗网络是如何进行迁移的？</li>
</ol>
</blockquote>
<p>Reference：</p>
<ol>
<li><a href="https%EF%BC%9A//github.com/jindongwang/transferlearning-tutorial">王晋东，迁移学习简明手册</a></li>
<li>Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., &amp; Vaughan, J. W. (2010). A theory of learning from different domains. Machine learning, 79(1-2), 151-175.</li>
<li>Tan, B., Song, Y., Zhong, E. and Yang, Q., 2015, August. Transitive transfer learning. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 1155-1164). ACM.</li>
</ol>
<h2 id="11-2-迁移学习的基本思路有哪些？">11.2 迁移学习的基本思路有哪些？</h2>
<p>​	迁移学习的基本方法可以分为四种。这四种基本的方法分别是：基于样本的迁移， 基于模型 的迁移， 基于特征的迁移，及基于关系的迁移。</p>
<h3 id="11-2-1-基于样本迁移">11.2.1 基于样本迁移</h3>
<p>​	基于样本的迁移学习方法 (Instance based Transfer Learning) 根据一定的权重生成规则，对数据样本进行重用，来进行迁移学习。图<a href="#bookmark90">14</a>形象地表示了基于样本迁移方法的思想源域中存在不同种类的动物，如狗、鸟、猫等，目标域只有狗这一种类别。在迁移时，为了最大限度地和目标域相似，我们可以人为地提高源域中属于狗这个类别的样本权重。</p>
<p><img src="631e5aab4e0680c374793804817bfbb6.jpg" alt></p>
<center>图 14: 基于样本的迁移学习方法示意图
<p>​	在迁移学习中，对于源域D~s~和目标域D~t~，通常假定产生它们的概率分布是不同且未知的(P(X~s~) =P(X~t~))。另外，由于实例的维度和数量通常都非常大，因此，直接对 P(X~s~) 和P(X~t~) 进行估计是不可行的。因而，大量的研究工作 [<a href="#bookmark267">Khan and Heisterkamp,2016</a>, <a href="#bookmark319">Zadrozny, 2004</a>, <a href="#bookmark242">Cortes et al.,2008</a>, <a href="#bookmark243">Dai et al., 2007</a>, <a href="#bookmark302">Tan et al.,2015</a>, <a href="#bookmark303">Tan et al., 2017</a>] 着眼于对源域和目标域的分布比值进行估计(P(<strong>X</strong>t)/P(<strong>X</strong>s))。所估计得到的比值即为样本的权重。这些方法通常都假设P(<strong>x</strong>s) &lt;并且源域和目标域的条件概率分布相同(P(y|x~s~)=<em>P</em>(y|x~t~))。特别地，上海交通大学Dai等人[<a href="#bookmark243">Dai et al.,2007</a>]提出了 TrAdaboost方法，将AdaBoost的思想应用于迁移学习中，提高有利于目标分类任务的实例权重、降低不利于目标分类任务的实例权重，并基于PAC理论推导了模型的泛化误差上界。TrAdaBoost方法是此方面的经典研究之一。文献 [<a href="#bookmark264">Huang et al., 2007</a>]提出核均值匹配方法 (Kernel Mean atching, KMM)对于概率分布进行估计，目标是使得加权后的源域和目标域的概率分布尽可能相近。在最新的研究成果中，香港科技大学的Tan等人扩展了实例迁移学习方法的应用场景，提出 了传递迁移学习方法(Transitive Transfer Learning, TTL) [<a href="#bookmark302">Tan etal., 2015</a>] 和远域迁移学习 (Distant Domain Transfer Learning,DDTL) [<a href="#bookmark303">Tan et al., 2017</a>]，利用联合矩阵分解和深度神经网络，将迁移学习应用于多个不相似的领域之间的知识共享，取得了良好的效果。</p>
<p>​	虽然实例权重法具有较好的理论支撑、容易推导泛化误差上界，但这类方法通常只在领域间分布差异较小时有效，因此对自然语言处理、计算机视觉等任务效果并不理想。而基于特征表示的迁移学习方法效果更好,是我们研究的重点。</p>
<h3 id="11-2-2-基于特征迁移">11.2.2 基于特征迁移</h3>
<p>​	基于特征的迁移方法 (Feature based Transfer Learning) 是指将通过特征变换的方式互相迁移 [<a href="#bookmark272">Liu et al., 2011</a>, <a href="#bookmark327">Zheng et al.,2008</a>, <a href="#bookmark263">Hu and Yang, 2011</a>],来减少源域和目标域之间的差距；或者将源域和目标域的数据特征变换到统一特征空间中 [<a href="#bookmark288">Pan et al.,2011</a>, <a href="#bookmark278">Long et al., 2014b</a>, <a href="#bookmark248">Duan et al.,2012</a>],然后利用传统的机器学习方法进行分类识别。根据特征的同构和异构性,又可以分为同构和异构迁移学习。图<a href="#bookmark93">15</a>很形象地表示了两种基于特 征的迁移学习方法。</p>
<p><img src="fa08900e89bfd53cc28345d21bc6aca0.jpg" alt></p>
<center>图 15: 基于特征的迁移学习方法示意图
<p>​	基于特征的迁移学习方法是迁移学习领域中最热门的研究方法,这类方法通常假设源域和目标域间有一些交叉的特征。香港科技大学的 Pan 等人 [<a href="#bookmark288">Pan et al.,2011</a>] 提出的迁移 成分分析方法 (Transfer Component Analysis, TCA)是其中较为典型的一个方法。该方法的 核心内容是以最大均值差异 (Maximum MeanDiscrepancy, MMD) [<a href="#bookmark236">Borgwardt et al., 2006</a>]作为度量准则,将不同数据领域中的分布差异最小化。加州大学伯克利分校的 Blitzer 等人 [<a href="#bookmark235">Blitzer et al., 2006</a>] 提出了一种基于结构对应的学习方法(Structural Corresponding Learning,SCL),该算法可以通过映射将一个空间中独有的一些特征变换到其他所有空间中的轴特征上,然后在该特征上使用机器学习的算法进行分类预测。清华大学龙明盛等人[<a href="#bookmark278">Long et al.,2014b</a>]提出在最小化分布距离的同时，加入实例选择的迁移联合匹配(Tran-fer Joint Matching, TJM) 方法,将实例和特征迁移学习方法进行了有机的结合。澳大利亚卧龙岗大学的 Jing Zhang 等人 [<a href="#bookmark321">Zhang et al., 2017a</a>]提出对于源域和目标域各自训练不同 的变换矩阵,从而达到迁移学习的目标。</p>
<h3 id="11-2-3-基于模型迁移">11.2.3 基于模型迁移</h3>
<p>​	基于模型的迁移方法 (Parameter/Model based Transfer Learning) 是指从源域和目标域中找到他们之间共享的参数信息,以实现迁移的方法。这种迁移方式要求的假设条件是： 源域中的数据与目标域中的数据可以共享一些模型的参数。其中的代表性工作主要有［<a href="#bookmark324">Zhao et al., 2010</a>, <a href="#bookmark325">Zhao et al., 2011</a>, <a href="#bookmark287">Panet al., 2008b</a>, <a href="#bookmark286">Pan et al., 2008a</a>］。图<a href="#bookmark96">16</a>形象地 表示了基于模型的迁移学习方法的基本思想。</p>
<p><img src="602723a1d3ce0f3abe7c591a8e4bb6ec.jpg" alt></p>
<center>图 16: 基于模型的迁移学习方法示意图
<p>​	其中，中科院计算所的Zhao等人[<a href="#bookmark325">Zhao et al., 2011</a>]提出了TransEMDT方法。该方法首先针对已有标记的数据，利用决策树构建鲁棒性的行为识别模型，然后针对无标定数据，利用K-Means聚类方法寻找最优化的标定参数。西安邮电大学的Deng等人[<a href="#bookmark245">Deng et al.,2014</a>] 也用超限学习机做了类似的工作。香港科技大学的Pan等人[<a href="#bookmark286">Pan etal., 2008a</a>]利用HMM，针对Wifi室内定位在不同设备、不同时间和不同空间下动态变化的特点，进行不同分布下的室内定位研究。另一部分研究人员对支持向量机 SVM 进行了改进研究 [<a href="#bookmark285">Nater et al.,2011</a>, <a href="#bookmark269">Li et al., 2012</a>]。这些方法假定 SVM中的权重向量 <strong>w</strong> 可以分成两个部分： <strong>w</strong> = <strong>wo</strong>+<strong>v</strong>， 其中 <strong>w</strong>0代表源域和目标域的共享部分， <strong>v</strong> 代表了对于不同领域的特定处理。在最新的研究成果中，香港科技大学的 Wei 等人 [<a href="#bookmark313">Wei et al., 2016b</a>]将社交信息加入迁移学习方法的 正则项中，对方法进行了改进。清华大学龙明盛等人[<a href="#bookmark275">Long et al., 2015a</a>, <a href="#bookmark276">Long et al., 2016</a>, <a href="#bookmark280">Long etal., 2017</a>]改进了深度网络结构，通过在网络中加入概率分布适配层，进一步提高了深度迁移学习网络对于大数据的泛化能力。</p>
<h3 id="11-2-4-基于关系迁移">11.2.4 基于关系迁移</h3>
<p>​	基于关系的迁移学习方法 (Relation Based Transfer Learning) 与上述三种方法具有截然不同的思路。这种方法比较关注源域和目标域的样本之间的关系。图<a href="#bookmark82">17</a>形象地表示了不 同领域之间相似的关系。</p>
<p>​	就目前来说，基于关系的迁移学习方法的相关研究工作非常少，仅有几篇连贯式的文章讨论： [<a href="#bookmark283">Mihalkova et al., 2007</a>, <a href="#bookmark284">Mihalkova and Mooney,2008</a>, <a href="#bookmark244">Davis and Domingos, 2009</a>]。这些文章都借助于马尔科夫逻辑网络(Markov Logic Net)来挖掘不同领域之间的关系相似性。</p>
<p>​	我们将重点讨论基于特征和基于模型的迁移学习方法，这也是目前绝大多数研究工作的热点。</p>
<p><img src="aa10d36f758430dd4ff72d2bf6a76a6c.jpg" alt></p>
<center>图 17: 基于关系的迁移学习方法示意图
<p><img src="1542812440636.png" alt="1542812440636"></p>
<center>图 18: 基于马尔科夫逻辑网的关系迁移
<h2 id="11-3-迁移学习的常用方法">11.3 迁移学习的常用方法</h2>
<h3 id="11-3-1-数据分布自适应">11.3.1 数据分布自适应</h3>
<p>​	数据分布自适应 (Distribution Adaptation) 是一类最常用的迁移学习方法。这种方法的基本思想是,由于源域和目标域的数据概率分布不同,那么最直接的方式就是通过一些变换,将不同的数据分布的距离拉近。</p>
<p>​	图 <a href="#bookmark84">19</a>形象地表示了几种数据分布的情况。简单来说，数据的边缘分布不同，就是数据整体不相似。数据的条件分布不同，就是数据整体相似，但是具体到每个类里，都不太相似。</p>
<p><img src="1542812748062.png" alt="1542812748062"></p>
<center>图 19: 不同数据分布的目标域数据
<p>​	根据数据分布的性质,这类方法又可以分为边缘分布自适应、条件分布自适应、以及联合分布自适应。下面我们分别介绍每类方法的基本原理和代表性研究工作。介绍每类研究工作时,我们首先给出基本思路,然后介绍该类方法的核心,最后结合最近的相关工作介绍该类方法的扩展。</p>
<h3 id="11-3-2-边缘分布自适应">11.3.2 边缘分布自适应</h3>
<p>​	边缘分布自适应方法 (Marginal Distribution Adaptation) 的目标是减小源域和目标域的边缘概率分布的距离,从而完成迁移学习。从形式上来说,边缘分布自适应方法是用P(X~s~)和 P(X~t~)之间的距离来近似两个领域之间的差异。即：</p>
<p>​	 $DISTANCE(D~s~,D~t~)\approx\lVert P(X_s)-P(X_t)\Vert$  (6.1)</p>
<p>​	边缘分布自适应对应于图<a href="#bookmark84">19</a>中由图<a href="#bookmark101">19(a)</a>迁移到图<a href="#bookmark83">19(b)</a>的情形。</p>
<h3 id="11-3-3-条件分布自适应">11.3.3 条件分布自适应</h3>
<p>​	条件分布自适应方法 (Conditional Distribution Adaptation) 的目标是减小源域和目标域的条件概率分布的距离，从而完成迁移学习。从形式上来说，条件分布自适应方法是用  P(y~s~|X~s~) 和 P (y~t~|X~t~) 之间的距离来近似两个领域之间的差异。即：</p>
<p>​	 $DISTANCE(D~s~,D~t~)\approx\lVert P(y_s|X_s)-P(y_t|X_t)\Vert$ (6.8)</p>
<p>​	条件分布自适应对应于图<a href="#bookmark84">19</a>中由图<a href="#bookmark101">19(a)</a>迁移到图<a href="#bookmark85">19©</a>的情形。</p>
<p>​	目前单独利用条件分布自适应的工作较少，这些工作主要可以在 [<a href="#bookmark292">Saito et al.,2017</a>] 中找到。最近，中科院计算所的 Wang 等人提出了 STL 方法(Stratified Transfer Learn­ing) [<a href="#bookmark309">Wang tal.,2018</a>]。作者提出了类内迁移 (Intra-class Transfer)的思想。指出现有的 绝大多数方法都只是学习一个全局的特征变换(Global DomainShift)，而忽略了类内的相 似性。类内迁移可以利用类内特征，实现更好的迁移效果。</p>
<p>​	STL 方法的基本思路如图所示。首先利用大多数投票的思想，对无标定的位置行为生成伪标；然后在再生核希尔伯特空间中，利用类内相关性进行自适应地空间降维，使得不同情境中的行为数据之间的相关性增大；最后，通过二次标定，实现对未知标定数据的精准标定。</p>
<p><img src="1542817481582.png" alt="1542817481582"></p>
<center>图 21: STL 方法的示意图
### 11.3.4 联合分布自适应
<p>​	联合分布自适应方法 (Joint Distribution Adaptation) 的目标是减小源域和目标域的联合概率分布的距离，从而完成迁移学习。从形式上来说，联合分布自适应方法是用<em>P</em>(<strong>x</strong>s) 和P(<strong>x</strong>t)之间的距离、以及P(ys|<strong>x</strong>s)和P(yt|<strong>x</strong>t)之间的距离来近似两个领域之间的差异。即:</p>
<p>​	 $DISTANCE(D~s~,D~t~)\approx\lVert P(X_s)-P(X_t)\Vert-\lVert P(y_s|X_s)-P(y_t|X_t)\Vert​$ (6.10)</p>
<p>​	联合分布自适应对应于图<a href="#bookmark84">19</a>中由图<a href="#bookmark101">19(a)</a>迁移到图<a href="#bookmark83">19(b)</a>的情形、以及图<a href="#bookmark101">19(a)</a>迁移到<br>
图<a href="#bookmark85">19©</a>的情形。</p>
<h3 id="11-3-4-概率分布自适应方法优劣性比较">11.3.4 概率分布自适应方法优劣性比较</h3>
<p>综合上述三种概率分布自适应方法，我们可以得出如下的结论：</p>
<ol>
<li>精度比较： BDA &gt;JDA &gt;TCA &gt;条件分布自适应。</li>
<li>将不同的概率分布自适应方法用于神经网络，是一个发展趋势。图<a href="#bookmark119">23</a>展示的结果表明将概率分布适配加入深度网络中，往往会取得比非深度方法更好的结果。</li>
</ol>
<p><img src="1542823019007.png" alt="1542823019007"></p>
<center>图 22: BDA 方法的效果第二类方法：特征选择
### 11.3.6 特征选择
<p>​	特征选择法的基本假设是：源域和目标域中均含有一部分公共的特征，在这部分公共的特征，源领域和目标领域的数据分布是一致的。因此，此类方法的目标就是，通过机器学习方法，选择出这部分共享的特征，即可依据这些特征构建模型。</p>
<p>​	图 <a href="#bookmark122">24</a>形象地表示了特征选择法的主要思路。</p>
<p><img src="1542823210556.png" alt="1542823210556"></p>
<center>图 23: 不同分布自适应方法的精度比较
<p><img src="a3db84158d9b6454adff88dbe4fa5d28.jpg" alt></p>
<center>图 24: 特征选择法示意图
<p>​	这这个领域比较经典的一个方法是发表在 2006 年的 ECML-PKDD 会议上,作者提出了一个叫做 SCL 的方法 (Structural Correspondence Learning) [<a href="#bookmark235">Blitzer et al.,2006</a>]。这个方法的目标就是我们说的,找到两个领域公共的那些特征。作者将这些公共的特征叫做Pivot feature。找出来这些Pivot feature,就完成了迁移学习的任务。</p>
<p><img src="4abacd82901988c3e0a98bdb07b2abc6.jpg" alt></p>
<center>图 25: 特征选择法中的 Pivot feature 示意图
<p>​	图 <a href="#bookmark124">25</a>形象地展示了 Pivot feature 的含义。 Pivot feature指的是在文本分类中,在不同领域中出现频次较高的那些词。总结起来：</p>
<ul>
<li>特征选择法从源域和目标域中选择提取共享的特征,建立统一模型</li>
<li>通常与分布自适应方法进行结合</li>
<li>通常采用稀疏表示 ||<strong>A</strong>||2,1 实现特征选择</li>
</ul>
<h3 id="11-3-5-统计特征对齐方法">11.3.5 统计特征对齐方法</h3>
<p>​	统计特征对齐方法主要将数据的统计特征进行变换对齐。对齐后的数据，可以利用传统机器学习方法构建分类器进行学习。SA方法(Subspace Alignment，子空间对齐)[<a href="#bookmark249">Fernando et al.,2013</a>]是其中的代表性成果。SA方法直接寻求一个线性变换<strong>M</strong>，将不同的数据实现变换对齐。SA方法的优化目标如下：</p>
<p><img src="1542823438846.png" alt="1542823438846"></p>
<p>则变换 <strong>M</strong> 的值为：</p>
<p><img src="1542823455820.png" alt="1542823455820"></p>
<p>可以直接获得上述优化问题的闭式解：</p>
<p><img src="1542823474720.png" alt="1542823474720"></p>
<p>​	SA 方法实现简单，计算过程高效，是子空间学习的代表性方法。</p>
<h3 id="11-3-6-流形学习方法">11.3.6 流形学习方法</h3>
<p><strong>什么是流形学习</strong></p>
<p>​	流形学习自从 2000 年在 Science 上被提出来以后,就成为了机器学习和数据挖掘领域的热门问题。它的基本假设是,现有的数据是从一个高维空间中采样出来的,所以,它具有高维空间中的低维流形结构。流形就是是一种几何对象（就是我们能想像能观测到的）。通俗点说就是,我们无法从原始的数据表达形式明显看出数据所具有的结构特征,那我把它想像成是处在一个高维空间,在这个高维空间里它是有个形状的。一个很好的例子就是星座。满天星星怎么描述？我们想像它们在一个更高维的宇宙空间里是有形状的,这就有了各自星座,比如织女座、猎户座。流形学习的经典方法有Isomap、locally linear embedding、 laplacian eigenmap 等。</p>
<p>​	流形空间中的距离度量：两点之间什么最短？在二维上是直线（线段）,可在三维呢？地球上的两个点的最短距离可不是直线,它是把地球展开成二维平面后画的那条直线。那条线在三维的地球上就是一条曲线。这条曲线就表示了两个点之间的最短距离,我们叫它测地线。更通俗一点, 两点之间，测地线最短。在流形学习中,我们遇到测量距离的时候更多的时候用的就是这个测地线。在我们要介绍的 GFK 方法中,也是利用了这个测地线距离。比如在下面的图中,从 A 到 C 最短的距离在就是展开后的线段,但是在三维球体上看它却是一条曲线。</p>
<p><img src="fcbe02803e45f6455a4602b645b472c5.jpg" alt></p>
<center>图 28: 三维空间中两点之间的距离示意图
<p>​	由于在流形空间中的特征通常都有着很好的几何性质,可以避免特征扭曲,因此我们首先将原始空间下的特征变换到流形空间中。在众多已知的流形中, Grassmann 流形G（d） 可以通过将原始的 d 维子空间 （特征向量）看作它基础的元素,从而可以帮助学习分类 器。在 Grassmann流形中,特征变换和分布适配通常都有着有效的数值形式,因此在迁移学习问题中可以被很高效地表示和求解 [<a href="#bookmark260">Hamm and Lee,2008</a>]。因此,利用 Grassmann流形空间中来进行迁移学习是可行的。现存有很多方法可以将原始特征变换到流形空间 中[<a href="#bookmark257">Gopalan et al., 2011</a>, <a href="#bookmark230">Baktashmotlagh et al.,2014</a>]。</p>
<p>​	在众多的基于流形变换的迁移学习方法中，GFK(Geodesic Flow Kernel)方法[<a href="#bookmark255">Gong et<br>
al., 2012</a>]是最为代表性的一个。GFK是在2011年发表在ICCV上的SGF方法[<a href="#bookmark257">Gopalan et al.,<br>
2011</a>]发展起来的。我们首先介绍SGF方法。</p>
<p>​	SGF 方法从增量学习中得到启发：人类从一个点想到达另一个点，需要从这个点一步一步走到那一个点。那么，如果我们把源域和目标域都分别看成是高维空间中的两个点，由源域变换到目标域的过程不就完成了迁移学习吗？也就是说， 路是一步一步走出来的。</p>
<p>​	于是 SGF 就做了这个事情。它是怎么做的呢？把源域和目标域分别看成高维空间 (即Grassmann流形)中的两个点，在这两个点的测地线距离上取d个中间点，然后依次连接起来。这样，源域和目标域就构成了一条测地线的路径。我们只需要找到合适的每一步的变换，就能从源域变换到目标域了。图 <a href="#bookmark133">29</a>是 SGF 方法的示意图。</p>
<p><img src="103de3658cbb97ad4c24bafe28f9d957.jpg" alt></p>
<center>图 29: SGF 流形迁移学习方法示意图
<p>​	SGF 方法的主要贡献在于：提出了这种变换的计算及实现了相应的算法。但是它有很明显的缺点：到底需要找几个中间点？ SGF也没能给出答案，就是说这个参数d是没法估计的，没有一个好的方法。这个问题在 GFK 中被回答了。</p>
<p>​	GFK方法首先解决SGF的问题：如何确定中间点的个数d。它通过提出一种核学习的方法，利用路径上的无穷个点的积分，把这个问题解决了。这是第一个贡献。然后，它又解决了第二个问题：当有多个源域的时候，我们如何决定使用哪个源域跟目标域进行迁移？ GFK通过提出Rank of Domain度量，度量出跟目标域最近的源域，来解决这个问题。图 <a href="#bookmark134">30</a>是 GFK 方法的示意图。</p>
<p><img src="e654d14df0b44ee4e8a0e505c654044b.jpg" alt></p>
<center>图 30: GFK 流形迁移学习方法示意图
<p>​	用Ss和St分别表示源域和目标域经过主成分分析(PCA)之后的子空间，则G可以视为所有的d维子空间的集合。每一个d维的原始子空间都可以被看作G上的一个点。因此，在两点之间的测地线｛\ $(t) :0 \< t \<1｝可以在两个子空间之间构成一条路径。如果我 们令ss="\$" (0)，st="\" $(1)，则寻找一条从\$ (0)到\ $(1)的测地线就等同于将原始的特征变换到一个无穷维度的空间中，最终减小域之间的漂移现象。这种方法可以被看作是一种从\$ $(1)的増量式“行走”方法。 ​ 特别地，流形空间中的特征可以被表示为**z**="\$" (t)t<strong>x。变换后的特征<strong>Z</strong>i和<strong>Z</strong>j的内积定义了一个半正定 (positive semidefinite) 的测地线流式核</1｝可以在两个子空间之间构成一条路径。如果我></p>
<p><img src="1542823895008.png" alt="1542823895008"></p>
<p>​	GFK 方法详细的计算过程可以参考原始的文章，我们在这里不再赘述。</p>
<h3 id="11-3-7-什么是finetune？">11.3.7 什么是finetune？</h3>
<p>​	深度网络的finetune也许是最简单的深度网络迁移方法。<strong>Finetune</strong>,也叫微调、fine-tuning, 是深度学习中的一个重要概念。简而言之，finetune就是利用别人己经训练好的网络，针对自己的任务再进行调整。从这个意思上看，我们不难理解finetune是迁移学习的一部分。</p>
<p><strong>为什么需要已经训练好的网络？</strong></p>
<p>​	在实际的应用中,我们通常不会针对一个新任务,就去从头开始训练一个神经网络。这样的操作显然是非常耗时的。尤其是，我们的训练数据不可能像ImageNet那么大，可以训练出泛化能力足够强的深度神经网络。即使有如此之多的训练数据,我们从头开始训练,其代价也是不可承受的。</p>
<p>​	那么怎么办呢？迁移学习告诉我们,利用之前己经训练好的模型,将它很好地迁移到自己的任务上即可。</p>
<p><strong>为什么需要 finetune？</strong></p>
<p>​	因为别人训练好的模型,可能并不是完全适用于我们自己的任务。可能别人的训练数据和我们的数据之间不服从同一个分布；可能别人的网络能做比我们的任务更多的事情；可能别人的网络比较复杂,我们的任务比较简单。</p>
<p>​	举一个例子来说,假如我们想训练一个猫狗图像二分类的神经网络,那么很有参考价值的就是在 CIFAR-100 上训练好的神经网络。但是 CIFAR-100 有 100 个类别,我们只需要 2个类别。此时,就需要针对我们自己的任务,固定原始网络的相关层,修改网络的输出层以使结果更符合我们的需要。</p>
<p>​	图<a href="#bookmark148">36</a>展示了一个简单的finetune过程。从图中我们可以看到，我们采用的预训练好的网络非常复杂,如果直接拿来从头开始训练,则时间成本会非常高昂。我们可以将此网络进行改造,固定前面若干层的参数,只针对我们的任务,微调后面若干层。这样,网络训练速度会极大地加快,而且对提高我们任务的表现也具有很大的促进作用。</p>
<p><img src="b1630ca5d004d4b430672c8b8ce7fb90.jpg" alt></p>
<center>图 36: 一个简单的 finetune 示意图
**Finetune 的优势**
<p>​	Finetune 的优势是显然的，包括:</p>
<ul>
<li>不需要针对新任务从头开始训练网络，节省了时间成本；</li>
<li>预训练好的模型通常都是在大数据集上进行的，无形中扩充了我们的训练数据，使得模型更鲁棒、泛化能力更好；</li>
<li>Finetune 实现简单，使得我们只关注自己的任务即可。</li>
</ul>
<p><strong>Finetune 的扩展</strong></p>
<p>​	在实际应用中，通常几乎没有人会针对自己的新任务从头开始训练一个神经网络。Fine-tune 是一个理想的选择。</p>
<p>​	Finetune 并不只是针对深度神经网络有促进作用，对传统的非深度学习也有很好的效果。例如， finetune对传统的人工提取特征方法就进行了很好的替代。我们可以使用深度网络对原始数据进行训练，依赖网络提取出更丰富更有表现力的特征。然后，将这些特征作为传统机器学习方法的输入。这样的好处是显然的: 既避免了繁复的手工特征提取，又能自动地提取出更有表现力的特征。</p>
<p>​	比如，图像领域的研究，一直是以 SIFT、SURF 等传统特征为依据的，直到 2014 年，伯克利的研究人员提出了 DeCAF特征提取方法［<a href="#bookmark246">Donahue et al.,2014</a>］，直接使用深度卷积神经网络进行特征提取。实验结果表明，该特征提取方法对比传统的图像特征，在精度上有着无可匹敌的优势。另外，也有研究人员用卷积神经网络提取的特征作为SVM分类器的输 入［<a href="#bookmark291">Razavian et al.,014</a>］，显著提升了图像分类的精度。</p>
<h3 id="11-3-8-finetune为什么有效？">11.3.8 finetune为什么有效？</h3>
<p>​	随着 AlexNet [<a href="#bookmark268">Krizhevsky et al., 2012</a>] 在 2012 年的 ImageNet大赛上获得冠军，深度学习开始在机器学习的研究和应用领域大放异彩。尽管取得了很好的结果，但是神经网络本身就像一个黑箱子，看得见，摸不着，解释性不好。由于神经网络具有良好的层次结构很自然地就有人开始关注，能否通过这些层次结构来很好地解释网络？于是，有了我们熟知的例子：假设一个网络要识别一只猫，那么一开始它只能检测到一些边边角角的东西，和猫根本没有关系；然后可能会检测到一些线条和圆形；慢慢地，可以检测到有猫的区域；接着是猫腿、猫脸等等。图 <a href="#bookmark137">32</a>是一个简单的示例。</p>
<p><img src="1542824195602.png" alt="1542824195602"></p>
<center>图 32: 深度神经网络进行特征提取到分类的简单示例
<p>​	这表达了一个什么事实呢？概括来说就是：前面几层都学习到的是通用的特征（general feature）；随着网络层次的加深，后面的网络更偏重于学习任务特定的特征（specific feature）。<br>
这非常好理解，我们也都很好接受。那么问题来了：如何得知哪些层能够学习到 general feature，哪些层能够学习到specific feature。更进一步：如果应用于迁移学习，如何决定该迁移哪些层、固定哪些层？</p>
<p>​	这个问题对于理解神经网络以及深度迁移学习都有着非常重要的意义。</p>
<p>​	来自康奈尔大学的 Jason Yosinski 等人 [<a href="#bookmark318">Yosinski et al., 2014</a>]率先进行了深度神经网络可迁移性的研究，将成果发表在2014年机器学习领域顶级会议NIPS上并做了口头汇报。该论文是一篇实验性质的文章（通篇没有一个公式）。其目的就是要探究上面我们提到的几个关键性问题。因此，文章的全部贡献都来自于实验及其结果。（别说为啥做实验也能发文章：都是高考，我只上了个普通一本，我高中同学就上了清华）</p>
<p>​	在ImageNet的1000类上，作者把1000类分成两份（A和B），每份500个类别。然后，分别对A和B基于Caffe训练了一个AlexNet网络。一个AlexNet网络一共有8层， 除去第8层是类别相关的网络无法迁移以外，作者在 1 到 7这 7层上逐层进行 finetune 实验，探索网络的可迁移性。</p>
<p>​	为了更好地说明 finetune 的结果，作者提出了有趣的概念： AnB 和 BnB。</p>
<p>​	迁移A网络的前n层到B （AnB） vs固定B网络的前n层（BnB）</p>
<p>​	简单说一下什么叫AnB:（所有实验都是针对数据B来说的）将A网络的前n层拿来并将它frozen，剩下的8 - n层随机初始化，然后对B进行分类。</p>
<p>​	相应地，有BnB:把训练好的B网络的前n层拿来并将它frozen，剩下的8 - n层随机初始化，然后对 B 进行分类。</p>
<p>​	<strong>实验结果</strong></p>
<p>​	实验结果如下图（图<a href="#bookmark145">33</a>） 所示:</p>
<p>​	这个图说明了什么呢？我们先看蓝色的BnB和BnB+（就是BnB加上finetune）。对 BnB而言，原训练好的 B 模型的前 3 层直接拿来就可以用而不会对模型精度有什么损失到了第4 和第5 层，精度略有下降，不过还是可以接受。然而到了第6 第第7层，精度居然奇迹般地回升了！这是为什么？原因如下:对于一开始精度下降的第4 第 5 层来说，确</p>
<p><img src="1542824318155.png" alt="1542824318155"></p>
<center>图 33: 深度网络迁移实验结果 1
<p>实是到了这一步，feature变得越来越specific,所以下降了。那对于第6第7层为什么精度又不变了？那是因为，整个网络就8层，我们固定了第6第7层，这个网络还能学什么呢？所以很自然地，精度和原来的 B 网络几乎一致！</p>
<p>​	对 BnB+ 来说，结果基本上都保持不变。说明 finetune 对模型结果有着很好的促进作用！</p>
<p>​	我们重点关注AnB和AnB+。对AnB来说，直接将A网络的前3层迁移到B,貌似不会有什么影响，再一次说明，网络的前3层学到的几乎都是general feature!往后，到了第4第5层的时候，精度开始下降，我们直接说：一定是feature不general 了！然而，到了第6第7层，精度出现了小小的提升后又下降，这又是为什么？作者在这里提出两点co-adaptation和feature representation。就是说，第4第5层精度下降的时候，主要是由于A和B两个数据集的差异比较大，所以会下降；至I」了第6第7层，由于网络几乎不迭代了，学习能力太差，此时 feature 学不到，所以精度下降得更厉害。</p>
<p>​	再看AnB+。加入了 finetune以后，AnB+的表现对于所有的n几乎都非常好，甚至 比baseB<br>
（最初的B）还要好一些！这说明：finetune对于深度迁移有着非常好的促进作用!</p>
<p>​	把上面的结果合并就得到了下面一张图 （图<a href="#bookmark138">34</a>）：</p>
<p>​	至此， AnB 和 BnB 基本完成。作者又想，是不是我分 A 和 B 数据的时候，里面存在一些比较相似的类使结果好了？比如说A里有猫，B里有狮子，所以结果会好？为了排除这些影响，作者又分了一下数据集，这次使得A和B里几乎没有相似的类别。在这个条件下再做AnB,与原来精度比较（0%为基准）得到了下图（图<a href="#bookmark139">35</a>）:</p>
<p>​	这个图说明了什么呢？简单：随着可迁移层数的增加，模型性能下降。但是，前3层仍然还是可以迁移的！同时,与随机初始化所有权重比较,迁移学习的精度是很高的!总之：</p>
<ul>
<li>
<p>深度迁移网络要比随机初始化权重效果好；</p>
</li>
<li>
<p>网络层数的迁移可以加速网络的学习和优化。</p>
</li>
</ul>
<h3 id="11-3-9-什么是深度网络自适应？">11.3.9 什么是深度网络自适应？</h3>
<p><strong>基本思路</strong></p>
<p>​	深度网络的 finetune 可以帮助我们节省训练时间，提高学习精度。但是 finetune 有它的先天不足:它无法处理训练数据和测试数据分布不同的情况。而这一现象在实际应用中比比皆是。因为 finetune 的基本假设也是训练数据和测试数据服从相同的数据分布。这在迁移学习中也是不成立的。因此，我们需要更进一步，针对深度网络开发出更好的方法使之更好地完成迁移学习任务。</p>
<p>​	以我们之前介绍过的数据分布自适应方法为参考，许多深度学习方法［<a href="#bookmark307">Tzeng et al.,2014</a>, <a href="#bookmark275">Long et al.,2015a</a>］都开发出了自适应层(AdaptationLayer)来完成源域和目标域数据的自适应。自适应能够使得源域和目标域的数据分布更加接近，从而使得网络的效果更好。</p>
<p>​	从上述的分析我们可以得出，深度网络的自适应主要完成两部分的工作:</p>
<p>​	一是哪些层可以自适应，这决定了网络的学习程度；</p>
<p>​	二是采用什么样的自适应方法 (度量准则)，这决定了网络的泛化能力。</p>
<p>​	深度网络中最重要的是网络损失的定义。绝大多数深度迁移学习方法都采用了以下的损失定义方式:</p>
<p><img src="1542824918145.png" alt="1542824918145"></p>
<p>​	其中，I表示网络的最终损失，lc(Ds,<strong>y</strong>s)表示网络在有标注的数据(大部分是源域)上的常规分类损失(这与普通的深度网络完全一致)，Ia(Ds,Dt)表示网络的自适应损失。最后一部分是传统的深度网络所不具有的、迁移学习所独有的。此部分的表达与我们先前讨论过的源域和目标域的分布差异，在道理上是相同的。式中的A是权衡两部分的权重参数。</p>
<p>​	上述的分析指导我们设计深度迁移网络的基本准则：决定自适应层，然后在这些层加入自适应度量，最后对网络进行 finetune。</p>
<h3 id="11-3-10-GAN在迁移学习中的应用">11.3.10 GAN在迁移学习中的应用</h3>
<p>生成对抗网络 GAN(Generative Adversarial Nets) [<a href="#bookmark256">Goodfellow et al.,2014</a>] 是目前人工智能领域最炙手可热的概念之一。其也被深度学习领军人物 Yann Lecun 评为近年来最令人欣喜的成就。由此发展而来的对抗网络，也成为了提升网络性能的利器。本小节介绍深度对抗网络用于解决迁移学习问题方面的基本思路以及代表性研究成果。</p>
<p><strong>基本思路</strong></p>
<p>​	GAN 受到自博弈论中的二人零和博弈 (two-player game) 思想的启发而提出。它一共包括两个部分：一部分为生成网络(Generative Network)，此部分负责生成尽可能地以假乱真的样本，这部分被成为生成器(Generator)；另一部分为判别网络(Discriminative Network), 此部分负责判断样本是真实的，还是由生成器生成的，这部分被成为判别器(Discriminator) 生成器和判别器的互相博弈，就完成了对抗训练。</p>
<p>​	GAN 的目标很明确：生成训练样本。这似乎与迁移学习的大目标有些许出入。然而，由于在迁移学习中，天然地存在一个源领域，一个目标领域，因此，我们可以免去生成样本的过程，而直接将其中一个领域的数据 (通常是目标域) 当作是生成的样本。此时，生成器的职能发生变化，不再生成新样本，而是扮演了特征提取的功能：不断学习领域数据的特征使得判别器无法对两个领域进行分辨。这样，原来的生成器也可以称为特征提取器<br>
(Feature Extractor)。</p>
<p>​	通常用 Gf 来表示特征提取器，用 Gd 来表示判别器。正是基于这样的领域对抗的思想，深度对抗网络可以被很好地运用于迁移学习问题中。与深度网络自适应迁移方法类似，深度对抗网络的损失也由两部分构成：网络训练的损失lc*和领域判别损失Id：</p>
<p><img src="1542826334834.png" alt="1542826334834"></p>
<p><strong>DANN</strong></p>
<p>Yaroslav Ganin 等人 [<a href="#bookmark251">Ganin et al., 2016</a>]首先在神经网络的训练中加入了对抗机制，作者将他们的网络称之为DANN(Domain-Adversarial Neural Network)。在此研宄中，网络的学习目标是：生成的特征尽可能帮助区分两个领域的特征，同时使得判别器无法对两个领域的差异进行判别。该方法的领域对抗损失函数表示为：</p>
<p><img src="1542826461988.png" alt="1542826461988"></p>
<p>Id = max 其中的 Ld 表示为</p>
<p><img src="1542826475517.png" alt="1542826475517"></p>
<h2 id="参考文献">参考文献</h2>
<p>王晋东，迁移学习简明手册</p>
<p>[Baktashmotlagh et al., 2013] Baktashmotlagh, M., Harandi, M. T., Lovell, B. C.,and Salz- mann, M. (2013). Unsupervised domain adaptation by domain invariant projection. In <em>ICCV,</em> pages 769-776.</p>
<p>[Baktashmotlagh et al., 2014] Baktashmotlagh, M., Harandi, M. T., Lovell, B. C., and Salz- mann, M. (2014). Domain adaptation on the statistical manifold. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*,pages 2481-2488.</p>
<p>[Ben-David et al., 2010] Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., and Vaughan, J. W. (2010). A theory of learning from different domains. <em>Machine learning,</em> 79(1-2):151-175.</p>
<p>[Ben-David et al., 2007] Ben-David, S., Blitzer, J., Crammer, K., and Pereira, F. (2007). Analysis of representations for domain adaptation. In <em>NIPS</em>, pages 137-144.</p>
<p>[Blitzer et al., 2008] Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., and Wortman, J. (2008). Learning bounds for domain adaptation. In <em>Advances in neural information processing systems</em>, pages 129-136.</p>
<p>[Blitzer et al., 2006] Blitzer, J., McDonald, R., and Pereira, F. (2006). Domain adaptation with structural correspondence learning. In <em>Proceedings of the 2006 conference on empiri­cal methods in natural language processing</em>, pages 120-128. Association for Computational Linguistics.</p>
<p>[Borgwardt et al., 2006] Borgwardt, K. M., Gretton, A., Rasch, M. J., Kriegel, H.-P., Scholkopf, B., and Smola, A. J. (2006). Integrating structured biological data by kernel maximum mean discrepancy. <em>Bioinformatics</em>, 22(14):e49-e57.</p>
<p>[Bousmalis et al., 2016] Bousmalis, K., Trigeorgis, G., Silberman, N., Krishnan, D., and Erhan, D. (2016). Domain separation networks. In <em>Advances in Neural Information Processing Systems</em>, pages 343-351.</p>
<p>[Cai et al., 2011] Cai, D., He, X., Han, J., and Huang, T. S. (2011). Graph regularized nonnegative matrix factorization for data representation. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 33(8):1548-1560.</p>
<p>[Cao et al., 2017] Cao, Z., Long, M., Wang, J., and Jordan, M. I. (2017). Partial transfer learning with selective adversarial networks. <em>arXiv preprint arXiv:1707.07901</em>.</p>
<p>[Carlucci et al., 2017] Carlucci, F. M., Porzi, L., Caputo, B., Ricci, E., and Bulo, S. R. (2017). Autodial: Automatic domain alignment layers. In International Conference on* Computer Vision.</p>
<p>[Cook et al., 2013] Cook, D., Feuz, K. D., and Krishnan, N. C. (2013). Transfer learning for activity recognition: A survey. <em>Knowledge and information systems</em>, 36(3):537-556.</p>
<p>[Cortes et al., 2008] Cortes, C., Mohri, M., Riley, M., and Rostamizadeh, A. (2008). Sample selection bias correction theory. In <em>International Conference on Algorithmic Learning Theory</em>, pages 38-53, Budapest, Hungary. Springer.</p>
<p>[Dai et al., 2007] Dai, W., Yang, Q., Xue, G.-R., and Yu, Y. (2007). Boosting for transfer learning. In <em>ICML</em>, pages 193-200. ACM.</p>
<p>[Davis and Domingos, 2009] Davis, J. and Domingos, P. (2009). Deep transfer via second- order markov logic. In <em>Proceedings of the 26th annual international conference on machine learning</em>, pages 217-224. ACM.</p>
<p>[Denget al., 2014] Deng,W.,Zheng,Q.,andWang,Z.(2014).Cross-personactivityrecog-nition using reduced kernel extreme learning machine. <em>Neural Networks,</em> 53:1-7.</p>
<p>[Donahue et al., 2014] Donahue, J., Jia, Y., et al. (2014). Decaf: A deep convolutional activation feature for generic visual recognition. In <em>ICML</em>, pages 647-655.</p>
<p>[Dorri and Ghodsi, 2012] Dorri, F. and Ghodsi, A. (2012). Adapting component analysis. In <em>Data Mining (ICDM), 2012 IEEE 12th International Conference on</em>, pages 846-851. IEEE.</p>
<p>[Duan et al., 2012] Duan, L., Tsang, I. W., and Xu, D. (2012). Domain transfer multi­ple kernel learning. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 34(3):465-479.</p>
<p>[Fernando et al., 2013] Fernando, B., Habrard, A., Sebban, M., and Tuytelaars, T. (2013). Unsupervised visual domain adaptation using subspace alignment. In ICCV*, pages 2960­2967.</p>
<p>[Fodor, 2002] Fodor, I. K. (2002). A survey of dimension reduction techniques. Center for Applied Scientific Computing, Lawrence Livermore National Laboratory*, 9:1-18.</p>
<p>[Ganin et al., 2016] Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Lavi- olette, F., Marchand, M., and Lempitsky, V. (2016).Domain-adversarial training of neural networks. <em>Journal of Machine Learning<br>
Research</em>, 17(59):1-35.</p>
<p>[Gao et al., 2012] Gao, C., Sang, N., and Huang, R. (2012). Online transfer boosting for object tracking. In <em>Pattern Recognition (ICPR), 2012 21st International Conference on</em>, pages 906-909. IEEE.</p>
<p>[Ghifary et al., 2017] Ghifary, M., Balduzzi, D., Kleijn, W. B., and Zhang, M. (2017). Scat­ter component analysis: A unified framework for domain adaptation and domain general­ization. <em>IEEE transactions on pattern analysis and machine intelligence</em>, 39(7):1414-1430.</p>
<p>[Ghifary et al., 2014] Ghifary, M., Kleijn, W. B., and Zhang, M. (2014). Domain adaptive neural networks for object recognition. In <em>PRICAI</em>, pages 898-904.</p>
<p>[Gong et al., 2012] Gong, B., Shi, Y., Sha, F., and Grauman, K. (2012). Geodesic flow kernel for unsupervised domain adaptation. In <em>CVPR</em>, pages 2066-2073.</p>
<p>[Goodfellow et al., 2014] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B.,  Warde- Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014). Generative adversarial nets. In <em>Advances in neural information processing systems</em>, pages 2672-2680.</p>
<p>[Gopalan et al., 2011] Gopalan, R., Li, R., and Chellappa, R. (2011). Domain adaptation for object recognition: An unsupervised approach. In <em>ICCV</em>, pages 999-1006. IEEE.</p>
<p>[Gretton et al., 2012] Gretton, A., Sejdinovic, D., Strathmann, H., Balakrishnan, S., Pontil, M., Fukumizu, K., and Sriperumbudur, B. K. (2012). Optimal kernel choice for large- scale two-sample tests. In <em>Advances in neural information processing systems</em>, pages 1205-1213.</p>
<p>[Gu et al., 2011] Gu, Q., Li, Z., Han, J., et al. (2011). Joint feature selection and subspace learning. In <em>IJCAI Proceedings-International Joint Conference on Artificial Intel ligence</em>, volume 22, page 1294.</p>
<p>[Hamm and Lee, 2008] Hamm, J. and Lee, D. D. (2008). Grassmann discriminant analysis: a unifying view on subspace-based learning. In <em>ICML</em>, pages 376-383. ACM.</p>
<p>[Hou et al., 2015] Hou, C.-A., Yeh, Y.-R., and Wang, Y.-C. F. (2015). An unsupervised domain adaptation approach for cross-domain visual classification. In <em>Advanced Video and Signal Based Surveil lance (AVSS), 2015 12th IEEE International Conference on</em>,pages 1-6. IEEE.</p>
<p>[Hsiao et al., 2016] Hsiao, P.-H., Chang, F.-J., and Lin, Y.-Y. (2016). Learning discrim­inatively reconstructed source data for object recognition with few examples. <em>IEEE</em>Transactions on Image Processing*, 25(8):3518-3532.</p>
<p>[Hu and Yang, 2011] Hu, D. H. and Yang, Q. (2011). Transfer learning for activity recog­nition via sensor mapping. In <em>IJCAI Proceedings-International Joint Conference on Artificial Intelligence</em>, volume 22, page 1962, Barcelona, Catalonia, Spain. IJCAI.</p>
<p>[Huang et al., 2007] Huang, J., Smola, A. J., Gretton, A., Borgwardt, K. M., Scholkopf, B., et al. (2007). Correcting sample selection bias by unlabeled  data. <em>Advances in neural information processing systems</em>, 19:601.</p>
<p>[Jaini et al., 2016] Jaini, P., Chen, Z., Carbajal, P., Law, E., Middleton, L., Regan, K., Schaekermann, M., Trimponias, G., Tung, J., and Poupart, P. (2016). Online bayesian transfer learning for sequential data modeling. In <em>ICLR 2017</em>.</p>
<p>[Kermany et al., 2018] Kermany, D. S., Goldbaum, M., Cai, W., Valentim, C. C., Liang, H., Baxter, S. L., McKeown, A., Yang, G., Wu, X., Yan, F., et al. (2018). Identifying medical diagnoses and treatable diseases by image-based deep learning. <em>Cell</em>, 172(5):1122-1131.</p>
<p>[Khan and Heisterkamp, 2016] Khan, M. N. A. and Heisterkamp, D. R. (2016). Adapting instance weights for unsupervised domain adaptation using quadratic mutual informa­tion and subspace learning. In <em>Pattern Recognition (ICPR), 2016 23rd International Conference on</em>, pages 1560-1565, Mexican City. IEEE.</p>
<p>[Krizhevsky et al., 2012] Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems*, pages 1097-1105.</p>
<p>[Li et al., 2012] Li, H., Shi, Y., Liu, Y., Hauptmann, A. G., and Xiong, Z. (2012). Cross­domain video concept detection: A joint discriminative and generative active learning approach. <em>Expert Systems with Applications</em>,<br>
39(15):12220-12228.</p>
<p>[Li et al., 2016] Li, J., Zhao, J., and Lu, K. (2016). Joint feature selection and structure preservation for domain adaptation. In <em>Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence</em>, pages<br>
1697-1703. AAAI Press.</p>
<p>[Li et al., 2018] Li, Y., Wang, N., Shi, J., Hou, X., and Liu, J. (2018). Adaptive batch normalization for practical domain adaptation. <em>Pattern Recognition</em>, 80:109-117.</p>
<p>[Liu et al., 2011] Liu, J., Shah, M., Kuipers, B., and Savarese, S. (2011). Cross-view action recognition via view knowledge transfer. In <em>Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</em>, pages 3209-3216, Colorado Springs, CO, USA. IEEE.</p>
<p>[Liu and Tuzel, 2016] Liu, M.-Y. and Tuzel, O. (2016). Coupled generative adversarial networks. In <em>Advances in neural information processing systems</em>, pages 469-477.</p>
<p>[Liu et al., 2017] Liu, T., Yang, Q., and Tao, D. (2017). Understanding how  feature struc­ture transfers in transfer learning. In <em>IJCAI</em>.</p>
<p>[Long et al., 2015a] Long, M., Cao, Y., Wang, J., and Jordan, M. (2015a). Learning trans­ferable features with deep adaptation networks. In <em>ICML</em>, pages 97-105.</p>
<p>[Long et al., 2016] Long, M., Wang, J., Cao, Y., Sun, J., and Philip, S. Y. (2016). Deep learning of transferable representation for scalable domain  adaptation. <em>IEEE Transac­tions on Knowledge and Data Engineering</em>,<br>
28(8):2027-2040.</p>
<p>[Long et al., 2014a] Long, M., Wang, J., Ding, G., Pan, S. J., and Yu, P. S. (2014a). Adaptation regularization: A general framework for transfer learning.*IEEE TKDE, 26(5):1076-1089.</p>
<p>[Long et al., 2014b] Long, M., Wang, J., Ding, G., Sun, J., and Yu, P. S. (2014b). Transfer joint matching for unsupervised domain adaptation. In *CVPR ,pages 1410-1417.</p>
<p>[Long et al., 2013] Long, M., Wang, J., et al. (2013). Transfer feature learning with joint distribution adaptation. In <em>ICCV</em>, pages 2200-2207.</p>
<p>[Long et al., 2017] Long, M., Wang, J., and Jordan, M. I. (2017). Deep transfer learning with joint adaptation networks. In <em>ICML</em>, pages 2208-2217.</p>
<p>[Long et al., 2015b] Long, M., Wang, J., Sun, J., and Philip, S. Y. (2015b). Domain invari­ant transfer kernel learning. <em>IEEE Transactions on Knowledge and Data Engineering</em>, 27(6):1519-1532.</p>
<p>[Luo et al., 2017] Luo, Z., Zou, Y., Hoffman, J., and Fei-Fei, L. F. (2017). Label efficient learning of transferable representations acrosss domains and tasks. In <em>Advances in Neural Information Processing Systems</em>, pages 164-176.</p>
<p>[Mihalkova et al., 2007] Mihalkova, L., Huynh, T., and Mooney, R. J. (2007). Mapping and revising markov logic networks for transfer learning. In <em>AAAI</em>, volume 7, pages 608-614.</p>
<p>[Mihalkova and Mooney, 2008] Mihalkova, L. and Mooney, R. J. (2008). Transfer learning by mapping with minimal target data. In <em>Proceedings of the AAAI-08 workshop on transfer learning for complex tasks</em>.</p>
<p>[Nater et al., 2011] Nater, F., Tommasi, T., Grabner, H., Van Gool, L., and Caputo, B. (2011). Transferring activities: Updating human behavior analysis. In <em>Computer Vision Workshops (ICCV Workshops), 2011 IEEE International Conference on</em>, pages 1737­1744, Barcelona, Spain. IEEE.</p>
<p>[Pan et al., 2008a] Pan, S. J., Kwok, J. T., and Yang, Q. (2008a). Transfer learning via dimensionality reduction. In <em>Proceedings of the 23rd AAAI conference on Artificial in­telligence</em>, volume 8, pages 677-682.</p>
<p>[Pan et al., 2008b] Pan, S. J., Shen, D., Yang, Q., and Kwok, J. T. (2008b). Transferring localization models across space. In <em>Proceedings of the 23rd AAAI Conference on Artificial Intelligence</em>, pages 1383-1388.</p>
<p>[Pan et al., 2011] Pan, S. J., Tsang, I. W., Kwok, J. T., and Yang, Q. (2011). Domain adaptation via transfer component analysis. <em>IEEE TNN</em>, 22(2):199-210.</p>
<p>[PanandYang, 2010] Pan,S.J.andYang,Q.(2010). A survey on transfer learning. IEEE TKDE*, 22(10):1345-1359.</p>
<p>[Patil and Phursule, 2013] Patil, D. M. and Phursule, R. (2013). Knowledge transfer using cost sensitive online learning classification. <em>International Journal of Science and Research</em>, pages 527-529.</p>
<p>[Razavian et al., 2014] Razavian, A. S., Azizpour, H., Sullivan, J., and Carlsson, S. (2014). Cnn features off-the-shelf: an astounding baseline for recognition. In <em>Computer Vision and Pattern Recognition Workshops (CVPRW), 2014 IEEE Conference on</em>, pages 512­519. IEEE.</p>
<p>[Saito et al., 2017] Saito, K., Ushiku, Y., and Harada, T. (2017). Asymmetric tri-training for unsupervised domain adaptation. In <em>International Conference on Machine Learning</em>.</p>
<p>[Sener et al., 2016] Sener, O., Song, H. O., Saxena, A., and Savarese, S. (2016). Learning transferrable representations for unsupervised domain adaptation. In <em>Advances in Neural Information Processing Systems</em>, pages 2110-2118.</p>
<p>[Shen et al., 2018] Shen, J., Qu, Y., Zhang, W., and Yu, Y. (2018). Wasserstein distance guided representation learning for domain adaptation. In <em>AAAI</em>.</p>
<p>[Si et al., 2010] Si, S., Tao, D., and Geng, B. (2010). Bregman divergence-based regu­larization for transfer subspace learning. <em>IEEE Transactions on Knowledge and Data Engineering</em>, 22(7):929-942.</p>
<p>[Silver et al., 2017] Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Baker, L., Lai, M., Bolton, A., et al. (2017). Mastering the game of go without human knowledge. <em>Nature</em>, 550(7676):354.</p>
<p>[Stewart and Ermon, 2017] Stewart, R. and Ermon, S. (2017). Label-free supervision of neural networks with physics and domain knowledge. In <em>AAAI</em>, pages 2576-2582.</p>
<p>[Sun et al., 2016] Sun, B., Feng, J., and Saenko, K. (2016). Return of frustratingly easy domain adaptation. In <em>AAAI</em>, volume 6, page 8.</p>
<p>[Sun and Saenko, 2015] Sun, B. and Saenko, K. (2015). Subspace distribution alignment for unsupervised domain adaptation. In <em>BMVC</em>, pages 24-1.</p>
<p>[Sun and Saenko, 2016] Sun, B. and Saenko, K. (2016). Deep coral: Correlation alignment for deep domain adaptation. In <em>European Conference on Computer Vision</em>, pages 443-450. Springer.</p>
<p>[Tahmoresnezhad and Hashemi, 2016] Tahmoresnezhad, J. and Hashemi, S. (2016). Visual domain adaptation via transfer feature learning. <em>Knowledge and Information Systems</em>, pages 1-21.</p>
<p>[Tan et al., 2015] Tan, B., Song, Y., Zhong, E., and Yang, Q. (2015). Transitive trans­fer learning. In <em>Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, pages 1155-1164. ACM.</p>
<p>[Tan et al., 2017] Tan, B., Zhang, Y., Pan, S. J., and Yang, Q. (2017). Distant domain transfer learning. In <em>Thirty-First AAAI Conference on Artificial Intelligence</em>.</p>
<p>[Taylor and Stone, 2009] Taylor, M. E. and Stone, P. (2009). Transfer learning for reinforce­ment learning domains: A survey. <em>Journal of Machine Learning Research</em>, 10(Jul):1633- 1685.</p>
<p>[Tzeng et al., 2015] Tzeng, E., Hoffman, J., Darrell, T., and Saenko, K. (2015). Simulta­neous deep transfer across domains and tasks. In <em>Proceedings of the IEEE International Conference on Computer Vision</em>, pages 4068-4076, Santiago, Chile. IEEE.</p>
<p>[Tzeng et al., 2017] Tzeng, E., Hoffman, J., Saenko, K., and Darrell, T. (2017). Adversarial discriminative domain adaptation. In <em>CVPR</em>, pages 2962-2971.</p>
<p>[Tzeng et al., 2014] Tzeng, E., Hoffman, J., Zhang, N., et al. (2014). Deep domain confu­sion: Maximizing for domain invariance. <em>arXiv preprint arXiv:1412.3474</em>.</p>
<p>[Wang et al., 2017] Wang, J., Chen, Y., Hao, S., et al. (2017). Balanced distribution adap­tation for transfer learning. In <em>ICDM</em>, pages 1129-1134.</p>
<p>[Wang et al., 2018] Wang, J., Chen, Y., Hu, L., Peng, X., and Yu, P. S. (2018). Strati­fied transfer learning for cross-domain activity recognition. In <em>2018 IEEE International Conference on Pervasive Computing and Communications (PerCom)</em>.</p>
<p>[Wang et al., 2014] Wang, J., Zhao, P., Hoi, S. C., and Jin, R. (2014). Online feature selection and its applications. <em>IEEE Transactions on Knowledge and Data Engineering</em>, 26(3):698-710.</p>
<p>[Wei et al., 2016a] Wei, P., Ke, Y., and Goh, C. K. (2016a). Deep nonlinearfeature coding for unsupervised domain adaptation. In <em>IJCAI</em>, pages 2189-2195.</p>
<p>[Wei et al., 2017] Wei, Y., Zhang, Y., and Yang, Q. (2017). Learning totransfer. <em>arXiv</em> preprint arXiv:1708.05629*.</p>
<p>[Wei et al., 2016b] Wei, Y., Zhu, Y., Leung, C. W.-k., Song, Y., and Yang, Q. (2016b). Instilling social to physical: Co-regularized heterogeneous transfer learning. In <em>Thirtieth</em> AAAI Conference on Artificial Intelligence*.</p>
<p>[Weiss et al., 2016] Weiss, K., Khoshgoftaar, T. M., and Wang, D. (2016). A survey of transfer learning. <em>Journal of Big Data</em>, 3(1):1-40.</p>
<p>[Wu et al., 2017] Wu, Q., Zhou, X., Yan, Y., Wu, H., and Min, H. (2017). Online transfer learning by leveraging multiple source domains. <em>Knowledge and Information Systems</em>, 52(3):687-707.</p>
<p>[xinhua, 2016] xinhua (2016). <a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MjM5ODYzNzAyMQ==&amp;">http://mp.weixin.qq.com/s?__biz=MjM5ODYzNzAyMQ==&amp;</a> mid=2651933920&amp;idx=1\&amp;sn=ae2866bd12000f1644eae1094497837e.</p>
<p>[Yan et al., 2017] Yan, Y., Wu, Q., Tan, M., Ng, M. K., Min, H., and Tsang, I. W. (2017). Online heterogeneous transfer by hedge ensemble of offline and online decisions. <em>IEEE transactions on neural networks and learning systems</em>.</p>
<p>[Yosinski et al., 2014] Yosinski, J., Clune, J., Bengio, Y., and Lipson, H. (2014). How transferable are features in deep neural networks? In <em>Advances in neural information processing systems</em>, pages 3320-3328.</p>
<p>[Zadrozny, 2004] Zadrozny, B. (2004). Learning and evaluating classifiers under sample selection bias. In <em>Proceedings of the twenty-first international conference on Machine learning</em>, page 114, Alberta, Canada. ACM.</p>
<p>[Zellinger et al., 2017] Zellinger, W., Grubinger, T., Lughofer, E., Natschlager, T., and Saminger-Platz, S. (2017). Central moment discrepancy (cmd) for domain-invariant rep­resentation learning. <em>arXiv preprint arXiv:1702.08811</em>.</p>
<p>[Zhang et al., 2017a] Zhang, J., Li, W., and Ogunbona, P. (2017a). Joint geometrical and statistical alignment for visual domain adaptation. In <em>CVPR</em>.</p>
<p>[Zhang et al., 2017b] Zhang, X., Zhuang, Y., Wang, W., and Pedrycz, W. (2017b). On­line feature transformation learning for cross-domain object category recognition. <em>IEEE transactions on neural networks and learning systems</em>.</p>
<p>[Zhao and Hoi, 2010] Zhao, P. and Hoi, S. C. (2010). Otl: A framework of online transfer learning. In <em>Proceedings of the 27th international conference on machine learning (ICML- 10)</em>, pages 1231-1238.</p>
<p>[Zhao et al., 2010] Zhao, Z., Chen, Y., Liu, J., and Liu, M. (2010). Cross-mobile elm based activity recognition. <em>International Journal of Engineering and Industries</em>, 1(1):30-38.</p>
<p>[Zhao et al., 2011] Zhao, Z., Chen, Y., Liu, J., Shen, Z., and Liu, M. (2011). Cross-people mobile-phone based activity recognition. In <em>Proceedings of the Twenty-Second interna­tional joint conference on Artificial Intelligence (IJCAI)</em>, volume 11, pages 2545-2550. Citeseer.</p>
<p>[Zheng et al., 2009] Zheng, V. W., Hu, D. H., and Yang, Q. (2009). Cross-domain activity recognition. In <em>Proceedings of the 11th international conference on Ubiquitous computing</em>, pages 61-70. ACM.</p>
<p>[Zheng et al., 2008] Zheng, V. W., Pan, S. J., Yang, Q., and Pan, J. J. (2008). Transferring multi-device localization models using latent multi-task learning. In <em>AAAI</em>, volume 8, pages 1427-1432, Chicago, Illinois, USA. AAAI.</p>
<p>[Zhuang et al., 2015] Zhuang, F., Cheng, X., Luo, P., Pan, S. J., and He, Q. (2015). Su­pervised representation learning: Transfer learning with deep autoencoders. In <em>IJCAI</em>,pages 4119-4125.</p>
<p>[Zhuo et al., 2017] Zhuo, J., Wang, S., Zhang, W., and Huang, Q. (2017). Deep unsuper­vised convolutional domain adaptation. In <em>Proceedings of the 2017 ACM on Multimedia Conference</em>, pages 261-269. ACM.</p>
</center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lilitom.github.io/2024/03/19/deep_learning/ch12/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/deep_learning/ch12/" class="post-title-link" itemprop="url">网络搭建及训练面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-24 10:14:03" itemprop="dateModified" datetime="2024-03-24T10:14:03+08:00">2024-03-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>网络搭建及训练</h1>
<h1>12.1 TensorFlow</h1>
<h2 id="12-1-1-TensorFlow是什么？">12.1.1 TensorFlow是什么？</h2>
<p>  TensorFlow支持各种异构平台，支持多CPU/GPU、服务器、移动设备，具有良好的跨平台的特性；TensorFlow架构灵活，能够支持各种网络模型，具有良好的通用性；此外，TensorFlow架构具有良好的可扩展性，对OP的扩展支持，Kernel特化方面表现出众。</p>
<p>  TensorFlow最初由Google大脑的研究员和工程师开发出来，用于机器学习和神经网络方面的研究，于2015.10宣布开源，在众多深度学习框架中脱颖而出，在Github上获得了最多的Star量。</p>
<h2 id="12-1-2-TensorFlow的设计理念是什么？">12.1.2 TensorFlow的设计理念是什么？</h2>
<p>TensorFlow的设计理念主要体现在两个方面：</p>
<p>（1）将图定义和图运算完全分开。<br>
  TensorFlow 被认为是一个“符号主义”的库。我们知道，编程模式通常分为命令式编程（imperative style programming）和符号式编程（symbolic style programming）。命令式编程就是编写我们理解的通常意义上的程序，很容易理解和调试，按照原有逻辑执行。符号式编程涉及很多的嵌入和优化，不容易理解和调试，但运行速度相对有所提升。现有的深度学习框架中，Torch 是典型的命令式的，Caffe、MXNet 采用了两种编程模式混合的方法，而 TensorFlow 完全采用符号式编程。</p>
<p>  符号式计算一般是先定义各种变量，然后建立一个数据流图，在数据流图中规定各个变量间的计算关系，最后需要对据流图进行编译，但此时的数据流图还是一个空壳儿，里面没有任何实际数据，只有把需要运算的输入放进去后，才能在整个模型中形成数据流，从而形成输出值。</p>
<p>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t = 8 + 9</span><br><span class="line">print(t)</span><br></pre></td></tr></table></figure>
<p>  在传统的程序操作中，定义了 t 的运算，在运行时就执行了，并输出 17。而在 TensorFlow中，数据流图中的节点，实际上对应的是 TensorFlow API 中的一个操作，并没有真正去运行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">t = tf.add(8,9)</span><br><span class="line">print(t)</span><br><span class="line"></span><br><span class="line">#输出  Tensor&#123;&quot;Add_1:0&quot;,shape=&#123;&#125;,dtype=int32&#125;</span><br></pre></td></tr></table></figure>
<p>  （2）TensorFlow 中涉及的运算都要放在图中，而图的运行只发生在会话（session）中。开启会话后，就可以用数据去填充节点，进行运算；关闭会话后，就不能进行计算了。因此，会话提供了操作运行和 Tensor 求值的环境。</p>
<p>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">#创建图</span><br><span class="line">a = tf.constant([4.0,5.0])</span><br><span class="line">b = tf.constant([6.0,7.0])</span><br><span class="line">c = a * b</span><br><span class="line">#创建会话</span><br><span class="line">sess  = tf.Session()</span><br><span class="line">#计算c</span><br><span class="line">print(sess.run(c))   #进行矩阵乘法，输出[24.,35.]</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>
<h2 id="12-1-3-TensorFlow特点有哪些？">12.1.3 TensorFlow特点有哪些？</h2>
<h3 id="1-高度的灵活性">1.高度的灵活性</h3>
<p>  TensorFlow 并不仅仅是一个深度学习库，只要可以把你的计算过程表示称一个数据流图的过程，我们就可以使用 TensorFlow 来进行计算。TensorFlow 允许我们用计算图的方式建立计算网络，同时又可以很方便的对网络进行操作。用户可以基于 TensorFlow 的基础上用 python 编写自己的上层结构和库，如果TensorFlow没有提供我们需要的API的，我们也可以自己编写底层的 C++ 代码，通过自定义操作将新编写的功能添加到 TensorFlow 中。</p>
<h3 id="2-真正的可移植性">2.真正的可移植性</h3>
<p>  TensorFlow 可以在 CPU 和 GPU 上运行，可以在台式机、服务器、移动设备上运行。你想在你的笔记本上跑一下深度学习的训练，或者又不想修改代码，想把你的模型在多个CPU上运行， 亦或想将训练好的模型放到移动设备上跑一下，这些TensorFlow都可以帮你做到。</p>
<h3 id="3-多语言支持">3.多语言支持</h3>
<p>  TensorFlow采用非常易用的python来构建和执行我们的计算图，同时也支持 C++ 的语言。我们可以直接写python和C++的程序来执行TensorFlow，也可以采用交互式的ipython来方便的尝试我们的想法。当然，这只是一个开始，后续会支持更多流行的语言，比如Lua，JavaScript 或者R语言。</p>
<h3 id="4-丰富的算法库">4.丰富的算法库</h3>
<p>  TensorFlow提供了所有开源的深度学习框架里，最全的算法库，并且在不断的添加新的算法库。这些算法库基本上已经满足了大部分的需求，对于普通的应用，基本上不用自己再去自定义实现基本的算法库了。</p>
<h3 id="5-完善的文档">5.完善的文档</h3>
<p>  TensorFlow的官方网站，提供了非常详细的文档介绍，内容包括各种API的使用介绍和各种基础应用的使用例子，也包括一部分深度学习的基础理论。</p>
<p>  自从宣布开源以来，大量人员对TensorFlow做出贡献，其中包括Google员工，外部研究人员和独立程序员，全球各地的工程师对TensorFlow的完善，已经让TensorFlow社区变成了Github上最活跃的深度学习框架。</p>
<h2 id="12-1-4-TensorFlow的系统架构是怎样的？">12.1.4 TensorFlow的系统架构是怎样的？</h2>
<h3 id="整个系统从底层到上层可分为七层：">  整个系统从底层到上层可分为七层：</h3>
<p><img src="img%5Cch12%5C1.bmp" alt></p>
<p>  设备层：硬件计算资源，支持CPU、GPU</p>
<p>  网络层：支持两种通信协议</p>
<p>  数值计算层：提供最基础的计算，有线性计算、卷积计算</p>
<p>  高维计算层：数据的计算都是以数组的形式参与计算</p>
<p>  计算图层：用来设计神经网络的结构</p>
<p>  工作流层：提供轻量级的框架调用</p>
<p>  构造层：最后构造的深度学习网络可以通过TensorBoard服务端可视化</p>
<h2 id="12-1-5-TensorFlow编程模型是怎样的？">12.1.5 TensorFlow编程模型是怎样的？</h2>
<p>TensorFlow的编程模型：让向量数据在计算图里流动。那么在编程时至少有这几个过程：1.构建图，2.启动图，3.给图输入数据并获取结果。</p>
<h3 id="1-构建图">1.构建图</h3>
<p>TensorFlow的图的类型是tf.Graph，它包含着计算节点和tensor的集合。</p>
<p>  这里引用了两个新概念：tensor和计算节点。<br>
  我们先介绍tensor，一开始我们就介绍了，我们需要把数据输入给启动的图才能获取计算结果。那么问题来了，在构建图时用什么表示中间计算结果？这个时候tensor的概念就需要引入了。<br>
  类型是tf.Tensor，代表某个计算节点的输出，一定要看清楚是“代表”。它主要有两个作用：</p>
<p>1.构建不同计算节点之间的数据流</p>
<p>2.在启动图时，可以设置某些tensor的值，然后获取指定tensor的值。这样就完成了计算的输入输出功能。</p>
<p>如下代码所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">inImage = tf.placeholder(tf.float32,[32,32,3],&quot;inputImage&quot;)</span><br><span class="line">processedImage = tf.image.per_image_standardization(inImage,&quot;processedImage&quot;)</span><br></pre></td></tr></table></figure>
<p>  这里inImage和processedImage都是tensor类型。它们代表着计算节点输出的数据，数据的值具体是多少在启动图的时候才知道。上面两个方法调用都传递了一个字符串，它是计算节点的名字，最好给节点命名，这样我们可以在图上调用get_tensor_by_name(name)获取对应的tensor对象，十分方便。（tensor名字为“&lt;计算节点名字&gt;:&lt;tensor索引&gt;”）</p>
<p>  创建tensor时，需要指定类型和shape。对不同tensor进行计算时要求类型相同，可以使用 tf.cast 进行类型转换。同时也要求 shape (向量维度)满足运算的条件，我们可以使用 tf.reshape 改变shape。</p>
<p>  现在了解计算节点的概念，其功能是对tensor进行计算、创建tensor或进行其他操作，类型是tf.Operation。获取节点对象的方法为get_operation_by_name(name)。</p>
<p>构建图，如下代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">g=tf.Graph()</span><br><span class="line"></span><br><span class="line">with g.as_default():</span><br><span class="line">    input_data=tf.placeholder(tf.float32,[None,2],&quot;input_data&quot;)</span><br><span class="line">    input_label=tf.placeholder(tf.float32,[None,2],&quot;input_label&quot;)</span><br><span class="line"></span><br><span class="line">    W1=tf.Variable(tf.truncated_normal([2,2]),name=&quot;W1&quot;)</span><br><span class="line">    B1=tf.Variable(tf.zeros([2]),name=&quot;B1&quot;)</span><br><span class="line"></span><br><span class="line">    output=tf.add(tf.matmul(input_data,W1),B1,name=&quot;output&quot;)</span><br><span class="line">    cross_entropy=tf.nn.softmax_cross_entropy_with_logits(logits=output,labels=input_label)</span><br><span class="line"></span><br><span class="line">    train_step=tf.train.AdamOptimizer().minimize(cross_entropy,name=&quot;train_step&quot;)</span><br><span class="line"></span><br><span class="line">    initer=tf.global_variables_initializer()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>  上面的代码中我们创建了一个图，并在上面添加了很多节点。我们可以通过调用get_default_graph()获取默认的图。</p>
<p>  Input_data，input_label，W1，B1，output，cross_entropy都是tensor类型，train_step，initer，是节点类型。</p>
<p>有几类tensor或节点比较重要，下面介绍一下：</p>
<h4 id="1-placeholder">1.placeholder</h4>
<p>  Tensorflow，顾名思义， tensor代表张量数据，flow代表流，其最初的设计理念就是构建一张静态的数据流图。图是有各个计算节点连接而成，计算节点之间流动的便是中间的张量数据。要想让张量数据在我们构建的静态计算图中流动起来，就必须有最初的输入数据流。而placeholder，翻译过来叫做占位符，顾名思义，是给我们的输入数据提供一个接口，也就是说我们的一切输入数据，例如训练样本数据，超参数数据等都可以通过占位符接口输送到数据流图之中。使用实例如下代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">x = tf.placeholder(dtype=tf.float32,shape=[],name=&#x27;x&#x27;)</span><br><span class="line">y = tf.placeholder(dtpe=tf.float32,shape=[],nmae=&#x27;y&#x27;)</span><br><span class="line">z = x*y</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">	prod = sess.run(z,feed_dict=&#123;x:1.,y:5.2&#125;)</span><br><span class="line">	print(prod)</span><br><span class="line">[out]:5.2</span><br></pre></td></tr></table></figure>
<h4 id="2-variable">2. variable</h4>
<p>  无论是传统的机器学习算法，例如线性支持向量机（Support Vector Machine, SVM)，其数学模型为y = &lt;w,x&gt; + b，还是更先进的深度学习算法，例如卷积神经网络（Convolutional Neural Network， CNN）单个神经元输出的模型y = w*x + b。可以看到，w和b就是我们要求的模型，模型的求解是通过优化算法（对于SVM，使用<br>
SMO[1]算法，对于CNN，一般基于梯度下降法）来一步一步更新w和b的值直到满足停止条件。因此，大多数机器学习的模型中的w和b实际上是以变量的形式出现在代码中的，这就要求我们在代码中定义模型变量。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">a = tf.Variable(2.)</span><br><span class="line">b = tf.Variable(3.)</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">	sess.run(tf.global_variables_initializer()) #变量初始化</span><br><span class="line">    print(sess.run(a*b))</span><br><span class="line">[out]:6.</span><br></pre></td></tr></table></figure>
<p>[1] Platt, John. “Sequential minimal optimization: A fast algorithm for training support vector machines.” (1998).</p>
<h4 id="3-initializer">3. initializer</h4>
<p>  由于tensorflow构建的是静态的计算流图，在开启会话之前，所有的操作都不会被执行。因此为了执行在计算图中所构建的赋值初始化计算节点，需要在开启会话之后，在会话环境下运行初始化。如果计算图中定义了变量，而会话环境下为执行初始化命令，则程序报错，代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">a = tf.Variable(2.)</span><br><span class="line">b = tf.Variable(3.)</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">	#sess.run(tf.global_variables_initializer()) #注释掉初始化命令</span><br><span class="line">    print(sess.run(a*b))</span><br><span class="line">[Error]: Attempting to use uninitialized value Variable</span><br></pre></td></tr></table></figure>
<h3 id="2-启动图">2.启动图</h3>
<p>  先了解session的概念，然后才能更好的理解图的启动。<br>
  图的每个运行实例都必须在一个session里，session为图的运行提供环境。Session的类型是tf.Session，在实例化session对象时我们需要给它传递一个图对象，如果不显示给出将使用默认的图。Session有一个graph属性，我们可以通过它获取session对应的图。</p>
<p>代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">numOfBatch=5</span><br><span class="line">datas=np.zeros([numOfBatch,2],np.float32)</span><br><span class="line">labels=np.zeros([numOfBatch,2],np.float32)</span><br><span class="line"></span><br><span class="line">sess=tf.Session(graph=g)</span><br><span class="line">graph=sess.graph</span><br><span class="line">sess.run([graph.get_operation_by_name(&quot;initer&quot;)])</span><br><span class="line"></span><br><span class="line">dataHolder=graph.get_tensor_by_name(&quot;input_data:0&quot;)</span><br><span class="line">labelHolder=graph.get_tensor_by_name(&quot;input_label:0&quot;)</span><br><span class="line">train=graph.get_operation_by_name(&quot;train_step&quot;)</span><br><span class="line">out=graph.get_tensor_by_name(&quot;output:0&quot;)</span><br><span class="line"></span><br><span class="line">for i inrange(200):</span><br><span class="line">   result=sess.run([out,train],feed_dict=&#123;dataHolder:datas,labelHolder:labels&#125;)</span><br><span class="line">   if i%100==0:</span><br><span class="line">       saver.save(sess,&quot;./moules&quot;)</span><br><span class="line"></span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>
<p>代码都比较简单，就不介绍了。不过要注意2点：1.别忘记运行初始化节点，2.别忘记close掉session对象以释放资源。</p>
<h4 id="3-给图输入数据并获取结果">3.给图输入数据并获取结果</h4>
<p>代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for i inrange(200):</span><br><span class="line">    result=sess.run([out,train],feed_dict=&#123;dataHolder:datas,labelHolder:labels&#125;)</span><br></pre></td></tr></table></figure>
<p>  这里主要用到了session对象的run方法，它用来运行某个节点或tensor并获取对应的值。我们一般会一次传递一小部分数据进行mini-batch梯度下降来优化模型。</p>
<p>  我们需要把我们需要运行的节点或tensor放入一个列表，然后作为第一个参数(不考虑self)传递给run方法，run方法会返回一个计算结果的列表，与我们传递的参数一一对应。</p>
<p>  如果我们运行的节点依赖某个placeholder，那我们必须给这个placeholder指定值，怎么指定代码里面很清楚，给关键字参数feed_dict传递一个字典即可，字典里的元素的key是placeholder对象，value是我们指定的值。值的数据的类型必须和placeholder一致，包括shape。值本身的类型是numpy数组。</p>
<p>这里再解释一个细节，在定义placeholder时代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input_data=tf.placeholder(tf.float32,[None,2],&quot;input_data&quot;)</span><br><span class="line">input_label=tf.placeholder(tf.float32,[None,2],&quot;input_label&quot;)</span><br></pre></td></tr></table></figure>
<p>  shape为[None,2]，说明数据第一个维度是不确定的，然后TensorFlow会根据我们传递的数据动态推断第一个维度，这样我们就可以在运行时改变batch的大小。比如一个数据是2维，一次传递10个数据对应的tensor的shape就是[10,2]。可不可以把多个维度指定为None？理论上不可以！</p>
<h2 id="12-1-6-如何基于tensorflow搭建VGG16">12.1.6 如何基于tensorflow搭建VGG16</h2>
<p>​	介绍完关于tensorflow的基础知识，是时候来一波网络搭建实战了。虽然网上有很多相关教程，但我想从最标准的tensorflow代码和语法出发（而不是调用更高级的API，失去了原来的味道），向大家展示如何搭建其标准的VGG16网络架构。话不多说，上代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_weight_variable</span>(<span class="params">shape</span>):</span><br><span class="line">    <span class="keyword">return</span> tf.get_variable(<span class="string">&#x27;weight&#x27;</span>, shape=shape, initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_bias_variable</span>(<span class="params">shape</span>):</span><br><span class="line">    <span class="keyword">return</span> tf.get_variable(<span class="string">&#x27;bias&#x27;</span>, shape=shape, initializer=tf.constant_initializer(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv2d</span>(<span class="params">x, w, padding = <span class="string">&#x27;SAME&#x27;</span>, s=<span class="number">1</span></span>):</span><br><span class="line">    x = tf.nn.conv2d(x, w, strides=[<span class="number">1</span>, s, s, <span class="number">1</span>], padding = padding)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">maxPoolLayer</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x, ksize = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                          strides = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding = <span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv2d_layer</span>(<span class="params">x,in_chs, out_chs, ksize, layer_name</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(layer_name):</span><br><span class="line">        w = get_weight_variable([ksize, ksize, in_chs, out_chs])</span><br><span class="line">        b = get_bias_variable([out_chs])</span><br><span class="line">        y = tf.nn.relu(tf.bias_add(conv2d(x,w,padding = <span class="string">&#x27;SAME&#x27;</span>, s=<span class="number">1</span>), b))</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fc_layer</span>(<span class="params">x,in_kernels, out_kernels, layer_name</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(layer_name):</span><br><span class="line">        w = get_weight_variable([in_kernels,out_kernels])</span><br><span class="line">        b = get_bias_variable([out_kernels])</span><br><span class="line">        y = tf.nn.relu(tf.bias_add(tf.matmul(x,w),b))</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line">        </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">VGG16</span>(<span class="params">x</span>):</span><br><span class="line">    conv1_1 = conv2d_layer(x,tf.get_shape(x).as_list()[-<span class="number">1</span>], <span class="number">64</span>, <span class="number">3</span>, <span class="string">&#x27;conv1_1&#x27;</span>)</span><br><span class="line">    conv1_2 = conv2d_layer(conv1_1,<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="string">&#x27;conv1_2&#x27;</span>)</span><br><span class="line">    pool_1 = maxPoolLayer(conv1_2)</span><br><span class="line">    </span><br><span class="line">    conv2_1 = conv2d_layer(pool1,<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="string">&#x27;conv2_1&#x27;</span>)</span><br><span class="line">    conv2_2 = conv2d_layer(conv2_1,<span class="number">128</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="string">&#x27;conv2_2&#x27;</span>)</span><br><span class="line">    pool2 = maxPoolLayer(conv2_2)</span><br><span class="line">    </span><br><span class="line">	conv3_1 = conv2d_layer(pool2,<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="string">&#x27;conv3_1&#x27;</span>)</span><br><span class="line">    conv3_2 = conv2d_layer(conv3_1,<span class="number">256</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="string">&#x27;conv3_2&#x27;</span>)</span><br><span class="line">	conv3_3 = conv2d_layer(conv3_2,<span class="number">256</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="string">&#x27;conv3_3&#x27;</span>)</span><br><span class="line">    pool3 = maxPoolLayer(conv3_3)</span><br><span class="line">    </span><br><span class="line">	conv4_1 = conv2d_layer(pool3,<span class="number">256</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="string">&#x27;conv4_1&#x27;</span>)</span><br><span class="line">    conv4_2 = conv2d_layer(conv4_1,<span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="string">&#x27;conv4_2&#x27;</span>)</span><br><span class="line">	conv4_3 = conv2d_layer(conv4_2,<span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="string">&#x27;conv4_3&#x27;</span>)</span><br><span class="line">    pool4 = maxPoolLayer(conv4_3)</span><br><span class="line">    </span><br><span class="line">	conv5_1 = conv2d_layer(pool4,<span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="string">&#x27;conv5_1&#x27;</span>)</span><br><span class="line">    conv5_2 = conv2d_layer(conv5_1,<span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="string">&#x27;conv5_2&#x27;</span>)</span><br><span class="line">	conv5_3 = conv2d_layer(conv5_1,<span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="string">&#x27;conv5_3&#x27;</span>)</span><br><span class="line">    pool5 = maxPoolLayer(conv5_3)</span><br><span class="line">    </span><br><span class="line">	pool5_flatten_dims = <span class="built_in">int</span>(np.prod(pool5.get_shape().as_list()[<span class="number">1</span>:]))</span><br><span class="line">    pool5_flatten = tf.reshape(pool5,[-<span class="number">1</span>,pool5_flatten_dims])</span><br><span class="line">    </span><br><span class="line">    fc_6 = fc_layer(pool5_flatten, pool5_flatten_dims, <span class="number">4096</span>, <span class="string">&#x27;fc6&#x27;</span>)</span><br><span class="line">	fc_7 = fc_layer(fc_6, <span class="number">4096</span>, <span class="number">4096</span>, <span class="string">&#x27;fc7&#x27;</span>)</span><br><span class="line">	fc_8 = fc_layer(fc_7, <span class="number">4096</span>, <span class="number">10</span>, <span class="string">&#x27;fc8&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> fc_8</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<h1>12.2 Pytorch</h1>
<h2 id="12-2-1-Pytorch是什么？">12.2.1 Pytorch是什么？</h2>
<p>  Pytorch是torch的python版本，是由Facebook开源的神经网络框架，专门针对 GPU 加速的深度神经网络（DNN）编程。Torch 是一个经典的对多维矩阵数据进行操作的张量（tensor ）库，在机器学习和其他数学密集型应用有广泛应用。与Tensorflow的静态计算图不同，pytorch的计算图是动态的，可以根据计算需要实时改变计算图。但由于Torch语言采用 Lua，导致在国内一直很小众，并逐渐被支持 Python 的 Tensorflow 抢走用户。作为经典机器学习库 Torch 的端口，PyTorch 为 Python 语言使用者提供了舒适的写代码选择。</p>
<h2 id="12-2-2-为什么选择-Pytorch？">12.2.2 为什么选择 Pytorch？</h2>
<h3 id="1-简洁：">1.简洁：</h3>
<p>  PyTorch的设计追求最少的封装，尽量避免重复造轮子。不像 TensorFlow 中充斥着session、graph、operation、name_scope、variable、tensor、layer等全新的概念，PyTorch 的设计遵循tensor→variable(autograd)→nn.Module 三个由低到高的抽象层次，分别代表高维数组（张量）、自动求导（变量）和神经网络（层/模块），而且这三个抽象之间联系紧密，可以同时进行修改和操作。<br>
简洁的设计带来的另外一个好处就是代码易于理解。PyTorch的源码只有TensorFlow的十分之一左右，更少的抽象、更直观的设计使得PyTorch的源码十分易于阅读。</p>
<h3 id="2-速度：">2.速度：</h3>
<p>  PyTorch 的灵活性不以速度为代价，在许多评测中，PyTorch 的速度表现胜过 TensorFlow和Keras 等框架。框架的运行速度和程序员的编码水平有极大关系，但同样的算法，使用PyTorch实现的那个更有可能快过用其他框架实现的。</p>
<h3 id="3-易用：">3.易用：</h3>
<p>  PyTorch 是所有的框架中面向对象设计的最优雅的一个。PyTorch的面向对象的接口设计来源于Torch，而Torch的接口设计以灵活易用而著称，Keras作者最初就是受Torch的启发才开发了Keras。PyTorch继承了Torch的衣钵，尤其是API的设计和模块的接口都与Torch高度一致。PyTorch的设计最符合人们的思维，它让用户尽可能地专注于实现自己的想法，即所思即所得，不需要考虑太多关于框架本身的束缚。</p>
<h3 id="4-活跃的社区：">4.活跃的社区：</h3>
<p>  PyTorch 提供了完整的文档，循序渐进的指南，作者亲自维护的论坛 供用户交流和求教问题。Facebook 人工智能研究院对 PyTorch 提供了强力支持，作为当今排名前三的深度学习研究机构，FAIR的支持足以确保PyTorch获得持续的开发更新，不至于像许多由个人开发的框架那样昙花一现。</p>
<h2 id="12-2-3-PyTorch-的架构是怎样的？">12.2.3 PyTorch 的架构是怎样的？</h2>
<p>  PyTorch(Caffe2) 通过混合前端，分布式训练以及工具和库生态系统实现快速，灵活的实验和高效生产。PyTorch 和 TensorFlow 具有不同计算图实现形式，TensorFlow 采用静态图机制(预定义后再使用)，PyTorch采用动态图机制(运行时动态定义)。PyTorch 具有以下高级特征：</p>
<p>  混合前端:新的混合前端在急切模式下提供易用性和灵活性，同时无缝转换到图形模式，以便在C ++运行时环境中实现速度，优化和功能。<br>
  分布式训练:通过利用本地支持集合操作的异步执行和可从Python和C ++访问的对等通信，优化了性能。<br>
  Python优先: PyTorch为了深入集成到Python中而构建的，因此它可以与流行的库和Cython和Numba等软件包一起使用。<br>
  丰富的工具和库:活跃的研究人员和开发人员社区建立了丰富的工具和库生态系统，用于扩展PyTorch并支持从计算机视觉到强化学习等领域的开发。<br>
  本机ONNX支持:以标准ONNX（开放式神经网络交换）格式导出模型，以便直接访问与ONNX兼容的平台，运行时，可视化工具等。<br>
  C++前端：C++前端是PyTorch的纯C++接口，它遵循已建立的Python前端的设计和体系结构。它旨在实现高性能，低延迟和裸机C++应用程序的研究。<br>
使用GPU和CPU优化的深度学习张量库。</p>
<h2 id="12-2-4-Pytorch-与-tensorflow-之间的差异在哪里？">12.2.4 Pytorch 与 tensorflow 之间的差异在哪里？</h2>
<p>  上面也将了PyTorch 最大优势是建立的神经网络是动态的, 对比静态的 Tensorflow, 它能更有效地处理一些问题, 比如说 RNN 变化时间长度的输出。各有各的优势和劣势。两者都是大公司发布的, Tensorflow（Google）宣称在分布式训练上下了很大的功夫, 那就默认 Tensorflow 在分布式训练上要超出 Pytorch（Facebook），还有tensorboard可视化工具, 但是 Tensorflow 的静态计算图使得在 RNN 上有一点点被动 (虽然它用其他途径解决了), 不过用 PyTorch 的时候, 会对这种动态的 RNN 有更好的理解。而且 Tensorflow 的高度工业化, 它的底层代码很难看懂， Pytorch 好那么一点点, 如果深入 PytorchAPI, 至少能比看 Tensorflow 多看懂一点点 Pytorch 的底层在干啥。</p>
<h2 id="12-2-5-Pytorch有哪些常用工具包？">12.2.5 Pytorch有哪些常用工具包？</h2>
<p>  torch ：类似 NumPy 的张量库，强 GPU 支持 ；<br>
  torch.autograd ：基于 tape 的自动区别库，支持 torch 之中的所有可区分张量运行；<br>
  torch.nn ：为最大化灵活性未涉及、与 autograd 深度整合的神经网络库；<br>
  torch.optim：与 torch.nn 一起使用的优化包，包含 SGD、RMSProp、LBFGS、Adam 等标准优化方式；<br>
  torch.multiprocessing： python 多进程并发，进程之间 torch Tensors 的内存共享；<br>
  torch.utils：数据载入器。具有训练器和其他便利功能；<br>
  torch.legacy(.nn/.optim) ：处于向后兼容性考虑，从 Torch 移植来的 legacy 代码；</p>
<h1>12.3 Caffe</h1>
<h2 id="12-3-1-什么是-Caffe？">12.3.1 什么是 Caffe？</h2>
<p>  Caffe的全称应该是Convolutional Architecture for Fast Feature Embedding，它是一个清晰、高效的深度学习框架，它是开源的，核心语言是C++，它支持命令行、Python和Matlab接口，它既可以在CPU上运行也可以在GPU上运行。它的license是BSD 2-Clause。</p>
<h2 id="12-3-2-Caffe的特点是什么？">12.3.2 Caffe的特点是什么？</h2>
<p>(1)、模块化：Caffe从一开始就设计得尽可能模块化，允许对新数据格式、网络层和损失函数进行扩展。</p>
<p>(2)、表示和实现分离：Caffe的模型(model)定义是用Protocol Buffer语言写进配置文件的。以任意有向无环图的形式，Caffe支持网络架构。Caffe会根据网络的需要来正确占用内存。通过一个函数调用，实现CPU和GPU之间的切换。</p>
<p>(3)、测试覆盖：在Caffe中，每一个单一的模块都对应一个测试。</p>
<p>(4)、python和Matlab接口：同时提供Python和Matlab接口。</p>
<p>(5)、预训练参考模型：针对视觉项目，Caffe提供了一些参考模型，这些模型仅应用在学术和非商业领域，它们的license不是BSD。</p>
<h2 id="12-3-3-Caffe的设计思想是怎样的？">12.3.3 Caffe的设计思想是怎样的？</h2>
<p>  基本上，Caffe 沿用了神经网络的一个简单假设----所有的计算都是以layer的形式表示的，layer做的事情就是take一些数据，然后输出一些计算以后的结果，比如说卷积，就是输入一个图像，然后和这一层的参数（filter）做卷积，然后输出卷积的结果。每一个layer需要做两个计算：forward是从输入计算输出，然后backward是从上面给的gradient来计算相对于输入的gradient，只要这两个函数实现了以后，我们就可以把很多层连接成一个网络，这个网络做的事情就是输入我们的数据（图像或者语音或者whatever），然后来计算我们需要的输出（比如说识别的label），在training的时候，我们可以根据已有的label来计算loss和gradient，然后用gradient来update网络的参数，这个就是Caffe的一个基本流程。</p>
<p>  基本上，最简单地用Caffe上手的方法就是先把数据写成Caffe的格式，然后设计一个网络，然后用Caffe提供的solver来做优化看效果如何，如果你的数据是图像的话，可以从现有的网络，比如说alexnet或者googlenet开始，然后做fine tuning，如果你的数据稍有不同，比如说是直接的float vector，你可能需要做一些custom的configuration，Caffe的logistic regression example兴许会很有帮助。</p>
<p>  Fine tune方法：fine tuning的想法就是说，在imagenet那么大的数据集上train好一个很牛的网络了，那别的task上肯定也不错，所以我们可以把pretrain的网络拿过来，然后只重新train最后几层，重新train的意思是说，比如我以前需要classify imagenet的一千类，现在我只想识别是狗还是猫，或者是不是车牌，于是我就可以把最后一层softmax从一个4096<em>1000的分类器变成一个4096</em>2的分类器，这个strategy在应用中非常好使，所以我们经常会先在imagenet上pretrain一个网络，因为我们知道imagenet上training的大概过程会怎么样。</p>
<h2 id="12-3-4-Caffe架构是怎样的？">12.3.4 Caffe架构是怎样的？</h2>
<p>  Caffe的架构与其它的深度学习框架稍微不同，它没有根据算法实现过程的方式来进行编码，而是以系统级的抽象作为整体架构，逐层的封装实现细节，使得上层的架构变得很清晰。Caffe的整体架构如下：</p>
<h3 id="1-SyncedMem">1. SyncedMem</h3>
<p>  这个类的主要功能是封装CPU和GPU的数据交互操作。一般来说，数据的流动形式都是：硬盘-&gt;CPU内存-&gt;GPU内存-&gt;CPU内存-&gt;（硬盘），所以在写代码的过程中经常会写CPU/GPU之间数据传输的代码，同时还要维护CPU和GPU两个处理端的内存指针。这些事情处理起来不会很难，但是会很繁琐。因此SyncedMem的出现就是把CPU/GPU的数据传输操作封装起来，只需要调用简单的接口就可以获得两个处理端同步后的数据。</p>
<h3 id="2-Blob">2. Blob</h3>
<p>  Blob是用于存储数据的对象，在Caffe中各种数据(图像输入、模型参数)都是以Blob的形式在网络中传输的，Blob提供统一的存储操作接口，可用来保存训练数据、模型参数等，同时Blob还能在CPU和GPU之间进行同步以支持CPU/GPU的混合运算。<br>
  这个类做了两个封装：一个是操作数据的封装，使用Blob可以操纵高维的数据，快速访问其中的数据，变换数据的维度等；另一个是对原始数据和更新量的封装，每一个Blob中都有data和diff两个数据指针，data用于存储原始数据，diff 用于存储反向传播（Backpropagation）的梯度更新值。Blob使用了SyncedMem，这样便于访问不同的处理端。Blob基本实现了整个Caffe数据结构部分的封装，在Net类中可以看到所有的前后向数据和参数都用Blob来表示就足够了。数据的抽象到这个就可以了，接下来作层级的抽象。神经网络的前后向计算可以做到层与层之间完全独立，只要每个层按照一定的接口规则实现，就可以确保整个网络的正确性。</p>
<h3 id="3-Layer">3. Layer</h3>
<p>  Layer是网络Net的基本单元，也是Caffe中能在外部进行调整的最小网络结构单元，每个Layer都有输入Blob和输出Blob。Layer（层）是Caffe中最庞大最繁杂的模块，它是神经网络的基本计算单元。由于Caffe强调模块化设计，因此只允许每个layer完成一类特定的计算，例如convolution操作、pooling、非线性变换、内积运算，以及数据加载、归一化和损失计算等。Caffe中layer的种类有很多，具体的种类及功能请看官方文档。在创建一个Caffe模型的时候，也是以Layer为基础进行的。Layer是一个父类，它的下面还有各种实现特定功能的子类，例如data_layer，conv_layer，loss_layer等。Layer是通过LayFactory来创建的。</p>
<h3 id="4-Net">4. Net</h3>
<p>  Net是一个完整的深度网络，包含输入层、隐藏层、输出层，在Caffe中一般是一个卷积神经网络(Convolution Neural Networ，CNN)。通过定义不同类型的Layer，并用Blob将不同的Layer连接起来，就能产生一个Net。Net将数据Blob和层Layer组合起来做进一步的封装，对外提供了初始化和前后传播的接口，使得整体看上去和一个层的功能类似，但内部的组合可以是多种多样的。值得一提的是，每一层的输入输出数据统一保存在Net中，同时每个层内的参数指针也保存在Net中，不同的层可以通过WeightShare共享相同的参数，因此可以通过配置来实现多个神经网络层之间共享参数的功能。一个Net由多个Layer组成。一个典型的网络从data layer（从磁盘中载入数据）出发到loss layer结束。</p>
<h3 id="5-Solver">5. Solver</h3>
<p>  有了Net就可以进行神经网络的前后向传播计算了，但是还缺少神经网络的训练和预测功能，Solver类进一步封装了训练和预测相关的一些功能。它还提供了两个接口：一个是更新参数的接口，继承Solver可以实现不同的参数更新方法，如Momentum，Nesterov，Adagrad等，因此可以使用不同的优化算法。另一个接口是训练过程中每一轮特定状态下的可注入的一些回调函数，在代码中这个回调点的直接使用者就是多GPU训练算法。Solver定义了针对Net网络模型的求解方法，记录网络的训练过程，保存网络模型参数，中断并恢复网络的训练过程。自定义Solver能够实现不同的神经网络求解方式。阅读Solver的代码可以了解网络的求解优化过程。Solver是一个父类，它下面还有实现不同优化方法的子类，例如sgd_solver，adagrad_sovler等，Solver是通过SolverFactory来创建的。</p>
<h3 id="6-Proto">6. Proto</h3>
<p>  caffe.proto位于…/src/caffe/proto目录下，在这个文件夹下还有一个.pb.cc和一个.pb.h文件，这两个文件都是由caffe.proto编译而来的。 在caffe.proto中定义了很多结构化数据，包括：<br>
BlobProto、Datum、FillerParameter、NetParameter、SolverParameter、SolverState、LayerParameter、ConcatParameter、ConvolutionParameter、DataParameter、DropoutParameter、HDF5DataParameter、HDF5OutputParameter、ImageDataParameter、InfogainLossParameter、InnerProductParameter、LRNParameter、MemoryDataParameter、PoolingParameter、PowerParameter、WindowDataParameter、V0LayerParameter。</p>
<h3 id="7-IO">7. IO</h3>
<p>  除了上面的东西之外，还需要输入数据和参数。DataReader和DataTransformer帮助准备输入数据，Filler对参数进行初始化，一些Snapshot方法可以对模型进行持久化。</p>
<h2 id="12-3-5-Caffe的有哪些接口？">12.3.5 Caffe的有哪些接口？</h2>
<p>  Caffe深度学习框架支持多种编程接口，包括命令行、Python和Matlab,下面将介绍如何使用这些接口。</p>
<h3 id="1-Caffe-Python接口">1. Caffe Python接口</h3>
<p>  Caffe提供 Python 接口，即Pycaffe，具体实现在caffe、python文件夹内。在Python代码中import caffe，可以load models（导入模型）、forward and backward （前向、反向迭代）、handle IO（数据输入输出）、visualize networks（绘制net）和instrument model solving（自定义优化方法)。所有的模型数据、计算参数都是暴露在外、可供读写的。<br>
  (1)<a target="_blank" rel="noopener" href="http://caffe.Net">caffe.Net</a> 是主要接口，负责导入数据、校验数据、计算模型。<br>
  (2)caffe.Classsifier 用于图像分类。<br>
  (3)caffe.Detector 用于图像检测。<br>
  (4)caffe.SGDSolver 是露在外的 solver 的接口。<br>
  (5)<a target="_blank" rel="noopener" href="http://caffe.io">caffe.io</a> 处理输入输出，数据预处理。<br>
  (6)caffe.draw 可视化 net 的结构。<br>
  (7)caffe blobs 以 numpy ndarrys 的形式表示，方便而且高效。</p>
<h3 id="2-Caffe-MATLAB接口">2. Caffe MATLAB接口</h3>
<p>  MATLAB接口（Matcaffe）在 caffe/matlab 目录的 caffe 软件包。在 matcaffe 的基础上，可将Caffe整合到MATLAB代码中。<br>
  MATLAB接口包括：<br>
  (1)MATLAB 中创建多个网络结构。<br>
  (2)网络的前向传播（Forward）与反向传播（Backward）计算。<br>
  (3)网络中的任意一层以及参数的存取。<br>
  (4)网络参数保存至文件或从文件夹加载。<br>
  (5)blob 和 network 形状调整。<br>
  (6)网络参数编辑和调整。<br>
  (7)创建多个 solvers 进行训练。<br>
  (8)从solver 快照（Snapshots）恢复并继续训练。<br>
  (9)访问训练网络（Train nets）和测试网络(Test nets)。<br>
  (10)迭代后网络交由 MATLAB 控制。<br>
  (11)MATLAB代码融合梯度算法。</p>
<h3 id="3-Caffe-命令行接口">3. Caffe 命令行接口</h3>
<p>  命令行接口 Cmdcaffe 是 Caffe 中用来训练模型、计算得分以及方法判断的工具。Cmdcaffe 存放在 caffe/build/tools 目录下。</p>
<h4 id="1-caffe-train">1. caffe train</h4>
<p>  caffe train 命令用于模型学习，具体包括：<br>
  (1)caffe train 带 solver.prototxt 参数完成配置。<br>
  (2)caffe train 带 snapshot mode_iter_1000.solverstate 参数加载 solver snapshot。<br>
  (3)caffe train 带 weights 参数 model.caffemodel 完成 Fine-tuning 模型初始化。</p>
<h4 id="2-caffe-test">2. caffe test</h4>
<p>  caffe test 命令用于测试运行模型的得分，并且用百分比表示网络输出的最终结果，比如 accuracyhuoloss 作为其结果。测试过程中，显示每个 batch 的得分，最后输出全部 batch 的平均得分值。</p>
<h4 id="3-caffe-time">3. caffe time</h4>
<p>  caffe time 命令用来检测系统性能和测量模型相对执行时间，此命令通过逐层计时与同步，执行模型检测。</p>
<p>参考文献：<br>
1.深度学习：Caffe之经典模型讲解与实战/ 乐毅，王斌</p>
<h3 id="10-4-网络搭建有什么原则？">10.4 网络搭建有什么原则？</h3>
<h3 id="10-4-1新手原则。">10.4.1新手原则。</h3>
<p>刚入门的新手不建议直接上来就开始搭建网络模型。比较建议的学习顺序如下：</p>
<ul>
<li>1.了解神经网络工作原理，熟悉基本概念及术语。</li>
<li>2.阅读经典网络模型论文+实现源码(深度学习框架视自己情况而定)。</li>
<li>3.找数据集动手跑一个网络，可以尝试更改已有的网络模型结构。</li>
<li>4.根据自己的项目需要设计网络。</li>
</ul>
<h3 id="10-4-2深度优先原则。">10.4.2深度优先原则。</h3>
<p>通常增加网络深度可以提高准确率，但同时会牺牲一些速度和内存。但深度不是盲目堆起来的，一定要在浅层网络有一定效果的基础上，增加深度。深度增加是为了增加模型的准确率，如果浅层都学不到东西，深了也没效果。</p>
<h3 id="10-4-3卷积核size一般为奇数。">10.4.3卷积核size一般为奇数。</h3>
<p>卷积核为奇数有以下好处：</p>
<ul>
<li>1 保证锚点刚好在中间，方便以 central pixel为标准进行滑动卷积，避免了位置信息发生偏移 。</li>
<li>2 保证在填充（Padding）时，在图像之间添加额外的零层，图像的两边仍然对称。</li>
</ul>
<h3 id="10-4-4卷积核不是越大越好。">10.4.4卷积核不是越大越好。</h3>
<p>AlexNet中用到了一些非常大的卷积核，比如11×11、5×5卷积核，之前人们的观念是，卷积核越大，感受野越大，看到的图片信息越多，因此获得的特征越好。但是大的卷积核会导致计算量的暴增，不利于模型深度的增加，计算性能也会降低。于是在VGG、Inception网络中，利用2个3×3卷积核的组合比1个5×5卷积核的效果更佳，同时参数量（3×3×2+1=19&lt;26=5×5×1+1）被降低，因此后来3×3卷积核被广泛应用在各种模型中。</p>
<h2 id="10-5-有哪些经典的网络模型值得我们去学习的？">10.5 有哪些经典的网络模型值得我们去学习的？</h2>
<p>提起经典的网络模型就不得不提起计算机视觉领域的经典比赛：ILSVRC .其全称是 ImageNet Large Scale Visual Recognition Challenge.正是因为ILSVRC 2012挑战赛上的AlexNet横空出世，使得全球范围内掀起了一波深度学习热潮。这一年也被称作“深度学习元年”。而在历年ILSVRC比赛中每次刷新比赛记录的那些神经网络也成为了人们心中的经典，成为学术界与工业届竞相学习与复现的对象，并在此基础上展开新的研究。</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>年份</th>
<th>网络名称</th>
<th>获得荣誉</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2012</td>
<td>AlexNet</td>
<td>ILSVRC图像分类冠军</td>
</tr>
<tr>
<td>2</td>
<td>2014</td>
<td>VGGNet</td>
<td>ILSVRC图像分类亚军</td>
</tr>
<tr>
<td>3</td>
<td>2014</td>
<td>GoogLeNet</td>
<td>ILSVRC图像分类冠军</td>
</tr>
<tr>
<td>4</td>
<td>2015</td>
<td>ResNet</td>
<td>ILSVRC图像分类冠军</td>
</tr>
<tr>
<td>5</td>
<td>2017</td>
<td>SeNet</td>
<td>ILSVRC图像分类冠军</td>
</tr>
</tbody>
</table>
<blockquote>
<ul>
<li>1 AlexNet<br>
论文:<a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">ImageNet Classification with Deep Convolutional Neural Networks</a><br>
代码实现:<a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/blob/361a82d73a50a800510674b3aaa20e4845e56434/tensorflow/contrib/slim/python/slim/nets/alexnet.py">tensorflow</a><br>
主要特点：</li>
</ul>
<blockquote>
<ul>
<li>1.第一次使用非线性激活函数ReLU。</li>
<li>2.增加防加过拟合方法：Droupout层,提升了模型鲁棒性。</li>
<li>3.首次使用数据增强。</li>
<li>4.首次使用GPU加速运算。</li>
</ul>
</blockquote>
</blockquote>
<blockquote>
<ul>
<li>2 VGGNet<br>
论文:<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a><br>
代码实现:<a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/blob/361a82d73a50a800510674b3aaa20e4845e56434/tensorflow/contrib/slim/python/slim/nets/vgg.py">tensorflow</a><br>
主要特点：</li>
</ul>
<blockquote>
<ul>
<li>1.网络结构更深。</li>
<li>2.普遍使用小卷积核。</li>
</ul>
</blockquote>
</blockquote>
<blockquote>
<ul>
<li>3 GoogLeNet<br>
论文:<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.4842">Going Deeper with Convolutions</a><br>
代码实现:<a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/blob/361a82d73a50a800510674b3aaa20e4845e56434/tensorflow/contrib/slim/python/slim/nets/inception_v1.py">tensorflow</a><br>
主要特点：</li>
</ul>
<blockquote>
<ul>
<li>1.增强卷积模块功能。<br>
主要的创新在于他的Inception，这是一种网中网（Network In Network）的结构，即原来的结点也是一个网络。Inception一直在不断发展，目前已经V2、V3、V4。其中1*1卷积主要用来降维，用了Inception之后整个网络结构的宽度和深度都可扩大，能够带来2-3倍的性能提升。</li>
<li>2.连续小卷积代替大卷积，保证感受野不变的同时，减少了参数数目。</li>
</ul>
</blockquote>
<ul>
<li>4 ResNet<br>
论文:<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a><br>
代码实现:<a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/blob/361a82d73a50a800510674b3aaa20e4845e56434/tensorflow/contrib/slim/python/slim/nets/inception_v1.py">tensorflow</a><br>
主要特点:</li>
</ul>
<blockquote>
<p>解决了“退化”问题，即当模型的层次加深时，错误率却提高了。</p>
</blockquote>
<ul>
<li>5 SeNet<br>
论文:<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1709.01507">Squeeze-and-Excitation Networks</a><br>
代码实现:<a target="_blank" rel="noopener" href="https://github.com/ry/tensorflow-resnet">tensorflow</a><br>
主要特点:</li>
</ul>
<blockquote>
<p>提出了feature recalibration，通过引入 attention 重新加权，可以得到抑制无效特征，提升有效特征的权重，并很容易地和现有网络结合，提升现有网络性能，而计算量不会增加太多。</p>
</blockquote>
</blockquote>
<p><strong>CV领域网络结构演进历程：</strong><br>
<img src="%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%BC%94%E8%BF%9B.png" alt="CV领域网络结构演进历程"></p>
<p><strong>ILSVRC挑战赛历年冠军:</strong><br>
<img src="%E5%8E%86%E5%B9%B4%E5%86%A0%E5%86%9B.png" alt="ILSVRC挑战赛历年冠军"></p>
<p>此后，ILSVRC挑战赛的名次一直是衡量一个研究机构或企业技术水平的重要标尺。<br>
ILSVRC 2017 已是最后一届举办.2018年起，将由WebVision竞赛（Challenge on Visual Understanding by Learning from Web Data）来接棒。因此，即使ILSVRC挑战赛停办了，但其对深度学习的深远影响和巨大贡献，将永载史册。</p>
<h2 id="10-6-网络训练有哪些技巧吗？">10.6 网络训练有哪些技巧吗？</h2>
<h3 id="10-6-1-合适的数据集。">10.6.1.合适的数据集。</h3>
<ul>
<li>1 没有明显脏数据(可以极大避免Loss输出为NaN)。</li>
<li>2 样本数据分布均匀。</li>
</ul>
<h3 id="10-6-2-合适的预处理方法。">10.6.2.合适的预处理方法。</h3>
<p>关于数据预处理，在Batch Normalization未出现之前预处理的主要做法是减去均值，然后除去方差。在Batch Normalization出现之后，减均值除方差的做法已经没有必要了。对应的预处理方法主要是数据筛查、数据增强等。</p>
<h3 id="10-6-3-网络的初始化。">10.6.3.网络的初始化。</h3>
<p>网络初始化最粗暴的做法是参数赋值为全0，这是绝对不可取的。因为如果所有的参数都是0，那么所有神经元的输出都将是相同的，那在back propagation的时候同一层内所有神经元的行为也是相同的，这可能会直接导致模型失效，无法收敛。吴恩达视频中介绍的方法是将网络权重初始化均值为0、方差为1符合的正态分布的随机数据。</p>
<h3 id="10-6-4-小规模数据试练。">10.6.4.小规模数据试练。</h3>
<p>在正式开始训练之前，可以先用小规模数据进行试练。原因如下：</p>
<ul>
<li>1 可以验证自己的训练流程对否。</li>
<li>2 可以观察收敛速度，帮助调整学习速率。</li>
<li>3 查看GPU显存占用情况，最大化batch_size(前提是进行了batch normalization，只要显卡不爆，尽量挑大的)。</li>
</ul>
<h3 id="10-6-5-设置合理Learning-Rate。">10.6.5.设置合理Learning Rate。</h3>
<ul>
<li>1 太大。Loss爆炸、输出NaN等。</li>
<li>2 太小。收敛速度过慢，训练时长大大延长。</li>
<li>3 可变的学习速率。比如当输出准确率到达某个阈值后，可以让Learning Rate减半继续训练。</li>
</ul>
<h3 id="10-6-6-损失函数">10.6.6.损失函数</h3>
<p>损失函数主要分为两大类:分类损失和回归损失</p>
<blockquote>
<p>1.回归损失：</p>
<blockquote>
<ul>
<li>1 均方误差(MSE 二次损失 L2损失)<br>
它是我们的目标变量与预测值变量差值平方。</li>
<li>2 平均绝对误差(MAE L1损失)<br>
它是我们的目标变量与预测值变量差值绝对值。<br>
关于MSE与MAE的比较。MSE更容易解决问题，但是MAE对于异常值更加鲁棒。更多关于MAE和MSE的性能，可以参考<a target="_blank" rel="noopener" href="https://rishy.github.io/ml/2015/07/28/l1-vs-l2-loss/">L1vs.L2 Loss Function</a></li>
</ul>
</blockquote>
</blockquote>
<blockquote>
<p>2.分类损失：</p>
<blockquote>
<ul>
<li>1 交叉熵损失函数。<br>
是目前神经网络中最常用的分类目标损失函数。</li>
<li>2 合页损失函数<br>
合页损失函数广泛在支持向量机中使用，有时也会在损失函数中使用。缺点:合页损失函数是对错误越大的样本施以更严重的惩罚，但是这样会导致损失函数对噪声敏感。</li>
</ul>
</blockquote>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lilitom.github.io/2024/03/19/deep_learning/ch13/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/deep_learning/ch13/" class="post-title-link" itemprop="url">优化算法面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-24 10:14:05" itemprop="dateModified" datetime="2024-03-24T10:14:05+08:00">2024-03-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>优化算法</h1>
<h2 id="13-1-如何解决训练样本少的问题">13.1 如何解决训练样本少的问题</h2>
<p>目前大部分的深度学习模型仍然需要海量的数据支持。例如 ImageNet 数据就拥有1400多万的图片。而现实生产环境中，数据集通常较小，只有几万甚至几百个样本。这时候，如何在这种情况下应用深度学习呢?<br>
（1）利用预训练模型进行迁移微调（fine-tuning），预训练模型通常在特征上拥有很好的语义表达。此时，只需将模型在小数据集上进行微调就能取得不错的效果。这也是目前大部分小数据集常用的训练方式。视觉领域内，通常会ImageNet上训练完成的模型。自然语言处理领域，也有BERT模型等预训练模型可以使用。<br>
  <br>
（2）单样本或者少样本学习（one-shot，few-shot learning），这种方式适用于样本类别远远大于样本数量的情况等极端数据集。例如有1000个类别，每个类别只提供1-5个样本。少样本学习同样也需要借助预训练模型，但有别于微调的在于，微调通常仍然在学习不同类别的语义，而少样本学习通常需要学习样本之间的距离度量。例如孪生网络（Siamese Neural Networks）就是通过训练两个同种结构的网络来判别输入的两张图片是否属于同一类。<br>
​	上述两种是常用训练小样本数据集的方式。此外，也有些常用的手段，例如数据集增强、正则或者半监督学习等方式来解决小样本数据集的训练问题。</p>
<h2 id="13-2-深度学习是否能胜任所有数据集">13.2 深度学习是否能胜任所有数据集?</h2>
<p>深度学习并不能胜任目前所有的数据环境，以下列举两种情况：</p>
<p>（1）深度学习能取得目前的成果，很大一部分原因依赖于海量的数据集以及高性能密集计算硬件。因此，当数据集过小时，需要考虑与传统机器学习相比，是否在性能和硬件资源效率更具有优势。<br>
（2）深度学习目前在视觉，自然语言处理等领域都有取得不错的成果。这些领域最大的特点就是具有局部相关性。例如图像中，人的耳朵位于两侧，鼻子位于两眼之间，文本中单词组成句子。这些都是具有局部相关性的，一旦被打乱则会破坏语义或者有不同的语义。所以当数据不具备这种相关性的时候，深度学习就很难取得效果。</p>
<h2 id="13-3-有没有可能找到比已知算法更好的算法">13.3 有没有可能找到比已知算法更好的算法?</h2>
<p>在最优化理论发展中，有个没有免费午餐的定律，其主要含义在于，在不考虑具体背景和细节的情况下，任何算法和随机猜的效果期望是一样的。即，没有任何一种算法能优于其他一切算法，甚至不比随机猜好。深度学习作为机器学习领域的一个分支同样符合这个定律。所以，虽然目前深度学习取得了非常不错的成果，但是我们同样不能盲目崇拜。</p>
<p>优化算法本质上是在寻找和探索更符合数据集和问题的算法，这里数据集是算法的驱动力，而需要通过数据集解决的问题就是算法的核心，任何算法脱离了数据都会没有实际价值，任何算法的假设都不能脱离实际问题。因此，实际应用中，面对不同的场景和不同的问题，可以从多个角度针对问题进行分析，寻找更优的算法。</p>
<h2 id="13-4-什么是共线性，如何判断和解决共线性问题">13.4 什么是共线性，如何判断和解决共线性问题?</h2>
<p>对于回归算法，无论是一般回归还是逻辑回归，在使用多个变量进行预测分析时，都可能存在多变量相关的情况，这就是多重共线性。共线性的存在，使得特征之间存在冗余，导致过拟合。</p>
<p>常用判断是否存在共线性的方法有：</p>
<p>（1）相关性分析。当相关性系数高于0.8，表明存在多重共线性；但相关系数低，并不能表示不存在多重共线性；</p>
<p>（2）方差膨胀因子VIF。当VIF大于5或10时，代表模型存在严重的共线性问题；</p>
<p>（3）条件系数检验。 当条件数大于100、1000时，代表模型存在严重的共线性问题。</p>
<p>通常可通过PCA降维、逐步回归法和LASSO回归等方法消除共线性。</p>
<h2 id="13-5-权值初始化方法有哪些？">13.5 权值初始化方法有哪些？</h2>
<p>在深度学习的模型中，从零开始训练时，权重的初始化有时候会对模型训练产生较大的影响。良好的初始化能让模型快速、有效的收敛，而糟糕的初始化会使得模型无法训练。</p>
<p>目前，大部分深度学习框架都提供了各类初始化方式，其中一般常用的会有如下几种：<br>
<strong>1. 常数初始化(constant)</strong></p>
<p>​	把权值或者偏置初始化为一个常数。例如设置为0，偏置初始化为0较为常见，权重很少会初始化为0。TensorFlow中也有zeros_initializer、ones_initializer等特殊常数初始化函数。</p>
<p><strong>2. 高斯初始化(gaussian)</strong></p>
<p>​	 给定一组均值和标准差，随机初始化的参数会满足给定均值和标准差的高斯分布。高斯初始化是很常用的初始化方式。特殊地，在TensorFlow中还有一种截断高斯分布初始化（truncated_normal_initializer），其主要为了将超过两个标准差的随机数重新随机，使得随机数更稳定。</p>
<p><strong>3. 均匀分布初始化(uniform)</strong></p>
<p>​	给定最大最小的上下限，参数会在该范围内以均匀分布方式进行初始化，常用上下限为（0，1）。</p>
<p><strong>4. xavier 初始化(uniform)</strong></p>
<p>​	在batchnorm还未出现之前，要训练较深的网络，防止梯度弥散，需要依赖非常好的初始化方式。xavier 就是一种比较优秀的初始化方式，也是目前最常用的初始化方式之一。其目的是为了使得模型各层的激活值和梯度在传播过程中的方差保持一致。本质上xavier 还是属于均匀分布初始化，但与上述的均匀分布初始化有所不同，xavier 的上下限将在如下范围内进行均匀分布采样：</p>
 $$
[-\sqrt{\frac{6}{n+m}},\sqrt{\frac{6}{n+m}}]
$$ 
<p>​	其中，n为所在层的输入维度，m为所在层的输出维度。</p>
<p><strong>6. kaiming初始化（msra 初始化）</strong></p>
<p>​	kaiming初始化，在caffe中也叫msra 初始化。kaiming初始化和xavier 一样都是为了防止梯度弥散而使用的初始化方式。kaiming初始化的出现是因为xavier存在一个不成立的假设。xavier在推导中假设激活函数都是线性的，而在深度学习中常用的ReLu等都是非线性的激活函数。而kaiming初始化本质上是高斯分布初始化，与上述高斯分布初始化有所不同，其是个满足均值为0，方差为2/n的高斯分布：</p>
 $$
[0,\sqrt{\frac{2}{n}}]
$$ 
<p>​	其中，n为所在层的输入维度。</p>
<p>除上述常见的初始化方式以外，不同深度学习框架下也会有不同的初始化方式，读者可自行查阅官方文档。</p>
<h2 id="13-5-如何防止梯度下降陷入局部最优解">13.5 如何防止梯度下降陷入局部最优解?</h2>
<p>梯度下降法(GD)及其一些变种算法是目前深度学习里最常用于求解凸优化问题的优化算法。神经网络很可能存在很多局部最优解，而非全局最优解。 为了防止陷入局部最优，通常会采用如下一些方法，当然，这并不能保证一定能找到全局最优解，或许能得到一个比目前更优的局部最优解也是不错的：</p>
<p><strong>（1）stochastic GD</strong> /<strong>Mini-Batch GD</strong></p>
<p>​	在GD算法中，每次的梯度都是从所有样本中累计获取的，这种情况最容易导致梯度方向过于稳定一致，且更新次数过少，容易陷入局部最优。而stochastic GD是GD的另一种极端更新方式，其每次都只使用一个样本进行参数更新，这样更新次数大大增加也就不容易陷入局部最优。但引出的一个问题的在于其更新方向过多，导致不易于进一步优化。Mini-Batch GD便是两种极端的折中，即每次更新使用一小批样本进行参数更新。Mini-Batch GD是目前最常用的优化算法，严格意义上Mini-Batch GD也叫做stochastic GD，所以很多深度学习框架上都叫做SGD。<br>
**（2）动量 **<br>
​	动量也是GD中常用的方式之一，SGD的更新方式虽然有效，但每次只依赖于当前批样本的梯度方向，这样的梯度方向依然很可能很随机。动量就是用来减少随机，增加稳定性。其思想是模仿物理学的动量方式，每次更新前加入部分上一次的梯度量，这样整个梯度方向就不容易过于随机。一些常见情况时，如上次梯度过大，导致进入局部最小点时，下一次更新能很容易借助上次的大梯度跳出局部最小点。</p>
<p>**（3）自适应学习率 **</p>
<p>​	无论是GD还是动量重点优化角度是梯度方向。而学习率则是用来直接控制梯度更新幅度的超参数。自适应学习率的优化方法有很多，例如Adagrad和RMSprop。两种自适应学习率的方式稍有差异，但主要思想都是基于历史的累计梯度去计算一个当前较优的学习率。</p>
<h2 id="13-7-为什么需要激活函数？">13.7 为什么需要激活函数？</h2>
<p>（1）非线性：即导数不是常数。这个条件是多层神经网络的基础，保证多层网络不退化成单层线性网络。这也是激活函数的意义所在。</p>
<p>（2）几乎处处可微：可微性保证了在优化中梯度的可计算性。传统的激活函数如sigmoid等满足处处可微。对于分段线性函数比如ReLU，只满足几乎处处可微（即仅在有限个点处不可微）。对于SGD算法来说，由于几乎不可能收敛到梯度接近零的位置，有限的不可微点对于优化结果不会有很大影响[1]。</p>
<p>（3）计算简单：非线性函数有很多。极端的说，一个多层神经网络也可以作为一个非线性函数，类似于Network In Network[2]中把它当做卷积操作的做法。但激活函数在神经网络前向的计算次数与神经元的个数成正比，因此简单的非线性函数自然更适合用作激活函数。这也是ReLU之流比其它使用Exp等操作的激活函数更受欢迎的其中一个原因。</p>
<p>（4）非饱和性（saturation）：饱和指的是在某些区间梯度接近于零（即梯度消失），使得参数无法继续更新的问题。最经典的例子是Sigmoid，它的导数在x为比较大的正值和比较小的负值时都会接近于0。更极端的例子是阶跃函数，由于它在几乎所有位置的梯度都为0，因此处处饱和，无法作为激活函数。ReLU在x&gt;0时导数恒为1，因此对于再大的正值也不会饱和。但同时对于x&lt;0，其梯度恒为0，这时候它也会出现饱和的现象（在这种情况下通常称为dying ReLU）。Leaky ReLU[3]和PReLU[4]的提出正是为了解决这一问题。</p>
<p>（5）单调性（monotonic）：即导数符号不变。这个性质大部分激活函数都有，除了诸如sin、cos等。个人理解，单调性使得在激活函数处的梯度方向不会经常改变，从而让训练更容易收敛。</p>
<p>（6）输出范围有限：有限的输出范围使得网络对于一些比较大的输入也会比较稳定，这也是为什么早期的激活函数都以此类函数为主，如Sigmoid、TanH。但这导致了前面提到的梯度消失问题，而且强行让每一层的输出限制到固定范围会限制其表达能力。因此现在这类函数仅用于某些需要特定输出范围的场合，比如概率输出（此时loss函数中的log操作能够抵消其梯度消失的影响[1]）、LSTM里的gate函数。</p>
<p>（7）接近恒等变换（identity）：即约等于x。这样的好处是使得输出的幅值不会随着深度的增加而发生显著的增加，从而使网络更为稳定，同时梯度也能够更容易地回传。这个与非线性是有点矛盾的，因此激活函数基本只是部分满足这个条件，比如TanH只在原点附近有线性区（在原点为0且在原点的导数为1），而ReLU只在x&gt;0时为线性。这个性质也让初始化参数范围的推导更为简单[5][4]。额外提一句，这种恒等变换的性质也被其他一些网络结构设计所借鉴，比如CNN中的ResNet[6]和RNN中的LSTM。</p>
<p>（8）参数少：大部分激活函数都是没有参数的。像PReLU带单个参数会略微增加网络的大小。还有一个例外是Maxout[7]，尽管本身没有参数，但在同样输出通道数下k路Maxout需要的输入通道数是其它函数的k倍，这意味着神经元数目也需要变为k倍；但如果不考虑维持输出通道数的情况下，该激活函数又能将参数个数减少为原来的k倍。</p>
<p>（9）归一化（normalization）：这个是最近才出来的概念，对应的激活函数是SELU[8]，主要思想是使样本分布自动归一化到零均值、单位方差的分布，从而稳定训练。在这之前，这种归一化的思想也被用于网络结构的设计，比如Batch Normalization[9]。</p>
<h2 id="13-6-常见的损失函数有哪些">13.6 常见的损失函数有哪些?</h2>
<p>机器学习通过对算法中的目标函数进行不断求解优化，得到最终想要的结果。分类和回归问题中，通常使用损失函数或代价函数作为目标函数。</p>
<p>损失函数用来评价预测值和真实值不一样的程度。通常损失函数越好，模型的性能也越好。</p>
<p>损失函数可分为<strong>经验风险损失</strong>和<strong>结构风险损失</strong>。经验风险损失是根据已知数据得到的损失。结构风险损失是为了防止模型被过度拟合已知数据而加入的惩罚项。</p>
<p>下面介绍常用的损失函数:<br>
<strong>（1）0-1 损失函数</strong><br>
  <br>
如果预测值和目标值相等，值为 0，如果不相等，值为 1：</p>
 $$
L(Y,f(x))=
\left\{
\begin{array}{}
1\;\;\;,\;\;Y\ne f(x), \\
0\;\;\;,\;\;Y=f(x).
\end{array}
\right.
$$ 
<p>  <br>
一般的在实际使用中，相等的条件过于严格，可适当放宽条件：</p>
 $$
L(Y,f(x))=
\left\{
\begin{array}{}
1\;\;\;,\;\;|Y - f(x)| \ge T, \\
0\;\;\;,\;\;|Y-f(x)| < T.
\end{array}
\right.
$$ 
<p>  <br>
<strong>（2）绝对值损失函数</strong><br>
  <br>
和 0-1 损失函数相似，绝对值损失函数表示为：</p>
 $$
L(Y,f(x))=|Y-f(x)|.
$$ 
<p>  <br>
<strong>（3）平方损失函数</strong></p>
 $$
L(Y|f(x))=\sum_{N}(Y-f(x))^2.
$$ 
<p>  <br>
这点可从最小二乘法和欧几里得距离角度理解。最小二乘法的原理是，最优拟合曲线应该 使所有点到回归直线的距离和最小。</p>
<p>  <br>
<strong>（4）log 对数损失函数</strong></p>
 $$
L(Y,P(Y|X))=-logP(Y|X).
$$ 
<p>  <br>
常见的逻辑回归使用的就是对数损失函数，有很多人认为逻辑回归的损失函数式平方损失， 其实不然。逻辑回归它假设样本服从伯努利分布，进而求得满足该分布的似然函数，接着取对 数求极值等。逻辑回归推导出的经验风险函数是最小化负的似然函数，从损失函数的角度看， 就是 log 损失函数。</p>
<p>  <br>
<strong>（5）指数损失函数</strong><br>
  <br>
指数损失函数的标准形式为：</p>
 $$
L(Y|f(x))=exp[-yf(x)].
$$ 
<p>  <br>
例如 AdaBoost 就是以指数损失函数为损失函数。</p>
<p>  <br>
<strong>（6）Hinge 损失函数</strong><br>
  <br>
Hinge 损失函数的标准形式如下：</p>
 $$
L(y)=max(0, 1-ty).
$$ 
<p>  <br>
其中 y 是预测值，范围为(-1,1), t 为目标值，其为-1 或 1。<br>
  <br>
在线性支持向量机中，最优化问题可等价于：</p>
 $$
\underset{w,b}{min}\sum_{i=1}^{N}(1-y_i(wx_i+b))+\lambda \lVert w^2 \rVert
$$ 
<p>  </p>
 $$
\frac{1}{m}\sum_{i=1}^{N}l(wx_i+by_i))+\lVert w^2 \rVert
$$ 
<p>  <br>
其中 $l(wx_i+by_i))$ 是Hinge损失函数， $\lVert w^2 \rVert$ 可看做为正则化项。</p>
<h2 id="13-7-如何进行特征选择-feature-selection">13.7 如何进行特征选择(feature selection)?</h2>
<h3 id="13-7-1-特征类型有哪些？">13.7.1 特征类型有哪些？</h3>
<p>对象本身会有许多属性。所谓特征，即能在某方面最能表征对象的一个或者一组属性。一般地，我们可以把特征分为如下三个类型：</p>
<p>（1）相关特征：对于特定的任务和场景具有一定帮助的属性，这些属性通常能有效提升算法性能；</p>
<p>（2）无关特征：在特定的任务和场景下完全无用的属性，这些属性对对象在本目标环境下完全无用；</p>
<p>（3）冗余特征：同样是在特定的任务和场景下具有一定帮助的属性，但这类属性已过多的存在，不具有产生任何新的信息的能力。</p>
<h3 id="13-7-2-如何考虑特征选择">13.7.2 如何考虑特征选择</h3>
<p>当完成数据预处理之后，对特定的场景和目标而言很多维度上的特征都是不具有任何判别或者表征能力的，所以需要对数据在维度上进行筛选。一般地，可以从以下两个方面考虑来选择特征:</p>
<p>（1）特征是否具有发散性：某个特征若在所有样本上的都是一样的或者接近一致，即方差非常小。 也就是说所有样本的都具有一致的表现，那这些就不具有任何信息。</p>
<p>（2）特征与目标的相关性：与目标相关性高的特征，应当优选选择。</p>
<h3 id="13-7-3-特征选择方法分类">13.7.3 特征选择方法分类</h3>
<p>根据特征选择的形式又可以将特征选择方法分为 3 种:<br>
（1）过滤法：按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。</p>
<p>（2）包装法：根据目标函数(通常是预测效果评分)，每次选择若干特征，或者排除若干特征。</p>
<p>（3）嵌入法：先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。</p>
<h3 id="13-7-4-特征选择目的">13.7.4 特征选择目的</h3>
<p>（1）减少特征维度，使模型泛化能力更强，减少过拟合;</p>
<p>（2）降低任务目标的学习难度；</p>
<p>（3）一组优秀的特征通常能有效的降低模型复杂度，提升模型效率</p>
<h2 id="13-8-梯度消失-梯度爆炸原因，以及解决方法">13.8 梯度消失/梯度爆炸原因，以及解决方法</h2>
<h3 id="13-8-1-为什么要使用梯度更新规则">13.8.1 为什么要使用梯度更新规则?</h3>
<p>目前深度学习的火热，其最大的功臣之一就是反向传播。反向传播，即根据损失评价函数计算的误差，计算得到梯度，通过梯度反向传播的方式，指导深度网络权值的更新优化。这样做的原因在于，深层网络由许多非线性层堆叠而来，每一层非线性层都可以视为是一个非线性函数，因此整个深度网络可以视为是一个复合的非线性多元函数：</p>
 $$
F(x)=f_n(\cdots f_3(f_2(f_1(x)*\theta_1+b)*\theta_2+b)\cdots)
$$ 
<p>我们最终的目的是希望这个多元函数可以很好的完成输入到输出之间的映射，假设不同的输入，输出的最优解是g(x) ，那么，优化深度网络就是为了寻找到合适的权值，满足 Loss=L(g(x),F(x))取得极小值点，比如最简单的损失函数：</p>
 $$
Loss = \lVert g(x)-f(x) \rVert^2_2.
$$ 
<p>假设损失函数的数据空间是下图这样的，我们最优的权值就是为了寻找下图中的最小值点， 对于这种数学寻找最小值问题，采用梯度下降的方法再适合不过了。</p>
<p><img src="figure_13_15_1.png" alt></p>
<center>图 13.8.1 </center>
<h3 id="13-8-2-梯度消失-爆炸产生的原因">13.8.2 梯度消失/爆炸产生的原因?</h3>
<p>本质上，梯度消失和爆炸是一种情况。在深层网络中，由于网络过深，如果初始得到的梯度过小，或者传播途中在某一层上过小，则在之后的层上得到的梯度会越来越小，即产生了梯度消失。梯度爆炸也是同样的。一般地，不合理的初始化以及激活函数，如sigmoid等，都会导致梯度过大或者过小，从而引起消失/爆炸。</p>
<p>下面分别从网络深度角度以及激活函数角度进行解释：</p>
<p>（1）网络深度</p>
<p>若在网络很深时，若权重初始化较小，各层上的相乘得到的数值都会0-1之间的小数，而激活函数梯度也是0-1之间的数。那么连乘后，结果数值就会变得非常小，导致<strong>梯度消失</strong>。若权重初始化较大，大到乘以激活函数的导数都大于1，那么连乘后，可能会导致求导的结果很大，形成<strong>梯度爆炸</strong>。</p>
<p>（2）激活函数<br>
如果激活函数选择不合适，比如使用 sigmoid，梯度消失就会很明显了，原因看下图，左图是sigmoid的函数图，右边是其导数的图像，如果使用sigmoid作为损失函数，其梯度是不可能超过0.25的，这样经过链式求导之后，很容易发生梯度消失。<br>
<img src="figure_13_15_2.png" alt></p>
<center>图 13.8.2 sigmod函数与其导数</center>
<h3 id="13-8-3-梯度消失、爆炸的解决方案">13.8.3 梯度消失、爆炸的解决方案</h3>
<p><strong>1、预训练加微调</strong><br>
此方法来自Hinton在2006年发表的一篇论文，Hinton为了解决梯度的问题，提出采取无监督逐层训练方法，其基本思想是每次训练一层隐节点，训练时将上一层隐节点的输出作为输入，而本层隐节点的输出作为下一层隐节点的输入，此过程就是逐层“预训练”（pre-training）；在预训练完成后，再对整个网络进行“微调”（fine-tunning）。Hinton在训练深度信念网络（Deep Belief Networks中，使用了这个方法，在各层预训练完成后，再利用BP算法对整个网络进行训练。此思想相当于是先寻找局部最优，然后整合起来寻找全局最优，此方法有一定的好处，但是目前应用的不是很多了。</p>
<p><strong>2、梯度剪切、正则</strong><br>
梯度剪切这个方案主要是针对梯度爆炸提出的，其思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。这可以防止梯度爆炸。<br>
另外一种解决梯度爆炸的手段是采用权重正则化（weithts regularization）比较常见的是L1和L2正则。</p>
<p><strong>3、ReLu、leakReLu等激活函数</strong><br>
（1）ReLu：其函数的导数在正数部分是恒等于1，这样在深层网络中，在激活函数部分就不存在导致梯度过大或者过小的问题，缓解了梯度消失或者爆炸。同时也方便计算。当然，其也存在存在一些缺点，例如过滤到了负数部分，导致部分信息的丢失，输出的数据分布不在以0为中心，改变了数据分布。<br>
（2）leakrelu：就是为了解决relu的0区间带来的影响，其数学表达为：leakrelu=max(k*x,0)其中k是leak系数，一般选择0.01或者0.02，或者通过学习而来。</p>
<p><strong>4、batchnorm</strong><br>
Batchnorm是深度学习发展以来提出的最重要的成果之一了，目前已经被广泛的应用到了各大网络中，具有加速网络收敛速度，提升训练稳定性的效果，Batchnorm本质上是解决反向传播过程中的梯度问题。Batchnorm全名是Batch Normalization，简称BN，即批规范化，通过规范化操作将输出信号x规范化到均值为0，方差为1保证网络的稳定性。</p>
<p><strong>5、残差结构</strong><br>
残差的方式，能使得深层的网络梯度通过跳级连接路径直接返回到浅层部分，使得网络无论多深都能将梯度进行有效的回传。</p>
<p><strong>6、LSTM</strong><br>
LSTM全称是长短期记忆网络（long-short term memory networks），是不那么容易发生梯度消失的，主要原因在于LSTM内部复杂的“门”(gates)。在计算时，将过程中的梯度进行了抵消。</p>
<h2 id="13-9-深度学习为什么不用二阶优化？">13.9 深度学习为什么不用二阶优化？</h2>
<p>目前深度学习中，反向传播主要是依靠一阶梯度。二阶梯度在理论和实际上都是可以应用都网络中的，但相比于一阶梯度，二阶优化会存在以下一些主要问题：<br>
（1）计算量大，训练非常慢。<br>
（2）二阶方法能够更快地求得更高精度的解，这在浅层模型是有益的。而在神经网络这类深层模型中对参数的精度要求不高，甚至不高的精度对模型还有益处，能够提高模型的泛化能力。<br>
（3）稳定性。二阶方法能更快求高精度的解，同样对数据本身要的精度也会相应的变高，这就会导致稳定性上的问题。</p>
<h2 id="13-10-为什么要设置单一数字评估指标，设置指标的意义？">13.10 为什么要设置单一数字评估指标，设置指标的意义？</h2>
<p>在训练模型时，无论是调整超参数，还是调整不同的模型算法，我们都需要一个有效的评价指标，这个评价标准能帮助我们快速了解新的尝试后模型的性能是否更优。例如在分类时，我们通常会选择选择准确率，当样本不平衡时，查准率和查全率又会是更好的评价指标。所以在训练模型时，如果设置了单一数字的评估指标通常能很快的反应出我们模型的改进是否直接产生了收益，从而加速我们的算法改进过程。若在训练过程中，发现优化目标进一步深入，现有指标无法完全反应进一步的目标时，就需要重新选择评估指标了。</p>
<h2 id="13-11训练-验证-测试集的定义及划分">13.11训练/验证/测试集的定义及划分</h2>
<p>训练、验证、测试集在机器学习领域是非常重要的三个内容。三者共同组成了整个项目的性能的上限和走向。</p>
<p>训练集：用于模型训练的样本集合，样本占用量是最大的；</p>
<p>验证集：用于训练过程中的模型性能评价，跟着性能评价才能更好的调参；</p>
<p>测试集：用于最终模型的一次最终评价，直接反应了模型的性能。</p>
<p>在划分上，可以分两种情况：</p>
<p>1、在样本量有限的情况下，有时候会把验证集和测试集合并。实际中，若划分为三类，那么训练集：验证集：测试集=6:2:2；若是两类，则训练集：验证集=7:3。这里需要主要在数据量不够多的情况，验证集和测试集需要占的数据比例比较多，以充分了解模型的泛化性。</p>
<p>2、在海量样本的情况下，这种情况在目前深度学习中会比较常见。此时由于数据量巨大，我们不需要将过多的数据用于验证和测试集。例如拥有1百万样本时，我们按训练集：验证集：测试集=98:1:1的比例划分，1%的验证和1%的测试集都已经拥有了1万个样本。这已足够验证模型性能了。</p>
<p>此外，三个数据集的划分不是一次就可以的，若调试过程中发现，三者得到的性能评价差异很大时，可以重新划分以确定是数据集划分的问题导致还是由模型本身导致的。其次，若评价指标发生变化，而导致模型性能差异在三者上很大时，同样可重新划分确认排除数据问题，以方便进一步的优化。</p>
<h2 id="13-12-什么是TOP5错误率？">13.12 什么是TOP5错误率？</h2>
<p>通常对于分类系统而言，系统会对某个未知样本进行所有已知样本的匹配，并给出该未知样本在每个已知类别上的概率。其中最大的概率就是系统系统判定最可能的一个类别。TOP5则就是在前五个最大概率的类别。TOP5错误率，即预测最可能的五类都不是该样本类别的错误率。</p>
<p>TOP5错误率通常会用于在类别数量很多或者细粒度类别的模型系统。典型地，例如著名的ImageNet ，其包含了1000个类别。通常就会采用TOP5错误率。</p>
<h2 id="13-13-什么是泛化误差，如何理解方差和偏差？">13.13 什么是泛化误差，如何理解方差和偏差？</h2>
<p>一般情况下，我们评价模型性能时都会使用泛化误差。泛化误差越低，模型性能越好。泛化误差可分解为方差、偏差和噪声三部分。这三部分中，噪声是个不可控因素，它的存在是算法一直无法解决的问题，很难约减，所以我们更多考虑的是方差和偏差。</p>
<p>方差和偏差在泛化误差上可做如下分解，假设我们的预测值为g(x)，真实值为f(x)，则均方误差为</p>
 $$
E((g(x)−f(x))2)
$$ 
<p>这里假设不考虑噪声，g来代表预测值，f代表真实值，g¯=E(g)代表算法的期望预测，则有如下表达：</p>
 $$
\begin{align}
E(g-f)^2&=E(g^2-2gf+f^2)
\\&=E(g^2)-\bar g^2+(\bar g-f)^2
\\&=E(g^2)-2\bar g^2+\bar g^2+(\bar g-f)^2
\\&=E(g^2-2g\bar g^2+\bar g^2)+(\bar g-f)^2
\\&=\underbrace{E(g-\bar g)^2}_{var(x)}+\underbrace{(\bar g-f)^2}_{bias^2(x)}
\end{align}
$$ 
<p>有上述公式可知，方差描述是理论期望和预测值之间的关系，这里的理论期望通常是指所有适用于模型的各种不同分布类型的数据集；偏差描述为真实值和预测值之间的关系，这里的真实值通常指某一个特定分布的数据集合。</p>
<p>所以综上方差表现为模型在各类分布数据的适应能力，方差越大，说明数据分布越分散，而偏差则表现为在特定分布上的适应能力，偏差越大越偏离真实值。</p>
<h2 id="13-14-如何提升模型的稳定性？">13.14 如何提升模型的稳定性？</h2>
<p>评价模型不仅要从模型的主要指标上的性能，也要注重模型的稳定性。模型的稳定性体现在对不同样本之间的体现的差异。如模型的方差很大，那可以从如下几个方面进行考虑：</p>
<p>（1）正则化（L2, L1, dropout）：模型方差大，很可能来自于过拟合。正则化能有效的降低模型的复杂度，增加对更多分布的适应性。</p>
<p>（2）提前停止训练：提前停止是指模型在验证集上取得不错的性能时停止训练。这种方式本质和正则化是一个道理，能减少方差的同时增加的偏差。目的为了平衡训练集和未知数据之间在模型的表现差异。</p>
<p>（3）扩充训练集：正则化通过控制模型复杂度，来增加更多样本的适应性。那增加训练集让模型适应不同类型的数据本身就是一种最简单直接的方式提升模型稳定的方法，也是最可靠的一种方式。  与正则有所不同的是，扩充数据集既可以减小偏差又能减小方差。</p>
<p>（4）特征选择：过高的特征维度会使模型过拟合，减少特征维度和正则一样可能会处理好方差问题，但是同时会增大偏差。但需要注意的是若过度删减特征，很可能会删除很多有用的特征，降低模型的性能。所以需要多注意删减的特征对模型的性能的影响。</p>
<h2 id="13-15-有哪些改善模型的思路">13.15 有哪些改善模型的思路</h2>
<p>改善模型本质是如何优化模型，这本身是个很宽泛的问题。也是目前学界一直探索的目的，而从目前常规的手段上来说，一般可取如下几点。</p>
<h3 id="13-15-1-数据角度">13.15.1 数据角度</h3>
<p>增强数据集。无论是有监督还是无监督学习，数据永远是最重要的驱动力。更多的类型数据对良好的模型能带来更好的稳定性和对未知数据的可预见性。对模型来说，“看到过的总比没看到的更具有判别的信心”。但增大数据并不是盲目的，模型容限能力不高的情况下即使增大数据也对模型毫无意义。而从数据获取的成本角度，对现有数据进行有效的扩充也是个非常有效且实际的方式。良好的数据处理，常见的处理方式如数据缩放、归一化和标准化等。</p>
<h3 id="13-15-2-模型角度">13.15.2 模型角度</h3>
<p>模型的容限能力决定着模型可优化的空间。在数据量充足的前提下，对同类型的模型，增大模型规模来提升容限无疑是最直接和有效的手段。但越大的参数模型优化也会越难，所以需要在合理的范围内对模型进行参数规模的修改。而不同类型的模型，在不同数据上的优化成本都可能不一样，所以在探索模型时需要尽可能挑选优化简单，训练效率更高的模型进行训练。</p>
<h3 id="13-15-3-调参优化角度">13.15.3 调参优化角度</h3>
<p>如果你知道模型的性能为什么不再提高了，那已经向提升性能跨出了一大步。 超参数调整本身是一个比较大的问题。一般可以包含模型初始化的配置，优化算法的选取、学习率的策略以及如何配置正则和损失函数等等。这里需要提出的是对于同一优化算法，相近参数规模的前提下，不同类型的模型总能表现出不同的性能。这实际上就是模型优化成本。从这个角度的反方向来考虑，同一模型也总能找到一种比较适合的优化算法。所以确定了模型后选择一个适合模型的优化算法也是非常重要的手段。</p>
<h3 id="13-15-4-训练角度">13.15.4 训练角度</h3>
<p>很多时候我们会把优化和训练放一起。但这里我们分开来讲，主要是为了强调充分的训练。在越大规模的数据集或者模型上，诚然一个好的优化算法总能加速收敛。但你在未探索到模型的上限之前，永远不知道训练多久算训练完成。所以在改善模型上充分训练永远是最必要的过程。充分训练的含义不仅仅只是增大训练轮数。有效的学习率衰减和正则同样是充分训练中非常必要的手段。</p>
<h2 id="13-16-如何快速构建有效初始模型？">13.16 如何快速构建有效初始模型？</h2>
<p>​	构建一个有效的初始模型能帮助我们快速了解数据的质量和确定模型构建的方向。构建一个良好的初始模型，一般需要注意如下几点：</p>
<p>​	1、了解&quot;对手&quot;。这里的“对手”通常是指数据，我们在得到数据时，第一步是需要了解数据特点和使用场合。了解数据特点能帮助我们快速定位如何进行建模。确定使用场合能帮助我们进一步确定模型需要优化的方向。数据特点一般需要了解例如数据集规模、训练集和验证集是否匹配、样本的分布是否均匀、数据是否存在缺失值等等。</p>
<p>​	2、站在巨人肩膀上。根据数据特点，我们通常能匹配到一个现有比较优秀的模型。这类模型都通常能在类似数据上表现出一个比较不错的性能。</p>
<p>​	3、一切从简。初始模型的作用在于迅速了解数据质量和特点，所以模型的性能通常不需要达到很高，模型复杂度也不需要很高。例如，做图像分类时，我们在使用预训练模型时，不需要一开始就使用例如ResNet152这类模型巨大，复杂度过高的模型。这在数据量较小时，很容易造成过拟合而导致出现我们对数据产生一些误导性的判断，此外也增加了额外训练构建时间。所以使用更小更简单的模型以及损失函数来试探数据是相比更明智的选择。</p>
<p>​	4、总比瞎猜强。构建模型的意义在于建立一个高效的模型，虽然初始模型我们不对性能做过高的要求。但前提在于必须要比随机猜测好，不然构建模型的意义就不存在了。</p>
<p>​	5、解剖模型。一旦确定了一个初始模型时，无论你对该模型多熟悉，当其面对一批新数据时，你永远需要重新去认识这个模型，因为你永远不确定模型内部到底发生了些什么。解剖模型一般需要在训练时注意误差变化、注意训练和验证集的差异；出现一些NAN或者INf等情况时，需要打印观察内部输出，确定问题出现的时间和位置；在完成训练后，需要测试模型的输出是否正确合理，以确认评价指标是否符合该数据场景。无论使用任何一种模型，我们都不能把它当做黑盒去看待。</p>
<h2 id="13-17-如何通过模型重新观察数据？">13.17 如何通过模型重新观察数据？</h2>
<p>​	对于这个问题，与其说如何做，倒不如说这个问题是用来强调这样做的重要性。如何重新观察数据其实不难，而是很多读者，会忽略这一项过程的重要性。</p>
<p>​	通过模型重新观察数据，不仅能让我们了解模型情况，也能让我们对数据质量产生进一步的理解。目前深度学习在监督学习领域成就是非常显著的。监督学习需要依赖大量的人为标注，人为标注很难确定是否使用的数据中是否存在错误标注或者漏标注等问题。这无论是哪种情况都会影响我们对模型的判断。所以通过模型重新验证数据质量是非常重要的一步。很多初学者，通常会忽略这一点，而导致出现对模型的一些误判，严重时甚至会影响整个建模方向。此外，对于若出现一些过拟合的情况，我们也可以通过观察来了解模型。例如分类任务，样本严重不平衡时，模型全预测到了一边时，其正确率仍然很高，但显然模型已经出现了问题。</p>
<h2 id="13-18-如何解决数据不匹配问题？">13.18 如何解决数据不匹配问题？</h2>
<h3 id="13-18-1-如何定位数据不匹配">13.18.1 如何定位数据不匹配?</h3>
<p>​	数据不匹配问题是个不容易定位和解决的问题。这个问题出现总会和模型过拟合表现很相似,即在训练集上能体现非常不错的性能,但在测试集上表现总是差强人意但区别在于如果遇到是数据不匹配的问题,通常在用一批和训<br>
练集有看相同或者相似分布的数据上仍然能取得不错的结果。但很多时候,当测试集上结果表现很差时,很多初学<br>
者可能会直接将问题定位在模型过拟合上,最后对模型尝试各种方法后,性能却始终不能得到有效提升。当遇到这<br>
种情况时,建议先定位出是否存在数据不匹配的问题。最简单的验证方式就是可以从训练集中挑选出一部分数据作<br>
为验证集,重新划分后训练和验证模型表现。</p>
<h3 id="13-18-2-举例常见几个数据不匹配的场景">13.18.2 举例常见几个数据不匹配的场景?</h3>
<p>​	例如设计款识别物体的app时,实际场景的图片均来自于手机拍摄,而训练集确是来自于网上各类抓取下来的图<br>
片。例如在图像去噪、去模糊、去雾、超分辨率等图像处理场景时,由于大量数据的难以获取,因此都会采用人为<br>
假设合成的图像进行训练,这时候应用到实际场景中也容易出现不匹配的问题</p>
<h3 id="13-18-3-如何解决数据不匹配问题">13.18.3 如何解决数据不匹配问题?</h3>
<p>​	数据不匹配是个很难有固定方法来解决的问题。这里提供几条供参考的途径：<br>
​	1、收集更多符合实际场最需要的数据。这似乎是最简单但也最难方式<br>
​	2、对结果做错误分析。找出数据集中出错的数据和正确数据之间的特点和区别,这对你无论是进行后续模型的分析或者是数据的处理提供非常有效的思路。注意,这里的数据集包括训练集和测试集<br>
​	3、数据集增强。数据集增强并不意味看数据集越大越好,其目的是丰富数据的分布以适应更多的变化当遇到数<br>
据不匹配时,对数据处理般可以有两种方式。其一,合成或处理更多接近需要的数据特点。其二,对所有数据包<br>
括实际场景数据都进行处理,将所有数据都统一到另一个分布上,统一出一种新的特点。</p>
<h3 id="13-18-4-如何提高深度学习系统的性能">13.18.4 如何提高深度学习系统的性能</h3>
<p>​	当我们要试图提高深度学习系统的性能时，目前我们大致可以从三方面考虑：</p>
<p>​	1、提高模型的结构，比如增加神经网络的层数，或者将简单的神经元单位换成复杂的 LSTM 神经元，比如在自然语言处理领域内，利用 LSTM 模型挖掘语法分析的优势。</p>
<p>​	2、改进模型的初始化方式，保证早期梯度具有某些有益的性质，或者具备大量的稀疏性，或者利用线性代数原理的优势。</p>
<p>​	3、选择更强大的学习算法，比如对度梯度更新的方式，也可以是采用除以先前梯度 L2 范数来更新所有参数，甚至还可以选用计算代价较大的二阶算法。</p>
<h2 id="参考文献">参考文献</h2>
<p>[1] 冯宇旭, 李裕梅. 深度学习优化器方法及学习率衰减方式综述[J]. 数据挖掘, 2018, 8(4): 186-200</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lilitom.github.io/2024/03/19/deep_learning/ch15/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/deep_learning/ch15/" class="post-title-link" itemprop="url">异构计算， GPU和框架选型指南面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-24 10:14:09" itemprop="dateModified" datetime="2024-03-24T10:14:09+08:00">2024-03-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>异构计算， GPU和框架选型指南</h1>
<p>深度学习训练和推理的过程中，会涉及到大量的向量(vector)，矩阵(matrix)和张量(tensor)操作，通常需要大量的浮点计算，包括高精度（在训练的时候）和低精度（在推理和部署的时候）。GPU， 作为一种通用可编程的加速器，最初设计是用来进行图形处理和渲染功能，但是从2007年开始，英伟达(NVIDIA)公司提出了第一个可编程通用计算平台（GPU），同时提出了CUDA框架，从此开启了GPU用于通用计算的新纪元。此后，不计其数的科研人员和开发者，对各种不同类型的算法用CUDA进行（部分）改写，从而达到几倍到数百倍的加速效果。尤其是在机器学习，特别是深度学习的浪潮来临后，GPU加速已经是各类工具实现的基本底层构架之一。本章里，会简单介绍GPU的基本架构，性能指标，框架选择等等和深度学习相关的内容。</p>
<h2 id="15-1-什么是异构计算？">15.1 什么是异构计算？</h2>
<p>异构计算是基于一个更加朴素的概念，”异构现象“，也就是不同计算平台之间，由于硬件结构（包括计算核心和内存），指令集和底层软件实现等方面的不同而有着不同的特性。异构计算就是使用结合了两个或者多个不同的计算平台，并进行协同运算。比如，比较常见的，在深度学习和机器学习中已经比较成熟的架构：CPU和GPU的异构计算;此外还有比较新的Google推出的协处理器（TPU），根据目的而定制的ASIC，可编程的FPGA等也都是现在在异构计算中使用比较多的协处理器。而，本章中会着重介绍和深度学习共同繁荣的图形加算器，也就是常说的GPU。</p>
<h2 id="15-2-什么是GPU？">15.2 什么是GPU？</h2>
<p>GPU,就如名字所包含的内容，原本开发的目的是为了进行计算机图形渲染，而减少对于CPU的负载。由于图像的原始特性，也就是像素间的独立性，所以GPU在设计的时候就遵从了“单指令流多数据流（SIMD）”架构，使得同一个指令（比如图像的某种变换），可以同时在多一个像素点上进行计算，从而得到比较大的吞吐量，才能使得计算机可以实时渲染比较复杂的2D/3D场景。在最初的应用场景里，GPU并不是作为一种通用计算平台出现的，直到2007年左右，一家伟大的公司将GPU带到通用计算的世界里，使得其可以在相对比较友好的编程环境（CUDA/OpenCL）里加速通用程序成了可能。从此之后，GPU通用计算，也就是GPU就成了学界和工业界都频繁使用的技术，在深度学习爆发的年代里，GPU成了推动这股浪潮非常重要的力量。</p>
<h2 id="15-3-GPU架构简介">15.3 GPU架构简介</h2>
<p>GPU，图形显示芯片作为不同于CPU的设计逻辑和应用场景，有着非常不同的架构，本部分将简单介绍GPU究竟是如何架构，其中的计算核心有哪些特性。</p>
<h3 id="15-3-1-如何通俗理解GPU的架构？">15.3.1 如何通俗理解GPU的架构？</h3>
<p>首先，下图简单地展示了几个GPU不同于CPU的特性：</p>
<ul>
<li>计算核心： 图中的CPU,i7-5960，Intel的第五代Broadwell架构，其中包括了8个CPU核心(支持16线程)，也就是理论上可以有16个不同的运算同时进行。除了8个核心计算单元，大部分的芯片面积是被3级缓存，内存和控制电路占据了。同样的，来自Nvidia的GTX980GPU，在差不多的芯片面积上，大部分是计算单元，16个SM，也就是流处理单元，每个流处理单元中包含着128个CUDA计算核心，所以总共来说，有2048个GPU运算单元，相应地这颗GPU理论上可以在一个时钟周期内可以进行2048次单精度运算。</li>
</ul>
<p><img src="cpu_gpu.png" alt="CPU和GPU的简单架构对比图"></p>
<ul>
<li>计算核心频率：时钟频率，代表每一秒中内能进行同步脉冲次数，也是从一个侧面反映一个计算元件的工作速度。下图中对比了个别早期产品，比如Intel的x5650和几款Nvidia的GPU。可以看出核心频率而言，CPU要远高于GPU。对于CPU而言，在不考虑能源消耗和制程工艺限制的情况下，追求更高的主频。但，在GPU的设计中，采用了多核心设计，即使是提高一些频率，其实对于总体性能影像不会特别大。当然，其中还有能耗方面的考虑，避免发热过高，也进行了权衡。还有一个可能的原因是，在一个流处理器中的每个核心（CUDA核心）的运行共享非常有限的缓存和寄存器，由于共享内存也是有性能极限的，所以即使每个GPU核心频率提高，如果被缓存等拖累也是无法展现出高性能的。</li>
</ul>
<p><img src="cpu_specs.png" alt="CPU简单信息"></p>
<p><img src="gpu_specs.png" alt="GPU的简单信息对比"></p>
<ul>
<li>内存架构：GPU的多层内存架构包括全局内存（也就是通常意义上大部分比较关注的内存，在若干到16GB之间，截至到当前最新），2级缓存，和芯片上的存储（包括寄存器，和1级缓存共用的共享内存，只读/纹理缓存和常量缓存）。通常来说，最高速的共享内存/缓存和寄存器都是非常有限的，比如在Tesla的K20中，只有48K的缓存可以作为共享内存或者1级缓存使用，所以在很多用GPU加速算法实现的过程中，有效地利用这些高速缓存是使得性能提升的非常重要的方面。</li>
</ul>
<p><img src="gpu_memory_arch.png" alt="GPU的简单信息对比"></p>
<p><img src="gpu_memory.png" alt="GPU的内存架构容量信息"></p>
<h3 id="15-3-2-CUDA-核心是什么？">15.3.2 CUDA 核心是什么？</h3>
<p>上面提到在一个GPU芯片里，会很几千个CUDA核心，被分布在多个流处理单元（SM）中，比如上面提到早期的GTX980中的16个SM中各包含了128个CUDA核心。如下图所示，作为GPU架构中的最小单元，其实它的设计和CPU有着非常类似的结构，其中包括了一个浮点运算单元和整型运算单元，和控制单元。同一个流处理器中，所有的CUDA核心将同步执行同一个指令，但是作用于不同的数据点上。</p>
<p><img src="cudacore.jpg" alt="CUDA简单介绍"></p>
<p>一般来说，更加多的CUDA核心意味着有更多的并行执行单元，所以也就可以片面地认为是有更加高的性能。但是，其实这个也是取决于很多方面，最重要的是算法在并行实现的时候有没有高效地调度和内存的使用优化。在现在我们使用的大部分GPU加速的深度学习框架里，包括Tensorflow，PyTorch等都是依赖于底层的GPU的矩阵加速代码的实现。为此Nvidia公司也是制定和实现了统一的接口，比如cuDNN，方便上层框架更好的利用GPU的性能。</p>
<h3 id="15-3-3-为什么要使用GPU？">15.3.3 为什么要使用GPU？</h3>
<p>对于并行计算来说，可以非常粗略地分为：</p>
<ul>
<li>并行指令： 也就是多个指令可以同时分配到不同的计算核心上同时进行，而他们的操作是不同的，并且他们之间相互独立，不需要额外的同步和信息共享。</li>
<li>并行数据流： 如果数据本身存在的天然的独立性，比如图像中的每一个像素，那么在对这个图像做处理的过程中，同一个指令可以同时作用于每一个像素。在这种情况下，这个对于完整图像的操作可以并行化。理论上，如果内存不是问题，并且计算单元的数量大于整个图像中总像素点的话，这个操作可以在一个时钟周期内完成。</li>
</ul>
<p>GPU整体的架构而言，某种意义上是同时支持以上两种并行模式。在同一个流处理器中，采用了“单一指令并行数据流的模式”，而在多个流处理器中，同一时间可以派发不同的指令。从这一点出发，GPU芯片算是一个非常灵活的架构。一个芯片中，流处理器的个数和其中包含的CUDA核心的数量也是一种面向应用设计时候找到的一个平衡点。</p>
<p>基于深度学习中大部分的操作的天然并行性（大量的矩阵操作），GPU在当下还是一种非常适合的计算平台。一个非常典型的例子就是常见的矩阵相乘（如下图），要计算Z = X×Y，通过并行计算，X和Y中的行向量和列向量的逐元素相乘就可以同时进行，只要得到结果后再进行累加，而且累加的过程中也是可以进行并行化，使得效率有非常大的提高。Nvidia也是制定和开发了一套底层类库，CUBlas方便开发者。我们熟悉的几大框架(e.g. Tensorflow, PyTorch等)也是遵循和使用了这些并行类库，所以才使得训练和部署性能有了非常多的提高。</p>
<p><img src="mat_mul_gpu.png" alt="CUDA 矩阵乘法示例"></p>
<h3 id="15-3-4-深度学习中的GPU应用">15.3.4 深度学习中的GPU应用</h3>
<p>深度学习在最近几年内出现的井喷现象背后也是GPU的存在和发展作为坚实的推动力量。</p>
<p>哪些场景使用GPU</p>
<p>ImageNet的例子</p>
<h3 id="15-3-5-新图灵架构里的tensor-core对深度学习有什么作用？">15.3.5 新图灵架构里的tensor core对深度学习有什么作用？</h3>
<h2 id="15-4-CUDA-框架">15.4 CUDA 框架</h2>
<h3 id="15-4-1-做CUDA编程难不难？">15.4.1 做CUDA编程难不难？</h3>
<h3 id="15-4-2-cuDNN">15.4.2 cuDNN</h3>
<h2 id="15-5-GPU硬件环境配置推荐">15.5 GPU硬件环境配置推荐</h2>
<h3 id="15-5-1-GPU主要性能指标">15.5.1 GPU主要性能指标</h3>
<p>GPU的性能主要由以下三个参数构成：</p>
<ol>
<li>计算能力。通常我们关心的是32位浮点计算能力。16位浮点训练也开始流行，如果只做预测的话也可以用8位整数。</li>
<li>内存大小。当模型越大，或者训练时的批量越大时，所需要的GPU内存就越多。</li>
<li>内存带宽。只有当内存带宽足够时才能充分发挥计算能力。</li>
</ol>
<p>对于大部分用户来说，只要考虑计算能力就可以了。GPU内存尽量不小于4GB。但如果GPU要同时显示图形界面，那么推荐的内存大小至少为6GB。内存带宽通常相对固定，选择空间较小。</p>
<p>下图描绘了GTX 900和1000系列里各个型号的32位浮点计算能力和价格的对比。其中价格为Wikipedia的建议价格。</p>
<p><img src="gtx.png" alt="浮点计算能力和价格的对比。"></p>
<p>我们可以从图中读出两点信息：</p>
<ol>
<li>在同一个系列里面，价格和性能大体上成正比。但后发布的型号性价比更高，例如980 TI和1080 TI。</li>
<li>GTX 1000系列比900系列在性价比上高出2倍左右。</li>
</ol>
<p>如果大家继续比较GTX较早的系列，也可以发现类似的规律。据此，我们推荐大家在能力范围内尽可能买较新的GPU。</p>
<p>对于RTX系列，新增了Tensor Cores单元及支持FP16，使得显卡的可选择范围更加多元。</p>
<h3 id="15-5-2-购买建议">15.5.2 购买建议</h3>
<p>首先给出一些总体的建议：</p>
<p>性价比高但较贵：RTX 2070，GTX 1080 Ti</p>
<p>性价比高又便宜：RTX 2060，GTX 1060（6GB）</p>
<p>当使用数据集&gt; 250GB：GTX Titan X（Maxwell） ，NVIDIA Titan X Pascal或NVIDIA Titan Xp</p>
<p>没有足够的钱：GTX 1060（6GB）</p>
<p>几乎没有钱，入门级：GTX 1050 Ti（4GB）</p>
<p>做Kaggle比赛：RTX 2070、GTX 1060（6GB）适用于任何“正常”比赛，GTX 1080 Ti（预算足够可以选择RTX 2080 Ti）用于“深度学习竞赛”</p>
<p>计算机视觉研究员：RTX 2080 Ti（涡轮散热或水冷散热较好，方便后期增加新的显卡）如果网络很深可以选择Titan RTX</p>
<p>一名NLP研究人员：RTX 2080 Ti，并使用FP16来训练</p>
<p>搭建一个GPU集群：这个有点复杂，另做探讨。</p>
<p>刚开始进行深度学习研究：从RTX 2060或GTX 1060（6GB）开始，根据你下一步兴趣（入门，Kaggle比赛，研究，应用深度学习）等等，再进行选择。目前，RTX 2060和GTX 1060都比较合适入门的选择。</p>
<p>想尝试下深度学习，但没有过多要求：GTX 1050 ti（4或2GB）</p>
<p>目前独立GPU主要有AMD和Nvidia两家厂商。其中Nvidia在深度学习布局较早，对深度学习框架支持更好。因此，目前大家主要会选择Nvidia的GPU。</p>
<p>Nvidia有面向个人用户（例如GTX系列）和企业用户（例如Tesla系列）的两类GPU。这两类GPU的计算能力相当。然而，面向企业用户的GPU通常使用被动散热并增加了内存校验，从而更适合数据中心，并通常要比面向个人用户的GPU贵上10倍。</p>
<p>如果你是拥有100台机器以上的大公司用户，通常可以考虑针对企业用户的Nvidia Tesla系列。如果你是拥有10到100台机器的实验室和中小公司用户，预算充足的情况下可以考虑Nvidia DGX系列，否则可以考虑购买如Supermicro之类的性价比比较高的服务器，然后再购买安装GTX系列的GPU。</p>
<p>Nvidia一般每一两年发布一次新版本的GPU，例如2017年发布的是GTX 1000系列。每个系列中会有数个不同的型号，分别对应不同的性能。</p>
<h2 id="15-6-软件环境搭建">15.6 软件环境搭建</h2>
<p>深度学习其实就是指基于一套完整的软件系统来构建算法，训练模型。如何搭建一套完整的软件系统，比如操作系统的选择？安装环境中遇到的问题等等，本节做一个简单的总结。</p>
<h3 id="15-6-1-操作系统选择？">15.6.1 操作系统选择？</h3>
<p>针对硬件厂商来说，比如NVIDIA，对各个操作系统的支持都是比较好的 ，比如Windows系列,Linux系列，但是由于Linux系统对专业技术人员比较友好，所以目前几乎所有的深度学习系统构建都是基于Linux的，比较常用的系统如Ubuntu系列，CentOS系列等等。<br>
在构建系统的时候，如何选择合适的操作系是一个刚刚入门深度学习的工作者面临的问题，在这里给出几点建议：<br>
（1）刚刚入门，熟悉Windows系统，但是对Linux和深度学习都不太熟，这个时候可以基于windows系列系统来做入门学习<br>
（2）简单了解Linux的使用，不太懂深度学习相关知识，可以直接基于Linux系统来搭建框架，跑一些开源的项目，慢慢深入研究学习<br>
（3）熟悉Linux，不熟悉深度学习理论，毫无疑问，强烈推荐使用Linux系统，安装软件简单，工作效率高<br>
总之一句话，如果不熟悉Linux，就先慢慢熟悉，最终还是要回归到Linux系统来构建深度学习系统</p>
<h3 id="15-6-2-常用基础软件安装？">15.6.2 常用基础软件安装？</h3>
<p>目前有众多深度学习框架可供大家使用，但是所有框架基本都有一个共同的特点，目前几乎都是基于Nvidia的GPU来训练模型，要想更好的使用Nvidia的GPU，cuda和cudnn就是必备的软件安装。</p>
<ol>
<li>
<p><strong>安装cuda</strong><br>
上文中有关于cuda的介绍，这里只是简单介绍基于Linux系统安装cuda的具体步骤，可以根据自己的需要安装cuda8.0或者cuda9.0，这两种版本的安装步骤基本一致，这里以最常用的ubuntu 16.04 lts版本为例：</p>
<ol>
<li>官网下载，地址<br>
cuda8.0https://developer.nvidia.com/cuda-80-ga2-download-archive<br>
cuda9.0https://developer.nvidia.com/cuda-90-download-archive<br>
进入网址之后选择对应的系统版本即可，如下图所示：<br>
<img src="cuda8.0.png" alt="cuda8.0"></li>
</ol>
<p><img src="cuda9.0.png" alt="cuda9.0"></p>
<ol start="2">
<li>
<p>命令行中进入到cuda所在的位置，授予运行权限：<br>
cuda8.0: sudo chmod +x cuda_8.0.61_375.26_linux.run<br>
cuda9.0:sudo chmod +x cuda_9.0.176_384.81_linux.run</p>
</li>
<li>
<p>执行命令安装cuda：<br>
cuda8.0:sudo sh cuda_8.0.61_375.26_linux.run<br>
cuda9.0:sudo sh cuda_9.0.176_384.81_linux.run<br>
之后命令之后下面就是安装步骤，cuda8.0和cuda9.0几乎一致：</p>
</li>
</ol>
<ul>
<li>
<p>首先出现cuda软件的版权说明，可以直接按q键跳过阅读</p>
</li>
<li>
<p>Do you accept the previously read EULA?<br>
​accept/decline/quit: <strong>accept</strong></p>
</li>
<li>
<p>Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 384.81?<br>
​(y)es/(n)o/(q)uit:<strong>no</strong></p>
</li>
<li>
<p>Install the CUDA 9.0 Toolkit?<br>
​(y)es/(n)o/(q)uit:<strong>yes</strong></p>
</li>
<li>
<p>Enter Toolkit Location<br>
​ [ default is /usr/local/cuda-9.0 ]:直接按enter键即可</p>
</li>
<li>
<p>Do you want to install a symbolic link at /usr/local/cuda?<br>
​(y)es/(n)o/(q)uit:<strong>yes</strong></p>
</li>
<li>
<p>Install the CUDA 9.0 Samples?<br>
​ (y)es/(n)o/(q)uit:<strong>yes</strong></p>
</li>
</ul>
<p>以上步骤基本就是cuda的安装步骤。</p>
</li>
<li>
<p><strong>安装cudnn</strong><br>
cudnn是Nvidia的专门针对深度学习的加速库。。。</p>
</li>
</ol>
<h3 id="15-6-3-本机安装还是使用docker？">15.6.3 本机安装还是使用docker？</h3>
<h3 id="15-6-4-GPU驱动问题">15.6.4 GPU驱动问题</h3>
<h2 id="15-7-框架选择">15.7 框架选择</h2>
<h3 id="15-7-1-主流框架比较">15.7.1 主流框架比较</h3>
<p>（一个大表格比较）</p>
<h3 id="15-7-2-框架详细信息">15.7.2 框架详细信息</h3>
<ul>
<li>
<p>Tensorflow<br>
Tensorflow是Google于2015年开源的基于数据流编程的深度学习框架，得益于Google强大的技术实力和品牌背书，目前Tensorflow发展迅猛，其用户量远远超过其它框架用户。<br>
优点：</p>
<ol>
<li>由谷歌开发、维护，因此可以保障支持、开发的持续性</li>
<li>巨大、活跃的社区</li>
<li>网络训练的低级、高级接口</li>
<li>「TensorBoard」是一款强大的可视化套件，旨在跟踪网络拓扑和性能，使调试更加简单</li>
<li>TensorFlow 不仅支持深度学习，还有支持强化学习和其他算法的工具<br>
缺点：</li>
<li>计算图是纯 Python 的，因此速度较慢</li>
<li>图构造是静态的，意味着图必须先被「编译」再运行</li>
</ol>
</li>
<li>
<p>PyTorch<br>
pytorch是Facebook于2017年才推出的深度学习框架，相对于其它框架，算是比较晚的了，但是这个同时也是优势，在设计的时候就会避免很多之前框架的问题，所以一经推出，就收到大家极大的欢迎<br>
优点：</p>
<ol>
<li>接口简洁且规范，文档齐全，和python无缝结合，</li>
<li>社区非常活跃，开源实现较多</li>
<li>提供动态计算图（意味着图是在运行时生成的），允许你处理可变长度的输入和输出，例如，在使用 RNN 时非常有用</li>
<li>易于编写自己的图层类型，易于在 GPU 上运行</li>
<li>「TensorBoard」缺少一些关键功能时，「Losswise」可以作为 Pytorch 的替代品</li>
</ol>
</li>
</ul>
<p>缺点:</p>
<ol>
<li>模型部署相对其它框架稍有劣势，不过后续的pytorch1.0版本应该会有很大改善，和caffe2合并后，caffe2的优秀的模型部署能力可以弥补这个不足</li>
<li></li>
<li></li>
</ol>
<p>相关资源链接：</p>
<ol>
<li>官网教程：<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/">https://pytorch.org/tutorials/</a></li>
<li>基于pytorch的开源项目汇总：<a target="_blank" rel="noopener" href="https://github.com/bharathgs/Awesome-pytorch-list">https://github.com/bharathgs/Awesome-pytorch-list</a></li>
<li></li>
</ol>
<ul>
<li>
<p>Keras<br>
Keras 是一个更高级、对用户最友好的 API，具有可配置的后端，由 Google Brain 团队成员 Francis Chollet 编写和维护<br>
优点：</p>
<ol>
<li>提供高级 API 来构建深度学习模型，使其易于阅读和使用</li>
<li>编写规范的文档</li>
<li>大型、活跃的社区</li>
<li>位于其他深度学习库（如 Theano 和 TensorFlow，可配置）之上</li>
<li>使用面向对象的设计，因此所有内容都被视为对象（如网络层、参数、优化器等）。所有模型参数都可以作为对象属性进行访问<br>
缺点：</li>
<li>由于用途非常普遍，所以在性能方面比较欠缺</li>
<li>与 TensorFlow 后端配合使用时会出现性能问题（因为并未针对其进行优化），但与 Theano 后端配合使用时效果良好</li>
<li>不像 TensorFlow 或 PyTorch 那样灵活</li>
</ol>
</li>
<li>
<p>Sonnet</p>
</li>
<li>
<p>Caffe<br>
caffe是第一个主流产品级深度学习库，于 2014 年由 UC Berkeley 发布开源<br>
优点：</p>
<ol>
<li>简单网络结构无需编写代码，可快速实现</li>
<li>漂亮的 Matlab 和 Python 接口</li>
<li>完全由c++编程实现，部署方便</li>
</ol>
</li>
</ul>
<p>缺点：</p>
<ol>
<li>不灵活。在 Caffe 中，每个节点被当做一个层，因此如果你想要一种新的层类型，你需要定义完整的前向、后向和梯度更新过程。这些层是网络的构建模块，你需要在无穷无尽的列表中进行选择。（相反，在 TensorFlow 中，每个节点被当做一个张量运算例如矩阵相加、相乘或卷积。你可以轻易地定义一个层作为这些运算的组合。因此 TensorFlow 的构建模块更小巧，允许更灵活的模块化。）</li>
<li>需要大量的非必要冗长代码。如果你希望同时支持 CPU 和 GPU，你需要为每一个实现额外的函数。你还需要使用普通的文本编辑器来定义你的模型。真令人头疼！几乎每个人都希望程序化地定义模型，因为这有利于不同组件之间的模块化。有趣的是，Caffe 的主要架构师现在在 TensorFlow 团队工作</li>
<li>专一性。仅定位在计算机视觉（但做得很不错）</li>
<li>不是以 Python 编写！如果你希望引入新的变动，你需要在 C++和 CUDA 上编程（对于更小的变动，你可以使用它的 Python 和 Matlab 接口）</li>
<li>糟糕的文档</li>
<li>安装比较困难！有大量的依赖包</li>
</ol>
<ul>
<li>
<p>Caffe2</p>
</li>
<li>
<p>MxNet<br>
MxNet是dmlc社区推出的深度学习框架，MXNet由学术界发起，包括数个顶尖大学的多个学科的研究人员的贡献，在2017年被亚马逊指定为官方框架。<br>
mxnet的最知名的优点就是其对多GPU的支持和扩展性强，其优秀的性能使之在工业界占有一席之地，在amazon支持之后，其文档和开发进度明显好很多。除了高可扩展性，MXNet 还提供混合编程模型（命令式和声明式），同时兼容多种编程语言（包括 Python、C ++、R、Scala、Julia、Matlab 和 JavaScript）的代码，目前主要在推python高层接口gluon</p>
</li>
</ul>
<p>优点：</p>
<ol>
<li>多GPU支持好，扩展性强，支持多种编程语言接口，主要是由华人团队开发，中文社区活跃，中文文档资源和课程丰富</li>
<li>针对两大热门领域推出gluoncv和gluonNLP模块，复现经典论文，达到State-of-the-art，接口设计简单，文档齐全，拿来就可以用<br>
缺点:</li>
<li>现在mxnet官方社区主要在推gluon接口，接口稍有混乱，坑较多，入手门槛稍高</li>
<li>偏小众，经典网络和项目的开源实现相对于tensorflow和pytorch还是比较少，很多还是需要自己手动实现<br>
相关资源链接：</li>
<li>官方教程：<a target="_blank" rel="noopener" href="http://mxnet.incubator.apache.org">http://mxnet.incubator.apache.org</a> 提供有快速入门教程和详细文档说明</li>
<li>中文教程：<a target="_blank" rel="noopener" href="http://zh.gluon.ai/">http://zh.gluon.ai/</a> 官方的中文教程，此课程有对应的中文版视频，主要由李沐大神讲课</li>
<li>中文论坛：<a target="_blank" rel="noopener" href="https://discuss.gluon.ai/">https://discuss.gluon.ai/</a> 官方发中文论坛，mxnet的主要作者都在这里，论坛比较活跃，可及时得到作者的回答</li>
<li>基于mxnet的开源项目实现：<a target="_blank" rel="noopener" href="https://github.com/chinakook/Awesome-MXNet%E8%BF%99%E9%87%8C%E4%B8%BB%E8%A6%81%E5%88%97%E4%B8%BE%E4%BA%86mxnet%E5%9C%A8%E5%90%84%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E9%A1%B9%E7%9B%AE%E7%9A%84%E5%BC%80%E6%BA%90%E5%AE%9E%E7%8E%B0">https://github.com/chinakook/Awesome-MXNet这里主要列举了mxnet在各个领域的项目的开源实现</a></li>
</ol>
<ul>
<li>
<p>CNTK</p>
</li>
<li>
<p>PaddlePaddle</p>
</li>
<li>
<p>其他国内自主开发开源框架</p>
</li>
</ul>
<h3 id="15-7-3-哪些框架对于部署环境友好？">15.7.3 哪些框架对于部署环境友好？</h3>
<ul>
<li>
<p>Tensorflow Serving</p>
</li>
<li>
<p>ONNX 标准</p>
</li>
<li>
<p>TensorRT</p>
</li>
<li>
<p>ONNPACK</p>
</li>
<li>
<p>Clipper</p>
</li>
</ul>
<h3 id="15-7-4-移动平台的框架如何选择？">15.7.4 移动平台的框架如何选择？</h3>
<ul>
<li>
<p>Tensorflow Lite</p>
</li>
<li>
<p>Caffe2</p>
</li>
</ul>
<h2 id="15-8-其他">15.8 其他</h2>
<h3 id="15-8-1-多GPU环境的配置">15.8.1 多GPU环境的配置</h3>
<ul>
<li>
<p>Tensorflow</p>
</li>
<li>
<p>PyTorch</p>
</li>
</ul>
<h3 id="15-8-2-是不是可以分布式训练？">15.8.2 是不是可以分布式训练？</h3>
<h3 id="15-8-3-可以在SPARK环境里训练或者部署模型吗？">15.8.3 可以在SPARK环境里训练或者部署模型吗？</h3>
<h3 id="15-8-4-怎么进一步优化性能？">15.8.4 怎么进一步优化性能？</h3>
<ul>
<li>
<p>TVM</p>
</li>
<li>
<p>nGraph</p>
</li>
</ul>
<h3 id="15-8-5-TPU和GPU的区别？">15.8.5 TPU和GPU的区别？</h3>
<h3 id="15-8-6-未来量子计算对于深度学习等AI技术的影响？">15.8.6 未来量子计算对于深度学习等AI技术的影响？</h3>
<hr>
<h2 id="15-1-GPU购买指南">15.1 GPU购买指南</h2>
<p>深度学习训练通常需要大量的计算资源。GPU目前是深度学习最常使用的计算加速硬件。相对于CPU来说，GPU更便宜且计算更加密集。一方面，相同计算能力的GPU的价格一般是CPU价格的十分之一。另一方面，一台服务器通常可以搭载8块或者16块GPU。因此，GPU数量可以看作是衡量一台服务器的深度学习计算能力的一个标准。</p>
<h3 id="15-1-1-如何选择GPU">15.1.1 如何选择GPU</h3>
<h3 id="15-1-2-GPU的主要性能指标">15.1.2 GPU的主要性能指标</h3>
<p>在选择GPU时，首先要考虑的第一个GPU性能问题是什么呢：是否为cuda核心？时钟速度多大？内存大小多少？<br>
这些都不是，对于深度学习性能而言，最重要的特征是内存带宽（memory bandwidth）。<br>
简而言之：GPU针对内存带宽进行了优化，但同时牺牲了内存访问时间（延迟）。CPU的设计恰恰相反：如果涉及少量内存（例如几个数字相乘（3 * 6 * 9）），CPU可以快速计算，但是对于大量内存（如矩阵乘法（A * B * C）则很慢。由于内存带宽的限制，当涉及大量内存的问题时，GPU快速计算的优势往往会受到限制。当然，GPU和CPU之间还有更复杂的区别，关于为何GPU如此适用于处理深度学习问题，另做探讨。</p>
<p>所以如果你想购买一个快速的GPU，首先要关注的是GPU的带宽（bandwidth）。</p>
<h3 id="15-1-3-整机配置">15.1.3 整机配置</h3>
<p>通常，我们主要用GPU做深度学习训练。因此，不需要购买高端的CPU。至于整机配置，尽量参考网上推荐的中高档的配置就好。不过，考虑到GPU的功耗、散热和体积，我们在整机配置上也需要考虑以下三个额外因素。</p>
<ol>
<li>机箱体积。GPU尺寸较大，通常考虑较大且自带风扇的机箱。</li>
<li>电源。购买GPU时需要查一下GPU的功耗，例如50W到300W不等。购买电源要确保功率足够，且不会过载机房的供电。</li>
<li>主板的PCIe卡槽。推荐使用PCIe 3.0 16x来保证充足的GPU到主内存的带宽。如果搭载多块GPU，要仔细阅读主板说明，以确保多块GPU一起使用时仍然是16x带宽。注意，有些主板搭载4块GPU时会降到8x甚至4x带宽。</li>
</ol>
<h3 id="15-1-4-小结">15.1.4 小结</h3>
<ul>
<li>在预算范围之内，尽可能买较新的GPU。</li>
<li>整机配置需要考虑到GPU的功耗、散热和体积。</li>
</ul>
<h2 id="15-2-框架选型">15.2 框架选型</h2>
<p>目前常用的框架有tensorflow,keras,pytorch,mxnet等等，各个框架的优缺点在此简单介绍：</p>
<h3 id="15-2-1-常用框架简介">15.2.1 常用框架简介</h3>
<ol>
<li>
<p>tensorflow：<br>
tensorflow由于有google的强大背书，加上其优秀的分布式设计，丰富的教程资源和论坛，工业部署方便，基本很多人都是从tensorflow入门的<br>
优点：google的强大背书，分布式训练，教程资源丰富，常见问题基本都可以在互联网中找到解决办法，工业部署方便<br>
缺点: 接口混乱，官方文档不够简洁，清晰，</p>
</li>
<li>
<p>keras:<br>
keras是一种高层编程接口，其可以选择不同的后端，比如tensorflow，therao等等<br>
优点：接口简洁，上手快，文档好，资源多<br>
缺点: 封装的太好了导致不理解其技术细节</p>
</li>
<li>
<p>pytorch:<br>
PyTorch是一个开源的Python机器学习库，基于Torch，从官方1.0版本开始已经完美结合caffe2，主要应用于人工智能领域，如自然语言处理。它最初由Facebook的人工智能研究团队开发.<br>
优点：文档清晰，兼容NumPy的张量计算，基于带基自动微分系统的深度神经网络，由Facebook开发维护，常见model都有pytorch复现版<br>
缺点：工业部署稍弱（但是合并caffe2后支持全平台部署）</p>
</li>
<li>
<p>mxnet<br>
mxnet是dmlc社区推出的深度学习框架，在2017年被亚马逊指定为官方框架<br>
优点：支持多种语言，代码设计优秀，省显存，华人团队开发，中文社区活跃，官方复现经典论文推出gluoncv和gluonNLP模块，非常方便，拿来就可以用。<br>
缺点:现在mxnet官方社区主要在推gluon接口，接口稍有混乱，坑较多，入手门槛稍高</p>
</li>
<li>
<p>caffe：<br>
目前很多做深度学习比较早的大厂基本都是在用caffe，因为在2013-2015年基本就是caffe的天下，并且caffe的代码设计很优秀，基本所有代码都被翻了很多遍了，被各种分析，大厂基本都是魔改caffe，基于caffe来进行二次开发，所在目前在很多大厂还是在使用caffe<br>
优点：资源丰富，代码容易理解，部署方便<br>
缺点：入门门槛高，文档较少</p>
</li>
</ol>
<p>框架选型总结:</p>
<ol>
<li>新手入门，首推pytorch，上手快，资源丰富,官方文档写的非常好(<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/">https://pytorch.org/tutorials/</a>)</li>
<li>目前工业部署，tensorflow是首选,资源丰富，并且在分布式训练这一块基本一家独大</li>
<li>mxnet的gluon接口有比较丰富的中文资源（教程：<a target="_blank" rel="noopener" href="http://zh.gluon.ai">zh.gluon.ai</a>，论坛：<a target="_blank" rel="noopener" href="http://discuss.gluon.ai">discuss.gluon.ai</a>）,gluoncv模块（<a target="_blank" rel="noopener" href="https://gluon-cv.mxnet.io">https://gluon-cv.mxnet.io</a>）,gluonNLP模块（<a target="_blank" rel="noopener" href="https://gluon-nlp.mxnet.io">https://gluon-nlp.mxnet.io</a>）</li>
</ol>
<h2 id="15-3-模型部署">15.3 模型部署</h2>
<p>我们一般都是通过python或者其他语言来编码训练模型，然后基于后端来进行部署<br>
一般的框架都有自身的部署框架，比如tensorflow，pytorch，caffe2，mxnet等等<br>
有一些框架是专门做推理部署使用的，比如<br>
(1)tensorRT<br>
(2)TVM<br>
(3)ONNX</p>
<h2 id="相关文献">相关文献</h2>
<p>[1] Aston Zhang, Mu Li, Zachary C. Lipton, and Alex J. Smola. <a target="_blank" rel="noopener" href="https://github.com/d2l-ai/d2l-zh/blob/master/chapter_appendix/buy-gpu.md">《动手学深度学习》附录 购买GPU</a>, 2019.<br>
[2] Tim Dettmers. <a target="_blank" rel="noopener" href="http://timdettmers.com/2019/04/03/which-gpu-for-deep-learning/">Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning</a>, 2019.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lilitom.github.io/2024/03/19/deep_learning/ch14/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/deep_learning/ch14/" class="post-title-link" itemprop="url">超参数调整面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-24 10:14:07" itemprop="dateModified" datetime="2024-03-24T10:14:07+08:00">2024-03-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>超参数调整</h1>
<h2 id="14-1-写在前面">14.1 写在前面</h2>
<p>​	关于训练深度学习模型最难的事情之一是你要处理的参数的数量。无论是从网络本身的层宽（宽度）、层数（深度）、连接方式，还是损失函数的超参数设计和调试，亦或者是学习率、批样本数量、优化器参数等等。这些大量的参数都会有网络模型最终的有效容限直接或者间接的影响。面对如此众多的参数，如果我们要一一对其优化调整，所需的无论是时间、资源都是不切实际。结果证实一些超参数比其它的更为重要，因此认识各个超参数的作用和其可能会造成的影响是深度学习训练中必不可少的一项重要技能。</p>
<p>​	超参数调整可以说是深度学习中理论和实际联系最重要的一个环节。目前，深度学习仍存在很多不可解释的部分，如何设计优化出好的网络可以为深度学习理论的探索提供重要的支持。超参数调整一般分为手动调整和自动优化超参数两种。读者可先浏览思维导图，本章节不会过多阐述所有超参数的详细原理，如果需要了解这部分，您可以翻阅前面的基础章节或者查阅相关文献资料。当然，下面会讲到的一些超参数优化的建议是根据笔者们的实践以及部分文献资料得到认知建议，并不是非常严格且一定有效的，很多研究者可能会很不同意某些的观点或有着不同的直觉，这都是可保留讨论的，因为这很依赖于数据本身情况。</p>
<p><img src="img%5Cch14%5C%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.png" alt></p>
<p>​</p>
<h2 id="14-2-超参数概念">14.2 超参数概念</h2>
<h3 id="14-2-1-什么是超参数，参数和超参数的区别？">14.2.1 什么是超参数，参数和超参数的区别？</h3>
<p>​	区分两者最大的一点就是是否通过数据来进行调整，模型参数通常是有数据来驱动调整，超参数则不需要数据来驱动，而是在训练前或者训练中人为的进行调整的参数。例如卷积核的具体核参数就是指模型参数，这是有数据驱动的。而学习率则是人为来进行调整的超参数。这里需要注意的是，通常情况下卷积核数量、卷积核尺寸这些也是超参数，注意与卷积核的核参数区分。</p>
<h3 id="14-2-2-神经网络中包含哪些超参数？">14.2.2 神经网络中包含哪些超参数？</h3>
<p>通常可以将超参数分为三类：网络参数、优化参数、正则化参数。</p>
<p>​	网络参数：可指网络层与层之间的交互方式（相加、相乘或者串接等）、卷积核数量和卷积核尺寸、网络层数（也称深度）和激活函数等。</p>
<p>​	优化参数：一般指学习率（learning rate）、批样本数量（batch size）、不同优化器的参数以及部分损失函数的可调参数。</p>
<p>​	正则化：权重衰减系数，丢弃比率（dropout）</p>
<h3 id="14-2-3-为什么要进行超参数调优？">14.2.3 为什么要进行超参数调优？</h3>
<p>​	本质上，这是模型优化寻找最优解和正则项之间的关系。网络模型优化调整的目的是为了寻找到全局最优解（或者相比更好的局部最优解），而正则项又希望模型尽量拟合到最优。两者通常情况下，存在一定的对立，但两者的目标是一致的，即最小化期望风险。模型优化希望最小化经验风险，而容易陷入过拟合，正则项用来约束模型复杂度。所以如何平衡两者之间的关系，得到最优或者较优的解就是超参数调整优化的目的。</p>
<h3 id="14-2-4-超参数的重要性顺序">14.2.4 超参数的重要性顺序</h3>
<ul>
<li>
<p>首先， <strong>学习率，损失函数上的可调参数</strong>。在网络参数、优化参数、正则化参数中最重要的超参数可能就是学习率了。学习率直接控制着训练中网络梯度更新的量级，直接影响着模型的<strong>有效容限能力</strong>；损失函数上的可调参数，这些参数通常情况下需要结合实际的损失函数来调整，大部分情况下这些参数也能很直接的影响到模型的的有效容限能力。这些损失一般可分成三类，第一类辅助损失结合常见的损失函数，起到辅助优化特征表达的作用。例如度量学习中的Center loss，通常结合交叉熵损失伴随一个权重完成一些特定的任务。这种情况下一般建议辅助损失值不高于或者不低于交叉熵损失值的两个数量级；第二类，多任务模型的多个损失函数，每个损失函数之间或独立或相关，用于各自任务，这种情况取决于任务之间本身的相关性，目前笔者并没有一个普适的经验由于提供参考；第三类，独立损失函数，这类损失通常会在特定的任务有显著性的效果。例如RetinaNet中的focal loss，其中的参数γ，α，对最终的效果会产生较大的影响。这类损失通常论文中会给出特定的建议值。</p>
</li>
<li>
<p>其次，<strong>批样本数量，动量优化器（Gradient Descent with Momentum）的动量参数<em>β</em></strong>。批样本决定了数量梯度下降的方向。过小的批数量，极端情况下，例如batch size为1，即每个样本都去修正一次梯度方向，样本之间的差异越大越难以收敛。若网络中存在批归一化（batchnorm），batch size过小则更难以收敛，甚至垮掉。这是因为数据样本越少，统计量越不具有代表性，噪声也相应的增加。而过大的batch size，会使得梯度方向基本稳定，容易陷入局部最优解，降低精度。一般参考范围会取在[1:1024]之间，当然这个不是绝对的，需要结合具体场景和样本情况；动量衰减参数<em>β</em>是计算梯度的指数加权平均数，并利用该值来更新参数，设置为 0.9 是一个常见且效果不错的选择；</p>
</li>
<li>
<p>最后，<strong>Adam优化器的超参数、权重衰减系数、丢弃法比率（dropout）和网络参数</strong>。在这里说明下，这些参数重要性放在最后<strong>并不等价于这些参数不重要</strong>。而是表示这些参数在大部分实践中<strong>不建议过多尝试</strong>，例如Adam优化器中的<em>β1，β2，ϵ</em>，常设为 0.9、0.999、10−8就会有不错的表现。权重衰减系数通常会有个建议值，例如0.0005 ，使用建议值即可，不必过多尝试。dropout通常会在全连接层之间使用防止过拟合，建议比率控制在[0.2,0.5]之间。使用dropout时需要特别注意两点：一、在RNN中，如果直接放在memory cell中,循环会放大噪声，扰乱学习。一般会建议放在输入和输出层；二、不建议dropout后直接跟上batchnorm，dropout很可能影响batchnorm计算统计量，导致方差偏移，这种情况下会使得推理阶段出现模型完全垮掉的极端情况；网络参数通常也属于超参数的范围内，通常情况下增加网络层数能增加模型的容限能力，但模型真正有效的容限能力还和样本数量和质量、层之间的关系等有关，所以一般情况下会选择先固定网络层数，调优到一定阶段或者有大量的硬件资源支持可以在网络深度上进行进一步调整。</p>
</li>
</ul>
<h3 id="14-2-5-部分超参数如何影响模型性能？">14.2.5 部分超参数如何影响模型性能？</h3>
<table>
<thead>
<tr>
<th style="text-align:center">超参数</th>
<th style="text-align:center">如何影响模型容量</th>
<th style="text-align:center">原因</th>
<th style="text-align:center">注意事项</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">学习率</td>
<td style="text-align:center">调至最优，提升有效容量</td>
<td style="text-align:center">过高或者过低的学习率，都会由于优化失败而导致降低模型有效容限</td>
<td style="text-align:center">学习率最优点，在训练的不同时间点都可能变化，所以需要一套有效的学习率衰减策略</td>
</tr>
<tr>
<td style="text-align:center">损失函数部分超参数</td>
<td style="text-align:center">调至最优，提升有效容量</td>
<td style="text-align:center">损失函数超参数大部分情况都会可能影响优化，不合适的超参数会使即便是对目标优化非常合适的损失函数同样难以优化模型，降低模型有效容限。</td>
<td style="text-align:center">对于部分损失函数超参数其变化会对结果十分敏感，而有些则并不会太影响。在调整时，建议参考论文的推荐值，并在该推荐值数量级上进行最大最小值调试该参数对结果的影响。</td>
</tr>
<tr>
<td style="text-align:center">批样本数量</td>
<td style="text-align:center">过大过小，容易降低有效容量</td>
<td style="text-align:center">大部分情况下，选择适合自身硬件容量的批样本数量，并不会对模型容限造成。</td>
<td style="text-align:center">在一些特殊的目标函数的设计中，如何选择样本是很可能影响到模型的有效容限的，例如度量学习（metric learning）中的N-pair loss。这类损失因为需要样本的多样性，可能会依赖于批样本数量。</td>
</tr>
<tr>
<td style="text-align:center">丢弃法</td>
<td style="text-align:center">比率降低会提升模型的容量</td>
<td style="text-align:center">较少的丢弃参数意味着模型参数量的提升，参数间适应性提升，模型容量提升，但不一定能提升模型有效容限</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">权重衰减系数</td>
<td style="text-align:center">调至最优，提升有效容量</td>
<td style="text-align:center">权重衰减可以有效的起到限制参数变化的幅度，起到一定的正则作用</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">优化器动量</td>
<td style="text-align:center">调至最优，可能提升有效容量</td>
<td style="text-align:center">动量参数通常用来加快训练，同时更容易跳出极值点，避免陷入局部最优解。</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">模型深度</td>
<td style="text-align:center">同条件下，深度增加，模型容量提升</td>
<td style="text-align:center">同条件，下增加深度意味着模型具有更多的参数，更强的拟合能力。</td>
<td style="text-align:center">同条件下，深度越深意味着参数越多，需要的时间和硬件资源也越高。</td>
</tr>
<tr>
<td style="text-align:center">卷积核尺寸</td>
<td style="text-align:center">尺寸增加，模型容量提升</td>
<td style="text-align:center">增加卷积核尺寸意味着参数量的增加，同条件下，模型参数也相应的增加。</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<h3 id="14-2-6-部分超参数合适的范围">14.2.6 部分超参数合适的范围</h3>
<table>
<thead>
<tr>
<th style="text-align:center">超参数</th>
<th style="text-align:center">建议范围</th>
<th style="text-align:center">注意事项</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">初始学习率</td>
<td style="text-align:center">SGD: [1e-2, 1e-1]<br>momentum: [1e-3, 1e-2]<br>Adagrad: [1e-3, 1e-2]<br>Adadelta: [1e-2, 1e-1]<br>RMSprop: [1e-3, 1e-2]<br>Adam: [1e-3, 1e-2]<br>Adamax: [1e-3, 1e-2]<br>Nadam: [1e-3, 1e-2]</td>
<td style="text-align:center">这些范围通常是指从头开始训练的情况。若是微调，初始学习率可在降低一到两个数量级。</td>
</tr>
<tr>
<td style="text-align:center">损失函数部分超参数</td>
<td style="text-align:center">多个损失函数之间，损失值之间尽量相近，不建议超过或者低于两个数量级</td>
<td style="text-align:center">这是指多个损失组合的情况，不一定完全正确。单个损失超参数需结合实际情况。</td>
</tr>
<tr>
<td style="text-align:center">批样本数量</td>
<td style="text-align:center">[1:1024]</td>
<td style="text-align:center">当批样本数量过大(大于6000)或者等于1时，需要注意学习策略或者内部归一化方式的调整。</td>
</tr>
<tr>
<td style="text-align:center">丢弃法比率</td>
<td style="text-align:center">[0, 0.5]</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">权重衰减系数</td>
<td style="text-align:center">[0, 1e-4]</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">卷积核尺寸</td>
<td style="text-align:center">[7x7],[5x5],[3x3],[1x1], [7x1,1x7]</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<h2 id="14-3-网络训练中的超参调整策略">14.3 网络训练中的超参调整策略</h2>
<h3 id="14-3-1-如何调试模型？">14.3.1 如何调试模型？</h3>
<p>在讨论如何调试模型之前，我们先来纠正一个误区。通常理解如何调试模型的时候，我们想到一系列优秀的神经网络模型以及调试技巧。但这里需要指出的是数据才是模型的根本，如果有一批质量优秀的数据，或者说你能将数据质量处理的很好的时候，往往比挑选或者设计模型的收益来的更大。那在这之后才是模型的设计和挑选以及训练技巧上的事情。</p>
<p>1、探索和清洗数据。探索数据集是设计算法之前最为重要的一步，以图像分类为例，我们需要重点知道给定的数据集样本类别和各类别样本数量是否平衡，图像之间是否存在跨域问题（例如网上爬取的图像通常质量各异，存在噪声）。若是类别数远远超过类别样本数（比如类别10000，每个类别却只有10张图像），那通常的方法可能效果并不显著，这时候few-shot learning或者对数据集做进一步增强可能是你比较不错的选择。再如目标检测，待检测目标在数据集中的尺度范围是对检测器的性能有很大影响的部分。因此重点是检测大目标还是小目标、目标是否密集完全取决于数据集本身。所以，探索和进一步清洗数据集一直都是深度学习中最重要的一步。这是很多新手通常会忽略的一点。</p>
<p>2、探索模型结果。探索模型的结果，通常是需要对模型在验证集上的性能进行进一步的分析，这是如何进一步提升模型性能很重要的步骤。将模型在训练集和验证集都进行结果的验证和可视化，可直观的分析出模型是否存在较大偏差以及结果的正确性。以图像分类为例，若类别间样本数量很不平衡时，我们需要重点关注少样本类别在验证集的结果是否和训练集的出入较大，对出错类别可进一步进行模型数值分析以及可视化结果分析，进一步确认模型的行为。</p>
<p>3、监控训练和验证误差。首先很多情况下，我们忽略代码的规范性和算法撰写正确性验证，这点上容易产生致命的影响。在训练和验证都存在问题时，首先请确认自己的代码是否正确。其次，根据训练和验证误差进一步追踪模型的拟合状态。若训练数据集很小，此时监控误差则显得格外重要。确定了模型的拟合状态对进一步调整学习率的策略的选择或者其他有效超参数的选择则会更得心应手。</p>
<p>4、反向传播数值的计算，这种情况通常适合自己设计一个新操作的情况。目前大部分流行框架都已包含自动求导部分，但并不一定是完全符合你的要求的。验证求导是否正确的方式是比较自动求导的结果和有限差分计算结果是否一致。所谓有限差分即导数的定义，使用一个极小的值近似导数。</p>
 $$
f^{'}(x_0) = \lim_{n\rightarrow0}\frac{\Delta y}{\Delta x} = \lim_{n\rightarrow0}\frac{f(x_0+\Delta x -f(x_0))}{\Delta x}
$$ 
<h3 id="14-3-2-为什么要做学习率调整">14.3.2 为什么要做学习率调整?</h3>
<p>​	学习率可以说是模型训练最为重要的超参数。通常情况下，一个或者一组优秀的学习率既能加速模型的训练，又能得到一个较优甚至最优的精度。过大或者过小的学习率会直接影响到模型的收敛。我们知道，当模型训练到一定程度的时候，损失将不再减少，这时候模型的一阶梯度接近零，对应Hessian 矩阵通常是两种情况，一、正定，即所有特征值均为正，此时通常可以得到一个局部极小值，若这个局部极小值接近全局最小则模型已经能得到不错的性能了，但若差距很大，则模型性能还有待于提升，通常情况下后者在训练初最常见。二，特征值有正有负，此时模型很可能陷入了鞍点，若陷入鞍点，模型性能表现就很差。以上两种情况在训练初期以及中期，此时若仍然以固定的学习率，会使模型陷入左右来回的震荡或者鞍点，无法继续优化。所以，学习率衰减或者增大能帮助模型有效的减少震荡或者逃离鞍点。</p>
<h3 id="14-3-3-学习率调整策略有哪些？">14.3.3 学习率调整策略有哪些？</h3>
<p>通常情况下，大部分学习率调整策略都是衰减学习率，但有时若增大学习率也同样起到奇效。这里结合TensorFlow的内置方法来举例。</p>
<p>1、<strong>exponential_decay</strong>和<strong>natural_exp_decay</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">exponential_decay(learning_rate, global_step, decay_steps, decay_rate,</span><br><span class="line">                   staircase=<span class="literal">False</span>, name=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">natural_exp_decay(learning_rate, global_step, decay_steps, decay_rate,</span><br><span class="line">                   staircase=<span class="literal">False</span>, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>指数衰减是最常用的衰减方式，这种方式简单直接，在训练初期衰减较大利于收敛，在后期衰减较小利于精调。以上两种均为指数衰减，区别在于后者使用以自然指数下降。</p>
<p><img src="img%5Cch14%5C%E6%8C%87%E6%95%B0%E8%A1%B0%E5%87%8F.jpeg" alt="./"></p>
<p>2、<strong>piecewise_constant</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">piecewise_constant(x, boundaries, values, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>分段设置学习率法，跟指数型类似，区别在于每个阶段的衰减并不是按指数调整。可在不同阶段设置手动不同的学习率。这种学习率重点在有利于精调。</p>
<p>3、<strong>polynomial_decay</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">polynomial_decay(learning_rate, global_step, decay_steps,</span><br><span class="line">                  end_learning_rate=<span class="number">0.0001</span>, power=<span class="number">1.0</span>,</span><br><span class="line">                  cycle=<span class="literal">False</span>, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>多项式衰减，计算如下：</p>
 $$
global setp = min(global step, decay steps)
$$ 
 $$
lr_{decayed} = (lr-lr_{end})*(1-{globalstep\over decaysteps})^{power} +lr_{end}
$$ 
<p>有别于上述两种，多项式衰减则是在每一步迭代上都会调整学习率。主要看Power参数，若Power为1，则是下图中的红色直线；若power小于1，则是开1/power次方，为蓝色线；绿色线为指数，power大于1。</p>
<p><img src="img%5Cch14%5C%E5%A4%9A%E9%A1%B9%E5%BC%8F%E8%A1%B0%E5%87%8F.jpeg" alt></p>
<p>此外，需要注意的是参数cycle，cycle对应的是一种周期循环调整的方式。这种cycle策略主要目的在后期防止在一个局部极小值震荡，若跳出该区域或许能得到更有的结果。这里说明cycle的方式不止可以在多项式中应用，可配合类似的周期函数进行衰减，如下图。</p>
<p><img src="img%5Cch14%5Ccycle%E8%A1%B0%E5%87%8F.jpeg" alt></p>
<p>4、<strong>inverse_time_decay</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">inverse_time_decay(learning_rate, global_step, decay_steps, decay_rate,</span><br><span class="line">                   staircase=<span class="literal">False</span>, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>逆时衰减，这种方式和指数型类似。如图，<img src="img%5Cch14%5C%E9%80%86%E6%97%B6%E8%A1%B0%E5%87%8F.jpeg" alt></p>
<p>5、<strong>cosine_decay</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cosine_decay(learning_rate, global_step, decay_steps, alpha=<span class="number">0.0</span>,</span><br><span class="line">                 name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>余弦衰减，即按余弦函数的方式衰减学习率，如图</p>
<p><img src="img%5Cch14%5C%E4%BD%99%E5%BC%A6%E8%A1%B0%E5%87%8F.jpeg" alt></p>
<p>6、<strong>cosine_decay_restarts</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cosine_decay_restarts(learning_rate, global_step, first_decay_steps,</span><br><span class="line">                           t_mul=<span class="number">2.0</span>, m_mul=<span class="number">1.0</span>, alpha=<span class="number">0.0</span>, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>余弦衰减，即余弦版本的cycle策略，作用与多项式衰减中的cycle相同。区别在于余弦重启衰减会重新回到初始学习率，拉长周期，而多项式版本则会逐周期衰减。</p>
<p><img src="img%5Cch14%5C%E4%BD%99%E5%BC%A6cycle%E8%A1%B0%E5%87%8F.jpeg" alt></p>
<p>7、<strong>linear_cosine_decay</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">linear_cosine_decay(learning_rate, global_step, decay_steps,</span><br><span class="line">                        num_periods=<span class="number">0.5</span>, alpha=<span class="number">0.0</span>, beta=<span class="number">0.001</span>,</span><br><span class="line">                        name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>线性余弦衰减，主要应用于增强学习领域。</p>
<p><img src="img%5Cch14%5C%E7%BA%BF%E6%80%A7%E4%BD%99%E5%BC%A6%E8%A1%B0%E5%87%8F.jpeg" alt></p>
<p>8、<strong>noisy_linear_cosine_decay</strong></p>
<p>噪声线性余弦衰减，即在线性余弦衰减中加入随机噪声，增大寻优的随机性。</p>
<p><img src="img%5Cch14%5C%E5%99%AA%E5%A3%B0%E7%BA%BF%E6%80%A7%E4%BD%99%E5%BC%A6%E8%A1%B0%E5%87%8F.jpeg" alt></p>
<h3 id="14-3-4-极端批样本数量下，如何训练网络？">14.3.4 极端批样本数量下，如何训练网络？</h3>
<p>​	极端批样本情况一般是指batch size为1或者batch size在6000以上的情况。这两种情况，在使用不合理的情况下都会导致模型最终性能无法达到最优甚至是崩溃的情况。</p>
<p>​	在目标检测、分割或者3D图像等输入图像尺寸较大的场景，通常batch size 会非常小。而在14.2.4中，我们已经讲到这种情况会导致梯度的不稳定以及batchnorm统计的不准确。针对梯度不稳定的问题，通常不会太致命，若训练中发现梯度不稳定导致性能的严重降低时可采用累计梯度的策略，即每次计算完不反向更新，而是累计多次的误差后进行一次更新，这是一种在内存有限情况下实现有效梯度更新的一个策略。batch size过小通常对batchnorm的影响是最大的，若网络模型中存在batchnorm，batch size若只为1或者2时会对训练结果产生非常大的影响。这时通常有两种策略，一、若模型使用了预训练网络，可冻结预训练网络中batchnorm的模型参数，有效降低batch size引起的统计量变化的影响。二、在网络不是过深或者过于复杂时可直接移除batchnorm或者使用groupnorm代替batchnorm，前者不多阐释，后者是有FAIR提出的一种用于减少batch对batchnorm影响，其主要策略是先将特征在通道上进行分组，然后在组内进行归一化。即归一化操作上完全与batch size无关。这种groupnorm的策略被证实在极小批量网络训练上能达到较优秀的性能。当然这里也引入里group这个超参数，一般情况下建议不宜取group为1或者各通道单独为组的group数量，可结合实际网络稍加调试。</p>
<p>​	为了降低训练时间的成本，多机多卡的分布式系统通常会使用超大的batch size进行网络训练。同样的在14.2.4中，我们提到了超大batch size会带来梯度方向过于一致而导致的精度大幅度降低的问题。这时通常可采用层自适应速率缩放（LARS）算法。从理论认知上将，batch size增大会减少反向传播的梯度更新次数，但为了达到相同的模型效果，需要增大学习率。但学习率一旦增大，又会引起模型的不收敛。为了解决这一矛盾，LARS算法就在各层上自适应的计算一个本地学习率用于更新本层的参数，这样能有效的提升训练的稳定性。目前利用LARS算法，腾讯公司使用65536的超大batch size能将ResNet50在ImageNet在4分钟完成训练，而谷歌使用32768的batch size使用TPU能将该时间缩短至2分钟。</p>
<h2 id="14-4-合理使用预训练网络">14.4 合理使用预训练网络</h2>
<h3 id="14-4-1-什么是微调（fine-tune）">14.4.1 什么是微调（fine-tune）</h3>
<p>​	微调（fine-tune），顾名思义指稍微调整参数即可得到优秀的性能，是迁移学习的一种实现方式。微调和从头训练（train from scratch）的本质区别在于模型参数的初始化，train from scratch通常指对网络各类参数进行随机初始化（当然随机初始化也存在一定技巧），随机初始化模型通常不具有任何预测能力，通常需要大量的数据或者特定域的数据进行从零开始的训练，这样需要训练到优秀的模型通常是稍困难的。而微调的网络，网络各类参数已经在其他数据集（例如ImageNet数据集）完成较好调整的，具备了较优秀的表达能力。因此，我们只需要以较小的学习速率在自己所需的数据集领域进行学习即可得到较为优秀的模型。微调通常情况下，无须再重新设计网络结构，预训练模型提供了优秀的结构，只需稍微修改部分层即可。在小数据集上，通常微调的效果比从头训练要好很多，原因在于数据量较小的前提下，训练更多参数容易导致过度拟合。</p>
<h3 id="14-4-2-微调有哪些不同方法？">14.4.2 微调有哪些不同方法？</h3>
<p>​	以图像分类为例，通常情况下由于不同数据集需要的类别数不同，我们需要修改网络的输出顶层。这种情况下有两种微调方式：</p>
<ul>
<li>
<p>不冻结网络模型的任何层，对最后的改动层使用较大的学习率，对未改动层以较小的学习率进行训练全模型训练，进行多轮训练即可。即一步完成训练。</p>
</li>
<li>
<p>冻结除了顶部改动层以外的所有层参数，即不对冻结部分的层进行参数训练更新，进行若干轮的微调训练后，放开顶部层以下的若干层或者全部放开所有层的参数，再次进行若干轮训练即可。即分多步训练。</p>
<p>以上两种都属于微调。目前由于存在大量优秀的预训练模型，如何确定哪个模型适合自己的任务并能得到最佳性能需要花大量的时间探索。此时，上述的前者是种不错训练方式，你无须进行过多分步的操作。而当探索到一个比较适合的模型时，你不妨可以再次重新尝试下以第二种方式进行训练，或许能得到相比于前者稍高些的性能，因为小数据集上调整过多的参数过拟合的机率也会增大，当然这并不是绝对的。</p>
</li>
</ul>
<h3 id="14-4-3-微调先冻结底层，训练顶层的原因？">14.4.3 微调先冻结底层，训练顶层的原因？</h3>
<p>​	14.12中第二种冻结多步训练的方式。首先冻结除了顶部改动层以外的所有层参数，对顶层进行训练，这个过程可以理解为顶层的域适应训练，主要用来训练适应模型的现有特征空间，防止顶层糟糕的初始化，对已经具备一定表达能力的层的干扰和破坏，影响最终的性能。之后，在很多深度学习框架教程中会使用放开顶层往下一半的层数，继续进行微调。这样的好处在于越底层的特征通常是越通用的特征，越往上其整体的高层次语义越完备，这通过感受野很容易理解。所以，若预训练模型的数据和微调训练的数据语义差异越大（例如ImageNet的预模型用于医学图像的训练），那越往顶层的特征语义差异就越大，因此通常也需要进行相应的调整。</p>
<h3 id="14-4-4-不同的数据集特性下如何微调？">14.4.4 不同的数据集特性下如何微调？</h3>
<ul>
<li>数据集数据量少，数据和原数据集类似。这是通常做法只需修改最后的输出层，训练即可，训练过多参数容易过拟合。</li>
<li>数据集数据量少，数据和原数据集差异较大。由于数据差异较大，可以在完成输出顶层的微调后，微调顶层往下一半的层数，进行微调。</li>
<li>数据集数据量大，数据与原数据集差异较大。这种情况下，通常已经不需要用预训练模型进行微调，通常直接重新训练即可。</li>
<li>数据集数据量大，数据与原数据类似。这时预训练模型的参数是个很好的初始化，可利用预训练模型放开所有层以较小的学习率微调即可。</li>
</ul>
<h3 id="14-4-4-目标检测中使用预训练模型的优劣？">14.4.4 目标检测中使用预训练模型的优劣？</h3>
<p>​	目标检测中无论是一阶段的YOLO、SSD或者RetinaNet 还是二阶段的Faster R-CNN、R-FCN 和 FPN都是基于ImageNet上预训练好的分类模型。</p>
<p>​	优势在于：</p>
<p>​	1、正如大部分微调的情况一样，使用预训练网络已拥有优秀的语义特征，能有效的加快训练速度；</p>
<p>​	2、其次，对于大部分二阶段的模型来说，并未实现严格意义上的完全端对端的训练，所以使用预训练模型能直接提取到语义特征，能使两个阶段的网络更容易实现模型的优化。</p>
<p>​	劣势在于，分类模型和检测模型之间仍然存在一定任务上的差异：</p>
<p>​	1、分类模型大部分训练于单目标数据，对同时进行多目标的捕捉能力稍弱，且不关注目标的位置，在一定程度上让模型损失部分空间信息，这对检测模型通常是不利的；</p>
<p>​	2、域适应问题，若预训练模型（ImageNet）和实际检测器的使用场景（医学图像，卫星图像）差异较大时，性能会受到影响；</p>
<p>​	3、使用预训练模型就意味着难以自由改变网络结构和参数限制了应用场合。</p>
<h3 id="14-4-5-目标检测中如何从零开始训练-train-from-scratch-？">14.4.5 目标检测中如何从零开始训练(train from scratch)？</h3>
<p>​	结合FAIR相关的研究，我们可以了解目标检测和其他任务从零训练模型一样，只要拥有足够的数据以及充分而有效的训练，同样能训练出不亚于利用预训练模型的检测器。这里我们提供如下几点建议：</p>
<p>​	1、数据集不大时，同样需要进行数据集增强。</p>
<p>​	2、预训练模型拥有更好的初始化，train from scratch需要更多的迭代次数以及时间训练和优化检测器。而二阶段模型由于并不是严格的端对端训练，此时可能需要更多的迭代次数以及时间，而一阶段检测模型训练会相对更容易些（例如DSOD以ScratchDet及）。</p>
<p>​	3、目标检测中train from scratch最大的问题还是batch size过小。所以可采取的策略是增加GPU使用异步batchnorm增大batch size，若条件限制无法使用更多GPU时，可使用groupnorm代替batchnorm</p>
<p>​	4、由于分类模型存在对多目标的捕捉能力弱以及对物体空间位置信息不敏感等问题，可借鉴DetNet训练一个专属于目标检测的模型网络，增强对多目标、尺度和位置拥有更强的适应性。</p>
<h2 id="14-5-如何改善-GAN-的性能">14.5 如何改善 GAN 的性能</h2>
<p>优化GAN性能通常需要在如下几个方面进行</p>
<ul>
<li>设计或选择更适合目的代价函数。</li>
<li>添加额外的惩罚。</li>
<li>避免判别器过度自信和生成器过度拟合。</li>
<li>更好的优化模型的方法。</li>
<li>添加标签明确优化目标。</li>
</ul>
<p>GAN常用训练技巧</p>
<ul>
<li>
<p>输入规范化到（-1，1）之间，最后一层的激活函数使用tanh（BEGAN除外）</p>
</li>
<li>
<p>使用wassertein GAN的损失函数，</p>
</li>
<li>
<p>如果有标签数据的话，尽量使用标签，也有人提出使用反转标签效果很好，另外使用标签平滑，单边标签平滑或者双边标签平滑</p>
</li>
<li>
<p>使用mini-batch norm， 如果不用batch norm 可以使用instance norm 或者weight norm</p>
</li>
<li>
<p>避免使用RELU和pooling层，减少稀疏梯度的可能性，可以使用leakrelu激活函数</p>
</li>
<li>
<p>优化器尽量选择ADAM，学习率不要设置太大，初始1e-4可以参考，另外可以随着训练进行不断缩小学习率，</p>
</li>
<li>
<p>给D的网络层增加高斯噪声，相当于是一种正则</p>
</li>
</ul>
<h2 id="14-6-AutoML">14.6 AutoML</h2>
<h3 id="14-6-1-什么是AutoML？">14.6.1 什么是AutoML？</h3>
<p>​	目前一个优秀的机器学习和深度学习模型，离不开这几个方面：</p>
<p>​	一、优秀的数据预处理；</p>
<p>​	二、合适的模型结构和功能；</p>
<p>​	三、优秀的训练策略和超参数；</p>
<p>​	四、合适的后处理操作；</p>
<p>​	五、严格的结果分析。</p>
<p>​	这几方面都对最终的结果有着举足轻重的影响，这也是目前的数据工程师和学者们的主要工作。但由于这每一方面都十分繁琐，尤其是在构建模型和训练模型上。而大部分情况下，这些工作有无须过深专业知识就能使用起来。所以AutoML主要的作用就是来帮助实现高效的模型构建和超参数调整。例如深度学习网络的架构搜索、超参数的重要性分析等等。当然AutoML并不简单的进行暴力或者随机的搜索，其仍然需要机器学习方面的知识，例如贝叶斯优化、强化学习、元学习以及迁移学习等等。目前也有些不错的AutoML工具包，例如Alex Honchar的Hyperopt、微软的NNI、Autokeras等。</p>
<p>目前AutoML已经成为最新的研究热点，有兴趣的可以参考<a target="_blank" rel="noopener" href="https://www.automl.org/automl/literature-on-neural-architecture-search/">AutoML literature</a>。</p>
<h3 id="14-6-2-自动化超参数搜索方法有哪些？">14.6.2 自动化超参数搜索方法有哪些？</h3>
<p>​	目前自动化搜索主要包含网格搜索，随机搜索，基于模型的超参优化</p>
<p>​	网格搜索：</p>
<p>​		通常当超参数量较少的时候，可以使用网格搜索法。即列出每个超参数的大致候选集合。利用这些集合		进行逐项组合优化。在条件允许的情况下，重复进行网格搜索会当优秀，当然每次重复需要根据上一步得到的最优参数组合，进行进一步的细粒度的调整。网格搜索最大的问题就在于计算时间会随着超参数的数量指数级的增长。</p>
<p>​	随机搜索：</p>
<p>​		随机搜索，是一种用来替代网格搜索的搜索方式。随机搜索有别于网格搜索的一点在于，我们不需要设定一个离散的超参数集合，而是对每个超参数定义一个分布函数来生成随机超参数。随机搜索相比于网格搜索在一些不敏感超参上拥有明显优势。例如网格搜索对于批样本数量（batch size），在[16,32,64]这些范围内进行逐项调试，这样的调试显然收益更低下。当然随机搜索也可以进行细粒度范围内的重复的搜索优化。</p>
<p><img src="img%5Cch14%5C14.14.png" alt></p>
<p>​	基于模型的超参优化：</p>
<p>​		有别于上述两种的搜索策略，基于模型的超参调优问题转化为了优化问题。直觉上会考虑是否进行一个可导建模，然后利用梯度下降进行优化。但不幸的是我们的超参数通常情况下是离散的，而且其计算代价依旧很高。</p>
<p>​		基于模型的搜索算法，最常见的就是贝叶斯超参优化。有别于的网格搜索和随机搜索独立于前几次搜索结果的搜索，贝叶斯则是利用历史的搜索结果进行优化搜索。其主要有四部分组成，1.目标函数，大部分情况下就是模型验证集上的损失。2、搜索空间，即各类待搜索的超参数。3、优化策略，建立的概率模型和选择超参数的方式。4、历史的搜索结果。首先对搜索空间进行一个先验性的假设猜想，即假设一种选择超参的方式，然后不断的优化更新概率模型，最终的目标是找到验证集上误差最小的一组超参数。</p>
<h3 id="14-6-3-什么是神经网络架构搜索（NAS）">14.6.3 什么是神经网络架构搜索（NAS）</h3>
<p>2015至2017年间，是CNN网络设计最兴盛的阶段，大多都是由学者人工设计的网络结构。这个过程通常会很繁琐。其主要原因在于对不同模块组件的组成通常是个黑盒优化的问题，此外，在不同结构超参数以及训练超参数的选择优化上非凸优化问题，或者是个混合优化问题，既有离散空间又有连续空间。NAS（Neural Architecture Search）的出现就是为了解决如何通过机器策略和自动化的方式设计出优秀高效的网络。而这种策略通常不是统一的标准，不同的网络结合实际的需求通常会有不同的设计，比如移动端的模型会在效率和精度之间做平衡。目前，NAS也是AUTOML中最重要的部分。NAS通常会分为三个方面，搜索空间（在哪搜索），搜索策略（如何搜索）及评价预估。</p>
<ul>
<li>
<p>搜索空间，即在哪搜索，定义了优化问题所需变量。不同规模的搜索空间的变量其对于的难度也是不一样的。早期由于网络结构以及层数相对比较简单，参数量较少，因此会更多的使用遗传算法等进化算法对网络的超参数和权重进行优化。深度学习发展到目前，模型网络结构越来越复杂，参数量级越来越庞大，这些进化算法已经无法继续使用。但若我们先验给定一些网络结构和超参数，模型的性能已经被限制在给定的空间，此时搜索的空间已变得有限，所以只需对复杂模型的架构参数和对应的超参数进行优化即可。</p>
</li>
<li>
<p>搜索策略， 即如何搜索，定义了如何快速、准确找到最优的网络结构参数配置的策略。常见的搜索方法包括：随机搜索、贝叶斯优化、强化学习、进化算法以及基于模型的搜索算法。其中主要代表为2017年谷歌大脑的使用强化学习的搜索方法。</p>
</li>
<li>
<p>评价预估，定义了如何高效对搜索的评估策略。深度学习中，数据规模往往是庞大的，模型要在如此庞大的数据规模上进行搜索，这无疑是非常耗时的，对优化也会造成非常大的困难，所以需要一些高效的策略做近似的评估。 这里一般会有如下三种思路：</p>
<p>一、使用些低保真的训练集来训练模型。低保真在实际中可以用不同的理解，比如较少的迭代次数，用一小部分数据集或者保证结构的同时减少通道数等。这些方法都可以在测试优化结构时大大降低计算时间，当然也会存在一定的偏差。但架构搜索从来并不是要一组固定的参数，而是一种优秀的模型结构。最终选取时，只需在较优秀的几组结构中进行全集训练，进行择优选取即可。</p>
<p>二、使用代理模型。除了低保真的训练方式外，学者们提出了一种叫做代理模型的回归模型，采用例如插值等策略对已知的一些参数范围进行预测，目的是为了用尽可能少的点预测到最佳的结果。</p>
<p>三、参数级别的迁移。例如知识蒸馏等。用已训练好的模型权重参数对目标问题搜索，通常会让搜索拥有一个优秀的起点。由于积累了大量的历史寻优数据，对新问题的寻优将会起到很大的帮助。</p>
</li>
</ul>
<h3 id="14-6-4-NASNet的设计策略">14.6.4 NASNet的设计策略</h3>
<p>NASNet是最早由google brain 通过网络架构搜索策略搜索并成功训练ImageNet的网络，其性能超越所有手动设计的网络模型。关于NASNet的搜索策略，首先需要参考google brain发表在ICLR2017的论文《Neural Architecture Search with Reinforcement Learning》。该论文是最早成功通过架构搜索策略在cifar-10数据集上取得比较不错效果的工作。NASNet很大程度上是沿用该搜索框架的设计思想。</p>
<p>NASNet的核心思想是利用强化学习对搜索空间内的结构进行反馈探索。架构搜索图如下，定义了一个以RNN为核心的搜索控制器。在搜索空间以概率p对模型进行搜索采样。得到网络模型A后，对该模型进行训练，待模型收敛得到设定的准确率R后，将梯度传递给控制器RNN进行梯度更新。</p>
<p><img src="img%5Cch14%5CNAS%E6%90%9C%E7%B4%A2%E7%AD%96%E7%95%A5.png" alt></p>
<p>​									架构搜索策略流程</p>
<p>RNN控制器会对卷积层的滤波器的尺寸、数量以及滑动间隔进行预测。每次预测的结果都会作为下一级的输入，档层数达到设定的阈值时，会停止预测。而这个阈值也会随着训练的进行而增加。这里的控制器之预测了卷积，并没有对例如inception系列的分支结构或者ResNet的跳级结构等进行搜索。所以，控制器需要进一步扩展到预测这些跳级结构上，这样搜索空间相应的也会增大。为了预测这些结构，RNN控制器内每一层都增加了一个预测跳级结构的神经元，文中称为锚点，稍有不同的是该锚点的预测会由前面所有层的锚点状态决定。</p>
<p><img src="img%5Cch14%5CRNN%E6%8E%A7%E5%88%B6%E5%99%A8.png" alt></p>
<p>​									RNN控制器</p>
<p>NASNet大体沿用了上述生成网络结构的机器，并在此基础上做了如下两点改进：</p>
<p>1、先验行地加入inception系列和ResNet的堆叠模块的思想。其定义了两种卷积模块，Normal Cell和Reduction Cell，前者不进行降采样，而后者是个降采样的模块。而由这两种模块组成的结构可以很方便的通过不同数量的模块堆叠将其从小数据集搜索到的架构迁移到大数据集上，大大提高了搜索效率。</p>
<p><img src="img%5Cch14%5CNASNet%E7%9A%84RNN%E6%8E%A7%E5%88%B6%E5%99%A8.png" alt></p>
<p>​									NASNet的RNN控制器</p>
<p>2、对RNN控制进行优化，先验性地将各种尺寸和类型的卷积和池化层加入到搜索空间内，用预测一个卷积模块代替原先预测一层卷积。如图，控制器RNN不在预测单个卷积内的超参数组成，而是对一个模块内的每一个部分进行搜索预测，搜索的空间则限定在如下这些操作中：</p>
<p>​						• identity					  • 1x3 then 3x1 convolution<br>
​						• 1x7 then 7x1 convolution	  • 3x3 dilated convolution<br>
​						• 3x3 average pooling 			  • 3x3 max pooling<br>
​						• 5x5 max pooling			  • 7x7 max pooling<br>
​						• 1x1 convolution				  • 3x3 convolution<br>
​						• 3x3 depthwise-separable conv • 5x5 depthwise-seperable conv<br>
​						• 7x7 depthwise-separable conv</p>
<p>在模块内的连接方式上也提供了element-wise addition和concatenate两种方式。NASNet的搜索方式和过程对NAS的一些后续工作都具有非常好的参考借鉴意义。</p>
<h3 id="14-6-5-网络设计中，为什么卷积核设计尺寸都是奇数">14.6.5 网络设计中，为什么卷积核设计尺寸都是奇数</h3>
<p>我们发现在很多大部分网络设计时都会使用例如3x3/5x5/7x7等奇数尺寸卷积核，主要原因有两点：</p>
<ul>
<li>保证像素点中心位置，避免位置信息偏移</li>
<li>填充边缘时能保证两边都能填充，原矩阵依然对称</li>
</ul>
<h3 id="14-6-6-网络设计中，权重共享的形式有哪些，为什么要权重共享">14.6.6 网络设计中，权重共享的形式有哪些，为什么要权重共享</h3>
<p>权重共享的形式：</p>
<ul>
<li>深度学习中，权重共享最具代表性的就是卷积网络的卷积操作。卷积相比于全连接神经网络参数大大减少；</li>
<li>多任务网络中，通常为了降低每个任务的计算量，会共享一个骨干网络。</li>
<li>一些相同尺度下的结构化递归网络</li>
</ul>
<p>权重共享的好处：</p>
<p>​	权重共享一定程度上能增强参数之间的联系，获得更好的共性特征。同时很大程度上降低了网络的参数，节省计算量和计算所需内存（当然，结构化递归并不节省计算量）。此外权重共享能起到很好正则的作用。正则化的目的是为了降低模型复杂度，防止过拟合，而权重共享则正好降低了模型的参数和复杂度。</p>
<p>​	因此一个设计优秀的权重共享方式，在降低计算量的同时，通常会较独享网络有更好的效果。</p>
<p>权重共享不仅在人工设计（human-invented）的网络结构中有简化参数，降低模型复杂度的作用，在神经网络搜索（NAS）的网络结构中可以使得child model的计算效率提升，使得搜索过程可以在单卡GPU上复现，见Efficient NAS(<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.03268">ENAS</a>)。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lilitom.github.io/2024/03/19/deep_learning/ch16/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/deep_learning/ch16/" class="post-title-link" itemprop="url">NLP面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-24 10:14:13" itemprop="dateModified" datetime="2024-03-24T10:14:13+08:00">2024-03-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>NLP</h1>
<h2 id="16-0-NLP-发展史简述">16.0 NLP 发展史简述</h2>
<p>50多年来 NLP 的历史发展可以分为三个浪潮，前两波以理性主义和经验主义的形式出现，为当前的深度学习浪潮铺平了道路。NLP的深层学习革命的主要支柱是: （1）语言嵌入实体的分布式表征，（2）由于嵌入而产生的语义泛化， （3）自然语言的大跨度深序列建模，（4）能够从低到高表示语言层次的分层网络，以及（5）解决许多联合 NLP 问题的端对端深度学习方法。</p>
<h3 id="第一个浪潮：理性主义">第一个浪潮：理性主义</h3>
<p>在第一个浪潮中，NLP的实验持续了很长一段时间，可以追溯到20世纪50年代。1950年，阿兰·图灵提出了图灵测试，以评估计算机表现出与人类无法区分的智能行为的能力。这项测试是基于人类和计算机之间的自然语言对话，旨在生成类似人类的反应。1954年，George-IBM 实验产出了能够将60多个俄语句子翻译成英语的rrst机器翻译系统。</p>
<p>这些方法是基于这样一种信念，即人类思维中的语言知识是由泛型继承提前进行的，而这种信念，在大约1960年至1980年代后期，占据了NLP的大部分研究中的主导地位。这些方法被称为理性主义方法（Church 2007）。理性主义方法在 NLP 中的主导地位主要是由于诺姆·乔姆斯基（Noam Chomsky）关于先天语言结构的论点被广泛接受以及他对 N-grams 方法的批评（Chomsky 1957）。理性主义者一般假设语言的关键部分在出生时就被硬连接到大脑中，作为人类遗传遗传的一部分，因此他们试图设计手工制作的规则，将知识和推理机制纳入智能 NLP 系统。直到20世纪80年代，最著名的成功的NLP系统，如为模拟 Rogerian psychotherapist 的 ELIZA 系统和为了规则化真实世界信息为规则本体的 MARGIE 系统，都是基于复杂的手写规则。</p>
<p>这一时期恰逢以专家知识工程为特点的早期智能的早期发展，即领域专家根据其所掌握的（非常狭窄的）应用领域的知识设计计算机程序（Nilsson 1982; Winston 1993）。专家们使用符号逻辑规则设计了这些程序，这些规则基于对这些知识的仔细表征和工程。这些以知识为基础的智能系统往往通过检测&quot;Head&quot;或最重要的参数，并就每种特殊情况采取特定的解决办法，而这在解决狭义问题方面往往是有效的。这些“Head”参数由人类专家预先确定，使“tail”参数和案例不受影响。由于缺乏学习能力，他们有必要将解决方案推广到新的情况和领域。这一时期的典型方法是专家系统所提供的证据，这是一个模拟人类专家决策能力的计算机系统。这种系统旨在通过知识推理来解决复杂的问题（Nilsson 1982）。第一个专家系统建立于1970年代，然后在1980年代推广。使用的主要&quot;算法&quot;是以&quot;if-then-else&quot;为形式的推断规则（Jackson 1998）。这些智能系统的主要优点是其在进行逻辑推理方面（有限）能力的透明度和可解释性。像NLP系统，如 ELIZA 和 MARGIE ，一般专家系统在早期使用手工制作的专家知识，这往往是有效的狭隘的问题，虽然推理无法处理不确定性，是普遍存在的实际应用。</p>
<p>同样，语音识别研究和系统设计，这又是另一个长期存在的 NLP 和反智能挑战，在这个理性主义时代，主要基于专家知识工程的范式，如elegantly analyzed in（Church and Mercer 1993）。在1970年代和1980年代初，专家系统的语音识别方法相当流行（Reddy 1976; Zue 1985）。然而，研究人员敏锐地认识到，缺乏从数据中学习和处理推理不确定性的能力，导致了接下来描述的第二波语音识别、NLP和对于文本的人工智能浪潮也走向失败。</p>
<h3 id="第二波浪潮：经验主义">第二波浪潮：经验主义</h3>
<p>第二波 NLP 浪潮的特点是利用语料库数据以及基于（浅层）机器学习、统计学等来利用这些数据（Manning and Schtze 1999）。由于许多自然语言的结构和理论都被贬低或抛弃，而倾向于数据驱动的方法，这个时代发展的主要方法被称为经验或务实的方法（ChurchandMercer 1993;Church 2014）。NLP 的一个主要会议甚至被命名为“自然语言处理的经验方法（Empirical Methods in Natural Language Processing）（EMNLP）”，最直接地反映了NLP研究人员在那个时代对经验方法的强烈积极情绪。</p>
<p>与理性主义方法相反，经验方法认为人类的思维只是从关联、模式识别和泛化的常规操作开始。丰富的感官输入需要使大脑学习自然语言的详细结构。经验主义盛行于1920年至1960年间，自1990年以来一直在兴起。NLP的早期经验方法主要是开发生成模型，如隐马尔可夫模型 （HMM） （Baum and Petrie 1966）， IBM 翻译模型 （Brown et al. 1993）， 和 head-driven parsing 模型（Collins 1997），以发现大型语料库的规律性。自1990年代后期以来，在各种NLP任务中，歧视性模式已成为事实上的做法。NLP的典型判别模型和方法包括最大熵模型（ratnaparkhi 1997）、支持向量机（Vapnik 1998）、条件随机（Lafferty et al. 2001）、最大相互信息和最小区分器错误（He et al. 2008）还有感知器（Collins 2002）。</p>
<p>在这种经验主义时代中、NLP 与同样的智能方法如语音识别和计算机视觉是平行的。这是在明确的证据表明，学习和感知能力对复杂的智能系统至关重要，但在前一波流行的专家系统中却不存在。例如，当 DARPA 开始对自动驾驶提出重大挑战时，大多数车辆随后依赖于基于知识的智能智能。正如语音识别和NLP 一样，自主驾驶和计算机视觉研究人员意识到基于知识的范式的局限性，因为机器学习需要进行不确定性处理和泛化能力。</p>
<p>在第二波浪潮中，NLP的经验主义和语音识别是基于数据密集型机器学习的，我们现在称之为“shallow”，因为在下一节中描述的第三波浪潮中，数据的多层或“deep”表征通常缺乏抽象结构。在机器学习中，在第一次浪潮中，研究人员不需要考虑构造精确规则，为知识为基础的 NLP 和语音系统。相反，他们把重点放在统计模型（Bishop 2006; Murphy 2012）或作为一个基本引擎的简单的神经网络（Bishop 1995）。然后，他们使用足够的训练数据进行自动学习或“tune（调整）”系统的参数，使它们能够处理不确定性，并尝试从一个条件泛化到另一个条件，从一个领域泛化到另一个领域。机器学习的关键算法和方法包括EM （期望最大化）、贝叶斯网络、支持向量机、决策树以及神经网络的反向传播算法。</p>
<p>一般来说，基于机器学习的NLP、语音和其他智能系统的性能比早期的基于知识的智能系统要好得多。成功的例子包括语音识别 （Jelinek 1998）， 脸部识别 （Viola and Jones 2004）， 实体识别 （Fei-Fei and Perona 2005）， 手写字体识别 （Plamondon and Srihari 2000）， 以及机器翻译 （Och 2003）。</p>
<p>在语音识别方面，从20世纪80年代初到2010年前后近30年，利用基于 HMM 与高斯混合模型相结合的统计生成模型，以及其推广的各种版本（Baker et al. 2009a，b; Deng and O’Shaughnessy 2003; Rabiner and Juang 1993）的统计生成模式。泛化 HMM 的许多版本都是基于统计和神经网络的隐动态模型（Deng 1998; Bridle et al. 1998; Deng and Yu 2007）。前者采用 EM 和 switching extended Kalman ﬁlter 算法学习模型参数（Ma and Deng 2004; Lee et al. 2004），后者采用反向传播（Picone et al. 1999），两者都广泛地利用多个潜在层表示法进行语音分析的生成过程。将这种“深度”生成过程转化为端到端过程的对应方案，导致了深度学习的工业化成功（Deng et al. 2010， 2013; Hinton et al. 2012） ，从而形成了第三波浪潮的驱动力。</p>
<h3 id="第三波浪潮：深度学习">第三波浪潮：深度学习</h3>
<p>在第二波浪潮中开发的 NLP 系统，包括语音识别、语言理解和机器翻译，表现得比在第一波浪潮时更好，鲁棒性更高，但它们远远没有达到人的水平，而这留下了很多需求。除了少数例外，NLP的（浅层）机器学习模型通常没有足够的容量来吸收大量的训练数据。此外，学习算法、方法和基础设施也都不够强大。所有这一切都在几年前发生了变化，而这导致了第三波 NLP 浪潮，这股浪潮是由深层机器学习或深度学习的新范式推动的（Bengio 2009; Deng and Yu 2014; LeCun et al. 2015; Goodfellow et al. 2016）。</p>
<p>深度学习起源于人工神经网络，它可以被看作是受生物神经系统启发的细胞类型的级联模型。随着反向传播算法的出现（Rumelhart et al. 1986），90年代对深度神经网络的训练引起了广泛关注。在没有大量训练数据和没有适当的设计和学习范式的情况下，在神经网络训练过程中，学习信号随着层次数（或更严格的信用分配深度）在层层传播时呈指数形式消失，使得调整深层神经网络特别是递归的版本的连接权重变得异常艰难。Hinton 等人（2006）克服了这个问题，使用无人监督的预训练模型来进行学习有用的特征探测器。然后，通过监督学习进一步训练网络，对标记数据进行分类。因此，可以学习使用低维表征的方式来学习高维的表征的分布。这项开创性的工作标志着神经网络的复兴。此后提出和发展了各种网络结构，包括 Deep Belief 网络（Hinton et al.2006）、堆积自编码器（Vincent et al.2010）、深层玻尔兹曼机（Hinton and Salakhutdinov 2012）、深度卷积神经网络（Krizhevsky et al. 2012），深层堆积网络 （Deng et al. 2012），和深层 Q-networks （Mnih et al. 2015）。深度学习自2010年以来已成功地应用于实际智能领域的实际任务，包括语音识别（Yu et al. 2010; Hinton et al. 2012），图像识别（Krizhevsky et al. 2012; He et al. 2016），以及 NLP 绝大多数领域。</p>
<p>其中由于微软公司在工业化上的成功，以及愈来愈高的准确率等迹象，这些2010-2011年语音识别的惊人成功预示着 NLP 的第三波浪潮和人工智能的到来。随着深度学习在语音识别方面取得成功，计算机视觉（Krizhevsky et al. 2012）和机器翻译（Bahdanau et al. 2015）被类似的深度学习范式所取代。特别是，虽然 Bengio 等人在2001的工作，在2011年就开发了强大的神经词嵌入技术（Bengio et al. 2001），但由于大数据的可用性和更快的计算，它直到10多年后才被证明在一个大规模和实际有用的规模上才能够实际有用（Mikolov et al. 2013）。此外，许多其他现实世界的NLP应用，如图像字幕（Karpathy and Fei-Fei 2015; Fang et al. 2015; Gan et al. 2017），视觉问题回答（Fei-Fei and Perona 2016），语音理解系统（Mesnil et al. 2013），网络搜索（Huang et al. 2013b）和推荐系统由于深度学习而取得成功，此外还有许多非NLP任务，包括药物发现和药理学、客户关系管理、推荐系统、手势识别、医学信息、广告投放、医学图像分析、机器人、自动驾驶车辆、纸板和电子游戏（例如 Atari， Go， Poker， and the latest， DOTA2）等。详情请参阅维基上的深度学习领域。</p>
<p>在更多基于文本的应用领域中，机器翻译可能受到深度学习的影响最大。从 NLP 第二波浪潮中发展起来的浅层——统计机器翻译开始看起的话，目前在实际应用中最好的机器翻译系统是基于深神经网络的。例如，谷歌在2016年9月宣布了其转向神经机器翻译的阶段，两个月后微软也发布了类似的声明。Facebook已经进行了大约一年的机器神经网络翻译的转换工作，到2017年8月它已经完全将这个系统部署成功。</p>
<p>在口语理解和对话系统领域，深度学习也正在产生巨大影响。目前流行的技术以多种方式维护和扩展了第二波时代浪潮中发展起来的统计方法。与经验（浅层）机器学习方法一样，深度学习也是基于数据密集型方法，以降低手工制作规则的成本，对噪声环境下的语音识别错误和语言理解错误具有很强的鲁棒性，并利用决策过程和强化学习的力量来设计对话策略，例如（Gasic et al. 2017; Dhingra et al. 2017）。与早期的方法相比，深度神经网络模型和表征方法更强大，它们使端到端学习成为可能。然而，深度学习也没有解决可解释性和领域泛化问题。</p>
<p>将深度学习应用于 NLP 问题方面的最近的两个重要技术突破是序列到序列学习（Sutskevar et al. 2014）和注意力机制建模（Bahdanau et al. 2015），以及最近的 BERT模型（Jacob el al.2018） 。序列到序列学习引入了一个强大的学习范式，即使用递归神经网络以端到端的方式进行编码和解码。注意力机制建模最初是为了克服编码一个长序列的难度而开发的，后来的持续发展又扩展了它的能力，提供了两个任意序列的高度可塑对齐能力，而其两个可以同时学习神经网络参数。而 BERT 则是实现了双向建模获取以得到更好的语言表征能力。序列到序列学习和注意力机制的关键概念在基于统计学习和词局部表征的最佳系统上提高了基于分布式单词嵌入的神经机器翻译的性能，而 BERT 更重要的意义是双向获取同一文段的高维意义。在这一成功之后，这些概念也被成功地应用到许多其他与NLP相关的任务中，如图像字幕（Karpathy and Fei-Fei 2015; Devlin et al. 2015）、语音识别（Chorowski et al. 2015）、一次性学习、句法分析、唇读、文本理解、摘要以及问答系统等。撇开他们巨大的经验成功不谈，基于神经网络的深度学习模型往往比早期浪潮中的传统机器学习模型更简单、更容易设计。在许多应用中，在端到端的任务中，模型的所有部分都同时进行深度学习，从特征抽取到预测。导致神经网络模型相对简单的另一个因素是，相同的模型构建成的块（即不同类型的层）通常在许多不同的应用中使用。为多种任务使用相同的构建块，这种方法使得模型更容易迁移到其它任务和数据上。此外，谷歌等公司还开发了软件工具包，以便更快、更有效地实现这些模型。由于以上这些原因，神经网络在数据量大而且基于云的方式上，是更常用的。</p>
<p>尽管深度学习在重塑语音、图像和视频的处理方面被证明是有效的，而且具有它的革命性，但在将深度学习与基于文本的 NLP 相结合方面的有效性并不那么明确，尽管它在一些实用的 NLP 任务中取得了经验上的成功。在语音、图像和视频处理中，深度学习通过直接从原始数据学习规律来解决语义差距问题。然而，在 NLP 中，人们提出了更强的理论和结构化模型，即语音、语法和语义，来提取理解和生成自然语言的基本机制，这些机制与神经网络不那么容易兼容。与语音、图像和视频信号相比，从文本数据中学习的神经表征可以对自然语言提供同样直接的见解，但是这个也不够直接。因此，将神经网络，特别是那些具有复杂层次结构的神经网络应用于 NLP，已成为 NLP 和深度学习社区中最活跃的领域，近年来取得了非常显著的进展（Deng 2016; Manning and Socher 2017;Jacob el al.2018）。</p>
<h2 id="16-1-如何理解序列到序列模型？">16.1 如何理解序列到序列模型？</h2>
<h2 id="16-2-序列到序列模型有什么限制吗？">16.2 序列到序列模型有什么限制吗？</h2>
<h2 id="16-3-如果不采用序列到序列模型，可以考虑用其它模型方法吗？">16.3 如果不采用序列到序列模型，可以考虑用其它模型方法吗？</h2>
<h2 id="16-4-如何理解词向量？">16.4 如何理解词向量？</h2>
<h2 id="16-5-词向量哪家好？">16.5 词向量哪家好？</h2>
<h2 id="16-6-解释一下注意力机制的原理？">16.6 解释一下注意力机制的原理？</h2>
<h2 id="16-7-注意力机制是不是适用于所有场景呢？它的鲁棒性如何？">16.7 注意力机制是不是适用于所有场景呢？它的鲁棒性如何？</h2>
<h2 id="16-8-怎么将原有的模型加上注意力机制呢？">16.8 怎么将原有的模型加上注意力机制呢？</h2>
<h2 id="16-9-通俗地解释一下词法分析是什么？有什么应用场景？">16.9 通俗地解释一下词法分析是什么？有什么应用场景？</h2>
<h2 id="16-10-深度学习中的词法分析有哪些常见模型呢？">16.10 深度学习中的词法分析有哪些常见模型呢？</h2>
<h2 id="16-11-通俗地解释一下知识图谱是什么？有什么应用场景？">16.11 通俗地解释一下知识图谱是什么？有什么应用场景？</h2>
<h2 id="16-12-深度学习中的知识图谱有哪些常见模型呢？">16.12 深度学习中的知识图谱有哪些常见模型呢？</h2>
<h2 id="16-13-深度学习中的机器翻译有哪些常见模型呢？">16.13 深度学习中的机器翻译有哪些常见模型呢？</h2>
<h2 id="16-14-机器翻译的通俗实现以及部署过程是怎样的呢？">16.14 机器翻译的通俗实现以及部署过程是怎样的呢？</h2>
<h2 id="16-15-通俗地解释一下文本情感分析是什么？常见的应用场景是？">16.15 通俗地解释一下文本情感分析是什么？常见的应用场景是？</h2>
<h2 id="16-16-最常用的情感分析模型是什么呢？如何快速部署呢？">16.16 最常用的情感分析模型是什么呢？如何快速部署呢？</h2>
<h2 id="16-17-通俗地解释一下问答系统？它涵盖哪些领域？常见的应用场景是？">16.17 通俗地解释一下问答系统？它涵盖哪些领域？常见的应用场景是？</h2>
<h2 id="16-18-常见的问答系统模型是什么？如何快速部署呢？">16.18 常见的问答系统模型是什么？如何快速部署呢？</h2>
<h2 id="16-19-图像文字生成是什么？它的技术原理是什么？">16.19 图像文字生成是什么？它的技术原理是什么？</h2>
<h2 id="16-20-常见的图像文字生成模型是什么？">16.20 常见的图像文字生成模型是什么？</h2>
<h2 id="16-21-NLP-的无监督学习发展动态是怎样的？有哪些领域在尝试无监督学习？">16.21 NLP 的无监督学习发展动态是怎样的？有哪些领域在尝试无监督学习？</h2>
<h2 id="16-22-NLP-和强化学习的结合方式是怎样的？有哪些方向在尝试强化学习？">16.22 NLP 和强化学习的结合方式是怎样的？有哪些方向在尝试强化学习？</h2>
<h2 id="16-23-NLP-和元学习？元学习如何能够和-NLP-结合起来？">16.23 NLP 和元学习？元学习如何能够和 NLP 结合起来？</h2>
<h2 id="16-24-能说一下各自领域最常用且常见的基准模型有哪些吗">16.24 能说一下各自领域最常用且常见的基准模型有哪些吗</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lilitom.github.io/2024/03/19/deep_learning/ch2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/deep_learning/ch2/" class="post-title-link" itemprop="url">机器学习基础面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-24 10:13:37" itemprop="dateModified" datetime="2024-03-24T10:13:37+08:00">2024-03-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>机器学习基础</h1>
<p>​	机器学习起源于上世纪50年代，1959年在IBM工作的Arthur Samuel设计了一个下棋程序，这个程序具有学习的能力，它可以在不断的对弈中提高自己。由此提出了“机器学习”这个概念，它是一个结合了多个学科如概率论，优化理论，统计等，最终在计算机上实现自我获取新知识，学习改善自己的这样一个研究领域。机器学习是人工智能的一个子集，目前已经发展出许多有用的方法，比如支持向量机，回归，决策树，随机森林，强化方法，集成学习，深度学习等等，一定程度上可以帮助人们完成一些数据预测，自动化，自动决策，最优化等初步替代脑力的任务。本章我们主要介绍下机器学习的基本概念、监督学习、分类算法、逻辑回归、代价函数、损失函数、LDA、PCA、决策树、支持向量机、EM算法、聚类和降维以及模型评估有哪些方法、指标等等。</p>
<h2 id="2-1-基本概念">2.1 基本概念</h2>
<h3 id="2-1-1-大话理解机器学习本质">2.1.1 大话理解机器学习本质</h3>
<p>​	机器学习(Machine Learning, ML)，顾名思义，让机器去学习。这里，机器指的是计算机，是算法运行的物理载体，你也可以把各种算法本身当做一个有输入和输出的机器。那么到底让计算机去学习什么呢？对于一个任务及其表现的度量方法，设计一种算法，让算法能够提取中数据所蕴含的规律，这就叫机器学习。如果输入机器的数据是带有标签的，就称作有监督学习。如果数据是无标签的，就是无监督学习。</p>
<h3 id="2-1-2-什么是神经网络">2.1.2 什么是神经网络</h3>
<p>​	神经网络就是按照一定规则将多个神经元连接起来的网络。不同的神经网络，具有不同的连接规则。例如全连接(Full Connected, FC)神经网络，它的规则包括：</p>
<p>（1）有三种层：输入层，输出层，隐藏层。</p>
<p>（2）同一层的神经元之间没有连接。</p>
<p>（3）fully connected的含义：第 N 层的每个神经元和第 N-1 层的所有神经元相连，第 N-1 层神经元的输出就是第 N 层神经元的输入。</p>
<p>（4）每个连接都有一个权值。</p>
<p><strong>神经网络架构</strong><br>
​	图2-1就是一个神经网络系统，它由很多层组成。输入层负责接收信息，比如一只猫的图片。输出层是计算机对这个输入信息的判断结果，它是不是猫。隐藏层就是对输入信息的传递和加工处理。<br>
<img src="2.5.1.png" alt="图2-2 神经网络系统"></p>
<p>​								图2-1 神经网络系统</p>
<h3 id="2-1-3-各种常见算法图示">2.1.3 各种常见算法图示</h3>
<p>​	日常使用机器学习的任务中，我们经常会遇见各种算法，图2-2是各种常见算法的图示。</p>
<table>
<thead>
<tr>
<th style="text-align:center">回归算法</th>
<th style="text-align:center">聚类算法</th>
<th style="text-align:center">正则化方法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="2.1/1.jpg" alt></td>
<td style="text-align:center"><img src="2.1/2.jpg" alt></td>
<td style="text-align:center"><img src="2.1/3.jpg" alt></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">决策树学习</th>
<th style="text-align:center">贝叶斯方法</th>
<th style="text-align:center">基于核的算法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="2.2.4.png" alt></td>
<td style="text-align:center"><img src="2.1/5.jpg" alt></td>
<td style="text-align:center"><img src="2.1/6.jpg" alt></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">聚类算法</th>
<th style="text-align:center">关联规则学习</th>
<th style="text-align:center">人工神经网络</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="2.1/7.jpg" alt></td>
<td style="text-align:center"><img src="2.2.8.png" alt></td>
<td style="text-align:center"><img src="2.2.09.png" alt></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">深度学习</th>
<th style="text-align:center">降低维度算法</th>
<th style="text-align:center">集成算法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="2.2.10.png" alt></td>
<td style="text-align:center"><img src="2.2.11.png" alt></td>
<td style="text-align:center"><img src="2.2.12.png" alt></td>
</tr>
</tbody>
</table>
<p>​										图2-2 各种常见算法图示</p>
<h3 id="2-1-4-计算图的导数计算">2.1.4 计算图的导数计算</h3>
<p>​	计算图导数计算是反向传播，利用链式法则和隐式函数求导。</p>
<p>​	假设  $z = f(u,v)$  在点  $(u,v)$  处偏导连续， $(u,v)$ 是关于  $t$  的函数，在  $t$  点可导，求  $z$  在  $t$  点的导数。</p>
<p>根据链式法则有</p>
 $$
\frac{dz}{dt}=\frac{\partial z}{\partial u}.\frac{du}{dt}+\frac{\partial z}{\partial v}
				.\frac{dv}{dt}
$$ 
<p>​	链式法则用文字描述:“由两个函数凑起来的复合函数，其导数等于里边函数代入外边函数的值之导数，乘以里边函数的导数。<br>
​	为了便于理解，下面举例说明：</p>
 $$
f(x)=x^2,g(x)=2x+1
$$ 
<p>​	则:</p>
 $$
{f[g(x)]}'=2[g(x)] \times g'(x)=2[2x+1] \times 2=8x+4
$$ 
<h3 id="2-1-5-理解局部最优与全局最优">2.1.5 理解局部最优与全局最优</h3>
<p>​	笑谈局部最优和全局最优</p>
<blockquote>
<p>​	柏拉图有一天问老师苏格拉底什么是爱情？苏格拉底叫他到麦田走一次，摘一颗最大的麦穗回来，不许回头，只可摘一次。柏拉图空着手出来了，他的理由是，看见不错的，却不知道是不是最好的，一次次侥幸，走到尽头时，才发现还不如前面的，于是放弃。苏格拉底告诉他：“这就是爱情。”这故事让我们明白了一个道理，因为生命的一些不确定性，所以全局最优解是很难寻找到的，或者说根本就不存在，我们应该设置一些限定条件，然后在这个范围内寻找最优解，也就是局部最优解——有所斩获总比空手而归强，哪怕这种斩获只是一次有趣的经历。<br>
​	柏拉图有一天又问什么是婚姻？苏格拉底叫他到树林走一次,选一棵最好的树做圣诞树，也是不许回头，只许选一次。这次他一身疲惫地拖了一棵看起来直挺、翠绿，却有点稀疏的杉树回来，他的理由是，有了上回的教训，好不容易看见一棵看似不错的，又发现时间、体力已经快不够用了，也不管是不是最好的，就拿回来了。苏格拉底告诉他：“这就是婚姻。”</p>
</blockquote>
<p>​	优化问题一般分为局部最优和全局最优。其中，</p>
<p>（1）局部最优，就是在函数值空间的一个有限区域内寻找最小值；而全局最优，是在函数值空间整个区域寻找最小值问题。</p>
<p>（2）函数局部最小点是它的函数值小于或等于附近点的点，但是有可能大于较远距离的点。</p>
<p>（3）全局最小点是那种它的函数值小于或等于所有的可行点。</p>
<h3 id="2-1-5-大数据与深度学习之间的关系">2.1.5 大数据与深度学习之间的关系</h3>
<p>首先来看大数据、机器学习及数据挖掘三者简单的定义：</p>
<p><strong>大数据</strong>通常被定义为“超出常用软件工具捕获，管理和处理能力”的数据集。<br>
<strong>机器学习</strong>关心的问题是如何构建计算机程序使用经验自动改进。<br>
<strong>数据挖掘</strong>是从数据中提取模式的特定算法的应用，在数据挖掘中，重点在于算法的应用，而不是算法本身。</p>
<p><strong>机器学习和数据挖掘</strong>之间的关系如下：<br>
数据挖掘是一个过程，在此过程中机器学习算法被用作提取数据集中的潜在有价值模式的工具。<br>
大数据与深度学习关系总结如下：</p>
<p>（1）深度学习是一种模拟大脑的行为。可以从所学习对象的机制以及行为等等很多相关联的方面进行学习，模仿类型行为以及思维。</p>
<p>（2）深度学习对于大数据的发展有帮助。深度学习对于大数据技术开发的每一个阶段均有帮助，不管是数据的分析还是挖掘还是建模，只有深度学习，这些工作才会有可能一一得到实现。</p>
<p>（3）深度学习转变了解决问题的思维。很多时候发现问题到解决问题，走一步看一步不是一个主要的解决问题的方式了，在深度学习的基础上，要求我们从开始到最后都要基于一个目标，为了需要优化的那个最终目标去进行处理数据以及将数据放入到数据应用平台上去，这就是端到端（End to End）。</p>
<p>（4）大数据的深度学习需要一个框架。在大数据方面的深度学习都是从基础的角度出发的，深度学习需要一个框架或者一个系统。总而言之，将你的大数据通过深度分析变为现实，这就是深度学习和大数据的最直接关系。</p>
<h2 id="2-2-机器学习学习方式">2.2 机器学习学习方式</h2>
<p>​	根据数据类型的不同，对一个问题的建模有不同的方式。依据不同的学习方式和输入数据，机器学习主要分为以下四种学习方式。</p>
<h3 id="2-2-1-监督学习">2.2.1 监督学习</h3>
<p>​	特点：监督学习是使用已知正确答案的示例来训练网络。已知数据和其一一对应的标签，训练一个预测模型，将输入数据映射到标签的过程。</p>
<p>​	常见应用场景：监督式学习的常见应用场景如分类问题和回归问题。</p>
<p>​	算法举例：常见的有监督机器学习算法包括支持向量机(Support Vector Machine, SVM)，朴素贝叶斯(Naive Bayes)，逻辑回归(Logistic Regression)，K近邻(K-Nearest Neighborhood, KNN)，决策树(Decision Tree)，随机森林(Random Forest)，AdaBoost以及线性判别分析(Linear Discriminant Analysis, LDA)等。深度学习(Deep Learning)也是大多数以监督学习的方式呈现。</p>
<h3 id="2-2-2-非监督式学习">2.2.2 非监督式学习</h3>
<p>​	定义：在非监督式学习中，数据并不被特别标识，适用于你具有数据集但无标签的情况。学习模型是为了推断出数据的一些内在结构。</p>
<p>​	常见应用场景：常见的应用场景包括关联规则的学习以及聚类等。</p>
<p>​	算法举例：常见算法包括Apriori算法以及k-Means算法。</p>
<h3 id="2-2-3-半监督式学习">2.2.3 半监督式学习</h3>
<p>​	特点：在此学习方式下，输入数据部分被标记，部分没有被标记，这种学习模型可以用来进行预测。</p>
<p>​	常见应用场景：应用场景包括分类和回归，算法包括一些对常用监督式学习算法的延伸，通过对已标记数据建模，在此基础上，对未标记数据进行预测。</p>
<p>​	算法举例：常见算法如图论推理算法（Graph Inference）或者拉普拉斯支持向量机（Laplacian SVM）等。</p>
<h3 id="2-2-4-弱监督学习">2.2.4 弱监督学习</h3>
<p>​	特点：弱监督学习可以看做是有多个标记的数据集合，次集合可以是空集，单个元素，或包含多种情况（没有标记，有一个标记，和有多个标记）的多个元素。 数据集的标签是不可靠的，这里的不可靠可以是标记不正确，多种标记，标记不充分，局部标记等。已知数据和其一一对应的弱标签，训练一个智能算法，将输入数据映射到一组更强的标签的过程。标签的强弱指的是标签蕴含的信息量的多少，比如相对于分割的标签来说，分类的标签就是弱标签。</p>
<p>​	算法举例：举例，给出一张包含气球的图片，需要得出气球在图片中的位置及气球和背景的分割线，这就是已知弱标签学习强标签的问题。</p>
<p>​	在企业数据应用的场景下， 人们最常用的可能就是监督式学习和非监督式学习的模型。 在图像识别等领域，由于存在大量的非标识的数据和少量的可标识数据， 目前半监督式学习是一个很热的话题。</p>
<h3 id="2-2-5-监督学习有哪些步骤">2.2.5 监督学习有哪些步骤</h3>
<p>​	监督学习是使用已知正确答案的示例来训练网络，每组训练数据有一个明确的标识或结果。想象一下，我们可以训练一个网络，让其从照片库中（其中包含气球的照片）识别出气球的照片。以下就是我们在这个假设场景中所要采取的步骤。</p>
<p><strong>步骤1：数据集的创建和分类</strong><br>
​	首先，浏览你的照片（数据集），确定所有包含气球的照片，并对其进行标注。然后，将所有照片分为训练集和验证集。目标就是在深度网络中找一函数，这个函数输入是任意一张照片，当照片中包含气球时，输出1，否则输出0。</p>
<p><strong>步骤2：数据增强（Data Augmentation）</strong><br>
​	当原始数据搜集和标注完毕，一般搜集的数据并不一定包含目标在各种扰动下的信息。数据的好坏对于机器学习模型的预测能力至关重要，因此一般会进行数据增强。对于图像数据来说，数据增强一般包括，图像旋转，平移，颜色变换，裁剪，仿射变换等。</p>
<p><strong>步骤3：特征工程（Feature Engineering）</strong><br>
​	一般来讲，特征工程包含特征提取和特征选择。常见的手工特征(Hand-Crafted Feature)有尺度不变特征变换(Scale-Invariant Feature Transform, SIFT)，方向梯度直方图(Histogram of Oriented Gradient, HOG)等。由于手工特征是启发式的，其算法设计背后的出发点不同，将这些特征组合在一起的时候有可能会产生冲突，如何将组合特征的效能发挥出来，使原始数据在特征空间中的判别性最大化，就需要用到特征选择的方法。在深度学习方法大获成功之后，人们很大一部分不再关注特征工程本身。因为，最常用到的卷积神经网络(Convolutional Neural Networks, CNNs)本身就是一种特征提取和选择的引擎。研究者提出的不同的网络结构、正则化、归一化方法实际上就是深度学习背景下的特征工程。</p>
<p><strong>步骤4：构建预测模型和损失</strong><br>
​	将原始数据映射到特征空间之后，也就意味着我们得到了比较合理的输入。下一步就是构建合适的预测模型得到对应输入的输出。而如何保证模型的输出和输入标签的一致性，就需要构建模型预测和标签之间的损失函数，常见的损失函数(Loss Function)有交叉熵、均方差等。通过优化方法不断迭代，使模型从最初的初始化状态一步步变化为有预测能力的模型的过程，实际上就是学习的过程。</p>
<p><strong>步骤5：训练</strong><br>
​	选择合适的模型和超参数进行初始化，其中超参数比如支持向量机中核函数、误差项惩罚权重等。当模型初始化参数设定好后，将制作好的特征数据输入到模型，通过合适的优化方法不断缩小输出与标签之间的差距，当迭代过程到了截止条件，就可以得到训练好的模型。优化方法最常见的就是梯度下降法及其变种，使用梯度下降法的前提是优化目标函数对于模型是可导的。</p>
<p><strong>步骤6：验证和模型选择</strong><br>
​	训练完训练集图片后，需要进行模型测试。利用验证集来验证模型是否可以准确地挑选出含有气球在内的照片。<br>
​	在此过程中，通常会通过调整和模型相关的各种事物（超参数）来重复步骤2和3，诸如里面有多少个节点，有多少层，使用怎样的激活函数和损失函数，如何在反向传播阶段积极有效地训练权值等等。</p>
<p><strong>步骤7：测试及应用</strong><br>
​	当有了一个准确的模型，就可以将该模型部署到你的应用程序中。你可以将预测功能发布为API（Application Programming Interface, 应用程序编程接口）调用，并且你可以从软件中调用该API，从而进行推理并给出相应的结果。</p>
<h2 id="2-8-分类算法">2.8 分类算法</h2>
<p>​	分类算法和回归算法是对真实世界不同建模的方法。分类模型是认为模型的输出是离散的，例如大自然的生物被划分为不同的种类，是离散的。回归模型的输出是连续的，例如人的身高变化过程是一个连续过程，而不是离散的。</p>
<p>​	因此，在实际建模过程时，采用分类模型还是回归模型，取决于你对任务（真实世界）的分析和理解。</p>
<h3 id="2-8-1-常用分类算法的优缺点？">2.8.1 常用分类算法的优缺点？</h3>
<p>​	接下来我们介绍常用分类算法的优缺点，如表2-1所示。</p>
<p>​									表2-1 常用分类算法的优缺点</p>
<table>
<thead>
<tr>
<th style="text-align:left">算法</th>
<th style="text-align:left">优点</th>
<th style="text-align:left">缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Bayes 贝叶斯分类法</td>
<td style="text-align:left">1）所需估计的参数少，对于缺失数据不敏感。<br>2）有着坚实的数学基础，以及稳定的分类效率。</td>
<td style="text-align:left">1）需要假设属性之间相互独立，这往往并不成立。（喜欢吃番茄、鸡蛋，却不喜欢吃番茄炒蛋）。<br>2）需要知道先验概率。<br>3）分类决策存在错误率。</td>
</tr>
<tr>
<td style="text-align:left">Decision Tree决策树</td>
<td style="text-align:left">1）不需要任何领域知识或参数假设。<br>2）适合高维数据。<br>3）简单易于理解。<br>4）短时间内处理大量数据，得到可行且效果较好的结果。<br>5）能够同时处理数据型和常规性属性。</td>
<td style="text-align:left">1）对于各类别样本数量不一致数据，信息增益偏向于那些具有更多数值的特征。<br>2）易于过拟合。<br>3）忽略属性之间的相关性。<br>4）不支持在线学习。</td>
</tr>
<tr>
<td style="text-align:left">SVM支持向量机</td>
<td style="text-align:left">1）可以解决小样本下机器学习的问题。<br>2）提高泛化性能。<br>3）可以解决高维、非线性问题。超高维文本分类仍受欢迎。<br>4）避免神经网络结构选择和局部极小的问题。</td>
<td style="text-align:left">1）对缺失数据敏感。<br>2）内存消耗大，难以解释。<br>3）运行和调参略烦人。</td>
</tr>
<tr>
<td style="text-align:left">KNN K近邻</td>
<td style="text-align:left">1）思想简单，理论成熟，既可以用来做分类也可以用来做回归； <br>2）可用于非线性分类；<br> 3）训练时间复杂度为O(n)； <br>4）准确度高，对数据没有假设，对outlier不敏感；</td>
<td style="text-align:left">1）计算量太大。<br>2）对于样本分类不均衡的问题，会产生误判。<br>3）需要大量的内存。<br>4）输出的可解释性不强。</td>
</tr>
<tr>
<td style="text-align:left">Logistic Regression逻辑回归</td>
<td style="text-align:left">1）速度快。<br>2）简单易于理解，直接看到各个特征的权重。<br>3）能容易地更新模型吸收新的数据。<br>4）如果想要一个概率框架，动态调整分类阀值。</td>
<td style="text-align:left">特征处理复杂。需要归一化和较多的特征工程。</td>
</tr>
<tr>
<td style="text-align:left">Neural Network 神经网络</td>
<td style="text-align:left">1）分类准确率高。<br>2）并行处理能力强。<br>3）分布式存储和学习能力强。<br>4）鲁棒性较强，不易受噪声影响。</td>
<td style="text-align:left">1）需要大量参数（网络拓扑、阀值、阈值）。<br>2）结果难以解释。<br>3）训练时间过长。</td>
</tr>
<tr>
<td style="text-align:left">Adaboosting</td>
<td style="text-align:left">1）adaboost是一种有很高精度的分类器。<br>2）可以使用各种方法构建子分类器，Adaboost算法提供的是框架。<br>3）当使用简单分类器时，计算出的结果是可以理解的。而且弱分类器构造极其简单。<br>4）简单，不用做特征筛选。<br>5）不用担心overfitting。</td>
<td style="text-align:left">对outlier比较敏感</td>
</tr>
</tbody>
</table>
<h3 id="2-8-2-分类算法的评估方法">2.8.2 分类算法的评估方法</h3>
<p>​	分类评估方法主要功能是用来评估分类算法的好坏，而评估一个分类器算法的好坏又包括许多项指标。了解各种评估方法，在实际应用中选择正确的评估方法是十分重要的。</p>
<ul>
<li>
<p><strong>几个常用术语</strong><br>
​	这里首先介绍几个常见的模型评价术语，现在假设我们的分类目标只有两类，计为正例（positive）和负例（negative）分别是：</p>
<ol>
<li>True positives(TP):  被正确地划分为正例的个数，即实际为正例且被分类器划分为正例的实例数；</li>
<li>False positives(FP): 被错误地划分为正例的个数，即实际为负例但被分类器划分为正例的实例数；</li>
<li>False negatives(FN):被错误地划分为负例的个数，即实际为正例但被分类器划分为负例的实例数；</li>
<li>True negatives(TN): 被正确地划分为负例的个数，即实际为负例且被分类器划分为负例的实例数。</li>
</ol>
<p>​									表2-2 四个术语的混淆矩阵</p>
</li>
</ul>
<p><img src="2.9/1.png" alt="图2-3 术语的混淆矩阵"></p>
<p>表2-2是这四个术语的混淆矩阵，做以下说明：<br>
1）P=TP+FN表示实际为正例的样本个数。<br>
2）True、False描述的是分类器是否判断正确。<br>
3）Positive、Negative是分类器的分类结果，如果正例计为1、负例计为-1，即positive=1、negative=-1。用1表示True，-1表示False，那么实际的类标=TF*PN，TF为true或false，PN为positive或negative。<br>
4）例如True positives(TP)的实际类标=1*1=1为正例，False positives(FP)的实际类标=(-1)*1=-1为负例，False negatives(FN)的实际类标=(-1)*(-1)=1为正例，True negatives(TN)的实际类标=1*(-1)=-1为负例。</p>
<ul>
<li>
<p><strong>评价指标</strong></p>
<ol>
<li>
<p>正确率（accuracy）<br>
正确率是我们最常见的评价指标，accuracy = (TP+TN)/(P+N)，正确率是被分对的样本数在所有样本数中的占比，通常来说，正确率越高，分类器越好。</p>
</li>
<li>
<p>错误率（error rate)<br>
错误率则与正确率相反，描述被分类器错分的比例，error rate = (FP+FN)/(P+N)，对某一个实例来说，分对与分错是互斥事件，所以accuracy =1 -  error rate。</p>
</li>
<li>
<p>灵敏度（sensitivity）<br>
sensitivity = TP/P，表示的是所有正例中被分对的比例，衡量了分类器对正例的识别能力。</p>
</li>
<li>
<p>特异性（specificity)<br>
specificity = TN/N，表示的是所有负例中被分对的比例，衡量了分类器对负例的识别能力。</p>
</li>
<li>
<p>精度（precision）<br>
precision=TP/(TP+FP)，精度是精确性的度量，表示被分为正例的示例中实际为正例的比例。</p>
</li>
<li>
<p>召回率（recall）<br>
召回率是覆盖面的度量，度量有多个正例被分为正例，recall=TP/(TP+FN)=TP/P=sensitivity，可以看到召回率与灵敏度是一样的。</p>
</li>
<li>
<p>其他评价指标<br>
计算速度：分类器训练和预测需要的时间；<br>
鲁棒性：处理缺失值和异常值的能力；<br>
可扩展性：处理大数据集的能力；<br>
可解释性：分类器的预测标准的可理解性，像决策树产生的规则就是很容易理解的，而神经网络的一堆参数就不好理解，我们只好把它看成一个黑盒子。</p>
</li>
<li>
<p>精度和召回率反映了分类器分类性能的两个方面。如果综合考虑查准率与查全率，可以得到新的评价指标F1-score，也称为综合分类率： $F1=\frac{2 \times precision \times recall}{precision + recall}​$ 。</p>
<p>为了综合多个类别的分类情况，评测系统整体性能，经常采用的还有微平均F1（micro-averaging）和宏平均F1（macro-averaging ）两种指标。</p>
<p>（1）宏平均F1与微平均F1是以两种不同的平均方式求的全局F1指标。</p>
<p>（2）宏平均F1的计算方法先对每个类别单独计算F1值，再取这些F1值的算术平均值作为全局指标。</p>
<p>（3）微平均F1的计算方法是先累加计算各个类别的a、b、c、d的值，再由这些值求出F1值。</p>
<p>（4）由两种平均F1的计算方式不难看出，宏平均F1平等对待每一个类别，所以它的值主要受到稀有类别的影响，而微平均F1平等考虑文档集中的每一个文档，所以它的值受到常见类别的影响比较大。</p>
</li>
</ol>
</li>
<li>
<p><strong>ROC曲线和PR曲线</strong></p>
<pre><code>  如图2-3，ROC曲线是（Receiver Operating Characteristic Curve，受试者工作特征曲线）的简称，是以灵敏度（真阳性率）为纵坐标，以1减去特异性（假阳性率）为横坐标绘制的性能评价曲线。可以将不同模型对同一数据集的ROC曲线绘制在同一笛卡尔坐标系中，ROC曲线越靠近左上角，说明其对应模型越可靠。也可以通过ROC曲线下面的面积（Area Under Curve, AUC）来评价模型，AUC越大，模型越可靠。
</code></pre>
</li>
</ul>
<p><img src="2.7.3.png" alt></p>
<p>​	                                                                         图2-3 ROC曲线</p>
<p>​	PR曲线是Precision Recall Curve的简称，描述的是precision和recall之间的关系，以recall为横坐标，precision为纵坐标绘制的曲线。该曲线的所对应的面积AUC实际上是目标检测中常用的评价指标平均精度（Average Precision, AP）。AP越高，说明模型性能越好。</p>
<h3 id="2-8-3-正确率能很好的评估分类算法吗">2.8.3 正确率能很好的评估分类算法吗</h3>
<p>​	不同算法有不同特点，在不同数据集上有不同的表现效果，根据特定的任务选择不同的算法。如何评价分类算法的好坏，要做具体任务具体分析。对于决策树，主要用正确率去评估，但是其他算法，只用正确率能很好的评估吗？<br>
​	答案是否定的。<br>
​	正确率确实是一个很直观很好的评价指标，但是有时候正确率高并不能完全代表一个算法就好。比如对某个地区进行地震预测，地震分类属性分为0：不发生地震、1发生地震。我们都知道，不发生的概率是极大的，对于分类器而言，如果分类器不加思考，对每一个测试样例的类别都划分为0，达到99%的正确率，但是，问题来了，如果真的发生地震时，这个分类器毫无察觉，那带来的后果将是巨大的。很显然，99%正确率的分类器并不是我们想要的。出现这种现象的原因主要是数据分布不均衡，类别为1的数据太少，错分了类别1但达到了很高的正确率缺忽视了研究者本身最为关注的情况。</p>
<h3 id="2-8-4-什么样的分类器是最好的">2.8.4 什么样的分类器是最好的</h3>
<p>​	对某一个任务，某个具体的分类器不可能同时满足或提高所有上面介绍的指标。<br>
​	如果一个分类器能正确分对所有的实例，那么各项指标都已经达到最优，但这样的分类器往往不存在。比如之前说的地震预测，既然不能百分百预测地震的发生，但实际情况中能容忍一定程度的误报。假设在1000次预测中，共有5次预测发生了地震，真实情况中有一次发生了地震，其他4次则为误报。正确率由原来的999/1000=99.9下降为996/1000=99.6。召回率由0/1=0%上升为1/1=100%。对此解释为，虽然预测失误了4次，但真的地震发生前，分类器能预测对，没有错过，这样的分类器实际意义更为重大，正是我们想要的。在这种情况下，在一定正确率前提下，要求分类器的召回率尽量高。</p>
<h2 id="2-9-逻辑回归">2.9 逻辑回归</h2>
<h3 id="2-9-1-回归划分">2.9.1 回归划分</h3>
<p>广义线性模型家族里，依据因变量不同，可以有如下划分：</p>
<p>（1）如果是连续的，就是多重线性回归。</p>
<p>（2）如果是二项分布，就是逻辑回归。</p>
<p>（3）如果是泊松（Poisson）分布，就是泊松回归。</p>
<p>（4）如果是负二项分布，就是负二项回归。</p>
<p>（5）逻辑回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最常用的就是二分类的逻辑回归。</p>
<h3 id="2-9-2-逻辑回归适用性">2.9.2 逻辑回归适用性</h3>
<p>逻辑回归可用于以下几个方面：</p>
<p>（1）用于概率预测。用于可能性预测时，得到的结果有可比性。比如根据模型进而预测在不同的自变量情况下，发生某病或某种情况的概率有多大。</p>
<p>（2）用于分类。实际上跟预测有些类似，也是根据模型，判断某人属于某病或属于某种情况的概率有多大，也就是看一下这个人有多大的可能性是属于某病。进行分类时，仅需要设定一个阈值即可，可能性高于阈值是一类，低于阈值是另一类。</p>
<p>（3）寻找危险因素。寻找某一疾病的危险因素等。</p>
<p>（4）仅能用于线性问题。只有当目标和特征是线性关系时，才能用逻辑回归。在应用逻辑回归时注意两点：一是当知道模型是非线性时，不适用逻辑回归；二是当使用逻辑回归时，应注意选择和目标为线性关系的特征。</p>
<p>（5）各特征之间不需要满足条件独立假设，但各个特征的贡献独立计算。</p>
<h3 id="2-9-3-生成模型和判别模型的区别">2.9.3 生成模型和判别模型的区别</h3>
<p>生成模型：由数据学习联合概率密度分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：P(Y|X)= P(X,Y)/ P(X)（贝叶斯概率）。基本思想是首先建立样本的联合概率概率密度模型P(X,Y)，然后再得到后验概率P(Y|X)，再利用它进行分类。典型的生成模型有朴素贝叶斯，隐马尔科夫模型等</p>
<p>判别模型：由数据直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。基本思想是有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。典型的判别模型包括k近邻，感知级，决策树，支持向量机等。这些模型的特点都是输入属性X可以直接得到后验概率P(Y|X)，输出条件概率最大的作为最终的类别（对于二分类任务来说，实际得到一个score，当score大于threshold时则为正类，否则为负类）。</p>
<p>举例：</p>
<p>判别式模型举例：要确定一个羊是山羊还是绵羊，用判别模型的方法是从历史数据中学习到模型，然后通过提取这只羊的特征来预测出这只羊是山羊的概率，是绵羊的概率。</p>
<p>生成式模型举例：利用生成模型是根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型，然后从这只羊中提取特征，放到山羊模型中看概率是多少，在放到绵羊模型中看概率是多少，哪个大就是哪个。</p>
<p>联系和区别：</p>
<pre><code>生成方法的特点：上面说到，生成方法学习联合概率密度分布P(X,Y)，所以就可以从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度。但它不关心到底划分各类的那个分类边界在哪。生成方法可以还原出联合概率分布P(Y,X)，而判别方法不能。生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快的收敛于真实模型，当存在隐变量时，仍可以用生成方法学习。此时判别方法就不能用。

判别方法的特点：判别方法直接学习的是决策函数Y=f(X)或者条件概率分布P(Y|X)。不能反映训练数据本身的特性。但它寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。直接面对预测，往往学习的准确率更高。由于直接学习P(Y|X)或P(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。
</code></pre>
<p>​	最后，由生成模型可以得到判别模型，但由判别模型得不到生成模型。</p>
<h3 id="2-9-4-逻辑回归与朴素贝叶斯有什么区别">2.9.4 逻辑回归与朴素贝叶斯有什么区别</h3>
<p>逻辑回归与朴素贝叶斯区别有以下几个方面：</p>
<p>（1）逻辑回归是判别模型， 朴素贝叶斯是生成模型，所以生成和判别的所有区别它们都有。</p>
<p>（2）朴素贝叶斯属于贝叶斯，逻辑回归是最大似然，两种概率哲学间的区别。</p>
<p>（3）朴素贝叶斯需要条件独立假设。</p>
<p>（4）逻辑回归需要求特征参数间是线性的。</p>
<h3 id="2-9-5-线性回归与逻辑回归的区别">2.9.5 线性回归与逻辑回归的区别</h3>
<p>线性回归与逻辑回归的区别如下描述：</p>
<p>（1）线性回归的样本的输出，都是连续值， $ y\in (-\infty ,+\infty )$ ，而逻辑回归中 $y\in (0,1)$ ，只能取0和1。</p>
<p>（2）对于拟合函数也有本质上的差别：</p>
<p>​	线性回归： $f(x)=\theta ^{T}x=\theta _{1}x _{1}+\theta _{2}x _{2}+...+\theta _{n}x _{n}$</p>
<p>​	逻辑回归： $f(x)=P(y=1|x;\theta )=g(\theta ^{T}x)$ ，其中， $g(z)=\frac{1}{1+e^{-z}}$</p>
<p>​	可以看出，线性回归的拟合函数，是对f(x)的输出变量y的拟合，而逻辑回归的拟合函数是对为1类样本的概率的拟合。</p>
<p>​	那么，为什么要以1类样本的概率进行拟合呢，为什么可以这样拟合呢？</p>
<p>​	 $\theta ^{T}x=0$ 就相当于是1类和0类的决策边界：</p>
<p>​	当 $\theta ^{T}x>0$ ，则y&gt;0.5；若 $\theta ^{T}x\rightarrow +\infty $ ，则 $y \rightarrow  1 $ ，即y为1类;</p>
<p>​	当 $\theta ^{T}x<0$ 0 ，则y&lt;0.5；若 $\theta ^{t}x\rightarrow -\infty $ ，则 $y \rightarrow ，即y为0类;< p>
<p>这个时候就能看出区别，在线性回归中 $\theta ^{T}x$ 为预测值的拟合函数；而在逻辑回归中 $\theta ^{T}x$ 为决策边界。下表2-3为线性回归和逻辑回归的区别。</p>
<p>​									表2-3 线性回归和逻辑回归的区别</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">线性回归</th>
<th style="text-align:center">逻辑回归</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">目的</td>
<td style="text-align:center">预测</td>
<td style="text-align:center">分类</td>
</tr>
<tr>
<td style="text-align:center">$y^{(i)}$</td>
<td style="text-align:center">未知</td>
<td style="text-align:center">（0,1）</td>
</tr>
<tr>
<td style="text-align:center">函数</td>
<td style="text-align:center">拟合函数</td>
<td style="text-align:center">预测函数</td>
</tr>
<tr>
<td style="text-align:center">参数计算方式</td>
<td style="text-align:center">最小二乘法</td>
<td style="text-align:center">极大似然估计</td>
</tr>
</tbody>
</table>
<p>下面具体解释一下：</p>
<ol>
<li>拟合函数和预测函数什么关系呢？简单来说就是将拟合函数做了一个逻辑函数的转换，转换后使得 $y^{(i)} \in (0,1)$ ;</li>
<li>最小二乘和最大似然估计可以相互替代吗？回答当然是不行了。我们来看看两者依仗的原理：最大似然估计是计算使得数据出现的可能性最大的参数，依仗的自然是Probability。而最小二乘是计算误差损失。</li>
</ol>
<h2 id="2-10-代价函数">2.10 代价函数</h2>
<h3 id="2-10-1-为什么需要代价函数">2.10.1 为什么需要代价函数</h3>
<ol>
<li>为了得到训练逻辑回归模型的参数，需要一个代价函数，通过训练代价函数来得到参数。</li>
<li>用于找到最优解的目的函数。</li>
</ol>
<h3 id="2-10-2-代价函数作用原理">2.10.2 代价函数作用原理</h3>
<p>​	在回归问题中，通过代价函数来求解最优解，常用的是平方误差代价函数。假设函数图像如图2-4所示，当参数发生变化时，假设函数状态也会随着变化。</p>
<p><img src="2.16/1.jpg" alt></p>
<p>​										图2-4   $h(x) = A + Bx$ 函数示意图</p>
<p>​	想要拟合图中的离散点，我们需要尽可能找到最优的 $A$ 和 $B$ 来使这条直线更能代表所有数据。如何找到最优解呢，这就需要使用代价函数来求解，以平方误差代价函数为例，假设函数为 $h(x)=\theta_0x$ 。<br>
​	<strong>平方误差代价函数的主要思想</strong>就是将实际数据给出的值与拟合出的线的对应值做差，求出拟合出的直线与实际的差距。在实际应用中，为了避免因个别极端数据产生的影响，采用类似方差再取二分之一的方式来减小个别数据的影响。因此，引出代价函数：</p>
 $$
J(\theta_0, \theta_1) = \frac{1}{m}\sum_{i=1}^m(h(x^{(i)})-y^{(i)})^2
$$ 
<p>​	<strong>最优解即为代价函数的最小值</strong> $\min J(\theta_0, \theta_1)$ 。如果是1个参数，代价函数一般通过二维曲线便可直观看出。如果是2个参数，代价函数通过三维图像可看出效果，参数越多，越复杂。<br>
当参数为2个时，代价函数是三维图像，如下图2-5所示。</p>
<p><img src="2.16/2.jpg" alt></p>
<p>​										图2-5  代价函数三维图像</p>
<h3 id="2-10-3-为什么代价函数要非负">2.10.3 为什么代价函数要非负</h3>
<p>​	目标函数存在一个下界，在优化过程当中，如果优化算法能够使目标函数不断减小，根据单调有界准则，这个优化算法就能证明是收敛有效的。<br>
​	只要设计的目标函数有下界，基本上都可以，代价函数非负更为方便。</p>
<h3 id="2-10-4-常见代价函数">2.10.4 常见代价函数</h3>
<p>（1）<strong>二次代价函数（quadratic cost）</strong>：</p>
 $$
J = \frac{1}{2n}\sum_x\Vert y(x)-a^L(x)\Vert^2
$$ 
<p>​	其中， $J$ 表示代价函数， $x$ 表示样本， $y$ 表示实际值， $a$ 表示输出值， $n$ 表示样本的总数。使用一个样本为例简单说明，此时二次代价函数为：</p>
 $$
J = \frac{(y-a)^2}{2}
$$ 
<p>​	假如使用梯度下降法（Gradient descent）来调整权值参数的大小，权值 $w$ 和偏置 $b$ 的梯度推导如下：</p>
 $$
\frac{\partial J}{\partial w}=(y-a)\sigma'(z)x\;,
\frac{\partial J}{\partial b}=(y-a)\sigma'(z)
$$ 
<p>其中， $z​$ 表示神经元的输入， $\sigma​$ 表示激活函数。权值 $w​$ 和偏置 $b​$ 的梯度跟激活函数的梯度成正比，激活函数的梯度越大，权值 $w​$ 和偏置 $b​$ 的大小调整得越快，训练收敛得就越快。</p>
<p><em>注</em>：神经网络常用的激活函数为sigmoid函数，该函数的曲线如下图2-6所示：</p>
<p><img src="2.18/1.jpg" alt></p>
<p>​												图2-6 sigmoid函数曲线</p>
<p>如上图所示，对0.88和0.98两个点进行比较：<br>
​	假设目标是收敛到1.0。0.88离目标1.0比较远，梯度比较大，权值调整比较大。0.98离目标1.0比较近，梯度比较小，权值调整比较小。调整方案合理。<br>
​	假如目标是收敛到0。0.88离目标0比较近，梯度比较大，权值调整比较大。0.98离目标0比较远，梯度比较小，权值调整比较小。调整方案不合理。<br>
​	原因：在使用sigmoid函数的情况下, 初始的代价（误差）越大，导致训练越慢。</p>
<p>（2）<strong>交叉熵代价函数（cross-entropy）</strong>：</p>
 $$
J = -\frac{1}{n}\sum_x[y\ln a + (1-y)\ln{(1-a)}]
$$ 
<p>其中， $J$ 表示代价函数， $x$ 表示样本， $y$ 表示实际值， $a$ 表示输出值， $n$ 表示样本的总数。<br>
权值 $w$ 和偏置 $b​$ 的梯度推导如下：</p>
 $$
\frac{\partial J}{\partial w_j}=\frac{1}{n}\sum_{x}x_j(\sigma{(z)}-y)\;，
\frac{\partial J}{\partial b}=\frac{1}{n}\sum_{x}(\sigma{(z)}-y)
$$ 
<p>当误差越大时，梯度就越大，权值 $w$ 和偏置 $b$ 调整就越快，训练的速度也就越快。<br>
<strong>二次代价函数适合输出神经元是线性的情况，交叉熵代价函数适合输出神经元是S型函数的情况。</strong></p>
<p>（3）<strong>对数似然代价函数（log-likelihood cost）</strong>：<br>
对数似然函数常用来作为softmax回归的代价函数。深度学习中普遍的做法是将softmax作为最后一层，此时常用的代价函数是对数似然代价函数。<br>
对数似然代价函数与softmax的组合和交叉熵与sigmoid函数的组合非常相似。对数似然代价函数在二分类时可以化简为交叉熵代价函数的形式。<br>
在tensorflow中：<br>
与sigmoid搭配使用的交叉熵函数：<code>tf.nn.sigmoid_cross_entropy_with_logits()</code>。<br>
与softmax搭配使用的交叉熵函数：<code>tf.nn.softmax_cross_entropy_with_logits()</code>。<br>
在pytorch中：<br>
与sigmoid搭配使用的交叉熵函数：<code>torch.nn.BCEWithLogitsLoss()</code>。<br>
与softmax搭配使用的交叉熵函数：<code>torch.nn.CrossEntropyLoss()</code>。</p>
<p>对数似然函数：</p>
<p>​	我们将似然函数作为机器学习模型的损失函数，并且用在分类问题中。这时似然函数是直接作用于模型的输出的（损失函数就是为了衡量当前参数下model的预测值predict距离真实值label的大小，所以似然函数用作损失函数时当然也是为了完成该任务），所以对于似然函数来说，这里的样本集就成了label集（而不是机器学习意义上的样本集X了），这里的参数也不是机器学习model 的参数，而是predict值。</p>
<p>其实作为损失函数的似然函数并不关心你当前的机器学习model的参数是怎样的，毕竟它此时所接收的输入只有两部分：<strong>1、predict。2、label 。3、分布模型（predict服从的分布）</strong>。</p>
<p>显然这里的label就是似然函数的观测值，即样本集。<strong>而它眼里的模型，当然就是predict这个随机变量所服从的概率分布模型。它的目的，就是衡量predict背后的模型对于当前观测值的解释程度。而每个样本的predict值，恰恰就是它所服从的分布模型的参数。</strong></p>
<p>比如此时我们的机器学习任务是一个4个类别的分类任务，机器学习model的输出就是当前样本X下的每个类别的概率，如predict=[0.1, 0.1, 0.7, 0.1]，而该样本的标签是类别3，表示成向量就是label=[0, 0, 1, 0]。那么label=[0, 0, 1, 0]就是似然函数眼里的样本，然后我们可以假设predict这个随机变量背后的模型是<strong>单次观测下的多项式分布</strong>，（<strong>因为softmax本身是基于多项式分布的</strong>）。</p>
<p>回顾：</p>
<p>伯努利分布，也叫做（0，1）分布，贝努利分布可以看成是将一枚硬币（只有正反两个面，代表两个类别）向上扔出，出现某个面（类别）的概率情况，因此其概率密度函数为：</p>
 $$
f(x)=p^x(1-p)^{1-x}=
\begin{cases}
p,& x=1\\
q,& x=0
\end{cases}
$$ 
<p>这是理解似然函数做损失函数的关键！另外，贝努利分布的模型参数就是其中一个类别的发生概率。</p>
<p>而二项分布呢，就是将贝努利实验重复n次（各次实验之间是相互独立的）。</p>
<p>而多项式分布呢，就是将二项分布推广到多个面（类别）。</p>
<p><strong>所以，单次观测下的多项式分布就是贝努利分布的多类推广！即：</strong></p>
 $$
f_{mulit}(x;p)=\prod_{i=1}^C p_{i}^{xi}
$$ 
<p>其中，C代表类别数。p代表向量形式的模型参数，即各个类别的发生概率，如p=[0.1, 0.1, 0.7, 0.1]，则p1=0.1, p3=0.7等。即，<strong>多项式分布的模型参数就是各个类别的发生概率！<strong>x代表</strong>one-hot形式</strong>的观测值，如x=类别3，则x=[0, 0, 1, 0]。xi代表x的第i个元素，比如x=类别3时，x1=0，x2=0，x3=1，x4=0。</p>
<p>想一下，机器学习model对某个样本的输出，就代表各个类别发生的概率。但是，对于当前<strong>这一个</strong>样本而言，它肯定只能有<strong>一个类别</strong>，所以这一个样本就可以看成是一次实验（观察），而这次实验（观察）的结果要服从上述各个类别发生的概率，那不就是服从多项式分布嘛！而且是单次观察！各个类别发生的概率predict当然就是这个多项式分布的参数。</p>
<p><strong>总结一下，对于多类分类问题，似然函数就是衡量当前这个以predict为参数的单次观测下的多项式分布模型与样本值label之间的似然度。</strong></p>
<p>所以，根据似然函数的定义，单个样本的似然函数即：</p>
 $$
L = f_{mulit}(label;predict)
$$ 
<p>所以，整个样本集（或者一个batch）的似然函数即：</p>
 $$
L=\prod_{X}f_{multi}(label;predict)= \prod_{X}\prod_{i=1}^{C}predict(i)^{label(i)}
$$ 
<p>所以在累乘号前面加上log函数后，就成了所谓的对数似然函数：</p>
 $$
L=\sum_{X}\sum_{i=1}^{C}label(i)log(predict(i))
$$ 
<p>而最大化对数似然函数就等效于最小化负对数似然函数，所以前面加个负号就和交叉熵的形式相同的了。</p>
<p>交叉熵定义：对于某种分布的随机变量X~p(x), 有一个模型q(x)用于近似p(x)的概率分布，则分布X与模型q之间的交叉熵即：</p>
 $$
H(X,q)=-\sum_{x}p(x)logq(x)
$$ 
<p>这里X的分布模型即样本集label的真实分布模型，这里模型q(x)即想要模拟真实分布模型的机器学习模型。可以说交叉熵是直接衡量两个分布，或者说两个model之间的差异。而似然函数则是解释以model的输出为参数的某分布模型对样本集的解释程度。因此，可以说这两者是“同貌不同源”，但是“殊途同归”啦。</p>
<p>tips：</p>
<p>最大似然估计：</p>
<p>给定一堆数据，假如我们知道它是从某一种分布中随机取出来的，可是我们并不知道这个分布具体的参，即“模型已定，参数未知”。例如，我们知道这个分布是正态分布，但是不知道均值和方差；或者是二项分布，但是不知道均值。最大似然估计（MLE，Maximum Likelihood Estimation）就可以用来估计模型的参数。<strong>MLE的目标是找出一组参数，使得模型产生出观测数据的概率最大。</strong></p>
<h3 id="2-10-5-为什么用交叉熵代替二次代价函数">2.10.5 为什么用交叉熵代替二次代价函数</h3>
<p>（1）<strong>为什么不用二次方代价函数</strong><br>
由上一节可知，权值 $w$ 和偏置 $b$ 的偏导数为 $\frac{\partial J}{\partial w}=(a-y)\sigma'(z)x$ ， $\frac{\partial J}{\partial b}=(a-y)\sigma'(z)$ ， 偏导数受激活函数的导数影响，sigmoid函数导数在输出接近0和1时非常小，会导致一些实例在刚开始训练时学习得非常慢。</p>
<p>（2）<strong>为什么要用交叉熵</strong><br>
交叉熵函数权值 $w$ 和偏置 $b$ 的梯度推导为：</p>
 $$
\frac{\partial J}{\partial w_j}=\frac{1}{n}\sum_{x}x_j(\sigma{(z)}-y)\;，
\frac{\partial J}{\partial b}=\frac{1}{n}\sum_{x}(\sigma{(z)}-y)
$$ 
<p>由以上公式可知，权重学习的速度受到 $\sigma{(z)}-y$ 影响，更大的误差，就有更快的学习速度，避免了二次代价函数方程中因 $\sigma'{(z)}$ 导致的学习缓慢的情况。</p>
<h2 id="2-11-损失函数">2.11 损失函数</h2>
<h3 id="2-11-1-什么是损失函数">2.11.1 什么是损失函数</h3>
<p>​	损失函数（Loss Function）又叫做误差函数，用来衡量算法的运行情况，估量模型的预测值与真实值的不一致程度，是一个非负实值函数，通常使用 $
L(Y, f(x))​$ 来表示。损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。</p>
<h3 id="2-11-2-常见的损失函数">2.11.2 常见的损失函数</h3>
<p>​	机器学习通过对算法中的目标函数进行不断求解优化，得到最终想要的结果。分类和回归问题中，通常使用损失函数或代价函数作为目标函数。<br>
​	损失函数用来评价预测值和真实值不一样的程度。通常损失函数越好，模型的性能也越好。<br>
​	损失函数可分为经验风险损失函数和结构风险损失函数。经验风险损失函数指预测结果和实际结果的差别，结构风险损失函数是在经验风险损失函数上加上正则项。<br>
​	下面介绍常用的损失函数：</p>
<p>（1）<strong>0-1损失函数</strong><br>
如果预测值和目标值相等，值为0，如果不相等，值为1。</p>
 $$
L(Y, f(x)) =
\begin{cases}
1,& Y\ne f(x)\\
0,& Y = f(x)
\end{cases}
$$ 
<p>一般的在实际使用中，相等的条件过于严格，可适当放宽条件：</p>
 $$
L(Y, f(x)) =
\begin{cases}
1,& |Y-f(x)|\geqslant T\\
0,& |Y-f(x)|< T
\end{cases}
$$ 
<p>（2）<strong>绝对值损失函数</strong><br>
和0-1损失函数相似，绝对值损失函数表示为：</p>
 $$
L(Y, f(x)) = |Y-f(x)|​
$$ 
<p>（3）<strong>平方损失函数</strong></p>
 $$
L(Y, f(x)) = \sum_N{(Y-f(x))}^2
$$ 
<p>这点可从最小二乘法和欧几里得距离角度理解。最小二乘法的原理是，最优拟合曲线应该使所有点到回归直线的距离和最小。</p>
<p>（4）<strong>对数损失函数</strong></p>
 $$
L(Y, P(Y|X)) = -\log{P(Y|X)}=-\frac{1}{N}\sum_{i=1}^N\sum_{j=1}^M y_{ij}log(p_{ij})
$$ 
<p>​	其中, Y 为输出变量, X为输入变量, L 为损失函数. N为输入样本量, M为可能的类别数,  $y_{ij}$  是一个二值指标, 表示类别 j 是否是输入实例 xi 的真实类别.  $p_{ij}$  为模型或分类器预测输入实例 xi 属于类别 j 的概率.</p>
<p>常见的逻辑回归使用的就是对数损失函数，有很多人认为逻辑回归的损失函数是平方损失，其实不然。逻辑回归它假设样本服从伯努利分布（0-1分布），进而求得满足该分布的似然函数，接着取对数求极值等。逻辑回归推导出的经验风险函数是最小化负的似然函数，从损失函数的角度看，就是对数损失函数。形式上等价于二分类的交叉熵损失函数。</p>
<p>（6）<strong>指数损失函数</strong><br>
指数损失函数的标准形式为：</p>
 $$
L(Y, f(x)) = \exp(-Yf(x))
$$ 
<p>例如AdaBoost就是以指数损失函数为损失函数。</p>
<p>（7）<strong>Hinge损失函数</strong><br>
Hinge损失函数的标准形式如下：</p>
 $$
L(y) = \max{(0, 1-ty)}
$$ 
<p>统一的形式：</p>
 $$
L(Y, f(x)) = \max{(0, Yf(x))}
$$ 
<p>其中y是预测值，范围为(-1,1)，t为目标值，其为-1或1。</p>
<p>在线性支持向量机中，最优化问题可等价于</p>
 $$
\underset{\min}{w,b}\sum_{i=1}^N (1-y_i(wx_i+b))+\lambda\Vert w\Vert ^2
$$ 
<p>上式相似于下式</p>
 $$
\frac{1}{m}\sum_{i=1}^{N}l(wx_i+by_i) + \Vert w\Vert ^2
$$ 
<p>其中 $l(wx_i+by_i)$ 是Hinge损失函数， $\Vert w\Vert ^2$ 可看做为正则化项。</p>
<h3 id="2-11-3-逻辑回归为什么使用对数损失函数">2.11.3 逻辑回归为什么使用对数损失函数</h3>
<p>假设逻辑回归模型</p>
 $$
P(y=1|x;\theta)=\frac{1}{1+e^{-\theta^{T}x}}
$$ 
<p>假设逻辑回归模型的概率分布是伯努利分布，其概率质量函数为：</p>
 $$
P(X=n)=
\begin{cases}
1-p, n=0\\
 p,n=1
\end{cases}
$$ 
<p>其似然函数为：</p>
 $$
L(\theta)=\prod_{i=1}^{m}
P(y=1|x_i)^{y_i}P(y=0|x_i)^{1-y_i}
$$ 
<p>对数似然函数为：</p>
 $$
\ln L(\theta)=\sum_{i=1}^{m}[y_i\ln{P(y=1|x_i)}+(1-y_i)\ln{P(y=0|x_i)}]\\
  =\sum_{i=1}^m[y_i\ln{P(y=1|x_i)}+(1-y_i)\ln(1-P(y=1|x_i))]
$$ 
<p>对数函数在单个数据点上的定义为：</p>
 $$
cost(y,p(y|x))=-y\ln{p(y|x)-(1-y)\ln(1-p(y|x))}
$$ 
<p>则全局样本损失函数为：</p>
 $$
cost(y,p(y|x)) = -\sum_{i=1}^m[y_i\ln p(y_i|x_i)+(1-y_i)\ln(1-p(y_i|x_i))]
$$ 
<p>由此可看出，对数损失函数与极大似然估计的对数似然函数本质上是相同的。所以逻辑回归直接采用对数损失函数。</p>
<h3 id="2-11-4-对数损失函数是如何度量损失的">2.11.4 对数损失函数是如何度量损失的</h3>
<p>​	例如，在高斯分布中，我们需要确定均值和标准差。<br>
​	如何确定这两个参数？最大似然估计是比较常用的方法。最大似然的目标是找到一些参数值，这些参数值对应的分布可以最大化观测到数据的概率。<br>
​	因为需要计算观测到所有数据的全概率，即所有观测到的数据点的联合概率。现考虑如下简化情况：</p>
<p>（1）假设观测到每个数据点的概率和其他数据点的概率是独立的。</p>
<p>（2）取自然对数。<br>
假设观测到单个数据点 $x_i(i=1,2,...n)$ 的概率为：</p>
 $$
P(x_i;\mu,\sigma)=\frac{1}{\sigma \sqrt{2\pi}}\exp 
		\left( - \frac{(x_i-\mu)^2}{2\sigma^2} \right)
$$ 
<p>（3）其联合概率为：</p>
 $$
P(x_1,x_2,...,x_n;\mu,\sigma)=\frac{1}{\sigma \sqrt{2\pi}}\exp 
		\left( - \frac{(x_1-\mu)^2}{2\sigma^2} \right) \\ \times
		 \frac{1}{\sigma \sqrt{2\pi}}\exp 
		\left( - \frac{(x_2-\mu)^2}{2\sigma^2} \right) \times ... \times
		\frac{1}{\sigma \sqrt{2\pi}}\exp 
		\left( - \frac{(x_n-\mu)^2}{2\sigma^2} \right)
$$ 
<p>​	对上式取自然对数，可得：</p>
 $$
 \ln(P(x_1,x_2,...x_n;\mu,\sigma))=
 		\ln \left(\frac{1}{\sigma \sqrt{2\pi}} \right) 
 		 - \frac{(x_1-\mu)^2}{2\sigma^2}  \\ +
 		 \ln \left( \frac{1}{\sigma \sqrt{2\pi}} \right) 
 		 - \frac{(x_2-\mu)^2}{2\sigma^2} +...+
 		 \ln \left( \frac{1}{\sigma \sqrt{2\pi}} \right) 
 		 - \frac{(x_n-\mu)^2}{2\sigma^2}
$$ 
<p>根据对数定律，上式可以化简为：</p>
 $$
\ln(P(x_1,x_2,...x_n;\mu,\sigma))=-n\ln(\sigma)-\frac{n}{2} \ln(2\pi)\\
     	-\frac{1}{2\sigma^2}[(x_1-\mu)^2+(x_2-\mu)^2+...+(x_n-\mu)^2]
$$ 
<p>然后求导为：</p>
 $$
\frac{\partial\ln(P(x_1,x_2,...,x_n;\mu,\sigma))}{\partial\mu}=
     			\frac{n}{\sigma^2}[\mu - (x_1+x_2+...+x_n)]
$$ 
<p>​     上式左半部分为对数损失函数。损失函数越小越好，因此我们令等式左半的对数损失函数为0，可得：</p>
 $$
\mu=\frac{x_1+x_2+...+x_n}{n}
$$ 
<p>同理，可计算 $\sigma ​$ 。</p>
<h2 id="2-12-梯度下降">2.12 梯度下降</h2>
<h3 id="2-12-1-机器学习中为什么需要梯度下降">2.12.1 机器学习中为什么需要梯度下降</h3>
<p>梯度下降是机器学习中常见优化算法之一，梯度下降法有以下几个作用：</p>
<p>（1）梯度下降是迭代法的一种，可以用于求解最小二乘问题。</p>
<p>（2）在求解机器学习算法的模型参数，即无约束优化问题时，主要有梯度下降法（Gradient Descent）和最小二乘法。</p>
<p>（3）在求解损失函数的最小值时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数和模型参数值。</p>
<p>（4）如果我们需要求解损失函数的最大值，可通过梯度上升法来迭代。梯度下降法和梯度上升法可相互转换。</p>
<p>（5）在机器学习中，梯度下降法主要有随机梯度下降法和批量梯度下降法。</p>
<h3 id="2-12-2-梯度下降法缺点">2.12.2 梯度下降法缺点</h3>
<p>梯度下降法缺点有以下几点：</p>
<p>（1）靠近极小值时收敛速度减慢。</p>
<p>（2）直线搜索时可能会产生一些问题。</p>
<p>（3）可能会“之字形”地下降。</p>
<p>梯度概念也有需注意的地方：</p>
<p>（1）梯度是一个向量，即有方向有大小。</p>
<p>（2）梯度的方向是最大方向导数的方向。</p>
<p>（3）梯度的值是最大方向导数的值。</p>
<h3 id="2-12-3-梯度下降法直观理解">2.12.3 梯度下降法直观理解</h3>
<p>梯度下降法经典图示如下图2.7所示：</p>
<p><img src="2.25/1.png" alt></p>
<p>​									图2.7 梯度下降法经典图示</p>
<p>​	形象化举例，由上图2.7所示，假如最开始，我们在一座大山上的某处位置，因为到处都是陌生的，不知道下山的路，所以只能摸索着根据直觉，走一步算一步，在此过程中，每走到一个位置的时候，都会求解当前位置的梯度，沿着梯度的负方向，也就是当前最陡峭的位置向下走一步，然后继续求解当前位置梯度，向这一步所在位置沿着最陡峭最易下山的位置走一步。不断循环求梯度，就这样一步步地走下去，一直走到我们觉得已经到了山脚。当然这样走下去，有可能我们不能走到山脚，而是到了某一个局部的山势低处。<br>
​	由此，从上面的解释可以看出，梯度下降不一定能够找到全局的最优解，有可能是一个局部的最优解。当然，如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。</p>
<p><strong>核心思想归纳</strong>：</p>
<p>（1）初始化参数，随机选取取值范围内的任意数；</p>
<p>（2）迭代操作：<br>
a）计算当前梯度；<br>
b）修改新的变量；<br>
c）计算朝最陡的下坡方向走一步；<br>
d）判断是否需要终止，如否，返回a）；</p>
<p>（3）得到全局最优解或者接近全局最优解。</p>
<h3 id="2-12-4-梯度下降法算法描述">2.12.4 梯度下降法算法描述</h3>
<p>梯度下降法算法步骤如下：</p>
<p>（1）确定优化模型的假设函数及损失函数。<br>
​	举例，对于线性回归，假设函数为：</p>
 $$
  h_\theta(x_1,x_2,...,x_n)=\theta_0+\theta_1x_1+...+\theta_nx_n
$$ 
<p>其中， $\theta_i,x_i(i=0,1,2,...,n)$ 分别为模型参数、每个样本的特征值。<br>
对于假设函数，损失函数为：</p>
 $$
  J(\theta_0,\theta_1,...,\theta_n)=\frac{1}{2m}\sum^{m}_{j=0}(h_\theta (x^{(j)}_0
  	,x^{(j)}_1,...,x^{(j)}_n)-y_j)^2
$$ 
<p>（2）相关参数初始化。<br>
​	主要初始化 ${\theta}_i$ 、算法迭代步长 ${\alpha} $ 、终止距离 ${\zeta} $ 。初始化时可以根据经验初始化，即 ${\theta} $ 初始化为0，步长 ${\alpha} $ 初始化为1。当前步长记为 ${\varphi}_i $ 。当然，也可随机初始化。</p>
<p>（3）迭代计算。</p>
<p>​	1）计算当前位置时损失函数的梯度，对 ${\theta}_i $ ，其梯度表示为：</p>
 $$
\frac{\partial}{\partial \theta_i}J({\theta}_0,{\theta}_1,...,{\theta}_n)=\frac{1}{2m}\sum^{m}_{j=0}(h_\theta (x^{(j)}_0
	,x^{(j)}_1,...,x^{(j)}_n)-y_j)^2
$$ 
<p>​	2）计算当前位置下降的距离。</p>
 $$
{\varphi}_i={\alpha} \frac{\partial}{\partial \theta_i}J({\theta}_0,{\theta}_1,...,{\theta}_n)
$$ 
<p>​	3）判断是否终止。<br>
​	确定是否所有 ${\theta}_i$ 梯度下降的距离 ${\varphi}_i$ 都小于终止距离 ${\zeta}$ ，如果都小于 ${\zeta}$ ，则算法终止，当然的值即为最终结果，否则进入下一步。<br>
​	4）更新所有的 ${\theta}_i$ ，更新后的表达式为：</p>
 $$
{\theta}_i={\theta}_i-\alpha \frac{\partial}{\partial \theta_i}J({\theta}_0,{\theta}_1,...,{\theta}_n)
$$ 
 $$
\theta_i=\theta_i - \alpha \frac{1}{m} \sum^{m}_{j=0}(h_\theta (x^{(j)}_0
	,x^{(j)}_1,...,x^{(j)}_n)-y_j)x^{(j)}_i
$$ 
<p>​	5）令上式 $x^{(j)}_0=1$ ，更新完毕后转入1)。<br>
​	由此，可看出，当前位置的梯度方向由所有样本决定，上式中  $\frac{1}{m}​$ 、 $\alpha \frac{1}{m}​$  的目的是为了便于理解。</p>
<h3 id="2-12-5-如何对梯度下降法进行调优">2.12.5 如何对梯度下降法进行调优</h3>
<p>实际使用梯度下降法时，各项参数指标不能一步就达到理想状态，对梯度下降法调优主要体现在以下几个方面：</p>
<p>（1）<strong>算法迭代步长 $\alpha$ 选择。</strong><br>
在算法参数初始化时，有时根据经验将步长初始化为1。实际取值取决于数据样本。可以从大到小，多取一些值，分别运行算法看迭代效果，如果损失函数在变小，则取值有效。如果取值无效，说明要增大步长。但步长太大，有时会导致迭代速度过快，错过最优解。步长太小，迭代速度慢，算法运行时间长。</p>
<p>（2）<strong>参数的初始值选择。</strong><br>
初始值不同，获得的最小值也有可能不同，梯度下降有可能得到的是局部最小值。如果损失函数是凸函数，则一定是最优解。由于有局部最优解的风险，需要多次用不同初始值运行算法，关键损失函数的最小值，选择损失函数最小化的初值。</p>
<p>（3）<strong>标准化处理。</strong><br>
由于样本不同，特征取值范围也不同，导致迭代速度慢。为了减少特征取值的影响，可对特征数据标准化，使新期望为0，新方差为1，可节省算法运行时间。</p>
<h3 id="2-12-6-随机梯度和批量梯度区别">2.12.6 随机梯度和批量梯度区别</h3>
<p>​	随机梯度下降（SGD）和批量梯度下降（BGD）是两种主要梯度下降法，其目的是增加某些限制来加速运算求解。<br>
下面通过介绍两种梯度下降法的求解思路，对其进行比较。<br>
假设函数为：</p>
 $$
h_\theta (x_0,x_1,...,x_3) = \theta_0 x_0 + \theta_1 x_1 + ... + \theta_n x_n
$$ 
<p>损失函数为：</p>
 $$
J(\theta_0, \theta_1, ... , \theta_n) = 
			\frac{1}{2m} \sum^{m}_{j=0}(h_\theta (x^{j}_0
	,x^{j}_1,...,x^{j}_n)-y^j)^2
$$ 
<p>其中， $m​$ 为样本个数， $j​$ 为参数个数。</p>
<p>1、 <strong>批量梯度下降的求解思路如下：</strong><br>
a) 得到每个 $ \theta ​$ 对应的梯度：</p>
 $$
\frac{\partial}{\partial \theta_i}J({\theta}_0,{\theta}_1,...,{\theta}_n)=\frac{1}{m}\sum^{m}_{j=0}(h_\theta (x^{j}_0
	,x^{j}_1,...,x^{j}_n)-y^j)x^{j}_i
$$ 
<p>b) 由于是求最小化风险函数，所以按每个参数  $ \theta ​$  的梯度负方向更新  $ \theta_i ​$  ：</p>
 $$
\theta_i=\theta_i - \frac{1}{m} \sum^{m}_{j=0}(h_\theta (x^{j}_0
	,x^{j}_1,...,x^{j}_n)-y^j)x^{j}_i
$$ 
<p>c) 从上式可以注意到，它得到的虽然是一个全局最优解，但每迭代一步，都要用到训练集所有的数据，如果样本数据很大，这种方法迭代速度就很慢。<br>
相比而言，随机梯度下降可避免这种问题。</p>
<p>2、<strong>随机梯度下降的求解思路如下：</strong><br>
a) 相比批量梯度下降对应所有的训练样本，随机梯度下降法中损失函数对应的是训练集中每个样本的粒度。<br>
损失函数可以写成如下这种形式，</p>
 $$
J(\theta_0, \theta_1, ... , \theta_n) = 
			\frac{1}{m} \sum^{m}_{j=0}(y^j - h_\theta (x^{j}_0
			,x^{j}_1,...,x^{j}_n))^2 = 
			\frac{1}{m} \sum^{m}_{j=0} cost(\theta,(x^j,y^j))
$$ 
<p>b）对每个参数  $ \theta​$  按梯度方向更新  $ \theta​$ ：</p>
 $$
\theta_i = \theta_i + (y^j - h_\theta (x^{j}_0, x^{j}_1, ... ,x^{j}_n))
$$ 
<p>c) 随机梯度下降是通过每个样本来迭代更新一次。<br>
随机梯度下降伴随的一个问题是噪音较批量梯度下降要多，使得随机梯度下降并不是每次迭代都向着整体最优化方向。</p>
<p><strong>小结：</strong><br>
随机梯度下降法、批量梯度下降法相对来说都比较极端，简单对比如下：</p>
<table>
<thead>
<tr>
<th style="text-align:center">方法</th>
<th style="text-align:left">特点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">批量梯度下降</td>
<td style="text-align:left">a）采用所有数据来梯度下降。<br>b）批量梯度下降法在样本量很大的时候，训练速度慢。</td>
</tr>
<tr>
<td style="text-align:center">随机梯度下降</td>
<td style="text-align:left">a）随机梯度下降用一个样本来梯度下降。<br>b）训练速度很快。<br>c）随机梯度下降法仅仅用一个样本决定梯度方向，导致解有可能不是全局最优。<br>d）收敛速度来说，随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。</td>
</tr>
</tbody>
</table>
<p>下面介绍能结合两种方法优点的小批量梯度下降法。</p>
<p>3、 <strong>小批量（Mini-Batch）梯度下降的求解思路如下</strong><br>
对于总数为 $m$ 个样本的数据，根据样本的数据，选取其中的 $n(1< n< m)$ 个子样本来迭代。其参数 $\theta$ 按梯度方向更新 $\theta_i$ 公式如下：</p>
 $$
\theta_i = \theta_i - \alpha \sum^{t+n-1}_{j=t}
		( h_\theta (x^{j}_{0}, x^{j}_{1}, ... , x^{j}_{n} ) - y^j ) x^{j}_{i}
$$ 
<h3 id="2-12-7-各种梯度下降法性能比较">2.12.7 各种梯度下降法性能比较</h3>
<p>​	下表简单对比随机梯度下降（SGD）、批量梯度下降（BGD）、小批量梯度下降（Mini-batch GD）、和Online GD的区别：</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">BGD</th>
<th style="text-align:center">SGD</th>
<th style="text-align:center">Mini-batch GD</th>
<th style="text-align:center">Online GD</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">训练集</td>
<td style="text-align:center">固定</td>
<td style="text-align:center">固定</td>
<td style="text-align:center">固定</td>
<td style="text-align:center">实时更新</td>
</tr>
<tr>
<td style="text-align:center">单次迭代样本数</td>
<td style="text-align:center">整个训练集</td>
<td style="text-align:center">单个样本</td>
<td style="text-align:center">训练集的子集</td>
<td style="text-align:center">根据具体算法定</td>
</tr>
<tr>
<td style="text-align:center">算法复杂度</td>
<td style="text-align:center">高</td>
<td style="text-align:center">低</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">低</td>
</tr>
<tr>
<td style="text-align:center">时效性</td>
<td style="text-align:center">低</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">高</td>
</tr>
<tr>
<td style="text-align:center">收敛性</td>
<td style="text-align:center">稳定</td>
<td style="text-align:center">不稳定</td>
<td style="text-align:center">较稳定</td>
<td style="text-align:center">不稳定</td>
</tr>
</tbody>
</table>
<p>BGD、SGD、Mini-batch GD，前面均已讨论过，这里介绍一下Online GD。</p>
<p>​	Online GD于Mini-batch GD/SGD的区别在于，所有训练数据只用一次，然后丢弃。这样做的优点在于可预测最终模型的变化趋势。</p>
<p>​	Online GD在互联网领域用的较多，比如搜索广告的点击率（CTR）预估模型，网民的点击行为会随着时间改变。用普通的BGD算法（每天更新一次）一方面耗时较长（需要对所有历史数据重新训练）；另一方面，无法及时反馈用户的点击行为迁移。而Online GD算法可以实时的依据网民的点击行为进行迁移。</p>
<h2 id="2-13-自然梯度法">2.13 自然梯度法</h2>
<p><strong>（贡献者：郜泉凯－华南理工大学）</strong></p>
<h3 id="2-13-1-为什么我们需要自然梯度">2.13.1 为什么我们需要自然梯度</h3>
<p>传统的梯度下降方法是在欧氏空间进行、并与时序过程结合的优化方法，但这样的更新过程无法度量由于参数变化引起的概率属性的变化（这一点也可以认为是传统梯度下降方法的缺点）。在如强化学习等很多应用领域关注模型输出的概率分布，优化过程常常需要在一定概率属性的约束下完成，这就需要自然梯度。</p>
<h3 id="2-12-2-如何定义自然梯度">2.12.2 如何定义自然梯度</h3>
<p>若度量模型参数变化引起的概率分布变化，常用的“距离”度量是KL散度（Kullback-Leibler divergence）。设模型概率分布为 $p(x;\theta)$ ，其与参数变动后的概率分布间的KL散度为：</p>
 $$
D_{KL}(p(x;\theta)||p(x;\theta+\delta\theta))=\int p(x;\theta)log\frac {p(x;\theta)}{p(x;\theta+\delta\theta)}dx
$$ 
<p>我们令 $f(\theta+\delta\theta)=log p(x;\theta+\delta\theta)$ ，做泰勒展开取二阶近似（忽略高阶余项）得到：</p>
 $$
f(\theta+\delta\theta)\approx f(\theta)+\delta\theta^T\frac{\partial f(\theta)}{\partial\theta}+\frac{1}{2}\delta\theta^T\frac{\partial f(\theta)}{\partial\theta}\frac{\partial f(\theta)^T}{\partial\theta}\delta\theta
$$ 
<p>带入到 $D_{KL}(p(x;\theta)||p(x;\theta+\delta\theta))$ 中可得到：</p>
 $$
\begin{eqnarray}
D_{KL}(p(x;\theta)||p(x;\theta+\delta\theta))&=&\int p(x;\theta)(f(\theta)-f(\theta+\delta\theta))dx\\
&=&-\int p(x;\theta)(\delta\theta^T\frac{\partial f(\theta)}{\partial\theta}+\frac{1}{2}\delta\theta^T\frac{\partial f(\theta)}{\partial\theta}\frac{\partial f(\theta)^T}{\partial\theta}\delta\theta)dx\\
&=&-\delta\theta^T\int p(x;\theta)\frac{\partial logp(x;\theta)}{\partial\theta}dx\\
&-&\frac{1}{2}\delta\theta^T\int p(x;\theta)\frac{\partial f(\theta)}{\partial\theta}\frac{\partial f(\theta)^T}{\partial\theta}dx\delta\theta\\
&=&-\delta\theta^T\int p(x;\theta)\frac{\frac{\partial p(x;\theta)}{\partial\theta}}{p(x;\theta)}dx-\frac{1}{2}\delta\theta^TG\delta\theta\\
&=&-\frac{1}{2}\delta\theta^TG\delta\theta
\end{eqnarray}
$$ 
<p>我们记在KL散度意义下的参数增量为 $\delta\theta_G$ ，接下来我们寻求在 $||\delta\theta_G||^2=\epsilon$ 约束下 $\delta\theta_G$ 的方向，使得目标函数 $J(\theta)$ 下降最快,即 $J(\theta+\delta\theta)-J(\theta)$ 最大。应用拉格朗日乘子法：</p>
 $$
\max_{\delta\theta}J(\theta+\delta\theta)-J(\theta)-\lambda(||\delta\theta_G||^2-\epsilon)
$$ 
<p>应用一阶泰勒展开等价于:</p>
 $$
\max_{\delta\theta}\nabla \delta\theta^T J(\theta)-\frac{1}{2}\lambda\delta\theta^TG\delta\theta
$$ 
<p>对 $\delta\theta$ 求导得 $\nabla J(\theta)-\lambda G\delta\theta=0$ ，即 $\delta\theta=\frac{1}{\lambda}G^{-1}\nabla J(\theta)$ ，其中 $G^{-1}\nabla J(\theta)$ 称为自然梯度，相应的自然梯度下降公式为 $\theta_{k+1}=\theta_k-\alpha_kG^{-1}(\theta_k)\nabla J(\theta_K)$ 。</p>
<h3 id="2-12-3-Fisher信息矩阵的意义">2.12.3 Fisher信息矩阵的意义</h3>
<p>首先我们对一个模型进行建模，成为以 $\theta$ 为参数的概率分布 $p(x;\theta)$ 。为求出一个合理的 $\theta$ 我们需要一个评分函数（score function）： $s(\theta)=\nabla_{\theta}logp(x;\theta)$ ，意为对数似然的梯度，当分数为0时（对数似然梯度为0），对数似然达到极值。对评分函数求关于 $p(x;\theta)$ 数学期望 $p_E$ 不难发现期望为0。接下来求估计误差的界，我们用评分函数的方差来确定，即 $E_{p(x;\theta)}[(s(\theta)-p_E)(s(\theta-p_E)^T)]$ 。带入评分函数的数学表达形式则等价于Fisher信息矩阵 $G(\theta)=\int p(x;\theta)\frac{\partial f(\theta)}{\partial\theta}\frac{\partial f(\theta)^T}{\partial\theta}dx$ 。特别地，Fisher信息矩阵与评分函数 $\nabla_{\theta}logp(x;\theta)$ 的Hessian似然的负数等价。</p>
<p>证明：首先求出评分函数的Hessian矩阵，由梯度的Jacobian决定</p>
 $$
\begin{eqnarray}
H_{logp(x;\theta)}&=&J(\frac{\nabla p(x;\theta)}{p(x;\theta)})\\
&=&\frac{\frac{\partial\nabla p(x;\theta)}{\partial\theta}p(x;\theta)-\nabla p(x;\theta)\nabla p(x;\theta)^T}{p(x;\theta)p(x;\theta)}\\
&=&\frac{H_{p(x;\theta)}p(x;\theta)}{p(x;\theta)p(x;\theta)}-\frac{\nabla p(x;\theta)\nabla p(x;\theta)^T}{p(x;\theta)p(x;\theta)}\\
\end{eqnarray}
$$ 
<p>等式两边同时求关于 $p(x;\theta)$ 的数学期望：</p>
 $$
\begin{eqnarray}
E_{p(x;\theta)}[H_{logp(x;\theta)}] &=& E_{p(x;\theta)}(\frac{H_{p(x;\theta)}p(x;\theta)}{p(x;\theta)p(x;\theta)})-G\\
&=&\int\frac{H_{p(x;\theta)}}{p(x;\theta)}p(x;\theta)dx-G\\
&=&\nabla^2\int p(x;\theta)dx-G\\
&=&-G
\end{eqnarray}
$$ 
<p>而Hessian矩阵刻画着对数似然函数的曲率，所以本质上自然梯度下降法是在一个消除了不同概率分布的曲率后，在同一个“平坦”曲面上进行迭代更新，步长等于原概率分布空间的步长按照曲率折合到新的“平坦曲面”的大小。</p>
<p>值得注意的一点是，一般来说似然函数获取很难，在实际问题中，我们可以用采样的方法从数据集中采样数据，将Fisher信息矩阵原始表达式的积分变为求和来近似估计，这样的方式得到的Fisher信息矩阵称为经验Fisher。</p>
<h2 id="2-14-线性判别分析（LDA）">2.14 线性判别分析（LDA）</h2>
<h3 id="2-14-1-LDA思想总结">2.14.1 LDA思想总结</h3>
<p>​	线性判别分析（Linear Discriminant Analysis，LDA）是一种经典的降维方法。和主成分分析PCA不考虑样本类别输出的无监督降维技术不同，LDA是一种监督学习的降维技术，数据集的每个样本有类别输出。</p>
<p>LDA分类思想简单总结如下：</p>
<ol>
<li>多维空间中，数据处理分类问题较为复杂，LDA算法将多维空间中的数据投影到一条直线上，将d维数据转化成1维数据进行处理。</li>
<li>对于训练数据，设法将多维数据投影到一条直线上，同类数据的投影点尽可能接近，异类数据点尽可能远离。</li>
<li>对数据进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定样本的类别。</li>
</ol>
<p>如果用一句话概括LDA思想，即“投影后类内方差最小，类间方差最大”。</p>
<h3 id="2-14-2-图解LDA核心思想">2.14.2 图解LDA核心思想</h3>
<p>​	假设有红、蓝两类数据，这些数据特征均为二维，如下图所示。我们的目标是将这些数据投影到一维，让每一类相近的数据的投影点尽可能接近，不同类别数据尽可能远，即图中红色和蓝色数据中心之间的距离尽可能大。</p>
<p><img src="2.29/1.png" alt></p>
<p>左图和右图是两种不同的投影方式。</p>
<p>​	左图思路：让不同类别的平均点距离最远的投影方式。</p>
<p>​	右图思路：让同类别的数据挨得最近的投影方式。</p>
<p>​	从上图直观看出，右图红色数据和蓝色数据在各自的区域来说相对集中，根据数据分布直方图也可看出，所以右图的投影效果好于左图，左图中间直方图部分有明显交集。</p>
<p>​	以上例子是基于数据是二维的，分类后的投影是一条直线。如果原始数据是多维的，则投影后的分类面是一低维的超平面。</p>
<h3 id="2-14-3-二类LDA算法原理">2.14.3 二类LDA算法原理</h3>
<p>​	输入：数据集  $D=\{(\boldsymbol x_1,\boldsymbol y_1),(\boldsymbol x_2,\boldsymbol y_2),...,(\boldsymbol x_m,\boldsymbol y_m)\}​$ ，其中样本  $\boldsymbol x_i ​$  是n维向量， $\boldsymbol y_i  \epsilon \{0, 1\}​$ ，降维后的目标维度  $d​$ 。定义</p>
<p>​	 $N_j(j=0,1)$  为第  $j$  类样本个数；</p>
<p>​	 $X_j(j=0,1)$  为第  $j$  类样本的集合；</p>
<p>​	 $u_j(j=0,1)​$  为第  $j​$  类样本的均值向量；</p>
<p>​	 $\sum_j(j=0,1)$  为第  $j$  类样本的协方差矩阵。</p>
<p>​	其中</p>
 $$
u_j = \frac{1}{N_j} \sum_{\boldsymbol x\epsilon X_j}\boldsymbol x(j=0,1)， 
\sum_j = \sum_{\boldsymbol x\epsilon X_j}(\boldsymbol x-u_j)(\boldsymbol x-u_j)^T(j=0,1)
$$ 
<p>​	假设投影直线是向量  $\boldsymbol w$ ，对任意样本  $\boldsymbol x_i$ ，它在直线  $w$ 上的投影为  $\boldsymbol w^Tx_i$ ，两个类别的中心点  $u_0$ ,  $u_1 $ 在直线  $w$  的投影分别为  $\boldsymbol w^Tu_0$  、 $\boldsymbol w^Tu_1$ 。</p>
<p>​	LDA的目标是让两类别的数据中心间的距离  $\| \boldsymbol w^Tu_0 - \boldsymbol w^Tu_1 \|^2_2$  尽量大，与此同时，希望同类样本投影点的协方差 $\boldsymbol w^T \sum_0 \boldsymbol w$ 、 $\boldsymbol w^T \sum_1 \boldsymbol w$  尽量小，最小化  $\boldsymbol w^T \sum_0 \boldsymbol w + \boldsymbol w^T \sum_1 \boldsymbol w​$  。<br>
​	定义<br>
​	类内散度矩阵</p>
 $$
S_w = \sum_0 + \sum_1 = 
	\sum_{\boldsymbol x\epsilon X_0}(\boldsymbol x-u_0)(\boldsymbol x-u_0)^T + 
	\sum_{\boldsymbol x\epsilon X_1}(\boldsymbol x-u_1)(\boldsymbol x-u_1)^T
$$ 
<p>​	类间散度矩阵  $S_b = (u_0 - u_1)(u_0 - u_1)^T$</p>
<p>​	据上分析，优化目标为</p>
 $$
\mathop{\arg\max}_\boldsymbol w J(\boldsymbol w) = \frac{\| \boldsymbol w^Tu_0 - \boldsymbol w^Tu_1 \|^2_2}{\boldsymbol w^T \sum_0\boldsymbol w + \boldsymbol w^T \sum_1\boldsymbol w} = 
\frac{\boldsymbol w^T(u_0-u_1)(u_0-u_1)^T\boldsymbol w}{\boldsymbol w^T(\sum_0 + \sum_1)\boldsymbol w} =
\frac{\boldsymbol w^TS_b\boldsymbol w}{\boldsymbol w^TS_w\boldsymbol w}
$$ 
<p>​	根据广义瑞利商的性质，矩阵  $S^{-1}_{w} S_b$  的最大特征值为  $J(\boldsymbol w)$  的最大值，矩阵  $S^{-1}_{w} S_b$  的最大特征值对应的特征向量即为  $\boldsymbol w$ 。</p>
<h3 id="2-14-4-LDA算法流程总结">2.14.4 LDA算法流程总结</h3>
<p>LDA算法降维流程如下：</p>
<p>​	输入：数据集  $D = \{ (x_1,y_1),(x_2,y_2), ... ,(x_m,y_m) \}$ ，其中样本  $x_i $  是n维向量， $y_i  \epsilon \{C_1, C_2, ..., C_k\}$ ，降维后的目标维度  $d$  。</p>
<p>​	输出：降维后的数据集  $\overline{D} $  。</p>
<p>步骤：</p>
<ol>
<li>计算类内散度矩阵  $S_w$ 。</li>
<li>计算类间散度矩阵  $S_b​$  。</li>
<li>计算矩阵  $S^{-1}_wS_b​$  。</li>
<li>计算矩阵  $S^{-1}_wS_b$  的最大的 d 个特征值。</li>
<li>计算 d 个特征值对应的 d 个特征向量，记投影矩阵为 W 。</li>
<li>转化样本集的每个样本，得到新样本  $P_i = W^Tx_i​$  。</li>
<li>输出新样本集  $\overline{D} = \{ (p_1,y_1),(p_2,y_2),...,(p_m,y_m) \}​$</li>
</ol>
<h3 id="2-14-5-LDA和PCA区别">2.14.5 LDA和PCA区别</h3>
<table>
<thead>
<tr>
<th style="text-align:center">异同点</th>
<th style="text-align:left">LDA</th>
<th style="text-align:left">PCA</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">相同点</td>
<td style="text-align:left">1. 两者均可以对数据进行降维；<br>2. 两者在降维时均使用了矩阵特征分解的思想；<br>3. 两者都假设数据符合高斯分布；</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:center">不同点</td>
<td style="text-align:left">有监督的降维方法；</td>
<td style="text-align:left">无监督的降维方法；</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:left">降维最多降到k-1维；</td>
<td style="text-align:left">降维多少没有限制；</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:left">可以用于降维，还可以用于分类；</td>
<td style="text-align:left">只用于降维；</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:left">选择分类性能最好的投影方向；</td>
<td style="text-align:left">选择样本点投影具有最大方差的方向；</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:left">更明确，更能反映样本间差异；</td>
<td style="text-align:left">目的较为模糊；</td>
</tr>
</tbody>
</table>
<h3 id="2-14-6-LDA优缺点">2.14.6 LDA优缺点</h3>
<table>
<thead>
<tr>
<th style="text-align:center">优缺点</th>
<th style="text-align:left">简要说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">优点</td>
<td style="text-align:left">1. 可以使用类别的先验知识；<br>2. 以标签、类别衡量差异性的有监督降维方式，相对于PCA的模糊性，其目的更明确，更能反映样本间的差异；</td>
</tr>
<tr>
<td style="text-align:center">缺点</td>
<td style="text-align:left">1. LDA不适合对非高斯分布样本进行降维；<br>2. LDA降维最多降到分类数k-1维；<br>3. LDA在样本分类信息依赖方差而不是均值时，降维效果不好；<br>4. LDA可能过度拟合数据。</td>
</tr>
</tbody>
</table>
<h2 id="2-15-主成分分析（PCA）">2.15  主成分分析（PCA）</h2>
<h3 id="2-15-1-主成分分析（PCA）思想总结">2.15.1 主成分分析（PCA）思想总结</h3>
<ol>
<li>PCA就是将高维的数据通过线性变换投影到低维空间上去。</li>
<li>投影思想：找出最能够代表原始数据的投影方法。被PCA降掉的那些维度只能是那些噪声或是冗余的数据。</li>
<li>去冗余：去除可以被其他向量代表的线性相关向量，这部分信息量是多余的。</li>
<li>去噪声，去除较小特征值对应的特征向量，特征值的大小反映了变换后在特征向量方向上变换的幅度，幅度越大，说明这个方向上的元素差异也越大，要保留。</li>
<li>对角化矩阵，寻找极大线性无关组，保留较大的特征值，去除较小特征值，组成一个投影矩阵，对原始样本矩阵进行投影，得到降维后的新样本矩阵。</li>
<li>完成PCA的关键是——协方差矩阵。协方差矩阵，能同时表现不同维度间的相关性以及各个维度上的方差。协方差矩阵度量的是维度与维度之间的关系，而非样本与样本之间。</li>
<li>之所以对角化，因为对角化之后非对角上的元素都是0，达到去噪声的目的。对角化后的协方差矩阵，对角线上较小的新方差对应的就是那些该去掉的维度。所以我们只取那些含有较大能量(特征值)的维度，其余的就舍掉，即去冗余。</li>
</ol>
<h3 id="2-15-2-图解PCA核心思想">2.15.2 图解PCA核心思想</h3>
<p>​	PCA可解决训练数据中存在数据特征过多或特征累赘的问题。核心思想是将m维特征映射到n维（n &lt; m），这n维形成主元，是重构出来最能代表原始数据的正交特征。</p>
<p>​	假设数据集是m个n维， $(\boldsymbol x^{(1)}, \boldsymbol x^{(2)}, \cdots, \boldsymbol x^{(m)})$ 。如果 $n=2$ ，需要降维到 $n'=1$ ，现在想找到某一维度方向代表这两个维度的数据。下图有 $u_1, u_2$ 两个向量方向，但是哪个向量才是我们所想要的，可以更好代表原始数据集的呢？</p>
<p><img src="2.34/1.png" alt></p>
<p>从图可看出， $u_1$ 比 $u_2$ 好，为什么呢？有以下两个主要评价指标：</p>
<ol>
<li>样本点到这个直线的距离足够近。</li>
<li>样本点在这个直线上的投影能尽可能的分开。</li>
</ol>
<p>如果我们需要降维的目标维数是其他任意维，则：</p>
<ol>
<li>样本点到这个超平面的距离足够近。</li>
<li>样本点在这个超平面上的投影能尽可能的分开。</li>
</ol>
<h3 id="2-15-3-PCA算法推理">2.15.3 PCA算法推理</h3>
<p>下面以基于最小投影距离为评价指标推理：</p>
<p>​	假设数据集是m个n维， $(x^{(1)}, x^{(2)},...,x^{(m)})$ ，且数据进行了中心化。经过投影变换得到新坐标为  ${w_1,w_2,...,w_n}$ ，其中  $w$  是标准正交基，即  $\| w \|_2 = 1$ ， $w^T_iw_j = 0$ 。</p>
<p>​	经过降维后，新坐标为  $\{ w_1,w_2,...,w_n \}$ ，其中  $n'$  是降维后的目标维数。样本点  $x^{(i)}$  在新坐标系下的投影为  $z^{(i)} = \left(z^{(i)}_1, z^{(i)}_2, ..., z^{(i)}_{n'}   \right)$ ，其中  $z^{(i)}_j = w^T_j x^{(i)}$  是  $x^{(i)} ​$  在低维坐标系里第 j 维的坐标。</p>
<p>​	如果用  $z^{(i)} $  去恢复  $x^{(i)} $  ，则得到的恢复数据为  $\widehat{x}^{(i)} = \sum^{n'}_{j=1} x^{(i)}_j w_j = Wz^{(i)}$ ，其中  $W$ 为标准正交基组成的矩阵。</p>
<p>​	考虑到整个样本集，样本点到这个超平面的距离足够近，目标变为最小化  $\sum^m_{i=1} \| \hat{x}^{(i)} - x^{(i)} \|^2_2$  。对此式进行推理，可得：</p>
 $$
\sum^m_{i=1} \| \hat{x}^{(i)} - x^{(i)} \|^2_2 = 
	\sum^m_{i=1} \| Wz^{(i)} - x^{(i)} \|^2_2 \\
	= \sum^m_{i=1} \left( Wz^{(i)} \right)^T \left( Wz^{(i)} \right)
	- 2\sum^m_{i=1} \left( Wz^{(i)} \right)^T x^{(i)}
	+ \sum^m_{i=1} \left( x^{(i)} \right)^T x^{(i)} \\
	= \sum^m_{i=1} \left( z^{(i)} \right)^T \left( z^{(i)} \right)
	- 2\sum^m_{i=1} \left( z^{(i)} \right)^T x^{(i)}
	+ \sum^m_{i=1} \left( x^{(i)} \right)^T x^{(i)} \\
	= - \sum^m_{i=1} \left( z^{(i)} \right)^T \left( z^{(i)} \right)
	+ \sum^m_{i=1} \left( x^{(i)} \right)^T x^{(i)} \\
	= -tr \left( W^T \left( \sum^m_{i=1} x^{(i)} \left( x^{(i)} \right)^T \right)W \right)
	+ \sum^m_{i=1} \left( x^{(i)} \right)^T x^{(i)} \\
	= -tr \left( W^TXX^TW \right)
	+ \sum^m_{i=1} \left( x^{(i)} \right)^T x^{(i)}
$$ 
<p>​	在推导过程中，分别用到了  $\overline{x}^{(i)} = Wz^{(i)}$  ，矩阵转置公式  $(AB)^T = B^TA^T$ ， $W^TW = I$ ， $z^{(i)} = W^Tx^{(i)}$  以及矩阵的迹，最后两步是将代数和转为矩阵形式。<br>
​	由于  $W$  的每一个向量  $w_j$  是标准正交基， $\sum^m_{i=1} x^{(i)} \left(  x^{(i)} \right)^T$  是数据集的协方差矩阵， $\sum^m_{i=1} \left(  x^{(i)} \right)^T x^{(i)} $  是一个常量。最小化  $\sum^m_{i=1} \| \hat{x}^{(i)} - x^{(i)} \|^2_2$  又可等价于</p>
 $$
\underbrace{\arg \min}_W - tr \left( W^TXX^TW \right) s.t.W^TW = I
$$ 
<p>利用拉格朗日函数可得到</p>
 $$
J(W) = -tr(W^TXX^TW) + \lambda(W^TW - I)
$$ 
<p>​	对  $W$  求导，可得  $-XX^TW + \lambda W = 0 $  ，也即  $ XX^TW = \lambda W $  。  $ XX^T $  是  $ n' $  个特征向量组成的矩阵， $\lambda$  为 $ XX^T $  的特征值。 $W$  即为我们想要的矩阵。<br>
​	对于原始数据，只需要  $z^{(i)} = W^TX^{(i)}$  ，就可把原始数据集降维到最小投影距离的  $n'$  维数据集。</p>
<p>​	基于最大投影方差的推导，这里就不再赘述，有兴趣的同仁可自行查阅资料。</p>
<h3 id="2-15-4-PCA算法流程总结">2.15.4 PCA算法流程总结</h3>
<p>输入： $n​$  维样本集  $D = \left( x^{(1)},x^{(2)},...,x^{(m)} \right)​$  ，目标降维的维数  $n'​$  。</p>
<p>输出：降维后的新样本集  $D'  = \left( z^{(1)},z^{(2)},...,z^{(m)} \right)$  。</p>
<p>主要步骤如下：</p>
<ol>
<li>对所有的样本进行中心化， $ x^{(i)} = x^{(i)} - \frac{1}{m} \sum^m_{j=1} x^{(j)} $  。</li>
<li>计算样本的协方差矩阵  $XX^T​$  。</li>
<li>对协方差矩阵  $XX^T$  进行特征值分解。</li>
<li>取出最大的  $n' $  个特征值对应的特征向量  $\{ w_1,w_2,...,w_{n'} \}$  。</li>
<li>标准化特征向量，得到特征向量矩阵  $W$  。</li>
<li>转化样本集中的每个样本  $z^{(i)} = W^T x^{(i)}$  。</li>
<li>得到输出矩阵  $D' = \left( z^{(1)},z^{(2)},...,z^{(n)} \right)​$  。<br>
<em>注</em>：在降维时，有时不明确目标维数，而是指定降维到的主成分比重阈值  $k(k \epsilon(0,1])​$  。假设  $n​$  个特征值为  $\lambda_1 \geqslant \lambda_2 \geqslant ... \geqslant \lambda_n​$  ，则  $n'​$  可从  $\sum^{n'}_{i=1} \lambda_i \geqslant k \times \sum^n_{i=1} \lambda_i ​$  得到。</li>
</ol>
<h3 id="2-15-5-PCA算法主要优缺点">2.15.5 PCA算法主要优缺点</h3>
<table>
<thead>
<tr>
<th style="text-align:center">优缺点</th>
<th style="text-align:left">简要说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">优点</td>
<td style="text-align:left">1. 仅仅需要以方差衡量信息量，不受数据集以外的因素影响。　2.各主成分之间正交，可消除原始数据成分间的相互影响的因素。3. 计算方法简单，主要运算是特征值分解，易于实现。</td>
</tr>
<tr>
<td style="text-align:center">缺点</td>
<td style="text-align:left">1.主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的解释性强。2. 方差小的非主成分也可能含有对样本差异的重要信息，因降维丢弃可能对后续数据处理有影响。</td>
</tr>
</tbody>
</table>
<h3 id="2-15-6-降维的必要性及目的">2.15.6 降维的必要性及目的</h3>
<p><strong>降维的必要性</strong>：</p>
<ol>
<li>多重共线性和预测变量之间相互关联。多重共线性会导致解空间的不稳定，从而可能导致结果的不连贯。</li>
<li>高维空间本身具有稀疏性。一维正态分布有68%的值落于正负标准差之间，而在十维空间上只有2%。</li>
<li>过多的变量，对查找规律造成冗余麻烦。</li>
<li>仅在变量层面上分析可能会忽略变量之间的潜在联系。例如几个预测变量可能落入仅反映数据某一方面特征的一个组内。</li>
</ol>
<p><strong>降维的目的</strong>：</p>
<ol>
<li>减少预测变量的个数。</li>
<li>确保这些变量是相互独立的。</li>
<li>提供一个框架来解释结果。相关特征，特别是重要特征更能在数据中明确的显示出来；如果只有两维或者三维的话，更便于可视化展示。</li>
<li>数据在低维下更容易处理、更容易使用。</li>
<li>去除数据噪声。</li>
<li>降低算法运算开销。</li>
</ol>
<h3 id="2-15-7-KPCA与PCA的区别">2.15.7 KPCA与PCA的区别</h3>
<p>​	应用PCA算法前提是假设存在一个线性超平面，进而投影。那如果数据不是线性的呢？该怎么办？这时候就需要KPCA，数据集从  $n$  维映射到线性可分的高维  $N >n$ ，然后再从  $N$  维降维到一个低维度  $n'(n'<n<N)$ 。< p>
<p>​	KPCA用到了核函数思想，使用了核函数的主成分分析一般称为核主成分分析(Kernelized PCA, 简称KPCA）。</p>
<p>假设高维空间数据由  $n​$  维空间的数据通过映射  $\phi​$  产生。</p>
<p>​	 $n$  维空间的特征分解为：</p>
 $$
\sum^m_{i=1} x^{(i)} \left( x^{(i)} \right)^T W = \lambda W
$$ 
<p>​	其映射为</p>
 $$
\sum^m_{i=1} \phi \left( x^{(i)} \right) \phi \left( x^{(i)} \right)^T W = \lambda W
$$ 
<p>​	通过在高维空间进行协方差矩阵的特征值分解，然后用和PCA一样的方法进行降维。由于KPCA需要核函数的运算，因此它的计算量要比PCA大很多。</p>
<h2 id="2-16-模型评估">2.16 模型评估</h2>
<h3 id="2-16-1-模型评估常用方法？">2.16.1 模型评估常用方法？</h3>
<p>​	一般情况来说，单一评分标准无法完全评估一个机器学习模型。只用good和bad偏离真实场景去评估某个模型，都是一种欠妥的评估方式。下面介绍常用的分类模型和回归模型评估方法。</p>
<p><strong>分类模型常用评估方法：</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">指标</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Accuracy</td>
<td style="text-align:center">准确率</td>
</tr>
<tr>
<td style="text-align:center">Precision</td>
<td style="text-align:center">精准度/查准率</td>
</tr>
<tr>
<td style="text-align:center">Recall</td>
<td style="text-align:center">召回率/查全率</td>
</tr>
<tr>
<td style="text-align:center">P-R曲线</td>
<td style="text-align:center">查准率为纵轴，查全率为横轴，作图</td>
</tr>
<tr>
<td style="text-align:center">F1</td>
<td style="text-align:center">F1值</td>
</tr>
<tr>
<td style="text-align:center">Confusion Matrix</td>
<td style="text-align:center">混淆矩阵</td>
</tr>
<tr>
<td style="text-align:center">ROC</td>
<td style="text-align:center">ROC曲线</td>
</tr>
<tr>
<td style="text-align:center">AUC</td>
<td style="text-align:center">ROC曲线下的面积</td>
</tr>
</tbody>
</table>
<p><strong>回归模型常用评估方法：</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">指标</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Mean Square Error (MSE, RMSE)</td>
<td style="text-align:center">平均方差</td>
</tr>
<tr>
<td style="text-align:center">Absolute Error (MAE, RAE)</td>
<td style="text-align:center">绝对误差</td>
</tr>
<tr>
<td style="text-align:center">R-Squared</td>
<td style="text-align:center">R平方值</td>
</tr>
</tbody>
</table>
<h3 id="2-16-2-误差、偏差和方差有什么区别和联系">2.16.2 误差、偏差和方差有什么区别和联系</h3>
<p>在机器学习中，Bias(偏差)，Error(误差)，和Variance(方差)存在以下区别和联系：</p>
<p>**对于Error **：</p>
<ul>
<li>
<p>误差（error）：一般地，我们把学习器的实际预测输出与样本的真是输出之间的差异称为“误差”。</p>
</li>
<li>
<p>Error = Bias + Variance + Noise，Error反映的是整个模型的准确度。</p>
</li>
</ul>
<p><strong>对于Noise:</strong></p>
<p>噪声：描述了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。</p>
<p><strong>对于Bias：</strong></p>
<ul>
<li>Bias衡量模型拟合训练数据的能力（训练数据不一定是整个 training dataset，而是只用于训练它的那一部分数据，例如：mini-batch），Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度。</li>
<li>Bias 越小，拟合能力越高（可能产生overfitting）；反之，拟合能力越低（可能产生underfitting）。</li>
<li>偏差越大，越偏离真实数据，如下图第二行所示。</li>
</ul>
<p><strong>对于Variance：</strong></p>
<ul>
<li>
<p>方差公式： $S_{N}^{2}=\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}$</p>
</li>
<li>
<p>Variance描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散，模型的稳定程度越差。</p>
</li>
<li>
<p>Variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。</p>
</li>
<li>
<p>Variance越小，模型的泛化的能力越高；反之，模型的泛化的能力越低。</p>
</li>
<li>
<p>如果模型在训练集上拟合效果比较优秀，但是在测试集上拟合效果比较差劣，则方差较大，说明模型的稳定程度较差，出现这种现象可能是由于模型对训练集过拟合造成的。 如下图右列所示。</p>
</li>
</ul>
<blockquote>
<p><img src="2.16.20.1.png" alt></p>
</blockquote>
<h3 id="2-16-3-经验误差与泛化误差">2.16.3 经验误差与泛化误差</h3>
<p>经验误差（empirical error）：也叫训练误差（training error），模型在训练集上的误差。</p>
<p>泛化误差（generalization error）：模型在新样本集（测试集）上的误差称为“泛化误差”。</p>
<h3 id="2-16-4-图解欠拟合、过拟合">2.16.4 图解欠拟合、过拟合</h3>
<p>根据不同的坐标方式，欠拟合与过拟合图解不同。</p>
<ol>
<li><strong>横轴为训练样本数量，纵轴为误差</strong></li>
</ol>
<p><img src="2.16.4.1.jpg" alt></p>
<p>如上图所示，我们可以直观看出欠拟合和过拟合的区别：</p>
<p>​	模型欠拟合：在训练集以及测试集上同时具有较高的误差，此时模型的偏差较大；</p>
<p>​	模型过拟合：在训练集上具有较低的误差，在测试集上具有较高的误差，此时模型的方差较大。</p>
<p>​	模型正常：在训练集以及测试集上，同时具有相对较低的偏差以及方差。</p>
<ol start="2">
<li><strong>横轴为模型复杂程度，纵轴为误差</strong></li>
</ol>
<p><img src="2.16.4.2.png" alt></p>
<p>​					红线为测试集上的Error,蓝线为训练集上的Error</p>
<p>​	模型欠拟合：模型在点A处，在训练集以及测试集上同时具有较高的误差，此时模型的偏差较大。</p>
<p>​	模型过拟合：模型在点C处，在训练集上具有较低的误差，在测试集上具有较高的误差，此时模型的方差较大。</p>
<p>​	模型正常：模型复杂程度控制在点B处为最优。</p>
<ol start="3">
<li><strong>横轴为正则项系数，纵轴为误差</strong></li>
</ol>
<p><img src="2.16.4.3.png" alt></p>
<p>​                                             红线为测试集上的Error,蓝线为训练集上的Error</p>
<p>​	模型欠拟合：模型在点C处，在训练集以及测试集上同时具有较高的误差，此时模型的偏差较大。</p>
<p>​	模型过拟合：模型在点A处，在训练集上具有较低的误差，在测试集上具有较高的误差，此时模型的方差较大。 它通常发生在模型过于复杂的情况下，如参数过多等，会使得模型的预测性能变弱，并且增加数据的波动性。虽然模型在训练时的效果可以表现的很完美，基本上记住了数据的全部特点，但这种模型在未知数据的表现能力会大减折扣，因为简单的模型泛化能力通常都是很弱的。</p>
<p>​	模型正常：模型复杂程度控制在点B处为最优。</p>
<h3 id="2-16-5-如何解决过拟合与欠拟合">2.16.5 如何解决过拟合与欠拟合</h3>
<p><strong>如何解决欠拟合：</strong></p>
<ol>
<li>添加其他特征项。组合、泛化、相关性、上下文特征、平台特征等特征是特征添加的重要手段，有时候特征项不够会导致模型欠拟合。</li>
<li>添加多项式特征。例如将线性模型添加二次项或三次项使模型泛化能力更强。例如，FM（Factorization Machine）模型、FFM（Field-aware Factorization Machine）模型，其实就是线性模型，增加了二阶多项式，保证了模型一定的拟合程度。</li>
<li>可以增加模型的复杂程度。</li>
<li>减小正则化系数。正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数。</li>
</ol>
<p><strong>如何解决过拟合：</strong></p>
<ol>
<li>重新清洗数据，数据不纯会导致过拟合，此类情况需要重新清洗数据。</li>
<li>增加训练样本数量。</li>
<li>降低模型复杂程度。</li>
<li>增大正则项系数。</li>
<li>采用dropout方法，dropout方法，通俗的讲就是在训练的时候让神经元以一定的概率不工作。</li>
<li>early stopping。</li>
<li>减少迭代次数。</li>
<li>增大学习率。</li>
<li>添加噪声数据。</li>
<li>树结构中，可以对树进行剪枝。</li>
<li>减少特征项。</li>
</ol>
<p>欠拟合和过拟合这些方法，需要根据实际问题，实际模型，进行选择。</p>
<h3 id="2-16-6-交叉验证的主要作用">2.16.6 交叉验证的主要作用</h3>
<p>​	为了得到更为稳健可靠的模型，对模型的泛化误差进行评估，得到模型泛化误差的近似值。当有多个模型可以选择时，我们通常选择“泛化误差”最小的模型。</p>
<p>​	交叉验证的方法有许多种，但是最常用的是：留一交叉验证、k折交叉验证。</p>
<h3 id="2-16-7-理解k折交叉验证">2.16.7 理解k折交叉验证</h3>
<ol>
<li>将含有N个样本的数据集，分成K份，每份含有N/K个样本。选择其中1份作为测试集，另外K-1份作为训练集，测试集就有K种情况。</li>
<li>在每种情况中，用训练集训练模型，用测试集测试模型，计算模型的泛化误差。</li>
<li>交叉验证重复K次，每份验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测，得到模型最终的泛化误差。</li>
<li>将K种情况下，模型的泛化误差取均值，得到模型最终的泛化误差。</li>
<li>一般 $2\leqslant K \leqslant10$ 。 k折交叉验证的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10折交叉验证是最常用的。</li>
<li>训练集中样本数量要足够多，一般至少大于总样本数的50%。</li>
<li>训练集和测试集必须从完整的数据集中均匀取样。均匀取样的目的是希望减少训练集、测试集与原数据集之间的偏差。当样本数量足够多时，通过随机取样，便可以实现均匀取样的效果。</li>
</ol>
<h3 id="2-16-8-混淆矩阵">2.16.8 混淆矩阵</h3>
<p>第一种混淆矩阵:</p>
<table>
<thead>
<tr>
<th style="text-align:center">真实情况T or F</th>
<th style="text-align:left">预测为正例1，P</th>
<th style="text-align:left">预测为负例0，N</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">本来label标记为1，预测结果真为T、假为F</td>
<td style="text-align:left">TP(预测为1，实际为1)</td>
<td style="text-align:left">FN(预测为0，实际为1)</td>
</tr>
<tr>
<td style="text-align:center">本来label标记为0，预测结果真为T、假为F</td>
<td style="text-align:left">FP(预测为1，实际为0)</td>
<td style="text-align:left">TN(预测为0，实际也为0)</td>
</tr>
</tbody>
</table>
<p>第二种混淆矩阵:</p>
<table>
<thead>
<tr>
<th style="text-align:center">预测情况P or N</th>
<th style="text-align:left">实际label为1,预测对了为T</th>
<th style="text-align:left">实际label为0,预测对了为T</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">预测为正例1，P</td>
<td style="text-align:left">TP(预测为1，实际为1)</td>
<td style="text-align:left">FP(预测为1，实际为0)</td>
</tr>
<tr>
<td style="text-align:center">预测为负例0，N</td>
<td style="text-align:left">FN(预测为0，实际为1)</td>
<td style="text-align:left">TN(预测为0，实际也为0)</td>
</tr>
</tbody>
</table>
<h3 id="2-16-9-错误率及精度">2.16.9 错误率及精度</h3>
<ol>
<li>错误率（Error Rate）：分类错误的样本数占样本总数的比例。</li>
<li>精度（accuracy）：分类正确的样本数占样本总数的比例。</li>
</ol>
<h3 id="2-16-10-查准率与查全率">2.16.10 查准率与查全率</h3>
<p>将算法预测的结果分成四种情况：</p>
<ol>
<li>正确肯定（True Positive,TP）：预测为真，实际为真</li>
<li>正确否定（True Negative,TN）：预测为假，实际为假</li>
<li>错误肯定（False Positive,FP）：预测为真，实际为假</li>
<li>错误否定（False Negative,FN）：预测为假，实际为真</li>
</ol>
<p>则：</p>
<p>查准率（Precision）=TP/（TP+FP）</p>
<p><strong>理解</strong>：预测出为阳性的样本中，正确的有多少。区别准确率（正确预测出的样本，包括正确预测为阳性、阴性，占总样本比例）。<br>
例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。</p>
<p>查全率（Recall）=TP/（TP+FN）</p>
<p><strong>理解</strong>：正确预测为阳性的数量占总样本中阳性数量的比例。<br>
例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。</p>
<h3 id="2-16-11-ROC与AUC">2.16.11 ROC与AUC</h3>
<p>​	ROC全称是“受试者工作特征”（Receiver Operating Characteristic）。</p>
<p>​	ROC曲线的面积就是AUC（Area Under Curve）。</p>
<p>​	AUC用于衡量“二分类问题”机器学习算法性能（泛化能力）。</p>
<p>​	ROC曲线，通过将连续变量设定出多个不同的临界值，从而计算出一系列真正率和假正率，再以假正率为横坐标、真正率为纵坐标绘制成曲线，曲线下面积越大，推断准确性越高。在ROC曲线上，最靠近坐标图左上方的点为假正率和真正率均较高的临界值。</p>
<p>​	对于分类器，或者说分类算法，评价指标主要有Precision，Recall，F-score。下图是一个ROC曲线的示例。</p>
<p><img src="2.40.10/1.png" alt></p>
<p>ROC曲线的横坐标为False Positive Rate（FPR），纵坐标为True Positive Rate（TPR）。其中</p>
 $$
TPR = \frac{TP}{TP+FN} ,FPR = \frac{FP}{FP+TN}
$$ 
<p>​	下面着重介绍ROC曲线图中的四个点和一条线。<br>
​	第一个点(0,1)，即FPR=0, TPR=1，这意味着FN（False Negative）=0，并且FP（False Positive）=0。意味着这是一个完美的分类器，它将所有的样本都正确分类。<br>
​	第二个点(1,0)，即FPR=1，TPR=0，意味着这是一个最糟糕的分类器，因为它成功避开了所有的正确答案。<br>
​	第三个点(0,0)，即FPR=TPR=0，即FP（False Positive）=TP（True Positive）=0，可以发现该分类器预测所有的样本都为负样本（Negative）。<br>
​	第四个点(1,1)，即FPR=TPR=1，分类器实际上预测所有的样本都为正样本。<br>
​	经过以上分析，ROC曲线越接近左上角，该分类器的性能越好。</p>
<p>​	ROC曲线所覆盖的面积称为AUC（Area Under Curve），可以更直观的判断学习器的性能，AUC越大则性能越好。</p>
<h3 id="2-16-12-如何画ROC曲线">2.16.12 如何画ROC曲线</h3>
<p>​	下图是一个示例，图中共有20个测试样本，“Class”一栏表示每个测试样本真正的标签（p表示正样本，n表示负样本），“Score”表示每个测试样本属于正样本的概率。</p>
<p>步骤：<br>
1、假设已经得出一系列样本被划分为正类的概率，按照大小排序。<br>
2、从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。<br>
3、每次选取一个不同的threshold，得到一组FPR和TPR，即ROC曲线上的一点。以此共得到20组FPR和TPR的值。<br>
4、根据3、中的每个坐标点，画图。</p>
<p><img src="2.40.11/1.jpg" alt></p>
<h3 id="2-16-13-如何计算TPR，FPR">2.16.13 如何计算TPR，FPR</h3>
<p>1、分析数据<br>
y_true = [0, 0, 1, 1]；scores = [0.1, 0.4, 0.35, 0.8]；<br>
2、列表</p>
<table>
<thead>
<tr>
<th>样本</th>
<th>预测属于P的概率(score)</th>
<th>真实类别</th>
</tr>
</thead>
<tbody>
<tr>
<td>y[0]</td>
<td>0.1</td>
<td>N</td>
</tr>
<tr>
<td>y[1]</td>
<td>0.4</td>
<td>N</td>
</tr>
<tr>
<td>y[2]</td>
<td>0.35</td>
<td>P</td>
</tr>
<tr>
<td>y[3]</td>
<td>0.8</td>
<td>P</td>
</tr>
</tbody>
</table>
<p>3、将截断点依次取为score值，计算TPR和FPR。<br>
当截断点为0.1时：<br>
说明只要score&gt;=0.1，它的预测类别就是正例。 因为4个样本的score都大于等于0.1，所以，所有样本的预测类别都为P。<br>
scores = [0.1, 0.4, 0.35, 0.8]；y_true = [0, 0, 1, 1]；y_pred = [1, 1, 1, 1]；<br>
正例与反例信息如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>正例</th>
<th>反例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>正例</strong></td>
<td>TP=2</td>
<td>FN=0</td>
</tr>
<tr>
<td><strong>反例</strong></td>
<td>FP=2</td>
<td>TN=0</td>
</tr>
</tbody>
</table>
<p>由此可得：<br>
TPR = TP/(TP+FN) = 1； FPR = FP/(TN+FP) = 1；</p>
<p>当截断点为0.35时：<br>
scores = [0.1, 0.4, 0.35, 0.8]；y_true = [0, 0, 1, 1]；y_pred = [0, 1, 1, 1];<br>
正例与反例信息如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>正例</th>
<th>反例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>正例</strong></td>
<td>TP=2</td>
<td>FN=0</td>
</tr>
<tr>
<td><strong>反例</strong></td>
<td>FP=1</td>
<td>TN=1</td>
</tr>
</tbody>
</table>
<p>由此可得：<br>
TPR = TP/(TP+FN) = 1； FPR = FP/(TN+FP) = 0.5；</p>
<p>当截断点为0.4时：<br>
scores = [0.1, 0.4, 0.35, 0.8]；y_true = [0, 0, 1, 1]；y_pred = [0, 1, 0, 1]；<br>
正例与反例信息如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>正例</th>
<th>反例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>正例</strong></td>
<td>TP=1</td>
<td>FN=1</td>
</tr>
<tr>
<td><strong>反例</strong></td>
<td>FP=1</td>
<td>TN=1</td>
</tr>
</tbody>
</table>
<p>由此可得：<br>
TPR = TP/(TP+FN) = 0.5； FPR = FP/(TN+FP) = 0.5；</p>
<p>当截断点为0.8时：<br>
scores = [0.1, 0.4, 0.35, 0.8]；y_true = [0, 0, 1, 1]；y_pred = [0, 0, 0, 1]；</p>
<p>正例与反例信息如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>正例</th>
<th>反例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>正例</strong></td>
<td>TP=1</td>
<td>FN=1</td>
</tr>
<tr>
<td><strong>反例</strong></td>
<td>FP=0</td>
<td>TN=2</td>
</tr>
</tbody>
</table>
<p>由此可得：<br>
TPR = TP/(TP+FN) = 0.5； FPR = FP/(TN+FP) = 0；</p>
<p>4、根据TPR、FPR值，以FPR为横轴，TPR为纵轴画图。</p>
<h3 id="2-16-14-如何计算AUC">2.16.14 如何计算AUC</h3>
<ul>
<li>将坐标点按照横坐标FPR排序 。</li>
<li>计算第 $i$ 个坐标点和第 $i+1$ 个坐标点的间距 $dx$  。</li>
<li>获取第 $i$ 或者 $i+1$ 个坐标点的纵坐标y。</li>
<li>计算面积微元 $ds=ydx$ 。</li>
<li>对面积微元进行累加，得到AUC。</li>
</ul>
<h3 id="2-16-15-为什么使用Roc和Auc评价分类器">2.16.15 为什么使用Roc和Auc评价分类器</h3>
<p>​	模型有很多评估方法，为什么还要使用ROC和AUC呢？<br>
​	因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变换的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现样本类不平衡，即正负样本比例差距较大，而且测试数据中的正负样本也可能随着时间变化。</p>
<h3 id="2-16-16-直观理解AUC">2.16.16 直观理解AUC</h3>
<p>​	下图展现了三种AUC的值：</p>
<p><img src="2.40.15/1.png" alt></p>
<p>​	AUC是衡量二分类模型优劣的一种评价指标，表示正例排在负例前面的概率。其他评价指标有精确度、准确率、召回率，而AUC比这三者更为常用。<br>
​	一般在分类模型中，预测结果都是以概率的形式表现，如果要计算准确率，通常都会手动设置一个阈值来将对应的概率转化成类别，这个阈值也就很大程度上影响了模型准确率的计算。<br>
​	举例：<br>
​	现在假设有一个训练好的二分类器对10个正负样本（正例5个，负例5个）预测，得分按高到低排序得到的最好预测结果为[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]，即5个正例均排在5个负例前面，正例排在负例前面的概率为100%。然后绘制其ROC曲线，由于是10个样本，除去原点我们需要描10个点，如下：</p>
<p><img src="2.16.17-1.png" alt></p>
<p>​	描点方式按照样本预测结果的得分高低从左至右开始遍历。从原点开始，每遇到1便向y轴正方向移动y轴最小步长1个单位，这里是1/5=0.2；每遇到0则向x轴正方向移动x轴最小步长1个单位，这里也是0.2。不难看出，上图的AUC等于1，印证了正例排在负例前面的概率的确为100%。</p>
<p>​	假设预测结果序列为[1, 1, 1, 1, 0, 1, 0, 0, 0, 0]。</p>
<p><img src="2.16.17-2.png" alt></p>
<p>​	计算上图的AUC为0.96与计算正例与排在负例前面的概率0.8 × 1 + 0.2 × 0.8 = 0.96相等，而左上角阴影部分的面积则是负例排在正例前面的概率0.2 × 0.2 = 0.04。</p>
<p>​	假设预测结果序列为[1, 1, 1, 0, 1, 0, 1, 0, 0, 0]。</p>
<p><img src="2.16.17-3.png" alt></p>
<p>​	计算上图的AUC为0.88与计算正例与排在负例前面的概率0.6 × 1 + 0.2 × 0.8 + 0.2 × 0.6 = 0.88相等，左上角阴影部分的面积是负例排在正例前面的概率0.2 × 0.2 × 3 = 0.12。</p>
<h3 id="2-16-17-代价敏感错误率与代价曲线">2.16.17 代价敏感错误率与代价曲线</h3>
<p>不同的错误会产生不同代价。以二分法为例，设置代价矩阵如下：</p>
<p><img src="2-1.png" alt></p>
<p>当判断正确的时候，值为0，不正确的时候，分别为 $Cost_{01}​$ 和 $Cost_{10}​$  。</p>
 $Cost_{10}$ :表示实际为反例但预测成正例的代价。
 $Cost_{01}$ :表示实际为正例但是预测为反例的代价。
<p><strong>代价敏感错误率</strong>=样本中由模型得到的错误值与代价乘积之和 / 总样本。<br>
其数学表达式为：</p>
 $$
E(f;D;cost)=\frac{1}{m}\left( \sum_{x_{i} \in D^{+}}({f(x_i)\neq y_i})\times Cost_{01}+ \sum_{x_{i} \in D^{-}}({f(x_i)\neq y_i})\times Cost_{10}\right)
$$ 
 $D^{+}、D^{-}​$ 分别代表样例集的正例子集和反例子集，x是预测值，y是真实值。
<p><strong>代价曲线</strong>：<br>
在均等代价时，ROC曲线不能直接反应出模型的期望总体代价，而代价曲线可以。<br>
代价曲线横轴为[0,1]的正例函数代价：</p>
 $$
P(+)Cost=\frac{p*Cost_{01}}{p*Cost_{01}+(1-p)*Cost_{10}}
$$ 
<p>其中p是样本为正例的概率。</p>
<p>代价曲线纵轴维[0,1]的归一化代价：</p>
 $$
Cost_{norm}=\frac{FNR*p*Cost_{01}+FNR*(1-p)*Cost_{10}}{p*Cost_{01}+(1-p)*Cost_{10}}
$$ 
<p>其中FPR为假阳率，FNR=1-TPR为假阴率。</p>
<p>注：ROC每个点，对应代价平面上一条线。</p>
<p>例如，ROC上(TPR,FPR),计算出FNR=1-TPR，在代价平面上绘制一条从(0,FPR)到(1,FNR)的线段，面积则为该条件下期望的总体代价。所有线段下界面积，所有条件下学习器的期望总体代价。</p>
<p><img src="2.16.18.1.png" alt></p>
<h3 id="2-16-18-模型有哪些比较检验方法">2.16.18 模型有哪些比较检验方法</h3>
<p>正确性分析：模型稳定性分析，稳健性分析，收敛性分析，变化趋势分析，极值分析等。<br>
有效性分析：误差分析，参数敏感性分析，模型对比检验等。<br>
有用性分析：关键数据求解，极值点，拐点，变化趋势分析，用数据验证动态模拟等。<br>
高效性分析：时空复杂度分析与现有进行比较等。</p>
<h3 id="2-16-19-为什么使用标准差">2.16.19 为什么使用标准差</h3>
<p>方差公式为： $S^2_{N}=\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}​$</p>
<p>标准差公式为： $S_{N}=\sqrt{\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}}​$</p>
<p>样本标准差公式为： $S_{N}=\sqrt{\frac{1}{N-1}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}}​$</p>
<p>与方差相比，使用标准差来表示数据点的离散程度有3个好处：<br>
1、表示离散程度的数字与样本数据点的数量级一致，更适合对数据样本形成感性认知。</p>
<p>2、表示离散程度的数字单位与样本数据的单位一致，更方便做后续的分析运算。</p>
<p>3、在样本数据大致符合正态分布的情况下，标准差具有方便估算的特性：68%的数据点落在平均值前后1个标准差的范围内、95%的数据点落在平均值前后2个标准差的范围内，而99%的数据点将会落在平均值前后3个标准差的范围内。</p>
<h3 id="2-16-20-类别不平衡产生原因">2.16.20 类别不平衡产生原因</h3>
<p>​	类别不平衡（class-imbalance）是指分类任务中不同类别的训练样例数目差别很大的情况。</p>
<p>产生原因：</p>
<p>​	分类学习算法通常都会假设不同类别的训练样例数目基本相同。如果不同类别的训练样例数目差别很大，则会影响学习结果，测试结果变差。例如二分类问题中有998个反例，正例有2个，那学习方法只需返回一个永远将新样本预测为反例的分类器，就能达到99.8%的精度；然而这样的分类器没有价值。</p>
<h3 id="2-16-21-常见的类别不平衡问题解决方法">2.16.21 常见的类别不平衡问题解决方法</h3>
<p>防止类别不平衡对学习造成的影响，在构建分类模型之前，需要对分类不平衡性问题进行处理。主要解决方法有：</p>
<p>1、扩大数据集</p>
<p>​	增加包含小类样本数据的数据，更多的数据能得到更多的分布信息。</p>
<p>2、对大类数据欠采样</p>
<p>​	减少大类数据样本个数，使与小样本个数接近。<br>
​	缺点：欠采样操作时若随机丢弃大类样本，可能会丢失重要信息。<br>
​	代表算法：EasyEnsemble。其思想是利用集成学习机制，将大类划分为若干个集合供不同的学习器使用。相当于对每个学习器都进行欠采样，但对于全局则不会丢失重要信息。</p>
<p>3、对小类数据过采样</p>
<p>​	过采样：对小类的数据样本进行采样来增加小类的数据样本个数。</p>
<p>​	代表算法：SMOTE和ADASYN。</p>
<p>​	SMOTE：通过对训练集中的小类数据进行插值来产生额外的小类样本数据。</p>
<p>​	新的少数类样本产生的策略：对每个少数类样本a，在a的最近邻中随机选一个样本b，然后在a、b之间的连线上随机选一点作为新合成的少数类样本。 	<br>
​	ADASYN：根据学习难度的不同，对不同的少数类别的样本使用加权分布，对于难以学习的少数类的样本，产生更多的综合数据。 通过减少类不平衡引入的偏差和将分类决策边界自适应地转移到困难的样本两种手段，改善了数据分布。</p>
<p>4、使用新评价指标</p>
<p>​	如果当前评价指标不适用，则应寻找其他具有说服力的评价指标。比如准确度这个评价指标在类别不均衡的分类任务中并不适用，甚至进行误导。因此在类别不均衡分类任务中，需要使用更有说服力的评价指标来对分类器进行评价。</p>
<p>5、选择新算法</p>
<p>​	不同的算法适用于不同的任务与数据，应该使用不同的算法进行比较。</p>
<p>6、数据代价加权</p>
<p>​	例如当分类任务是识别小类，那么可以对分类器的小类样本数据增加权值，降低大类样本的权值，从而使得分类器将重点集中在小类样本身上。</p>
<p>7、转化问题思考角度</p>
<p>​	例如在分类问题时，把小类的样本作为异常点，将问题转化为异常点检测或变化趋势检测问题。 异常点检测即是对那些罕见事件进行识别。变化趋势检测区别于异常点检测在于其通过检测不寻常的变化趋势来识别。</p>
<p>8、将问题细化分析</p>
<p>​	对问题进行分析与挖掘，将问题划分成多个更小的问题，看这些小问题是否更容易解决。</p>
<h2 id="2-17-决策树">2.17 决策树</h2>
<h3 id="2-17-1-决策树的基本原理">2.17.1 决策树的基本原理</h3>
<p>​	决策树（Decision Tree）是一种分而治之的决策过程。一个困难的预测问题，通过树的分支节点，被划分成两个或多个较为简单的子集，从结构上划分为不同的子问题。将依规则分割数据集的过程不断递归下去（Recursive Partitioning）。随着树的深度不断增加，分支节点的子集越来越小，所需要提的问题数也逐渐简化。当分支节点的深度或者问题的简单程度满足一定的停止规则（Stopping Rule）时, 该分支节点会停止分裂，此为自上而下的停止阈值（Cutoff Threshold）法；有些决策树也使用自下而上的剪枝（Pruning）法。</p>
<h3 id="2-17-2-决策树的三要素？">2.17.2 决策树的三要素？</h3>
<p>​	一棵决策树的生成过程主要分为下3个部分：</p>
<p>​	1、特征选择：从训练数据中众多的特征中选择一个特征作为当前节点的分裂标准，如何选择特征有着很多不同量化评估标准，从而衍生出不同的决策树算法。</p>
<p>​	2、决策树生成：根据选择的特征评估标准，从上至下递归地生成子节点，直到数据集不可分则决策树停止生长。树结构来说，递归结构是最容易理解的方式。</p>
<p>​	3、剪枝：决策树容易过拟合，一般来需要剪枝，缩小树结构规模、缓解过拟合。剪枝技术有预剪枝和后剪枝两种。</p>
<h3 id="2-17-3-决策树学习基本算法">2.17.3 决策树学习基本算法</h3>
<p><img src="2-5.png" alt></p>
<h3 id="2-17-4-决策树算法优缺点">2.17.4 决策树算法优缺点</h3>
<p><strong>决策树算法的优点</strong>：</p>
<p>1、决策树算法易理解，机理解释起来简单。</p>
<p>2、决策树算法可以用于小数据集。</p>
<p>3、决策树算法的时间复杂度较小，为用于训练决策树的数据点的对数。</p>
<p>4、相比于其他算法智能分析一种类型变量，决策树算法可处理数字和数据的类别。</p>
<p>5、能够处理多输出的问题。</p>
<p>6、对缺失值不敏感。</p>
<p>7、可以处理不相关特征数据。</p>
<p>8、效率高，决策树只需要一次构建，反复使用，每一次预测的最大计算次数不超过决策树的深度。</p>
<p><strong>决策树算法的缺点</strong>：</p>
<p>1、对连续性的字段比较难预测。</p>
<p>2、容易出现过拟合。</p>
<p>3、当类别太多时，错误可能就会增加的比较快。</p>
<p>4、在处理特征关联性比较强的数据时表现得不是太好。</p>
<p>5、对于各类别样本数量不一致的数据，在决策树当中，信息增益的结果偏向于那些具有更多数值的特征。</p>
<h3 id="2-17-5-熵的概念以及理解">2.17.5 熵的概念以及理解</h3>
<p>​	熵：度量随机变量的不确定性。<br>
​	定义：假设随机变量X的可能取值有 $x_{1},x_{2},...,x_{n}$ ，对于每一个可能的取值 $x_{i}$ ，其概率为 $P(X=x_{i})=p_{i},i=1,2...,n$ 。随机变量的熵为：</p>
 $$
H(X)=-\sum_{i=1}^{n}p_{i}log_{2}p_{i}
$$ 
<p>​       对于样本集合，假设样本有k个类别，每个类别的概率为 $\frac{|C_{k}|}{|D|}$ ，其中  ${|C_{k}|}{|D|}$ 为类别为k的样本个数， $|D|​$ 为样本总数。样本集合D的熵为：</p>
 $$
H(D)=-\sum_{k=1}^{k}\frac{|C_{k}|}{|D|}log_{2}\frac{|C_{k}|}{|D|}
$$ 
<h3 id="2-17-6-信息增益的理解">2.17.6 信息增益的理解</h3>
<p>​	定义：以某特征划分数据集前后的熵的差值。<br>
​	熵可以表示样本集合的不确定性，熵越大，样本的不确定性就越大。因此可以使用划分前后集合熵的差值来衡量使用当前特征对于样本集合D划分效果的好坏。  ​	假设划分前样本集合D的熵为H(D)。使用某个特征A划分数据集D，计算划分后的数据子集的熵为H(D|A)。<br>
​	则信息增益为：</p>
 $$
g(D,A)=H(D)-H(D|A)
$$ 
<p>​	*注：*在决策树构建的过程中我们总是希望集合往最快到达纯度更高的子集合方向发展，因此我们总是选择使得信息增益最大的特征来划分当前数据集D。<br>
​	思想：计算所有特征划分数据集D，得到多个特征划分数据集D的信息增益，从这些信息增益中选择最大的，因而当前结点的划分特征便是使信息增益最大的划分所使用的特征。<br>
​	另外这里提一下信息增益比相关知识：<br>
​	 $信息增益比=惩罚参数\times信息增益$<br>
​	信息增益比本质：在信息增益的基础之上乘上一个惩罚参数。特征个数较多时，惩罚参数较小；特征个数较少时，惩罚参数较大。<br>
​	惩罚参数：数据集D以特征A作为随机变量的熵的倒数。</p>
<h3 id="2-17-7-剪枝处理的作用及策略">2.17.7 剪枝处理的作用及策略</h3>
<p>​	剪枝处理是决策树学习算法用来解决过拟合问题的一种办法。</p>
<p>​	在决策树算法中，为了尽可能正确分类训练样本， 节点划分过程不断重复， 有时候会造成决策树分支过多，以至于将训练样本集自身特点当作泛化特点， 而导致过拟合。 因此可以采用剪枝处理来去掉一些分支来降低过拟合的风险。</p>
<p>​	剪枝的基本策略有预剪枝（pre-pruning）和后剪枝（post-pruning）。</p>
<p>​	预剪枝：在决策树生成过程中，在每个节点划分前先估计其划分后的泛化性能， 如果不能提升，则停止划分，将当前节点标记为叶结点。</p>
<p>​	后剪枝：生成决策树以后，再自下而上对非叶结点进行考察， 若将此节点标记为叶结点可以带来泛化性能提升，则修改之。</p>
<h2 id="2-18-支持向量机">2.18 支持向量机</h2>
<h3 id="2-18-1-什么是支持向量机">2.18.1 什么是支持向量机</h3>
<p>​	支持向量：在求解的过程中，会发现只根据部分数据就可以确定分类器，这些数据称为支持向量。</p>
<p>​	支持向量机（Support Vector Machine，SVM）：其含义是通过支持向量运算的分类器。</p>
<p>​	在一个二维环境中，其中点R，S，G点和其它靠近中间黑线的点可以看作为支持向量，它们可以决定分类器，即黑线的具体参数。</p>
<p><img src="2-6.png" alt></p>
<p>​	支持向量机是一种二分类模型，它的目的是寻找一个超平面来对样本进行分割，分割的原则是边界最大化，最终转化为一个凸二次规划问题来求解。由简至繁的模型包括：</p>
<p>​	当训练样本线性可分时，通过硬边界（hard margin）最大化，学习一个线性可分支持向量机；</p>
<p>​	当训练样本近似线性可分时，通过软边界（soft margin）最大化，学习一个线性支持向量机；</p>
<p>​	当训练样本线性不可分时，通过核技巧和软边界最大化，学习一个非线性支持向量机；</p>
<h3 id="2-18-2-支持向量机能解决哪些问题">2.18.2 支持向量机能解决哪些问题</h3>
<p><strong>线性分类</strong></p>
<p>​	在训练数据中，每个数据都有n个的属性和一个二分类类别标志，我们可以认为这些数据在一个n维空间里。我们的目标是找到一个n-1维的超平面，这个超平面可以将数据分成两部分，每部分数据都属于同一个类别。</p>
<p>​	这样的超平面有很多，假如我们要找到一个最佳的超平面。此时，增加一个约束条件：要求这个超平面到每边最近数据点的距离是最大的，成为最大边距超平面。这个分类器即为最大边距分类器。</p>
<p><strong>非线性分类</strong></p>
<p>​	SVM的一个优势是支持非线性分类。它结合使用拉格朗日乘子法（Lagrange Multiplier）和KKT（Karush Kuhn Tucker）条件，以及核函数可以生成非线性分类器。</p>
<h3 id="2-18-3-核函数特点及其作用">2.18.3 核函数特点及其作用</h3>
<p>​	引入核函数目的：把原坐标系里线性不可分的数据用核函数Kernel投影到另一个空间，尽量使得数据在新的空间里线性可分。<br>
​	核函数方法的广泛应用，与其特点是分不开的：</p>
<p>1）核函数的引入避免了“维数灾难”，大大减小了计算量。而输入空间的维数n对核函数矩阵无影响。因此，核函数方法可以有效处理高维输入。</p>
<p>2）无需知道非线性变换函数Φ的形式和参数。</p>
<p>3）核函数的形式和参数的变化会隐式地改变从输入空间到特征空间的映射，进而对特征空间的性质产生影响，最终改变各种核函数方法的性能。</p>
<p>4）核函数方法可以和不同的算法相结合，形成多种不同的基于核函数技术的方法，且这两部分的设计可以单独进行，并可以为不同的应用选择不同的核函数和算法。</p>
<h3 id="2-18-4-SVM为什么引入对偶问题">2.18.4 SVM为什么引入对偶问题</h3>
<p>1，对偶问题将原始问题中的约束转为了对偶问题中的等式约束，对偶问题往往更加容易求解。</p>
<p>2，可以很自然的引用核函数（拉格朗日表达式里面有内积，而核函数也是通过内积进行映射的）。</p>
<p>3，在优化理论中，目标函数 f(x) 会有多种形式：如果目标函数和约束条件都为变量 x 的线性函数，称该问题为线性规划；如果目标函数为二次函数，约束条件为线性函数，称该最优化问题为二次规划；如果目标函数或者约束条件均为非线性函数，称该最优化问题为非线性规划。每个线性规划问题都有一个与之对应的对偶问题，对偶问题有非常良好的性质，以下列举几个：</p>
<p>​	a, 对偶问题的对偶是原问题；</p>
<p>​	b, 无论原始问题是否是凸的，对偶问题都是凸优化问题；</p>
<p>​	c, 对偶问题可以给出原始问题一个下界；</p>
<p>​	d, 当满足一定条件时，原始问题与对偶问题的解是完全等价的。</p>
<h3 id="2-18-5-如何理解SVM中的对偶问题">2.18.5 如何理解SVM中的对偶问题</h3>
<p>在硬边界支持向量机中，问题的求解可以转化为凸二次规划问题。</p>
<p>​	假设优化目标为</p>
 $$
\begin{align}
&\min_{\boldsymbol w, b}\frac{1}{2}||\boldsymbol w||^2\\
&s.t. y_i(\boldsymbol w^T\boldsymbol x_i+b)\geqslant 1, i=1,2,\cdots,m.\\
\end{align}  \tag{1}
$$ 
<p><strong>step 1</strong>. 转化问题：</p>
 $$
\min_{\boldsymbol w, b} \max_{\alpha_i \geqslant 0}  \left\{\frac{1}{2}||\boldsymbol w||^2 + \sum_{i=1}^m\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))\right\}  \tag{2}
$$ 
<p>上式等价于原问题，因为若满足(1)中不等式约束，则(2)式求max时, $\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))$ 必须取0，与(1)等价；若不满足(1)中不等式约束，(2)中求max会得到无穷大。 交换min和max获得其对偶问题:</p>
 $$
\max_{\alpha_i \geqslant 0} \min_{\boldsymbol w, b}  \left\{\frac{1}{2}||\boldsymbol w||^2 + \sum_{i=1}^m\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))\right\}
$$ 
<p>交换之后的对偶问题和原问题并不相等，上式的解小于等于原问题的解。</p>
<p><strong>step 2</strong>.现在的问题是如何找到问题(1) 的最优值的一个最好的下界?</p>
 $$
\frac{1}{2}||\boldsymbol w||^2 < v\\
1 - y_i(\boldsymbol w^T\boldsymbol x_i+b) \leqslant 0\tag{3}
$$ 
<p>若方程组(3)无解， 则v是问题(1)的一个下界。若(3)有解， 则</p>
 $$
\forall \boldsymbol \alpha >  0 , \ \min_{\boldsymbol w, b}  \left\{\frac{1}{2}||\boldsymbol w||^2 + \sum_{i=1}^m\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))\right\} < v
$$ 
<p>由逆否命题得：若</p>
 $$
\exists \boldsymbol \alpha >  0 , \ \min_{\boldsymbol w, b}  \left\{\frac{1}{2}||\boldsymbol w||^2 + \sum_{i=1}^m\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))\right\} \geqslant v
$$ 
<p>则(3)无解。</p>
<p>那么v是问题</p>
<p>(1)的一个下界。<br>
要求得一个好的下界，取最大值即可</p>
 $$
\max_{\alpha_i \geqslant 0}  \min_{\boldsymbol w, b} \left\{\frac{1}{2}||\boldsymbol w||^2 + \sum_{i=1}^m\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))\right\}
$$ 
<p><strong>step 3</strong>. 令</p>
 $$
L(\boldsymbol w, b,\boldsymbol a) =   \frac{1}{2}||\boldsymbol w||^2 + \sum_{i=1}^m\alpha_i(1 - y_i(\boldsymbol w^T\boldsymbol x_i+b))
$$ 
 $p^*$ 为原问题的最小值，对应的 $w,b$ 分别为 $w^*,b^*$ ,则对于任意的 $a>0$ :
 $$
p^* = \frac{1}{2}||\boldsymbol w^*||^2 \geqslant  L(\boldsymbol w^*, b,\boldsymbol a) \geqslant \min_{\boldsymbol w, b} L(\boldsymbol w, b,\boldsymbol a)
$$ 
<p>则  $\min_{\boldsymbol w, b} L(\boldsymbol w, b,\boldsymbol a)$ 是问题（1）的一个下界。</p>
<p>此时，取最大值即可求得好的下界，即</p>
 $$
\max_{\alpha_i \geqslant 0} \min_{\boldsymbol w, b} L(\boldsymbol w, b,\boldsymbol a)
$$ 
<h3 id="2-18-7-常见的核函数有哪些">2.18.7 常见的核函数有哪些</h3>
<table>
<thead>
<tr>
<th>核函数</th>
<th>表达式</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linear Kernel线性核</td>
<td>$k(x,y)=x^{t}y+c$</td>
<td></td>
</tr>
<tr>
<td>Polynomial Kernel多项式核</td>
<td>$k(x,y)=(ax^{t}y+c)^{d}$</td>
<td>$d\geqslant1$ 为多项式的次数</td>
</tr>
<tr>
<td>Exponential Kernel指数核</td>
<td>$k(x,y)=exp(-\frac{\left \|x-y \right \|}{2\sigma ^{2}})$</td>
<td>$\sigma>0$</td>
</tr>
<tr>
<td>Gaussian Kernel高斯核</td>
<td>$k(x,y)=exp(-\frac{\left \|x-y \right \|^{2}}{2\sigma ^{2}})$</td>
<td>$\sigma$ 为高斯核的带宽， $\sigma>0$ ,</td>
</tr>
<tr>
<td>Laplacian Kernel拉普拉斯核</td>
<td>$k(x,y)=exp(-\frac{\left \|x-y \right \|}{\sigma})$</td>
<td>$\sigma>0$</td>
</tr>
<tr>
<td>ANOVA Kernel</td>
<td>$k(x,y)=exp(-\sigma(x^{k}-y^{k})^{2})^{d}$</td>
<td></td>
</tr>
<tr>
<td>Sigmoid Kernel</td>
<td>$k(x,y)=tanh(ax^{t}y+c)$</td>
<td>$tanh$ 为双曲正切函数， $a>0,c<0$< td>
</0$<></td></tr>
</tbody>
</table>
<h3 id="2-18-9-SVM主要特点">2.18.9 SVM主要特点</h3>
<p>特点：</p>
<p>(1)  SVM方法的理论基础是非线性映射，SVM利用内积核函数代替向高维空间的非线性映射。<br>
(2)  SVM的目标是对特征空间划分得到最优超平面，SVM方法核心是最大化分类边界。<br>
(3)  支持向量是SVM的训练结果，在SVM分类决策中起决定作用的是支持向量。<br>
(4)  SVM是一种有坚实理论基础的新颖的适用小样本学习方法。它基本上不涉及概率测度及大数定律等，也简化了通常的分类和回归等问题。<br>
(5)  SVM的最终决策函数只由少数的支持向量所确定，计算的复杂性取决于支持向量的数目，而不是样本空间的维数，这在某种意义上避免了“维数灾难”。<br>
(6)  少数支持向量决定了最终结果，这不但可以帮助我们抓住关键样本、“剔除”大量冗余样本,而且注定了该方法不但算法简单，而且具有较好的“鲁棒性”。这种鲁棒性主要体现在：<br>
​        ①增、删非支持向量样本对模型没有影响;<br>
​        ②支持向量样本集具有一定的鲁棒性;<br>
​        ③有些成功的应用中，SVM方法对核的选取不敏感<br>
(7)  SVM学习问题可以表示为凸优化问题，因此可以利用已知的有效算法发现目标函数的全局最小值。而其他分类方法（如基于规则的分类器和人工神经网络）都采用一种基于贪心学习的策略来搜索假设空间，这种方法一般只能获得局部最优解。<br>
(8)  SVM通过最大化决策边界的边缘来控制模型的能力。尽管如此，用户必须提供其他参数，如使用核函数类型和引入松弛变量等。<br>
(9)  SVM在小样本训练集上能够得到比其它算法好很多的结果。SVM优化目标是结构化风险最小，而不是经验风险最小，避免了过拟合问题，通过margin的概念，得到对数据分布的结构化描述，减低了对数据规模和数据分布的要求，有优秀的泛化能力。<br>
(10)  它是一个凸优化问题，因此局部最优解一定是全局最优解的优点。</p>
<h3 id="2-18-10-SVM主要缺点">2.18.10 SVM主要缺点</h3>
<p>(1) SVM算法对大规模训练样本难以实施<br>
​        SVM的空间消耗主要是存储训练样本和核矩阵，由于SVM是借助二次规划来求解支持向量，而求解二次规划将涉及m阶矩阵的计算（m为样本的个数），当m数目很大时该矩阵的存储和计算将耗费大量的机器内存和运算时间。<br>
​        如果数据量很大，SVM的训练时间就会比较长，如垃圾邮件的分类检测，没有使用SVM分类器，而是使用简单的朴素贝叶斯分类器，或者是使用逻辑回归模型分类。</p>
<p>(2) 用SVM解决多分类问题存在困难</p>
<p>​        经典的支持向量机算法只给出了二类分类的算法，而在实际应用中，一般要解决多类的分类问题。可以通过多个二类支持向量机的组合来解决。主要有一对多组合模式、一对一组合模式和SVM决策树；再就是通过构造多个分类器的组合来解决。主要原理是克服SVM固有的缺点，结合其他算法的优势，解决多类问题的分类精度。如：与粗糙集理论结合，形成一种优势互补的多类问题的组合分类器。</p>
<p>(3) 对缺失数据敏感，对参数和核函数的选择敏感</p>
<p>​        支持向量机性能的优劣主要取决于核函数的选取，所以对于一个实际问题而言，如何根据实际的数据模型选择合适的核函数从而构造SVM算法。目前比较成熟的核函数及其参数的选择都是人为的，根据经验来选取的，带有一定的随意性。在不同的问题领域，核函数应当具有不同的形式和参数，所以在选取时候应该将领域知识引入进来，但是目前还没有好的方法来解决核函数的选取问题。</p>
<h3 id="2-18-11-逻辑回归与SVM的异同">2.18.11 逻辑回归与SVM的异同</h3>
<p>相同点：</p>
<ul>
<li>LR和SVM都是<strong>分类</strong>算法。</li>
<li>LR和SVM都是<strong>监督学习</strong>算法。</li>
<li>LR和SVM都是<strong>判别模型</strong>。</li>
<li>如果不考虑核函数，LR和SVM都是<strong>线性分类</strong>算法，也就是说他们的分类决策面都是线性的。<br>
说明：LR也是可以用核函数的.但LR通常不采用核函数的方法。（<strong>计算量太大</strong>）</li>
</ul>
<p>不同点：</p>
<p><strong>1、LR采用log损失，SVM采用合页(hinge)损失。</strong><br>
逻辑回归的损失函数：</p>
 $$
J(\theta)=-\frac{1}{m}\sum^m_{i=1}\left[y^{i}logh_{\theta}(x^{i})+ (1-y^{i})log(1-h_{\theta}(x^{i}))\right]
$$ 
<p>支持向量机的目标函数:</p>
 $$
L(w,n,a)=\frac{1}{2}||w||^2-\sum^n_{i=1}\alpha_i \left( y_i(w^Tx_i+b)-1\right)
$$ 
<p>​	逻辑回归方法基于概率理论，假设样本为1的概率可以用sigmoid函数来表示，然后通过<strong>极大似然估计</strong>的方法估计出参数的值。<br>
​	支持向量机基于几何<strong>边界最大化</strong>原理，认为存在最大几何边界的分类面为最优分类面。</p>
<p>2、<strong>LR对异常值敏感，SVM对异常值不敏感</strong>。</p>
<p>​	支持向量机只考虑局部的边界线附近的点，而逻辑回归考虑全局。LR模型找到的那个超平面，是尽量让所有点都远离他，而SVM寻找的那个超平面，是只让最靠近中间分割线的那些点尽量远离，即只用到那些支持向量的样本。<br>
​	支持向量机改变非支持向量样本并不会引起决策面的变化。<br>
​	逻辑回归中改变任何样本都会引起决策面的变化。</p>
<p>3、<strong>计算复杂度不同。对于海量数据，SVM的效率较低，LR效率比较高</strong></p>
<p>​	当样本较少，特征维数较低时，SVM和LR的运行时间均比较短，SVM较短一些。准确率的话，LR明显比SVM要高。当样本稍微增加些时，SVM运行时间开始增长，但是准确率赶超了LR。SVM时间虽长，但在可接受范围内。当数据量增长到20000时，特征维数增长到200时，SVM的运行时间剧烈增加，远远超过了LR的运行时间。但是准确率却和LR相差无几。(这其中主要原因是大量非支持向量参与计算，造成SVM的二次规划问题)</p>
<p>4、<strong>对非线性问题的处理方式不同</strong></p>
<p>​	LR主要靠特征构造，必须组合交叉特征，特征离散化。SVM也可以这样，还可以通过核函数kernel（因为只有支持向量参与核计算，计算复杂度不高）。由于可以利用核函数，SVM则可以通过对偶求解高效处理。LR则在特征空间维度很高时，表现较差。</p>
<p>5、<strong>SVM的损失函数就自带正则</strong>。<br>
​	损失函数中的1/2||w||^2项，这就是为什么SVM是结构风险最小化算法的原因！！！而LR必须另外在损失函数上添加正则项！！！**</p>
<p>6、SVM自带<strong>结构风险最小化</strong>，LR则是<strong>经验风险最小化</strong>。</p>
<p>7、SVM会用核函数而LR一般不用核函数。</p>
<h2 id="2-19-贝叶斯分类器">2.19 贝叶斯分类器</h2>
<h3 id="2-19-1-图解极大似然估计">2.19.1 图解极大似然估计</h3>
<p>极大似然估计的原理，用一张图片来说明，如下图所示：</p>
<p><img src="2.19.1.1.png" alt></p>
<p>​	例：有两个外形完全相同的箱子，1号箱有99只白球，1只黑球；2号箱有1只白球，99只黑球。在一次实验中，取出的是黑球，请问是从哪个箱子中取出的？</p>
<p>​	一般的根据经验想法，会猜测这只黑球最像是从2号箱取出，此时描述的“最像”就有“最大似然”的意思，这种想法常称为“最大似然原理”。</p>
<h3 id="2-19-2-极大似然估计原理">2.19.2 极大似然估计原理</h3>
<p>​	总结起来，最大似然估计的目的就是：利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。</p>
<p>​	极大似然估计是建立在极大似然原理的基础上的一个统计方法。极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。通过若干次试验，观察其结果，利用试验结果得到某个参数值能够使样本出现的概率为最大，则称为极大似然估计。</p>
<p>​	由于样本集中的样本都是独立同分布，可以只考虑一类样本集 $D$ ，来估计参数向量 $\vec\theta$ 。记已知的样本集为：</p>
 $$
D=\vec x_{1},\vec x_{2},...,\vec x_{n}
$$ 
<p>似然函数（likelihood function）：联合概率密度函数 $p(D|\vec\theta )$ 称为相对于 $\vec x_{1},\vec x_{2},...,\vec x_{n}$ 的 $\vec\theta$ 的似然函数。</p>
 $$
l(\vec\theta )=p(D|\vec\theta ) =p(\vec x_{1},\vec x_{2},...,\vec x_{n}|\vec\theta )=\prod_{i=1}^{n}p(\vec x_{i}|\vec \theta )
$$ 
<p>如果 $\hat{\vec\theta}$ 是参数空间中能使似然函数 $l(\vec\theta)$ 最大的 $\vec\theta$ 值，则 $\hat{\vec\theta}$ 应该是“最可能”的参数值，那么 $\hat{\vec\theta}​$ 就是 $\theta$ 的极大似然估计量。它是样本集的函数，记作：</p>
 $$
\hat{\vec\theta}=d(D)= \mathop {\arg \max}_{\vec\theta} l(\vec\theta )
$$ 
 $\hat{\vec\theta}(\vec x_{1},\vec x_{2},...,\vec x_{n})$ 称为极大似然函数估计值。
<h3 id="2-19-3-贝叶斯分类器基本原理">2.19.3 贝叶斯分类器基本原理</h3>
<p>​	贝叶斯决策论通过<strong>相关概率已知</strong>的情况下利用<strong>误判损失</strong>来选择最优的类别分类。<br>
假设有 $N$ 种可能的分类标记，记为 $Y=\{c_1,c_2,...,c_N\}$ ，那对于样本 $\boldsymbol{x}$ ，它属于哪一类呢？</p>
<p>计算步骤如下：</p>
<p>step 1. 算出样本 $\boldsymbol{x}$ 属于第i个类的概率，即 $P(c_i|x)​$ ；</p>
<p>step 2. 通过比较所有的 $P(c_i|\boldsymbol{x})$ ，得到样本 $\boldsymbol{x}$ 所属的最佳类别。</p>
<p>step 3. 将类别 $c_i$ 和样本 $\boldsymbol{x}$ 代入到贝叶斯公式中，得到：</p>
 $$
P(c_i|\boldsymbol{x})=\frac{P(\boldsymbol{x}|c_i)P(c_i)}{P(\boldsymbol{x})}.
$$ 
<p>​	一般来说， $P(c_i)$ 为先验概率， $P(\boldsymbol{x}|c_i)$ 为条件概率， $P(\boldsymbol{x})$ 是用于归一化的证据因子。对于 $P(c_i)$ 可以通过训练样本中类别为 $c_i$ 的样本所占的比例进行估计；此外，由于只需要找出最大的 $P(\boldsymbol{x}|c_i)$ ，因此我们并不需要计算 $P(\boldsymbol{x})$ 。<br>
​	为了求解条件概率，基于不同假设提出了不同的方法，以下将介绍朴素贝叶斯分类器和半朴素贝叶斯分类器。</p>
<h3 id="2-19-4-朴素贝叶斯分类器">2.19.4 朴素贝叶斯分类器</h3>
<p>​	假设样本 $\boldsymbol{x}$ 包含 $d$ 个属性，即 $\boldsymbol{x}=\{ x_1,x_2,...,x_d\}$ 。于是有：</p>
 $$
P(\boldsymbol{x}|c_i)=P(x_1,x_2,\cdots,x_d|c_i)
$$ 
<p>这个联合概率难以从有限的训练样本中直接估计得到。于是，朴素贝叶斯（Naive Bayesian，简称NB）采用了“属性条件独立性假设”：对已知类别，假设所有属性相互独立。于是有：</p>
 $$
P(x_1,x_2,\cdots,x_d|c_i)=\prod_{j=1}^d P(x_j|c_i)
$$ 
<p>这样的话，我们就可以很容易地推出相应的判定准则了：</p>
 $$
h_{nb}(\boldsymbol{x})=\mathop{\arg \max}_{c_i\in Y} P(c_i)\prod_{j=1}^dP(x_j|c_i)
$$ 
<p><strong>条件概率 $P(x_j|c_i)​$ 的求解</strong></p>
<p>如果 $x_j$ 是标签属性，那么我们可以通过计数的方法估计 $P(x_j|c_i)$</p>
 $$
P(x_j|c_i)=\frac{P(x_j,c_i)}{P(c_i)}\approx\frac{\#(x_j,c_i)}{\#(c_i)}
$$ 
<p>其中， $\#(x_j,c_i)$ 表示在训练样本中 $x_j$ 与 $c_{i}$ 共同出现的次数。</p>
<p>如果 $x_j​$ 是数值属性，通常我们假设类别中 $c_{i}​$ 的所有样本第 $j​$ 个属性的值服从正态分布。我们首先估计这个分布的均值 $μ​$ 和方差 $σ​$ ，然后计算 $x_j​$ 在这个分布中的概率密度 $P(x_j|c_i)​$ 。</p>
<h3 id="2-19-5-举例理解朴素贝叶斯分类器">2.19.5 举例理解朴素贝叶斯分类器</h3>
<p>使用经典的西瓜训练集如下：</p>
<table>
<thead>
<tr>
<th style="text-align:center">编号</th>
<th style="text-align:center">色泽</th>
<th style="text-align:center">根蒂</th>
<th style="text-align:center">敲声</th>
<th style="text-align:center">纹理</th>
<th style="text-align:center">脐部</th>
<th style="text-align:center">触感</th>
<th style="text-align:center">密度</th>
<th style="text-align:center">含糖率</th>
<th style="text-align:center">好瓜</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.697</td>
<td style="text-align:center">0.460</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">沉闷</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.774</td>
<td style="text-align:center">0.376</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.634</td>
<td style="text-align:center">0.264</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">沉闷</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.608</td>
<td style="text-align:center">0.318</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">浅白</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.556</td>
<td style="text-align:center">0.215</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">稍凹</td>
<td style="text-align:center">软粘</td>
<td style="text-align:center">0.403</td>
<td style="text-align:center">0.237</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">稍糊</td>
<td style="text-align:center">稍凹</td>
<td style="text-align:center">软粘</td>
<td style="text-align:center">0.481</td>
<td style="text-align:center">0.149</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">稍凹</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.437</td>
<td style="text-align:center">0.211</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">9</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">沉闷</td>
<td style="text-align:center">稍糊</td>
<td style="text-align:center">稍凹</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.666</td>
<td style="text-align:center">0.091</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">10</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">硬挺</td>
<td style="text-align:center">清脆</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">平坦</td>
<td style="text-align:center">软粘</td>
<td style="text-align:center">0.243</td>
<td style="text-align:center">0.267</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">11</td>
<td style="text-align:center">浅白</td>
<td style="text-align:center">硬挺</td>
<td style="text-align:center">清脆</td>
<td style="text-align:center">模糊</td>
<td style="text-align:center">平坦</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.245</td>
<td style="text-align:center">0.057</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">12</td>
<td style="text-align:center">浅白</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">模糊</td>
<td style="text-align:center">平坦</td>
<td style="text-align:center">软粘</td>
<td style="text-align:center">0.343</td>
<td style="text-align:center">0.099</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">13</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">稍糊</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.639</td>
<td style="text-align:center">0.161</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">14</td>
<td style="text-align:center">浅白</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">沉闷</td>
<td style="text-align:center">稍糊</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.657</td>
<td style="text-align:center">0.198</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">15</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">稍蜷</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">稍凹</td>
<td style="text-align:center">软粘</td>
<td style="text-align:center">0.360</td>
<td style="text-align:center">0.370</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">16</td>
<td style="text-align:center">浅白</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">模糊</td>
<td style="text-align:center">平坦</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.593</td>
<td style="text-align:center">0.042</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">17</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">沉闷</td>
<td style="text-align:center">稍糊</td>
<td style="text-align:center">稍凹</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.719</td>
<td style="text-align:center">0.103</td>
<td style="text-align:center">否</td>
</tr>
</tbody>
</table>
<p>对下面的测试例“测1”进行 分类：</p>
<table>
<thead>
<tr>
<th style="text-align:center">编号</th>
<th style="text-align:center">色泽</th>
<th style="text-align:center">根蒂</th>
<th style="text-align:center">敲声</th>
<th style="text-align:center">纹理</th>
<th style="text-align:center">脐部</th>
<th style="text-align:center">触感</th>
<th style="text-align:center">密度</th>
<th style="text-align:center">含糖率</th>
<th style="text-align:center">好瓜</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">测1</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">清晰</td>
<td style="text-align:center">凹陷</td>
<td style="text-align:center">硬滑</td>
<td style="text-align:center">0.697</td>
<td style="text-align:center">0.460</td>
<td style="text-align:center">？</td>
</tr>
</tbody>
</table>
<p>首先，估计类先验概率 $P(c_j)$ ，有</p>
 $$
\begin{align} 
&P(好瓜=是)=\frac{8}{17}=0.471 \newline 
&P(好瓜=否)=\frac{9}{17}=0.529 
\end{align}
$$ 
<p>然后，为每个属性估计条件概率（这里，对于连续属性，假定它们服从正态分布）</p>
 $$
P_{青绿|是}=P（色泽=青绿|好瓜=是）=\frac{3}{8}=0.375
$$ 
 $$
P_{青绿|否}=P（色泽=青绿|好瓜=否）=\frac{3}{9}\approx0.333
$$ 
 $$
P_{蜷缩|是}=P（根蒂=蜷缩|好瓜=是）=\frac{5}{8}=0.625
$$ 
 $$
P_{蜷缩|否}=P（根蒂=蜷缩|好瓜=否）=\frac{3}{9}=0.333
$$ 
 $$
P_{浊响|是}=P（敲声=浊响|好瓜=是）=\frac{6}{8}=0.750
$$ 
 $$
P_{浊响|否}=P（敲声=浊响|好瓜=否）=\frac{4}{9}\approx 0.444
$$ 
 $$
P_{清晰|是}=P（纹理=清晰|好瓜=是）=\frac{7}{8}= 0.875
$$ 
 $$
P_{清晰|否}=P（纹理=清晰|好瓜=否）=\frac{2}{9}\approx 0.222
$$ 
 $$
P_{凹陷|是}=P（脐部=凹陷|好瓜=是）=\frac{6}{8}= 0.750
$$ 
 $$
P_{凹陷|否}=P（脐部=凹陷|好瓜=否）=\frac{2}{9} \approx 0.222
$$ 
 $$
P_{硬滑|是}=P（触感=硬滑|好瓜=是）=\frac{6}{8}= 0.750
$$ 
 $$
P_{硬滑|否}=P（触感=硬滑|好瓜=否）=\frac{6}{9} \approx 0.667
$$ 
 $$
\begin{aligned}
\rho_{密度：0.697|是}&=\rho（密度=0.697|好瓜=是）\\&=\frac{1}{\sqrt{2 \pi}\times0.129}exp\left( -\frac{(0.697-0.574)^2}{2\times0.129^2}\right) \approx 1.959
\end{aligned}
$$ 
 $$
\begin{aligned}
\rho_{密度：0.697|否}&=\rho（密度=0.697|好瓜=否）\\&=\frac{1}{\sqrt{2 \pi}\times0.195}exp\left( -\frac{(0.697-0.496)^2}{2\times0.195^2}\right) \approx 1.203
\end{aligned}
$$ 
 $$
\begin{aligned}
\rho_{含糖：0.460|是}&=\rho（密度=0.460|好瓜=是）\\&=\frac{1}{\sqrt{2 \pi}\times0.101}exp\left( -\frac{(0.460-0.279)^2}{2\times0.101^2}\right) \approx 0.788
\end{aligned}
$$ 
 $$
\begin{aligned}
\rho_{含糖：0.460|否}&=\rho（密度=0.460|好瓜=是）\\&=\frac{1}{\sqrt{2 \pi}\times0.108}exp\left( -\frac{(0.460-0.154)^2}{2\times0.108^2}\right) \approx 0.066
\end{aligned}
$$ 
<p>于是有</p>
 $$
\begin{align} 
P(&好瓜=是)\times P_{青绿|是} \times P_{蜷缩|是} \times P_{浊响|是} \times P_{清晰|是} \times P_{凹陷|是}\newline 
&\times P_{硬滑|是} \times p_{密度：0.697|是} \times p_{含糖：0.460|是} \approx 0.063 \newline\newline 
P(&好瓜=否)\times P_{青绿|否} \times P_{蜷缩|否} \times P_{浊响|否} \times P_{清晰|否} \times P_{凹陷|否}\newline 
&\times P_{硬滑|否} \times p_{密度：0.697|否} \times p_{含糖：0.460|否} \approx 6.80\times 10^{-5} 
\end{align}
$$ 
<p>由于 $0.063>6.80\times 10^{-5}$ ，因此，朴素贝叶斯分类器将测试样本“测1”判别为“好瓜”。</p>
<h3 id="2-19-6-半朴素贝叶斯分类器">2.19.6 半朴素贝叶斯分类器</h3>
<p>​	朴素贝叶斯采用了“属性条件独立性假设”，半朴素贝叶斯分类器的基本想法是适当考虑一部分属性间的相互依赖信息。<strong>独依赖估计</strong>（One-Dependence Estimator，简称ODE）是半朴素贝叶斯分类器最常用的一种策略。顾名思义，独依赖是假设每个属性在类别之外最多依赖一个其他属性，即：</p>
 $$
P(\boldsymbol{x}|c_i)=\prod_{j=1}^d P(x_j|c_i,{\rm pa}_j)
$$ 
<p>其中 $pa_j$ 为属性 $x_i$ 所依赖的属性，成为 $x_i$ 的父属性。假设父属性 $pa_j$ 已知，那么可以使用下面的公式估计 $P(x_j|c_i,{\rm pa}_j)$</p>
 $$
P(x_j|c_i,{\rm pa}_j)=\frac{P(x_j,c_i,{\rm pa}_j)}{P(c_i,{\rm pa}_j)}
$$ 
<h2 id="2-20-EM算法">2.20 EM算法</h2>
<h3 id="2-20-1-EM算法基本思想">2.20.1 EM算法基本思想</h3>
<p>​	最大期望算法（Expectation-Maximization algorithm, EM），是一类通过迭代进行极大似然估计的优化算法，通常作为牛顿迭代法的替代，用于对包含隐变量或缺失数据的概率模型进行参数估计。</p>
<p>​	最大期望算法基本思想是经过两个步骤交替进行计算：</p>
<p>​	第一步是计算期望（E），利用对隐藏变量的现有估计值，计算其最大似然估计值**；**</p>
<p>​	第二步是最大化（M），最大化在E步上求得的最大似然值来计算参数的值。</p>
<p>​	M步上找到的参数估计值被用于下一个E步计算中，这个过程不断交替进行。</p>
<h3 id="2-20-2-EM算法推导">2.20.2 EM算法推导</h3>
<p>​	对于 $m$ 个样本观察数据 $x=(x^{1},x^{2},...,x^{m})$ ，现在想找出样本的模型参数 $\theta$ ，其极大化模型分布的对数似然函数为：</p>
 $$
\theta = \mathop{\arg\max}_\theta\sum\limits_{i=1}^m logP(x^{(i)};\theta)
$$ 
<p>如果得到的观察数据有未观察到的隐含数据 $z=(z^{(1)},z^{(2)},...z^{(m)})$ ，极大化模型分布的对数似然函数则为：</p>
 $$
\theta =\mathop{\arg\max}_\theta\sum\limits_{i=1}^m logP(x^{(i)};\theta) = \mathop{\arg\max}_\theta\sum\limits_{i=1}^m log\sum\limits_{z^{(i)}}P(x^{(i)}, z^{(i)};\theta)  \tag{a}
$$ 
<p>由于上式不能直接求出 $\theta$ ，采用缩放技巧：</p>
 $$
\begin{align} \sum\limits_{i=1}^m log\sum\limits_{z^{(i)}}P(x^{(i)}, z^{(i)};\theta)   & = \sum\limits_{i=1}^m log\sum\limits_{z^{(i)}}Q_i(z^{(i)})\frac{P(x^{(i)}, z^{(i)};\theta)}{Q_i(z^{(i)})} \\ & \geqslant  \sum\limits_{i=1}^m \sum\limits_{z^{(i)}}Q_i(z^{(i)})log\frac{P(x^{(i)}, z^{(i)};\theta)}{Q_i(z^{(i)})} \end{align}   \tag{1}
$$ 
<p>上式用到了Jensen不等式：</p>
 $$
log\sum\limits_j\lambda_jy_j \geqslant \sum\limits_j\lambda_jlogy_j\;\;,  \lambda_j \geqslant 0, \sum\limits_j\lambda_j =1
$$ 
<p>并且引入了一个未知的新分布 $Q_i(z^{(i)})$ 。</p>
<p>此时，如果需要满足Jensen不等式中的等号，所以有：</p>
 $$
\frac{P(x^{(i)}, z^{(i)};\theta)}{Q_i(z^{(i)})} =c, c为常数
$$ 
<p>由于 $Q_i(z^{(i)})$ 是一个分布，所以满足</p>
 $$
\sum\limits_{z}Q_i(z^{(i)}) =1
$$ 
<p>综上，可得：</p>
 $$
Q_i(z^{(i)})  = \frac{P(x^{(i)}， z^{(i)};\theta)}{\sum\limits_{z}P(x^{(i)}, z^{(i)};\theta)} =  \frac{P(x^{(i)}, z^{(i)};\theta)}{P(x^{(i)};\theta)} = P( z^{(i)}|x^{(i)};\theta)
$$ 
<p>如果 $Q_i(z^{(i)}) = P( z^{(i)}|x^{(i)};\theta)$  ，则第(1)式是我们的包含隐藏数据的对数似然的一个下界。如果我们能极大化这个下界，则也在尝试极大化我们的对数似然。即我们需要最大化下式：</p>
 $$
\mathop{\arg\max}_\theta \sum\limits_{i=1}^m \sum\limits_{z^{(i)}}Q_i(z^{(i)})log\frac{P(x^{(i)}， z^{(i)};\theta)}{Q_i(z^{(i)})}
$$ 
<p>简化得：</p>
 $$
\mathop{\arg\max}_\theta \sum\limits_{i=1}^m \sum\limits_{z^{(i)}}Q_i(z^{(i)})log{P(x^{(i)}, z^{(i)};\theta)}
$$ 
<p>以上即为EM算法的M步， $\sum\limits_{z^{(i)}}Q_i(z^{(i)})log{P(x^{(i)}, z^{(i)};\theta)}​$ 可理解为 $logP(x^{(i)}, z^{(i)};\theta) $ 基于条件概率分布 $Q_i(z^{(i)}) $ 的期望。以上即为EM算法中E步和M步的具体数学含义。</p>
<h3 id="2-20-3-图解EM算法">2.20.3 图解EM算法</h3>
<p>​	考虑上一节中的（a）式，表达式中存在隐变量，直接找到参数估计比较困难，通过EM算法迭代求解下界的最大值到收敛为止。</p>
<p><img src="2.20.1.jpg" alt></p>
<p>​	图片中的紫色部分是我们的目标模型 $p(x|\theta)$ ，该模型复杂，难以求解析解，为了消除隐变量 $z^{(i)}$ 的影响，我们可以选择一个不包含 $z^{(i)}$ 的模型 $r(x|\theta)$ ，使其满足条件 $r(x|\theta) \leqslant p(x|\theta) $ 。</p>
<p>求解步骤如下：</p>
<p>（1）选取 $\theta_1$ ，使得 $r(x|\theta_1) = p(x|\theta_1)$ ，然后对此时的 $r$ 求取最大值，得到极值点 $\theta_2$ ，实现参数的更新。</p>
<p>（2）重复以上过程到收敛为止，在更新过程中始终满足 $r \leqslant p $ .</p>
<h3 id="2-20-4-EM算法流程">2.20.4 EM算法流程</h3>
<p>输入：观察数据 $x=(x^{(1)},x^{(2)},...x^{(m)})$ ，联合分布 $p(x,z ;\theta)$ ，条件分布 $p(z|x; \theta)$ ，最大迭代次数 $J$</p>
<p>1）随机初始化模型参数 $\theta$ 的初值 $\theta^0$ 。</p>
<p>2） $for \ j  \ from \ 1  \ to  \ j$ ：</p>
<p>​	a） E步。计算联合分布的条件概率期望：</p>
 $$
Q_i(z^{(i)}) = P( z^{(i)}|x^{(i)}, \theta^{j})
$$ 
 $$
L(\theta, \theta^{j}) = \sum\limits_{i=1}^m\sum\limits_{z^{(i)}}P( z^{(i)}|x^{(i)}, \theta^{j})log{P(x^{(i)}, z^{(i)};\theta)}
$$ 
<p>​	b） M步。极大化 $L(\theta, \theta^{j})$ ，得到 $\theta^{j+1}$ :</p>
 $$
\theta^{j+1} = \mathop{\arg\max}_\theta L(\theta, \theta^{j})
$$ 
<p>​	c） 如果 $\theta^{j+1}$ 收敛，则算法结束。否则继续回到步骤a）进行E步迭代。</p>
<p>输出：模型参数 $\theta​$ 。</p>
<h2 id="2-21-降维和聚类">2.21 降维和聚类</h2>
<h3 id="2-21-1-图解为什么会产生维数灾难">2.21.1 图解为什么会产生维数灾难</h3>
<p>​	假如数据集包含10张照片，照片中包含三角形和圆两种形状。现在来设计一个分类器进行训练，让这个分类器对其他的照片进行正确分类（假设三角形和圆的总数是无限大），简单的，我们用一个特征进行分类：</p>
<p><img src="2.21.1.1.png" alt></p>
<p>​											图2.21.1.a</p>
<p>​	从上图可看到，如果仅仅只有一个特征进行分类，三角形和圆几乎是均匀分布在这条线段上，很难将10张照片线性分类。那么，增加一个特征后的情况会怎么样：</p>
<p><img src="2.21.1.2.png" alt></p>
<p>​											图2.21.1.b</p>
<p>增加一个特征后，我们发现仍然无法找到一条直线将猫和狗分开。所以，考虑需要再增加一个特征：</p>
<p><img src="2.21.1.3.png" alt></p>
<p>​											图2.21.1.c</p>
<p><img src="2.21.1.4.png" alt></p>
<p>​											图2.21.1.d</p>
<p>​	此时，可以找到一个平面将三角形和圆分开。</p>
<p>​	现在计算一下不同特征数是样本的密度：</p>
<p>​	（1）一个特征时，假设特征空间时长度为5的线段，则样本密度为 $10 \div 5 = 2$ 。</p>
<p>​	（2）两个特征时，特征空间大小为 $ 5\times5 = 25$ ，样本密度为 $10 \div 25 = 0.4$ 。</p>
<p>​	（3）三个特征时，特征空间大小是 $ 5\times5\times5 = 125$ ，样本密度为 $10 \div 125 = 0.08$ 。</p>
<p>​	以此类推，如果继续增加特征数量，样本密度会越来越稀疏，此时，更容易找到一个超平面将训练样本分开。当特征数量增长至无限大时，样本密度就变得非常稀疏。</p>
<p>​	下面看一下将高维空间的分类结果映射到低维空间时，会出现什么情况？</p>
<p><img src="2.21.1.5.png" alt></p>
<p>​										图2.21.1.e</p>
<p>​	上图是将三维特征空间映射到二维特征空间后的结果。尽管在高维特征空间时训练样本线性可分，但是映射到低维空间后，结果正好相反。事实上，增加特征数量使得高维空间线性可分，相当于在低维空间内训练一个复杂的非线性分类器。不过，这个非线性分类器太过“聪明”，仅仅学到了一些特例。如果将其用来辨别那些未曾出现在训练样本中的测试样本时，通常结果不太理想，会造成过拟合问题。</p>
<p><img src="2.21.1.6a.png" alt></p>
<p>​										图2.21.1.f</p>
<p>​	上图所示的只采用2个特征的线性分类器分错了一些训练样本，准确率似乎没有图2.21.1.e的高，但是，采用2个特征的线性分类器的泛化能力比采用3个特征的线性分类器要强。因为，采用2个特征的线性分类器学习到的不只是特例，而是一个整体趋势，对于那些未曾出现过的样本也可以比较好地辨别开来。换句话说，通过减少特征数量，可以避免出现过拟合问题，从而避免“维数灾难”。</p>
<p><img src="2.21.1.6.png" alt></p>
<p>​	上图从另一个角度诠释了“维数灾难”。假设只有一个特征时，特征的值域是0到1，每一个三角形和圆的特征值都是唯一的。如果我们希望训练样本覆盖特征值值域的20%，那么就需要三角形和圆总数的20%。我们增加一个特征后，为了继续覆盖特征值值域的20%就需要三角形和圆总数的45%( $0.452^2\approx0.2$ )。继续增加一个特征后，需要三角形和圆总数的58%( $0.583^3\approx0.2$ )。随着特征数量的增加，为了覆盖特征值值域的20%，就需要更多的训练样本。如果没有足够的训练样本，就可能会出现过拟合问题。</p>
<p>​	通过上述例子，我们可以看到特征数量越多，训练样本就会越稀疏，分类器的参数估计就会越不准确，更加容易出现过拟合问题。“维数灾难”的另一个影响是训练样本的稀疏性并不是均匀分布的。处于中心位置的训练样本比四周的训练样本更加稀疏。</p>
<p><img src="2.21.1.7.png" alt></p>
<p>​	假设有一个二维特征空间，如上图所示的矩形，在矩形内部有一个内切的圆形。由于越接近圆心的样本越稀疏，因此，相比于圆形内的样本，那些位于矩形四角的样本更加难以分类。当维数变大时，特征超空间的容量不变，但单位圆的容量会趋于0，在高维空间中，大多数训练数据驻留在特征超空间的角落。散落在角落的数据要比处于中心的数据难于分类。</p>
<h3 id="2-21-2-怎样避免维数灾难">2.21.2 怎样避免维数灾难</h3>
<p><strong>有待完善！！！</strong></p>
<p>解决维度灾难问题：</p>
<p>主成分分析法PCA，线性判别法LDA</p>
<p>奇异值分解简化数据、拉普拉斯特征映射</p>
<p>Lassio缩减系数法、小波分析法、</p>
<h3 id="2-21-3-聚类和降维有什么区别与联系">2.21.3 聚类和降维有什么区别与联系</h3>
<p>​	聚类用于找寻数据内在的分布结构，既可以作为一个单独的过程，比如异常检测等等。也可作为分类等其他学习任务的前驱过程。聚类是标准的无监督学习。</p>
<p>​	1）在一些推荐系统中需确定新用户的类型，但定义“用户类型”却可能不太容易，此时往往可先对原有的用户数据进行聚类，根据聚类结果将每个簇定义为一个类,然后再基于这些类训练分类模型,用于判别新用户的类型。</p>
<p><img src="2.21.3.1.png" alt></p>
<p>​	2）而降维则是为了缓解维数灾难的一个重要方法，就是通过某种数学变换将原始高维属性空间转变为一个低维“子空间”。其基于的假设就是，虽然人们平时观测到的数据样本虽然是高维的，但是实际上真正与学习任务相关的是个低维度的分布。从而通过最主要的几个特征维度就可以实现对数据的描述，对于后续的分类很有帮助。比如对于Kaggle（数据分析竞赛平台之一）上的泰坦尼克号生还问题。通过给定一个乘客的许多特征如年龄、姓名、性别、票价等，来判断其是否能在海难中生还。这就需要首先进行特征筛选，从而能够找出主要的特征，让学习到的模型有更好的泛化性。</p>
<p>​	聚类和降维都可以作为分类等问题的预处理步骤。</p>
<p><img src="2-19.jpg" alt></p>
<p>​	但是他们虽然都能实现对数据的约减。但是二者适用的对象不同，聚类针对的是数据点，而降维则是对于数据的特征。另外它们有着很多种实现方法。聚类中常用的有K-means、层次聚类、基于密度的聚类等；降维中常用的则PCA、Isomap、LLE等。</p>
<h3 id="2-21-4-有哪些聚类算法优劣衡量标准">2.21.4 有哪些聚类算法优劣衡量标准</h3>
<p>不同聚类算法有不同的优劣和不同的适用条件。可从以下方面进行衡量判断：<br>
1、算法的处理能力：处理大的数据集的能力，即算法复杂度；处理数据噪声的能力；处理任意形状，包括有间隙的嵌套的数据的能力；<br>
2、算法是否需要预设条件：是否需要预先知道聚类个数，是否需要用户给出领域知识；</p>
<p>​    3、算法的数据输入属性：算法处理的结果与数据输入的顺序是否相关，也就是说算法是否独立于数据输入顺序；算法处理有很多属性数据的能力，也就是对数据维数是否敏感，对数据的类型有无要求。</p>
<h3 id="2-21-5-聚类和分类有什么区别">2.21.5 聚类和分类有什么区别</h3>
<p>**聚类（Clustering） **<br>
聚类，简单地说就是把相似的东西分到一组，聚类的时候，我们并不关心某一类是什么，我们需要实现的目标只是把相似的东西聚到一起。一个聚类算法通常只需要知道如何计算相似度就可以开始工作了，因此聚类通常并不需要使用训练数据进行学习，在机器学习中属于无监督学习。</p>
<p>**分类（Classification） **</p>
<p>​     分类，对于一个分类器，通常需要你告诉它“这个东西被分为某某类”。一般情况下，一个分类器会从它得到的训练集中进行学习，从而具备对未知数据进行分类的能力，在机器学习中属于监督学习。</p>
<h3 id="2-21-6-不同聚类算法特点性能比较">2.21.6 不同聚类算法特点性能比较</h3>
<table>
<thead>
<tr>
<th style="text-align:center">算法名称</th>
<th style="text-align:center">可伸缩性</th>
<th style="text-align:center">适合的数据类型</th>
<th style="text-align:center">高维性</th>
<th style="text-align:center">异常数据抗干扰性</th>
<th style="text-align:center">聚类形状</th>
<th style="text-align:center">算法效率</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">WAVECLUSTER</td>
<td style="text-align:center">很高</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">很高</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">很高</td>
</tr>
<tr>
<td style="text-align:center">ROCK</td>
<td style="text-align:center">很高</td>
<td style="text-align:center">混合型</td>
<td style="text-align:center">很高</td>
<td style="text-align:center">很高</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">一般</td>
</tr>
<tr>
<td style="text-align:center">BIRCH</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">球形</td>
<td style="text-align:center">很高</td>
</tr>
<tr>
<td style="text-align:center">CURE</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">很高</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">较高</td>
</tr>
<tr>
<td style="text-align:center">K-PROTOTYPES</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">混合型</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">一般</td>
</tr>
<tr>
<td style="text-align:center">DENCLUE</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">较高</td>
</tr>
<tr>
<td style="text-align:center">OPTIGRID</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">一般</td>
</tr>
<tr>
<td style="text-align:center">CLIQUE</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">较低</td>
</tr>
<tr>
<td style="text-align:center">DBSCAN</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">任意形状</td>
<td style="text-align:center">一般</td>
</tr>
<tr>
<td style="text-align:center">CLARANS</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">数值型</td>
<td style="text-align:center">较低</td>
<td style="text-align:center">较高</td>
<td style="text-align:center">球形</td>
<td style="text-align:center">较低</td>
</tr>
</tbody>
</table>
<h3 id="2-21-7-四种常用聚类方法之比较">2.21.7 四种常用聚类方法之比较</h3>
<p>​	聚类就是按照某个特定标准把一个数据集分割成不同的类或簇，使得同一个簇内的数据对象的相似性尽可能大，同时不在同一个簇中的数据对象的差异性也尽可能地大。即聚类后同一类的数据尽可能聚集到一起，不同类数据尽量分离。<br>
​	主要的聚类算法可以划分为如下几类：划分方法、层次方法、基于密度的方法、基于网格的方法以及基于模型的方法。下面主要对k-means聚类算法、凝聚型层次聚类算法、神经网络聚类算法之SOM,以及模糊聚类的FCM算法通过通用测试数据集进行聚类效果的比较和分析。</p>
<h3 id="2-21-8-k-means聚类算法">2.21.8 k-means聚类算法</h3>
<p>k-means是划分方法中较经典的聚类算法之一。由于该算法的效率高，所以在对大规模数据进行聚类时被广泛应用。目前，许多算法均围绕着该算法进行扩展和改进。<br>
k-means算法以k为参数，把n个对象分成k个簇，使簇内具有较高的相似度，而簇间的相似度较低。k-means算法的处理过程如下：首先，随机地 选择k个对象，每个对象初始地代表了一个簇的平均值或中心;对剩余的每个对象，根据其与各簇中心的距离，将它赋给最近的簇;然后重新计算每个簇的平均值。 这个过程不断重复，直到准则函数收敛。通常，采用平方误差准则，其定义如下：</p>
 $$
E=\sum_{i=1}^{k}\sum_{p\in C_i}\left\|p-m_i\right\|^2
$$ 
<p>这里E是数据中所有对象的平方误差的总和，p是空间中的点， $m_i$ 是簇 $C_i$ 的平均值[9]。该目标函数使生成的簇尽可能紧凑独立，使用的距离度量是欧几里得距离，当然也可以用其他距离度量。</p>
<p><strong>算法流程</strong>：<br>
​    输入：包含n个对象的数据和簇的数目k；<br>
​    输出：n个对象到k个簇，使平方误差准则最小。<br>
​    步骤：<br>
　　(1) 任意选择k个对象作为初始的簇中心；<br>
　　(2) 根据簇中对象的平均值，将每个对象(重新)赋予最类似的簇；<br>
　　(3) 更新簇的平均值，即计算每个簇中对象的平均值；<br>
　　(4) 重复步骤(2)、(3)直到簇中心不再变化；</p>
<h3 id="2-21-9-层次聚类算法">2.21.9 层次聚类算法</h3>
<p>​    根据层次分解的顺序是自底向上的还是自上向下的，层次聚类算法分为凝聚的层次聚类算法和分裂的层次聚类算法。<br>
　凝聚型层次聚类的策略是先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到所有对象都在一个簇中，或者某个终结条件被满足。绝大多数层次聚类属于凝聚型层次聚类，它们只是在簇间相似度的定义上有所不同。</p>
<p><strong>算法流程</strong>：</p>
<p>注：以采用最小距离的凝聚层次聚类算法为例：</p>
<p>(1) 将每个对象看作一类，计算两两之间的最小距离；<br>
　(2) 将距离最小的两个类合并成一个新类；<br>
　(3) 重新计算新类与所有类之间的距离；<br>
　(4) 重复(2)、(3)，直到所有类最后合并成一类。</p>
<h3 id="2-21-10-SOM聚类算法">2.21.10 SOM聚类算法</h3>
<p>​	SOM神经网络[11]是由芬兰神经网络专家Kohonen教授提出的，该算法假设在输入对象中存在一些拓扑结构或顺序，可以实现从输入空间(n维)到输出平面(2维)的降维映射，其映射具有拓扑特征保持性质,与实际的大脑处理有很强的理论联系。</p>
<p>​	SOM网络包含输入层和输出层。输入层对应一个高维的输入向量，输出层由一系列组织在2维网格上的有序节点构成，输入节点与输出节点通过权重向量连接。 学习过程中，找到与之距离最短的输出层单元，即获胜单元，对其更新。同时，将邻近区域的权值更新，使输出节点保持输入向量的拓扑特征。</p>
<p><strong>算法流程</strong>：</p>
<p>​	(1) 网络初始化，对输出层每个节点权重赋初值；<br>
​	(2) 从输入样本中随机选取输入向量并且归一化，找到与输入向量距离最小的权重向量；<br>
​	(3) 定义获胜单元，在获胜单元的邻近区域调整权重使其向输入向量靠拢；<br>
​	(4) 提供新样本、进行训练；<br>
​	(5) 收缩邻域半径、减小学习率、重复，直到小于允许值，输出聚类结果。</p>
<h3 id="2-21-11-FCM聚类算法">2.21.11 FCM聚类算法</h3>
<p>​	1965年美国加州大学柏克莱分校的扎德教授第一次提出了‘集合’的概念。经过十多年的发展，模糊集合理论渐渐被应用到各个实际应用方面。为克服非此即彼的分类缺点，出现了以模糊集合论为数学基础的聚类分析。用模糊数学的方法进行聚类分析，就是模糊聚类分析[12]。<br>
​	FCM算法是一种以隶属度来确定每个数据点属于某个聚类程度的算法。该聚类算法是传统硬聚类算法的一种改进。<br>
​	设数据集 $X={x_1,x_2,...,x_n}$ ,它的模糊 $c$ 划分可用模糊矩阵 $U=[u_{ij}]$ 表示，矩阵 $U$ 的元素 $u_{ij}$ 表示第 $j(j=1,2,...,n)$ 个数据点属于第 $i(i=1,2,...,c)$ 类的隶属度， $u_{ij}$ 满足如下条件：</p>
 $$
\begin{equation}
\left\{
\begin{array}{lr}
\sum_{i=1}^c u_{ij}=1 \quad\forall~j
\\u_{ij}\in[0,1] \quad\forall ~i,j
\\\sum_{j=1}^c u_{ij}>0 \quad\forall ~i
\end{array}
\right.
\end{equation}
$$ 
<p>目前被广泛使用的聚类准则是取类内加权误差平方和的极小值。即：</p>
 $$
(min)J_m(U,V)=\sum^n_{j=1}\sum^c_{i=1}u^m_{ij}d^2_{ij}(x_j,v_i)
$$ 
<p>其中 $V$ 为聚类中心， $m$ 为加权指数， $d_{ij}(x_j,v_i)=||v_i-x_j||$ 。</p>
<p><strong>算法流程</strong>：</p>
<p>(1) 标准化数据矩阵；<br>
　(2) 建立模糊相似矩阵，初始化隶属矩阵；<br>
　(3) 算法开始迭代，直到目标函数收敛到极小值；<br>
　(4) 根据迭代结果，由最后的隶属矩阵确定数据所属的类，显示最后的聚类结果。</p>
<h3 id="2-21-12-四种聚类算法试验">2.21.12 四种聚类算法试验</h3>
<p>​	选取专门用于测试分类、聚类算法的国际通用的UCI数据库中的IRIS数据集，IRIS数据集包含150个样本数据，分别取自三种不同 的莺尾属植物setosa、versicolor和virginica的花朵样本,每个数据含有4个属性，即萼片长度、萼片宽度、花瓣长度、花瓣宽度，单位为cm。 在数据集上执行不同的聚类算法，可以得到不同精度的聚类结果。基于前面描述的各算法原理及流程，可初步得如下聚类结果。</p>
<table>
<thead>
<tr>
<th>聚类方法</th>
<th>聚错样本数</th>
<th>运行时间/s</th>
<th>平均准确率/（%）</th>
</tr>
</thead>
<tbody>
<tr>
<td>K-means</td>
<td>17</td>
<td>0.146001</td>
<td>89</td>
</tr>
<tr>
<td>层次聚类</td>
<td>51</td>
<td>0.128744</td>
<td>66</td>
</tr>
<tr>
<td>SOM</td>
<td>22</td>
<td>5.267283</td>
<td>86</td>
</tr>
<tr>
<td>FCM</td>
<td>12</td>
<td>0.470417</td>
<td>92</td>
</tr>
</tbody>
</table>
<p><strong>注</strong>：</p>
<p>(1) 聚错样本数：总的聚错的样本数，即各类中聚错的样本数的和；<br>
(2) 运行时间：即聚类整个过程所耗费的时间，单位为s；<br>
(3) 平均准确度：设原数据集有k个类,用 $c_i$ 表示第i类， $n_i$ 为 $c_i$ 中样本的个数， $m_i$ 为聚类正确的个数,则 $m_i/n_i$ 为 第i类中的精度，则平均精度为： $avg=\frac{1}{k}\sum_{i=1}^{k}\frac{m_{i}}{n_{i}}$ 。</p>
<h2 id="参考文献">参考文献</h2>
<p>[1]   Goodfellow I, Bengio Y, Courville A. Deep learning[M]. MIT press, 2016.<br>
[2]   周志华. 机器学习[M].清华大学出版社, 2016.<br>
[3]   Michael A. Nielsen. “Neural Networks and Deep Learning”, Determination Press, 2015.<br>
[4]   Suryansh S. Gradient Descent: All You Need to Know, 2018.<br>
[5]   刘建平. 梯度下降小结,EM算法的推导, 2018<br>
[6]   杨小兵．聚类分析中若干关键技术的研究[D]． 杭州：浙江大学, 2005.<br>
[7]   XU Rui, Donald Wunsch 1 1． survey of clustering algorithm[J]．IEEE．Transactions on Neural Networks, 2005, 16(3)：645-67 8.<br>
[8]   YI Hong, SAM K． Learning assignment order of instances for the constrained k-means clustering algorithm[J]．IEEE Transactions on Systems, Man, and Cybernetics, Part B：Cybernetics,2009,39 (2)：568-574.<br>
[9]   贺玲, 吴玲达, 蔡益朝．数据挖掘中的聚类算法综述[J]．计算机应用研究, 2007, 24(1):10-13．<br>
[10]  孙吉贵, 刘杰, 赵连宇．聚类算法研究[J]．软件学报, 2008, 19(1)：48-61．<br>
[11]  孔英会, 苑津莎, 张铁峰等．基于数据流管理技术的配变负荷分类方法研究．中国国际供电会议, CICED2006．<br>
[12]  马晓艳, 唐雁．层次聚类算法研究[J]．计算机科学, 2008, 34(7)：34-36．<br>
[13]  FISHER R A． Iris Plants Database <a target="_blank" rel="noopener" href="https://www.ics.uci.edu/vmlearn/MLRepository.html">https://www.ics.uci.edu/vmlearn/MLRepository.html</a>, Authorized license．<br>
[14]  Quinlan J R. Induction of decision trees[J]. Machine learning, 1986, 1(1): 81-106.<br>
[15]  Breiman L. Random forests[J]. Machine learning, 2001, 45(1): 5-32.</p>
</n<N)$></p></0$></p>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lilitom.github.io/2024/03/19/deep_learning/ch3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tom">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="算法工程师的日常">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/03/19/deep_learning/ch3/" class="post-title-link" itemprop="url">深度学习基础面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-19 23:29:20" itemprop="dateCreated datePublished" datetime="2024-03-19T23:29:20+08:00">2024-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-24 10:13:39" itemprop="dateModified" datetime="2024-03-24T10:13:39+08:00">2024-03-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">算法面试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>深度学习基础</h1>
<h2 id="3-1-基本概念">3.1 基本概念</h2>
<h3 id="3-1-1-神经网络组成？">3.1.1 神经网络组成？</h3>
<p>神经网络类型众多，其中最为重要的是多层感知机。为了详细地描述神经网络，我们先从最简单的神经网络说起。</p>
<p><strong>感知机</strong></p>
<p>多层感知机中的特征神经元模型称为感知机，由<em>Frank Rosenblatt</em>于1957年发明。</p>
<p>简单的感知机如下图所示：</p>
<p><img src="3-1.png" alt></p>
<p>其中 $x_1$ ， $x_2$ ， $x_3$ 为感知机的输入，其输出为：</p>
 $$
output = \left\{
\begin{aligned}
0, \quad if \ \ \sum_i w_i x_i \leqslant threshold \\
1, \quad if \ \ \sum_i w_i x_i > threshold
\end{aligned}
\right.
$$ 
<p>假如把感知机想象成一个加权投票机制，比如 3 位评委给一个歌手打分，打分分别为 $ 4 $ 分、 $1$  分、 $-3 $ 分，这 $ 3$  位评分的权重分别是  $1、3、2$ ，则该歌手最终得分为  $4 \times 1 + 1 \times 3 + (-3) \times 2 = 1$  。按照比赛规则，选取的  $threshold$  为  $3$ ，说明只有歌手的综合评分大于 $ 3$  时，才可顺利晋级。对照感知机，该选手被淘汰，因为：</p>
 $$
\sum_i w_i x_i < threshold=3, output = 0
$$ 
<p>用  $-b$   代替  $threshold$ ，输出变为：</p>
 $$
output = \left\{
\begin{aligned}
0, \quad if \ \ \boldsymbol{w} \cdot \boldsymbol{x} + b \leqslant 0 \\
1, \quad if \ \ \boldsymbol{w} \cdot \boldsymbol{x} + b > 0
\end{aligned}
\right.
$$ 
<p>设置合适的   $\boldsymbol{x}$   和   $b$  ，一个简单的感知机单元的与非门表示如下：</p>
<p><img src="3-2.png" alt></p>
<p>当输入为  $0$ ， $1$  时，感知机输出为  $ 0 \times (-2) + 1 \times (-2) + 3 = 1$ 。</p>
<p>复杂一些的感知机由简单的感知机单元组合而成：</p>
<p><img src="3-3.png" alt></p>
<p><strong>多层感知机</strong></p>
<p>多层感知机由感知机推广而来，最主要的特点是有多个神经元层，因此也叫深度神经网络。相比于单独的感知机，多层感知机的第  $ i $  层的每个神经元和第  $ i-1 $  层的每个神经元都有连接。</p>
<p><img src="3.1.1.5.png" alt></p>
<p>输出层可以不止有 $ 1$  个神经元。隐藏层可以只有 $ 1$  层，也可以有多层。输出层为多个神经元的神经网络例如下图所示：</p>
<p><img src="3.1.1.6.png" alt></p>
<h3 id="3-1-2-神经网络有哪些常用模型结构？">3.1.2 神经网络有哪些常用模型结构？</h3>
<p>下图包含了大部分常用的模型：</p>
<p><img src="3-7.jpg" alt></p>
<h3 id="3-1-3-如何选择深度学习开发平台？">3.1.3 如何选择深度学习开发平台？</h3>
<p>​	现有的深度学习开源平台主要有 Caffe, PyTorch, MXNet, CNTK, Theano, TensorFlow, Keras, fastai等。那如何选择一个适合自己的平台呢，下面列出一些衡量做参考。</p>
<p><strong>参考1：与现有编程平台、技能整合的难易程度</strong></p>
<p>​	主要是前期积累的开发经验和资源，比如编程语言，前期数据集存储格式等。</p>
<p><strong>参考2: 与相关机器学习、数据处理生态整合的紧密程度</strong></p>
<p>​	深度学习研究离不开各种数据处理、可视化、统计推断等软件包。考虑建模之前，是否具有方便的数据预处理工具？建模之后，是否具有方便的工具进行可视化、统计推断、数据分析。</p>
<p><strong>参考3：对数据量及硬件的要求和支持</strong></p>
<p>​	深度学习在不同应用场景的数据量是不一样的，这也就导致我们可能需要考虑分布式计算、多GPU计算的问题。例如，对计算机图像处理研究的人员往往需要将图像文件和计算任务分部到多台计算机节点上进行执行。当下每个深度学习平台都在快速发展，每个平台对分布式计算等场景的支持也在不断演进。</p>
<p><strong>参考4：深度学习平台的成熟程度</strong></p>
<p>​	成熟程度的考量是一个比较主观的考量因素，这些因素可包括：社区的活跃程度；是否容易和开发人员进行交流；当前应用的势头。</p>
<p><strong>参考5：平台利用是否多样性？</strong></p>
<p>​	有些平台是专门为深度学习研究和应用进行开发的，有些平台对分布式计算、GPU 等构架都有强大的优化，能否用这些平台/软件做其他事情？比如有些深度学习软件是可以用来求解二次型优化；有些深度学习平台很容易被扩展，被运用在强化学习的应用中。</p>
<h3 id="3-1-4-为什么使用深层表示">3.1.4 为什么使用深层表示?</h3>
<ol>
<li>深度神经网络是一种特征递进式的学习算法，浅层的神经元直接从输入数据中学习一些低层次的简单特征，例如边缘、纹理等。而深层的特征则基于已学习到的浅层特征继续学习更高级的特征，从计算机的角度学习深层的语义信息。</li>
<li>深层的网络隐藏单元数量相对较少，隐藏层数目较多，如果浅层的网络想要达到同样的计算结果则需要指数级增长的单元数量才能达到。</li>
</ol>
<h3 id="3-1-5-为什么深层神经网络难以训练？">3.1.5 为什么深层神经网络难以训练？</h3>
<ol>
<li>
<p>梯度消失<br>
梯度消失是指通过隐藏层从后向前看，梯度会变的越来越小，说明前面层的学习会显著慢于后面层的学习，所以学习会卡住，除非梯度变大。</p>
<p>​	梯度消失的原因受到多种因素影响，例如学习率的大小，网络参数的初始化，激活函数的边缘效应等。在深层神经网络中，每一个神经元计算得到的梯度都会传递给前一层，较浅层的神经元接收到的梯度受到之前所有层梯度的影响。如果计算得到的梯度值非常小，随着层数增多，求出的梯度更新信息将会以指数形式衰减，就会发生梯度消失。下图是不同隐含层的学习速率：</p>
</li>
</ol>
<p><img src="3-8.png" alt></p>
<ol start="2">
<li>
<p>梯度爆炸<br>
在深度网络或循环神经网络（Recurrent Neural Network, RNN）等网络结构中，梯度可在网络更新的过程中不断累积，变成非常大的梯度，导致网络权重值的大幅更新，使得网络不稳定；在极端情况下，权重值甚至会溢出，变为 $NaN$ 值，再也无法更新。</p>
</li>
<li>
<p>权重矩阵的退化导致模型的有效自由度减少。</p>
<p>​	参数空间中学习的退化速度减慢，导致减少了模型的有效维数，网络的可用自由度对学习中梯度范数的贡献不均衡，随着相乘矩阵的数量（即网络深度）的增加，矩阵的乘积变得越来越退化。在有硬饱和边界的非线性网络中（例如 ReLU 网络），随着深度增加，退化过程会变得越来越快。Duvenaud等人2014年的论文里展示了关于该退化过程的可视化：</p>
</li>
</ol>
<p><img src="3-9.jpg" alt></p>
<p>随着深度的增加，输入空间（左上角所示）会在输入空间中的每个点处被扭曲成越来越细的单丝，只有一个与细丝正交的方向影响网络的响应。沿着这个方向，网络实际上对变化变得非常敏感。</p>
<h3 id="3-1-6-深度学习和机器学习有什么不同？">3.1.6 深度学习和机器学习有什么不同？</h3>
<p>​	<strong>机器学习</strong>：利用计算机、概率论、统计学等知识，输入数据，让计算机学会新知识。机器学习的过程，就是训练数据去优化目标函数。</p>
<p>​	<strong>深度学习</strong>：是一种特殊的机器学习，具有强大的能力和灵活性。它通过学习将世界表示为嵌套的层次结构，每个表示都与更简单的特征相关，而抽象的表示则用于计算更抽象的表示。</p>
<p>​	传统的机器学习需要定义一些手工特征，从而有目的的去提取目标信息， 非常依赖任务的特异性以及设计特征的专家经验。而深度学习可以从大数据中先学习简单的特征，并从其逐渐学习到更为复杂抽象的深层特征，不依赖人工的特征工程，这也是深度学习在大数据时代受欢迎的一大原因。</p>
<p><img src="3.1.6.1.png" alt></p>
<p><img src="3-11.jpg" alt></p>
<h2 id="3-2-网络操作与计算">3.2 网络操作与计算</h2>
<h3 id="3-2-1-前向传播与反向传播？">3.2.1 前向传播与反向传播？</h3>
<p>神经网络的计算主要有两种：前向传播（foward propagation, FP）作用于每一层的输入，通过逐层计算得到输出结果；反向传播（backward propagation, BP）作用于网络的输出，通过计算梯度由深到浅更新网络参数。</p>
<p><strong>前向传播</strong></p>
<p><img src="3.2.1.1.png" alt></p>
<p>假设上一层结点  $ i,j,k,... $  等一些结点与本层的结点  $ w $  有连接，那么结点  $ w $  的值怎么算呢？就是通过上一层的  $ i,j,k,... $  等结点以及对应的连接权值进行加权和运算，最终结果再加上一个偏置项（图中为了简单省略了），最后在通过一个非线性函数（即激活函数），如  $ReLu$ ， $sigmoid$  等函数，最后得到的结果就是本层结点  $ w $  的输出。</p>
<p>最终不断的通过这种方法一层层的运算，得到输出层结果。</p>
<p><strong>反向传播</strong></p>
<p><img src="3.2.1.2.png" alt></p>
<p>由于我们前向传播最终得到的结果，以分类为例，最终总是有误差的，那么怎么减少误差呢，当前应用广泛的一个算法就是梯度下降算法，但是求梯度就要求偏导数，下面以图中字母为例讲解一下：</p>
<p>设最终误差为  $ E $ 且输出层的激活函数为线性激活函数，对于输出那么  $ E $  对于输出节点  $ y_l $  的偏导数是  $ y_l - t_l $ ，其中  $ t_l $  是真实值， $ \frac{\partial y_l}{\partial z_l} $  是指上面提到的激活函数， $ z_l $  是上面提到的加权和，那么这一层的  $ E $  对于  $ z_l $  的偏导数为  $ \frac{\partial E}{\partial z_l} = \frac{\partial E}{\partial y_l} \frac{\partial y_l}{\partial z_l} $ 。同理，下一层也是这么计算，只不过  $ \frac{\partial E}{\partial y_k} $  计算方法变了，一直反向传播到输入层，最后有  $ \frac{\partial E}{\partial x_i} = \frac{\partial E}{\partial y_j} \frac{\partial y_j}{\partial z_j} $ ，且  $ \frac{\partial z_j}{\partial x_i} = w_i j $ 。然后调整这些过程中的权值，再不断进行前向传播和反向传播的过程，最终得到一个比较好的结果。</p>
<h3 id="3-2-2-如何计算神经网络的输出？">3.2.2 如何计算神经网络的输出？</h3>
<p><img src="3.2.2.1.png" alt></p>
<p>如上图，输入层有三个节点，我们将其依次编号为 1、2、3；隐藏层的 4 个节点，编号依次为 4、5、6、7；最后输出层的两个节点编号为 8、9。比如，隐藏层的节点 4，它和输入层的三个节点 1、2、3 之间都有连接，其连接上的权重分别为是  $ w_{41}, w_{42}, w_{43} $ 。</p>
<p>为了计算节点 4 的输出值，我们必须先得到其所有上游节点（也就是节点 1、2、3）的输出值。节点 1、2、3 是输入层的节点，所以，他们的输出值就是输入向量本身。按照上图画出的对应关系，可以看到节点 1、2、3 的输出值分别是  $ x_1, x_2, x_3 $ 。</p>
 $$
a_4 = \sigma(w^T \cdot a) = \sigma(w_{41}x_4 + w_{42}x_2 + w_{43}a_3 + w_{4b})
$$ 
<p>其中  $ w_{4b} $  是节点 4 的偏置项。</p>
<p>同样，我们可以继续计算出节点 5、6、7 的输出值  $ a_5, a_6, a_7 $ 。</p>
<p>计算输出层的节点 8 的输出值  $ y_1 $ ：</p>
 $$
y_1 = \sigma(w^T \cdot a) = \sigma(w_{84}a_4 + w_{85}a_5 + w_{86}a_6 + w_{87}a_7 + w_{8b})
$$ 
<p>其中  $ w_{8b} $  是节点 8 的偏置项。</p>
<p>同理，我们还可以计算出  $ y_2 $ 。这样输出层所有节点的输出值计算完毕，我们就得到了在输入向量  $ x_1, x_2, x_3, x_4 $  时，神经网络的输出向量  $ y_1, y_2 $  。这里我们也看到，输出向量的维度和输出层神经元个数相同。</p>
<h3 id="3-2-3-如何计算卷积神经网络输出值？">3.2.3 如何计算卷积神经网络输出值？</h3>
<p>假设有一个 5*5 的图像，使用一个 3*3 的 filter 进行卷积，想得到一个 3*3 的 Feature Map，如下所示：</p>
<p><img src="3.2.3.1.png" alt></p>
 $ x_{i,j} $  表示图像第   $ i $  行第  $ j $  列元素。 $ w_{m,n} $  表示 filter​ 第  $ m $  行第  $ n $  列权重。  $ w_b $  表示  $filter$  的偏置项。 表 $a_i,_j$ 示 feature map 第  $ i$  行第  $ j $  列元素。  $f$  表示激活函数，这里以 $ ReLU$  函数为例。
<p>卷积计算公式如下：</p>
 $$
a_{i,j} = f(\sum_{m=0}^2 \sum_{n=0}^2 w_{m,n} x_{i+m, j+n} + w_b )
$$ 
<p>当步长为  $1$  时，计算 feature map 元素  $ a_{0,0} $  如下：</p>
 $$
a_{0,0} = f(\sum_{m=0}^2 \sum_{n=0}^2 w_{m,n} x_{0+m, 0+n} + w_b )

= relu(w_{0,0} x_{0,0} + w_{0,1} x_{0,1} + w_{0,2} x_{0,2} + w_{1,0} x_{1,0} + \\w_{1,1} x_{1,1} + w_{1,2} x_{1,2} + w_{2,0} x_{2,0} + w_{2,1} x_{2,1} + w_{2,2} x_{2,2}) \\

= 1 + 0 + 1 + 0 + 1 + 0 + 0 + 0 + 1 \\

= 4
$$ 
<p>其计算过程图示如下：</p>
<p><img src="3.2.3.2.png" alt></p>
<p>以此类推，计算出全部的Feature Map。</p>
<p><img src="3.2.3.4.png" alt></p>
<p>当步幅为 2 时，Feature Map计算如下</p>
<p><img src="3.2.3.5.png" alt></p>
<p>注：图像大小、步幅和卷积后的Feature Map大小是有关系的。它们满足下面的关系：</p>
 $$
W_2 = (W_1 - F + 2P)/S + 1\\
H_2 = (H_1 - F + 2P)/S + 1
$$ 
<p>​	其中  $ W_2 $ ， 是卷积后 Feature Map 的宽度； $ W_1 $  是卷积前图像的宽度； $ F $  是 filter 的宽度； $ P $  是 Zero Padding 数量，Zero Padding 是指在原始图像周围补几圈  $0$ ，如果  $P$  的值是  $1$ ，那么就补  $1$  圈  $0$ ； $S$  是步幅； $ H_2 $  卷积后 Feature Map 的高度； $ H_1 $  是卷积前图像的宽度。</p>
<p>​	举例：假设图像宽度  $ W_1 = 5 $ ，filter 宽度  $ F=3 $ ，Zero Padding  $ P=0 $ ，步幅  $ S=2 $ ， $ Z $  则</p>
 $$
W_2 = (W_1 - F + 2P)/S + 1

= (5-3+0)/2 + 1

= 2
$$ 
<p>​	说明 Feature Map 宽度是2。同样，我们也可以计算出 Feature Map 高度也是 2。</p>
<p>如果卷积前的图像深度为  $ D $ ，那么相应的 filter 的深度也必须为  $ D $ 。深度大于 1 的卷积计算公式：</p>
 $$
a_{i,j} = f(\sum_{d=0}^{D-1} \sum_{m=0}^{F-1} \sum_{n=0}^{F-1} w_{d,m,n} x_{d,i+m,j+n} + w_b)
$$ 
<p>​	其中， $ D $  是深度； $ F $  是 filter 的大小； $ w_{d,m,n} $  表示 filter 的第  $ d $  层第  $ m $  行第  $ n $  列权重； $ a_{d,i,j} $  表示 feature map 的第  $ d $  层第  $ i $  行第  $ j $  列像素；其它的符号含义前面相同，不再赘述。</p>
<p>​	每个卷积层可以有多个 filter。每个 filter 和原始图像进行卷积后，都可以得到一个 Feature Map。卷积后 Feature Map 的深度(个数)和卷积层的 filter 个数相同。下面的图示显示了包含两个 filter 的卷积层的计算。 $7*7*3$  输入，经过两个  $3*3*3$  filter 的卷积(步幅为  $2$ )，得到了  $3*3*2$  的输出。图中的 Zero padding 是  $1$ ，也就是在输入元素的周围补了一圈  $0$ 。</p>
<p><img src="3.2.3.6.png" alt></p>
<p>​	以上就是卷积层的计算方法。这里面体现了局部连接和权值共享：每层神经元只和上一层部分神经元相连(卷积计算规则)，且 filter 的权值对于上一层所有神经元都是一样的。对于包含两个  $ 3 * 3 * 3 $  的 fitler 的卷积层来说，其参数数量仅有  $ (3 * 3 * 3+1) * 2 = 56 $  个，且参数数量与上一层神经元个数无关。与全连接神经网络相比，其参数数量大大减少了。</p>
<h3 id="3-2-4-如何计算-Pooling-层输出值输出值？">3.2.4 如何计算 Pooling 层输出值输出值？</h3>
<p>​	Pooling 层主要的作用是下采样，通过去掉 Feature Map 中不重要的样本，进一步减少参数数量。Pooling 的方法很多，最常用的是 Max Pooling。Max Pooling 实际上就是在 n*n 的样本中取最大值，作为采样后的样本值。下图是 2*2 max pooling：</p>
<p><img src="3.2.4.1.png" alt></p>
<p>​	除了 Max Pooing 之外，常用的还有 Average Pooling ——取各样本的平均值。<br>
​	对于深度为  $ D $  的 Feature Map，各层独立做 Pooling，因此 Pooling 后的深度仍然为  $ D $ 。</p>
<h3 id="3-2-5-实例理解反向传播">3.2.5 实例理解反向传播</h3>
<p>​	一个典型的三层神经网络如下所示：</p>
<p><img src="3.2.5.1.png" alt></p>
<p>​	其中 Layer  $ L_1 $  是输入层，Layer  $ L_2 $  是隐含层，Layer  $ L_3 $  是输出层。</p>
<p>​	假设输入数据集为  $ D={x_1, x_2, ..., x_n} $ ，输出数据集为  $ y_1, y_2, ..., y_n $ 。</p>
<p>​	如果输入和输出是一样，即为自编码模型。如果原始数据经过映射，会得到不同于输入的输出。</p>
<p>假设有如下的网络层：</p>
<p><img src="3.2.5.2.png" alt></p>
<p>​	输入层包含神经元  $ i_1, i_2 $ ，偏置  $ b_1 $ ；隐含层包含神经元  $ h_1, h_2 $ ，偏置  $ b_2 $ ，输出层为   $ o_1, o_2 $ ， $ w_i $  为层与层之间连接的权重，激活函数为  $sigmoid$  函数。对以上参数取初始值，如下图所示：</p>
<p><img src="3.2.5.3.png" alt></p>
<p>其中：</p>
<ul>
<li>输入数据  $ i1=0.05, i2 = 0.10 $</li>
<li>输出数据  $ o1=0.01, o2=0.99 $ ;</li>
<li>初始权重  $ w1=0.15, w2=0.20, w3=0.25,w4=0.30, w5=0.40, w6=0.45, w7=0.50, w8=0.55 $</li>
<li>目标：给出输入数据  $ i1,i2 $  (  $0.05$ 和 $0.10$  )，使输出尽可能与原始输出  $ o1,o2 $ ，(  $0.01$ 和 $0.99$ )接近。</li>
</ul>
<p><strong>前向传播</strong></p>
<ol>
<li>输入层 --&gt; 输出层</li>
</ol>
<p>计算神经元  $ h1 $  的输入加权和：</p>
 $$
net_{h1} = w_1 * i_1 + w_2 * i_2 + b_1 * 1\\

net_{h1} = 0.15 * 0.05 + 0.2 * 0.1 + 0.35 * 1 = 0.3775
$$ 
<p>神经元  $ h1 $  的输出  $ o1 $  ：（此处用到激活函数为 sigmoid 函数）：</p>
 $$
out_{h1} = \frac{1}{1 + e^{-net_{h1}}} = \frac{1}{1 + e^{-0.3775}} = 0.593269992
$$ 
<p>同理，可计算出神经元  $ h2 $  的输出  $ o1 $ ：</p>
 $$
out_{h2} = 0.596884378
$$ 
<ol start="2">
<li>隐含层–&gt;输出层：</li>
</ol>
<p>计算输出层神经元  $ o1 $  和  $ o2 $  的值：</p>
 $$
net_{o1} = w_5 * out_{h1} + w_6 * out_{h2} + b_2 * 1
$$ 
 $$
net_{o1} = 0.4 * 0.593269992 + 0.45 * 0.596884378 + 0.6 * 1 = 1.105905967
$$ 
 $$
out_{o1} = \frac{1}{1 + e^{-net_{o1}}} = \frac{1}{1 + e^{1.105905967}} = 0.75136079
$$ 
<p>这样前向传播的过程就结束了，我们得到输出值为  $ [0.75136079 ,  0.772928465] $ ，与实际值  $ [0.01 , 0.99] $  相差还很远，现在我们对误差进行反向传播，更新权值，重新计算输出。</p>
<p>**反向传播 **</p>
<p>​	1.计算总误差</p>
<p>总误差：(这里使用Square Error)</p>
 $$
E_{total} = \sum \frac{1}{2}(target - output)^2
$$ 
<p>但是有两个输出，所以分别计算  $ o1 $  和  $ o2 $  的误差，总误差为两者之和：</p>
 $E_{o1} = \frac{1}{2}(target_{o1} - out_{o1})^2 
= \frac{1}{2}(0.01 - 0.75136507)^2 = 0.274811083$ .
 $E_{o2} = 0.023560026$ .
 $E_{total} = E_{o1} + E_{o2} = 0.274811083 + 0.023560026 = 0.298371109$ .
<p>​	2.隐含层 --&gt; 输出层的权值更新：</p>
<p>以权重参数  $ w5 $  为例，如果我们想知道  $ w5 $  对整体误差产生了多少影响，可以用整体误差对  $ w5 $  求偏导求出：（链式法则）</p>
 $$
\frac{\partial E_{total}}{\partial w5} = \frac{\partial E_{total}}{\partial out_{o1}} * \frac{\partial out_{o1}}{\partial net_{o1}} * \frac{\partial net_{o1}}{\partial w5}
$$ 
<p>下面的图可以更直观的看清楚误差是怎样反向传播的：</p>
<p><img src="3.2.5.4.png" alt></p>
<h3 id="3-2-6-神经网络更“深”有什么意义？">3.2.6 神经网络更“深”有什么意义？</h3>
<p>前提：在一定范围内。</p>
<ul>
<li>在神经元数量相同的情况下，深层网络结构具有更大容量，分层组合带来的是指数级的表达空间，能够组合成更多不同类型的子结构，这样可以更容易地学习和表示各种特征。</li>
<li>隐藏层增加则意味着由激活函数带来的非线性变换的嵌套层数更多，就能构造更复杂的映射关系。</li>
</ul>
<h2 id="3-3-超参数">3.3 超参数</h2>
<h3 id="3-3-1-什么是超参数？">3.3.1 什么是超参数？</h3>
<p>​	<strong>超参数</strong> : 在机器学习的上下文中，超参数是在开始学习过程之前设置值的参数，而不是通过训练得到的参数数据。通常情况下，需要对超参数进行优化，给学习机选择一组最优超参数，以提高学习的性能和效果。</p>
<p>​	超参数通常存在于：</p>
<pre><code>1.  定义关于模型的更高层次的概念，如复杂性或学习能力。
2.  不能直接从标准模型培训过程中的数据中学习，需要预先定义。
3.  可以通过设置不同的值，训练不同的模型和选择更好的测试值来决定
</code></pre>
<p>​	超参数具体来讲比如算法中的学习率（learning rate）、梯度下降法迭代的数量（iterations）、隐藏层数目（hidden layers）、隐藏层单元数目、激活函数（ activation function）都需要根据实际情况来设置，这些数字实际上控制了最后的参数和的值，所以它们被称作超参数。</p>
<h3 id="3-3-2-如何寻找超参数的最优值？">3.3.2 如何寻找超参数的最优值？</h3>
<p>​	在使用机器学习算法时，总有一些难调的超参数。例如权重衰减大小，高斯核宽度等等。这些参数需要人为设置，设置的值对结果产生较大影响。常见设置超参数的方法有：</p>
<ol>
<li>
<p>猜测和检查：根据经验或直觉，选择参数，一直迭代。</p>
</li>
<li>
<p>网格搜索：让计算机尝试在一定范围内均匀分布的一组值。</p>
</li>
<li>
<p>随机搜索：让计算机随机挑选一组值。</p>
</li>
<li>
<p>贝叶斯优化：使用贝叶斯优化超参数，会遇到贝叶斯优化算法本身就需要很多的参数的困难。</p>
</li>
<li>
<p>MITIE方法，好初始猜测的前提下进行局部优化。它使用BOBYQA算法，并有一个精心选择的起始点。由于BOBYQA只寻找最近的局部最优解，所以这个方法是否成功很大程度上取决于是否有一个好的起点。在MITIE的情况下，我们知道一个好的起点，但这不是一个普遍的解决方案，因为通常你不会知道好的起点在哪里。从好的方面来说，这种方法非常适合寻找局部最优解。稍后我会再讨论这一点。</p>
</li>
<li>
<p>最新提出的LIPO的全局优化方法。这个方法没有参数，而且经验证比随机搜索方法好。</p>
</li>
</ol>
<h3 id="3-3-3-超参数搜索一般过程？">3.3.3 超参数搜索一般过程？</h3>
<p>超参数搜索一般过程：</p>
<ol>
<li>将数据集划分成训练集、验证集及测试集。</li>
<li>在训练集上根据模型的性能指标对模型参数进行优化。</li>
<li>在验证集上根据模型的性能指标对模型的超参数进行搜索。</li>
<li>步骤 2 和步骤 3 交替迭代，最终确定模型的参数和超参数，在测试集中验证评价模型的优劣。</li>
</ol>
<p>其中，搜索过程需要搜索算法，一般有：网格搜索、随机搜过、启发式智能搜索、贝叶斯搜索。</p>
<h2 id="3-4-激活函数">3.4 激活函数</h2>
<h3 id="3-4-1-为什么需要非线性激活函数？">3.4.1 为什么需要非线性激活函数？</h3>
<p><strong>为什么需要激活函数？</strong></p>
<ol>
<li>激活函数对模型学习、理解非常复杂和非线性的函数具有重要作用。</li>
<li>激活函数可以引入非线性因素。如果不使用激活函数，则输出信号仅是一个简单的线性函数。线性函数一个一级多项式，线性方程的复杂度有限，从数据中学习复杂函数映射的能力很小。没有激活函数，神经网络将无法学习和模拟其他复杂类型的数据，例如图像、视频、音频、语音等。</li>
<li>激活函数可以把当前特征空间通过一定的线性映射转换到另一个空间，让数据能够更好的被分类。</li>
</ol>
<p><strong>为什么激活函数需要非线性函数？</strong></p>
<ol>
<li>假若网络中全部是线性部件，那么线性的组合还是线性，与单独一个线性分类器无异。这样就做不到用非线性来逼近任意函数。</li>
<li>使用非线性激活函数 ，以便使网络更加强大，增加它的能力，使它可以学习复杂的事物，复杂的表单数据，以及表示输入输出之间非线性的复杂的任意函数映射。使用非线性激活函数，能够从输入输出之间生成非线性映射。</li>
</ol>
<h3 id="3-4-2-常见的激活函数及图像">3.4.2 常见的激活函数及图像</h3>
<ol>
<li>
<p>sigmoid 激活函数</p>
<p>函数的定义为： $ f(x) = \frac{1}{1 + e^{-x}} $ ，其值域为  $ (0,1) $ 。</p>
<p>函数图像如下：</p>
</li>
</ol>
<p><img src="3-26.png" alt></p>
<ol start="2">
<li>
<p>tanh激活函数</p>
<p>函数的定义为： $ f(x) = tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} $ ，值域为  $ (-1,1) $ 。</p>
<p>函数图像如下：</p>
</li>
</ol>
<p><img src="3-27.png" alt></p>
<ol start="3">
<li>
<p>Relu激活函数</p>
<p>函数的定义为： $ f(x) = max(0, x) $   ，值域为  $ [0,+∞) $ ；</p>
<p>函数图像如下：</p>
</li>
</ol>
<p><img src="3-28.png" alt></p>
<ol start="4">
<li>
<p>Leak Relu 激活函数</p>
<p>函数定义为：  $ f(x) =  \left\{
   \begin{aligned}
   ax, \quad x<0 \\ x, \quad x>0
   \end{aligned}
   \right. $ ，值域为  $ (-∞,+∞) $ 。</0></p>
<p>图像如下（ $ a = 0.5 $ ）：</p>
</li>
</ol>
<p><img src="3-29.png" alt></p>
<ol start="5">
<li>
<p>SoftPlus 激活函数</p>
<p>函数的定义为： $ f(x) = ln( 1 + e^x) $ ，值域为  $ (0,+∞) $ 。</p>
<p>函数图像如下:</p>
</li>
</ol>
<p><img src="3-30.png" alt></p>
<ol start="6">
<li>
<p>softmax 函数</p>
<p>函数定义为：  $ \sigma(z)_j = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}} $ 。</p>
<p>Softmax 多用于多分类神经网络输出。</p>
</li>
</ol>
<h3 id="3-4-3-常见激活函数的导数计算？">3.4.3 常见激活函数的导数计算？</h3>
<p>对常见激活函数，导数计算如下：</p>
<table>
<thead>
<tr>
<th>原函数</th>
<th>函数表达式</th>
<th>导数</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sigmoid激活函数</td>
<td>$f(x)=\frac{1}{1+e^{-x}}$</td>
<td>$f^{'}(x)=\frac{1}{1+e^{-x}}\left( 1- \frac{1}{1+e^{-x}} \right)=f(x)(1-f(x))$</td>
<td>当 $x=10$ ,或 $x=-10​$ ， $f^{'}(x) \approx0​$ ,当 $x=0​ {% raw%}$$f^{'}(x) =0.25​${% endraw %}</td>
</tr>
<tr>
<td>Tanh激活函数</td>
<td>{% raw%}$f(x)=tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}${% endraw %}</td>
<td>{% raw%}$f^{'}(x)=-(tanh(x))^2${% endraw %}</td>
<td>当 {% raw%}$x=10${% endraw %} ,或 {% raw%}$x=-10${% endraw %} ， {% raw%}$f^{'}(x) \approx0${% endraw %} ,当 {% raw%}$x=0$${% endraw %} f^{`}(x) =1$</td>
</tr>
<tr>
<td>Relu激活函数</td>
<td>$f(x)=max(0,x)$</td>
<td>$c(u)=\begin{cases} 0,x<0 \\ 1,x>0 \\ undefined,x=0\end{cases}$</0></td>
<td>通常 $x=0$ 时，给定其导数为1和0</td>
</tr>
</tbody>
</table>
<h3 id="3-4-4-激活函数有哪些性质？">3.4.4 激活函数有哪些性质？</h3>
<ol>
<li>非线性： 当激活函数是非线性的，一个两层的神经网络就可以基本上逼近所有的函数。但如果激活函数是恒等激活函数的时候，即  $ f(x)=x $ ，就不满足这个性质，而且如果 MLP 使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的；</li>
<li>可微性： 当优化方法是基于梯度的时候，就体现了该性质；</li>
<li>单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数；</li>
<li>
$ f(x)≈x $ ： 当激活函数满足这个性质的时候，如果参数的初始化是随机的较小值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要详细地去设置初始值；
</li>
<li>输出值的范围： 当激活函数输出值是有限的时候，基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是无限的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的 Learning Rate。</li>
</ol>
<h3 id="3-4-5-如何选择激活函数？">3.4.5 如何选择激活函数？</h3>
<p>​	选择一个适合的激活函数并不容易，需要考虑很多因素，通常的做法是，如果不确定哪一个激活函数效果更好，可以把它们都试试，然后在验证集或者测试集上进行评价。然后看哪一种表现的更好，就去使用它。</p>
<p>以下是常见的选择情况：</p>
<ol>
<li>如果输出是 0、1 值（二分类问题），则输出层选择 sigmoid 函数，然后其它的所有单元都选择 Relu 函数。</li>
<li>如果在隐藏层上不确定使用哪个激活函数，那么通常会使用 Relu 激活函数。有时，也会使用 tanh 激活函数，但 Relu 的一个优点是：当是负值的时候，导数等于 0。</li>
<li>sigmoid 激活函数：除了输出层是一个二分类问题基本不会用它。</li>
<li>tanh 激活函数：tanh 是非常优秀的，几乎适合所有场合。</li>
<li>ReLu 激活函数：最常用的默认函数，如果不确定用哪个激活函数，就使用 ReLu 或者 Leaky ReLu，再去尝试其他的激活函数。</li>
<li>如果遇到了一些死的神经元，我们可以使用 Leaky ReLU 函数。</li>
</ol>
<h3 id="3-4-6-使用-ReLu-激活函数的优点？">3.4.6 使用 ReLu 激活函数的优点？</h3>
<ol>
<li>在区间变动很大的情况下，ReLu 激活函数的导数或者激活函数的斜率都会远大于 0，在程序实现就是一个 if-else 语句，而 sigmoid 函数需要进行浮点四则运算，在实践中，使用 ReLu 激活函数神经网络通常会比使用 sigmoid 或者 tanh 激活函数学习的更快。</li>
<li>sigmoid 和 tanh 函数的导数在正负饱和区的梯度都会接近于 0，这会造成梯度弥散，而 Relu 和Leaky ReLu 函数大于 0 部分都为常数，不会产生梯度弥散现象。</li>
<li>需注意，Relu 进入负半区的时候，梯度为 0，神经元此时不会训练，产生所谓的稀疏性，而 Leaky ReLu 不会产生这个问题。</li>
</ol>
<h3 id="3-4-7-什么时候可以用线性激活函数？">3.4.7 什么时候可以用线性激活函数？</h3>
<ol>
<li>输出层，大多使用线性激活函数。</li>
<li>在隐含层可能会使用一些线性激活函数。</li>
<li>一般用到的线性激活函数很少。</li>
</ol>
<h3 id="3-4-8-怎样理解-Relu（-0-时）是非线性激活函数？">3.4.8 怎样理解 Relu（&lt; 0 时）是非线性激活函数？</h3>
<p>Relu 激活函数图像如下：</p>
<p><img src="3-32.png" alt></p>
<p>根据图像可看出具有如下特点：</p>
<ol>
<li>
<p>单侧抑制；</p>
</li>
<li>
<p>相对宽阔的兴奋边界；</p>
</li>
<li>
<p>稀疏激活性；</p>
<p>ReLU 函数从图像上看，是一个分段线性函数，把所有的负值都变为 0，而正值不变，这样就成为单侧抑制。</p>
<p>因为有了这单侧抑制，才使得神经网络中的神经元也具有了稀疏激活性。</p>
<p><strong>稀疏激活性</strong>：从信号方面来看，即神经元同时只对输入信号的少部分选择性响应，大量信号被刻意的屏蔽了，这样可以提高学习的精度，更好更快地提取稀疏特征。当  $ x<0 $ 时，relu 硬饱和，而当 x>0 $  时，则不存在饱和问题。ReLU 能够在  $ x>0 $  时保持梯度不衰减，从而缓解梯度消失问题。</0></p>
</li>
</ol>
<h3 id="3-4-9-Softmax-定义及作用">3.4.9 Softmax 定义及作用</h3>
<p>Softmax 是一种形如下式的函数：</p>
 $$
P(i) = \frac{exp(\theta_i^T x)}{\sum_{k=1}^{K} exp(\theta_i^T x)}
$$ 
<p>​	其中， $ \theta_i $  和  $ x $  是列向量， $ \theta_i^T x $  可能被换成函数关于  $ x $  的函数  $ f_i(x) $</p>
<p>​	通过 softmax 函数，可以使得  $ P(i) $  的范围在  $ [0,1] $  之间。在回归和分类问题中，通常  $ \theta $  是待求参数，通过寻找使得  $ P(i) $  最大的  $ \theta_i $  作为最佳参数。</p>
<p>​	但是，使得范围在  $ [0,1] $   之间的方法有很多，为啥要在前面加上以  $ e $  的幂函数的形式呢？参考 logistic 函数：</p>
 $$
P(i) = \frac{1}{1+exp(-\theta_i^T x)}
$$ 
<p>​	这个函数的作用就是使得  $ P(i) $  在负无穷到 0 的区间趋向于 0， 在 0 到正无穷的区间趋向 1,。同样 softmax 函数加入了  $ e $  的幂函数正是为了两极化：正样本的结果将趋近于 1，而负样本的结果趋近于 0。这样为多类别提供了方便（可以把  $ P(i) $  看做是样本属于类别的概率）。可以说，Softmax 函数是 logistic 函数的一种泛化。</p>
<p>​	softmax 函数可以把它的输入，通常被称为 logits 或者 logit scores，处理成 0 到 1 之间，并且能够把输出归一化到和为 1。这意味着 softmax 函数与分类的概率分布等价。它是一个网络预测多酚类问题的最佳输出激活函数。</p>
<h3 id="3-4-10-Softmax-函数如何应用于多分类？">3.4.10 Softmax 函数如何应用于多分类？</h3>
<p>​	softmax 用于多分类过程中，它将多个神经元的输出，映射到  $ (0,1) $  区间内，可以看成概率来理解，从而来进行多分类！</p>
<p>​	假设我们有一个数组， $ V_i $  表示  $ V $   中的第  $ i $  个元素，那么这个元素的 softmax 值就是</p>
 $$
S_i = \frac{e^{V_i}}{\sum_j e^{V_j}}
$$ 
<p>​	从下图看，神经网络中包含了输入层，然后通过两个特征层处理，最后通过 softmax 分析器就能得到不同条件下的概率，这里需要分成三个类别，最终会得到  $ y=0, y=1, y=2 $  的概率值。</p>
<p><img src="3.4.9.1.png" alt></p>
<p>继续看下面的图，三个输入通过 softmax 后得到一个数组  $ [0.05 , 0.10 , 0.85] $ ，这就是 soft 的功能。</p>
<p><img src="3.4.9.2.png" alt></p>
<p>更形象的映射过程如下图所示：</p>
<p><img src="3.4.9.3.png" alt="****"></p>
<p>​	softmax 直白来说就是将原来输出是  $ 3,1,-3 $  通过 softmax 函数一作用，就映射成为  $ (0,1) $  的值，而这些值的累和为  $ 1 $ （满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标！</p>
<h3 id="3-4-11-交叉熵代价函数定义及其求导推导">3.4.11 交叉熵代价函数定义及其求导推导</h3>
<p>(<strong>贡献者：黄钦建－华南理工大学</strong>)</p>
<p>​	神经元的输出就是 a = σ(z)，其中 $z=\sum w_{j}i_{j}+b$ 是输⼊的带权和。</p>
 $C=-\frac{1}{n}\sum[ylna+(1-y)ln(1-a)]$ 
<p>​	其中 n 是训练数据的总数，求和是在所有的训练输⼊ x 上进⾏的， y 是对应的⽬标输出。</p>
<p>​	表达式是否解决学习缓慢的问题并不明显。实际上，甚⾄将这个定义看做是代价函数也不是显⽽易⻅的！在解决学习缓慢前，我们来看看交叉熵为何能够解释成⼀个代价函数。</p>
<p>​	将交叉熵看做是代价函数有两点原因。</p>
<p>​	第⼀，它是⾮负的， C &gt; 0。可以看出：式子中的求和中的所有独⽴的项都是负数的，因为对数函数的定义域是 (0，1)，并且求和前⾯有⼀个负号，所以结果是非负。</p>
<p>​	第⼆，如果对于所有的训练输⼊ x，神经元实际的输出接近⽬标值，那么交叉熵将接近 0。</p>
<p>​	假设在这个例⼦中， y = 0 ⽽ a ≈ 0。这是我们想到得到的结果。我们看到公式中第⼀个项就消去了，因为 y = 0，⽽第⼆项实际上就是 − ln(1 − a) ≈ 0。反之， y = 1 ⽽ a ≈ 1。所以在实际输出和⽬标输出之间的差距越⼩，最终的交叉熵的值就越低了。（这里假设输出结果不是0，就是1，实际分类也是这样的）</p>
<p>​	综上所述，交叉熵是⾮负的，在神经元达到很好的正确率的时候会接近 0。这些其实就是我们想要的代价函数的特性。其实这些特性也是⼆次代价函数具备的。所以，交叉熵就是很好的选择了。但是交叉熵代价函数有⼀个⽐⼆次代价函数更好的特性就是它避免了学习速度下降的问题。为了弄清楚这个情况，我们来算算交叉熵函数关于权重的偏导数。我们将 $a={\varsigma}(z)$ 代⼊到 公式中应⽤两次链式法则，得到：</p>
 $\begin{eqnarray}\frac{\partial C}{\partial w_{j}}&=&-\frac{1}{n}\sum \frac{\partial }{\partial w_{j}}[ylna+(1-y)ln(1-a)]\\&=&-\frac{1}{n}\sum \frac{\partial }{\partial a}[ylna+(1-y)ln(1-a)]*\frac{\partial a}{\partial w_{j}}\\&=&-\frac{1}{n}\sum (\frac{y}{a}-\frac{1-y}{1-a})*\frac{\partial a}{\partial w_{j}}\\&=&-\frac{1}{n}\sum (\frac{y}{\varsigma(z)}-\frac{1-y}{1-\varsigma(z)})\frac{\partial \varsigma(z)}{\partial w_{j}}\\&=&-\frac{1}{n}\sum (\frac{y}{\varsigma(z)}-\frac{1-y}{1-\varsigma(z)}){\varsigma}'(z)x_{j}\end{eqnarray}$ 
<p>​	根据 $\varsigma(z)=\frac{1}{1+e^{-z}}$  的定义，和⼀些运算，我们可以得到  ${\varsigma}'(z)=\varsigma(z)(1-\varsigma(z))$ 。化简后可得：</p>
 $\frac{\partial C}{\partial w_{j}}=\frac{1}{n}\sum x_{j}({\varsigma}(z)-y)$ 
<p>​	这是⼀个优美的公式。它告诉我们权重学习的速度受到 $\varsigma(z)-y$ ，也就是输出中的误差的控制。更⼤的误差，更快的学习速度。这是我们直觉上期待的结果。特别地，这个代价函数还避免了像在⼆次代价函数中类似⽅程中 ${\varsigma}'(z)$ 导致的学习缓慢。当我们使⽤交叉熵的时候， ${\varsigma}'(z)$ 被约掉了，所以我们不再需要关⼼它是不是变得很⼩。这种约除就是交叉熵带来的特效。实际上，这也并不是⾮常奇迹的事情。我们在后⾯可以看到，交叉熵其实只是满⾜这种特性的⼀种选择罢了。</p>
<p>​	根据类似的⽅法，我们可以计算出关于偏置的偏导数。我这⾥不再给出详细的过程，你可以轻易验证得到：</p>
 $\frac{\partial C}{\partial b}=\frac{1}{n}\sum ({\varsigma}(z)-y)$ 
<p>​	再⼀次, 这避免了⼆次代价函数中类似 ${\varsigma}'(z)$ 项导致的学习缓慢。</p>
<h3 id="3-4-12-为什么Tanh收敛速度比Sigmoid快？">3.4.12 为什么Tanh收敛速度比Sigmoid快？</h3>
<p><strong>（贡献者：黄钦建－华南理工大学）</strong></p>
<p>首先看如下两个函数的求导：</p>
 $tanh^{,}(x)=1-tanh(x)^{2}\in (0,1)$ 
 $s^{,}(x)=s(x)*(1-s(x))\in (0,\frac{1}{4}]$ 
<p>由上面两个公式可知tanh(x)梯度消失的问题比sigmoid轻，所以Tanh收敛速度比Sigmoid快。</p>
<p><strong>（贡献者：郜泉凯 - 华南理工大学）</strong></p>
<p>注：梯度消失（gradient vanishing）或者爆炸（gradient explosion）是激活函数<strong>以及当前权重</strong>耦合产生的综合结果：<br>
​   设任意激活函数为 $\sigma(\cdot)$ ，k+1层网络输出为 $f_{k+1}=\sigma(Wf_k)$ ，求导得到 $\frac {\partial h_{t+1}}{\partial h_t}=diag(\sigma'(Wh_t))W$ 。可见求导结果同时会受到权重 $W$ 和激活函数的导数 $\sigma'(\cdot)$ 的影响，以sigmoid函数 $\sigma(X)=\frac {1}{1+e^{-x}}$ 为例，其导数为 $\sigma'(x)=\frac{1}{1+e^{-x}}(1-\frac{1}{1+e^{-x}})$ ，其值恒大于零小于1，用链式法则求梯度回传时连续相乘使得结果趋于0，但是如果权重 $W$ 是较大的数值，使得 $\frac {\partial f_{t+1}}{\partial f_t}$ 相乘结果大于1，则梯度回传时连续相乘则不会发生梯度消失。<br>
综上，在讨论激活函数收敛速度或与梯度消失或者爆炸相关时，应同时考虑当前权重 $W$ 数值的影响。</p>
<p>3.4.13</p>
<h3 id="3-4-12-内聚外斥-Center-Loss">3.4.12 内聚外斥 - Center Loss</h3>
<p><strong>（贡献者：李世轩－加州大学伯克利分校）</strong></p>
<p>在计算机视觉任务中, 由于其简易性, 良好的表现, 与对分类任务的概率性理解, Cross Entropy Loss (交叉熵代价) + Softmax 组合被广泛应用于以分类任务为代表的任务中. 在此应用下, 我们可将其学习过程进一步理解为: 更相似(同类/同物体)的图像在特征域中拥有“更近的距离”, 相反则”距离更远“. 换而言之, 我们可以进一步理解为其学习了一种低类内距离(Intra-class Distance)与高类间距离(Inter-class Distance)的特征判别模型. 在此Center Loss则可以高效的计算出这种具判别性的特征. 不同于传统的Softmax Loss, Center Loss通过学习“特征中心”从而最小化其类内距离. 其表达形式如下:</p>
 $L_{C} = \frac{1}{2}\sum^{m}_{i=1}||x_{i}-c_{y_{i}}||^{2}_{2}$ 
<p>其中 $x_{i}$ 表示FCN(全连接层)之前的特征,  $c_{y_{i}}$ 表示第 $y_{i} $ 个类别的特征中心,  $m$ 表示mini-batch的大小. 我们很清楚的看到 $L_{C}$ 的终极目标为最小化每个特征与其特征中心的方差, 即最小化类内距离. 其迭代公式为:</p>
 $\frac{\partial L_{C}}{\partial x_{i}}=x_{i}-c_{y_{i}}$ 
 $\Delta{c_{j}} = \frac{\sum^{m}_{i=1}\delta(y_{i}=j)\cdot(c_{j}-x_{i})}{1+\sum^{m}_{i=1}\delta(y_{i}=j)}$ 
<p>其中 $ \delta(condition)=\left\{
\begin{array}{rcl}
1       &      & {condition\ is\ True}\\
0     &      & {otherwise}\\ \end{array} \right.$</p>
<p>结合Softmax, 我们可以搭配二者使用, 适当平衡这两种监督信号. 在Softmax拉开类间距离的同时, 利用Center Loss最小化类内距离. 例如:</p>
 $\begin{eqnarray}L & = & L_{S} + \lambda L_{C} \\ &=& -\sum^{m}_{i=1}log\frac{e^{W_{y}^{T}x_{i}+b_{y_{i}}}}{\sum^{m}_{i=1}e^{W^{T}_{j}x_{i}+b_{j}}} + \frac{\lambda}{2}\sum^{m}_{i=1}||x_{i}-c_{y_{i}}||^{2}_{2}\\ \end{eqnarray}$ 
<p>即便如此, Center Loss仍有它的不足之处: 其特征中心为存储在网络模型之外的额外参数, 不能与模型参数一同优化. 这些额外参数将与记录每一步特征变化的自动回归均值估计(autoregressive mean estimator)进行更迭. 当需要学习的类别数量较大时, mini-batch可能无力提供足够的样本进行均值估计. 若此Center Loss将需要平衡两种监督损失来以确定更迭, 其过程需要一个对平衡超参数的搜索过程, 使得其择值消耗昂贵.</p>
<h2 id="3-5-Batch-Size">3.5 Batch_Size</h2>
<h3 id="3-5-1-为什么需要-Batch-Size？">3.5.1 为什么需要 Batch_Size？</h3>
<p>Batch的选择，首先决定的是下降的方向。</p>
<p>如果数据集比较小，可采用全数据集的形式，好处是：</p>
<ol>
<li>由全数据集确定的方向能够更好地代表样本总体，从而更准确地朝向极值所在的方向。</li>
<li>由于不同权重的梯度值差别巨大，因此选取一个全局的学习率很困难。 Full Batch Learning 可以使用 Rprop 只基于梯度符号并且针对性单独更新各权值。</li>
</ol>
<p>对于更大的数据集，假如采用全数据集的形式，坏处是：</p>
<ol>
<li>随着数据集的海量增长和内存限制，一次性载入所有的数据进来变得越来越不可行。</li>
<li>以 Rprop 的方式迭代，会由于各个 Batch 之间的采样差异性，各次梯度修正值相互抵消，无法修正。这才有了后来 RMSProp 的妥协方案。</li>
</ol>
<h3 id="3-5-2-Batch-Size-值的选择">3.5.2 Batch_Size 值的选择</h3>
<p>​	假如每次只训练一个样本，即 Batch_Size = 1。线性神经元在均方误差代价函数的错误面是一个抛物面，横截面是椭圆。对于多层神经元、非线性网络，在局部依然近似是抛物面。此时，每次修正方向以各自样本的梯度方向修正，横冲直撞各自为政，难以达到收敛。</p>
<p>​	既然 Batch_Size 为全数据集或者Batch_Size = 1都有各自缺点，可不可以选择一个适中的Batch_Size值呢？</p>
<p>​	此时，可采用批梯度下降法（Mini-batches Learning）。因为如果数据集足够充分，那么用一半（甚至少得多）的数据训练算出来的梯度与用全部数据训练出来的梯度是几乎一样的。</p>
<h3 id="3-5-3-在合理范围内，增大Batch-Size有何好处？">3.5.3 在合理范围内，增大Batch_Size有何好处？</h3>
<ol>
<li>内存利用率提高了，大矩阵乘法的并行化效率提高。</li>
<li>跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。</li>
<li>在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。</li>
</ol>
<h3 id="3-5-4-盲目增大-Batch-Size-有何坏处？">3.5.4 盲目增大 Batch_Size 有何坏处？</h3>
<ol>
<li>内存利用率提高了，但是内存容量可能撑不住了。</li>
<li>跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。</li>
<li>Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化。</li>
</ol>
<h3 id="3-5-5-调节-Batch-Size-对训练效果影响到底如何？">3.5.5 调节 Batch_Size 对训练效果影响到底如何？</h3>
<ol>
<li>Batch_Size 太小，模型表现效果极其糟糕(error飙升)。</li>
<li>随着 Batch_Size 增大，处理相同数据量的速度越快。</li>
<li>随着 Batch_Size 增大，达到相同精度所需要的 epoch 数量越来越多。</li>
<li>由于上述两种因素的矛盾， Batch_Size 增大到某个时候，达到时间上的最优。</li>
<li>由于最终收敛精度会陷入不同的局部极值，因此 Batch_Size 增大到某些时候，达到最终收敛精度上的最优。</li>
</ol>
<h2 id="3-6-归一化">3.6 归一化</h2>
<h3 id="3-6-1-归一化含义？">3.6.1 归一化含义？</h3>
<ol>
<li>
<p>归纳统一样本的统计分布性。归一化在  $ 0-1$  之间是统计的概率分布，归一化在 $ -1--+1$  之间是统计的坐标分布。</p>
</li>
<li>
<p>无论是为了建模还是为了计算，首先基本度量单位要同一，神经网络是以样本在事件中的统计分别几率来进行训练（概率计算）和预测，且 sigmoid 函数的取值是 0 到 1 之间的，网络最后一个节点的输出也是如此，所以经常要对样本的输出归一化处理。</p>
</li>
<li>
<p>归一化是统一在  $ 0-1 $  之间的统计概率分布，当所有样本的输入信号都为正值时，与第一隐含层神经元相连的权值只能同时增加或减小，从而导致学习速度很慢。</p>
</li>
<li>
<p>另外在数据中常存在奇异样本数据，奇异样本数据存在所引起的网络训练时间增加，并可能引起网络无法收敛。为了避免出现这种情况及后面数据处理的方便，加快网络学习速度，可以对输入信号进行归一化，使得所有样本的输入信号其均值接近于 0 或与其均方差相比很小。</p>
</li>
</ol>
<h3 id="3-6-2-为什么要归一化？">3.6.2 为什么要归一化？</h3>
<ol>
<li>为了后面数据处理的方便，归一化的确可以避免一些不必要的数值问题。</li>
<li>为了程序运行时收敛加快。</li>
<li>同一量纲。样本数据的评价标准不一样，需要对其量纲化，统一评价标准。这算是应用层面的需求。</li>
<li>避免神经元饱和。啥意思？就是当神经元的激活在接近 0 或者 1 时会饱和，在这些区域，梯度几乎为 0，这样，在反向传播过程中，局部梯度就会接近 0，这会有效地“杀死”梯度。</li>
<li>保证输出数据中数值小的不被吞食。</li>
</ol>
<h3 id="3-6-3-为什么归一化能提高求解最优解速度？">3.6.3 为什么归一化能提高求解最优解速度？</h3>
<p><img src="3.6.3.1.png" alt></p>
<p>​	上图是代表数据是否均一化的最优解寻解过程（圆圈可以理解为等高线）。左图表示未经归一化操作的寻解过程，右图表示经过归一化后的寻解过程。</p>
<p>​	当使用梯度下降法寻求最优解时，很有可能走“之字型”路线（垂直等高线走），从而导致需要迭代很多次才能收敛；而右图对两个原始特征进行了归一化，其对应的等高线显得很圆，在梯度下降进行求解时能较快的收敛。</p>
<p>​	因此如果机器学习模型使用梯度下降法求最优解时，归一化往往非常有必要，否则很难收敛甚至不能收敛。</p>
<h3 id="3-6-4-3D-图解未归一化">3.6.4 3D 图解未归一化</h3>
<p>例子：</p>
<p>​	假设  $ w1 $  的范围在  $ [-10, 10] $ ，而  $ w2 $  的范围在  $ [-100, 100] $ ，梯度每次都前进 1 单位，那么在  $ w1 $  方向上每次相当于前进了  $ 1/20 $ ，而在  $ w2 $  上只相当于  $ 1/200 $ ！某种意义上来说，在  $ w2 $  上前进的步长更小一些,而  $ w1 $  在搜索过程中会比  $ w2 $  “走”得更快。</p>
<p>​	这样会导致，在搜索过程中更偏向于  $ w1 $  的方向。走出了“L”形状，或者成为“之”字形。</p>
<p><img src="3-37.png" alt></p>
<h3 id="3-6-5-归一化有哪些类型？">3.6.5 归一化有哪些类型？</h3>
<ol>
<li>线性归一化</li>
</ol>
 $$
x^{\prime} = \frac{x-min(x)}{max(x) - min(x)}
$$ 
<p>​	适用范围：比较适用在数值比较集中的情况。</p>
<p>​	缺点：如果 max 和 min 不稳定，很容易使得归一化结果不稳定，使得后续使用效果也不稳定。</p>
<ol start="2">
<li>标准差标准化</li>
</ol>
 $$
x^{\prime} = \frac{x-\mu}{\sigma}
$$ 
<p>​	含义：经过处理的数据符合标准正态分布，即均值为 0，标准差为 1 其中  $ \mu $  为所有样本数据的均值， $ \sigma $  为所有样本数据的标准差。</p>
<ol start="3">
<li>
<p>非线性归一化</p>
<p>适用范围：经常用在数据分化比较大的场景，有些数值很大，有些很小。通过一些数学函数，将原始值进行映射。该方法包括  $ log $ 、指数，正切等。</p>
</li>
</ol>
<h3 id="3-6-6-局部响应归一化作用">3.6.6 局部响应归一化作用</h3>
<p>​	LRN 是一种提高深度学习准确度的技术方法。LRN 一般是在激活、池化函数后的一种方法。</p>
<p>​	在 ALexNet 中，提出了 LRN 层，对局部神经元的活动创建竞争机制，使其中响应比较大对值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。</p>
<h3 id="3-6-7-理解局部响应归一化">3.6.7 理解局部响应归一化</h3>
<p>​	局部响应归一化原理是仿造生物学上活跃的神经元对相邻神经元的抑制现象（侧抑制），其公式如下：</p>
 $$
b_{x,y}^i = a_{x,y}^i / (k + \alpha \sum_{j=max(0, i-n/2)}^{min(N-1, i+n/2)}(a_{x,y}^j)^2 )^\beta
$$ 
<p>其中，</p>
<ol>
<li>
$ a $ ：表示卷积层（包括卷积操作和池化操作）后的输出结果，是一个四维数组[batch,height,width,channel]。
</li>
</ol>
<ul>
<li>batch：批次数(每一批为一张图片)。</li>
<li>height：图片高度。</li>
<li>width：图片宽度。</li>
<li>channel：通道数。可以理解成一批图片中的某一个图片经过卷积操作后输出的神经元个数，或理解为处理后的图片深度。</li>
</ul>
<ol start="2">
<li>
$ a_{x,y}^i $  表示在这个输出结构中的一个位置  $ [a,b,c,d] $ ，可以理解成在某一张图中的某一个通道下的某个高度和某个宽度位置的点，即第  $ a $  张图的第  $ d $  个通道下的高度为b宽度为c的点。
</li>
<li>
$ N $ ：论文公式中的  $ N $  表示通道数 (channel)。
</li>
<li>
$ a $ ， $ n/2 $ ，  $ k $  分别表示函数中的 input,depth_radius,bias。参数  $ k, n, \alpha, \beta $  都是超参数，一般设置  $ k=2, n=5, \alpha=1*e-4, \beta=0.75 $ 
</li>
<li>
$ \sum $ ： $ \sum $  叠加的方向是沿着通道方向的，即每个点值的平方和是沿着  $ a $  中的第 3 维 channel 方向的，也就是一个点同方向的前面  $ n/2 $  个通道（最小为第  $ 0 $  个通道）和后  $ n/2 $  个通道（最大为第  $ d-1 $  个通道）的点的平方和(共  $ n+1 $  个点)。而函数的英文注解中也说明了把 input 当成是  $ d $  个 3 维的矩阵，说白了就是把 input 的通道数当作 3 维矩阵的个数，叠加的方向也是在通道方向。 
</li>
</ol>
<p>简单的示意图如下：</p>
<p><img src="3.6.7.1.png" alt></p>
<h3 id="3-6-8-什么是批归一化（Batch-Normalization）">3.6.8 什么是批归一化（Batch Normalization）</h3>
<p>​	以前在神经网络训练中，只是对输入层数据进行归一化处理，却没有在中间层进行归一化处理。要知道，虽然我们对输入数据进行了归一化处理，但是输入数据经过  $ \sigma(WX+b) $  这样的矩阵乘法以及非线性运算之后，其数据分布很可能被改变，而随着深度网络的多层运算之后，数据分布的变化将越来越大。如果我们能在网络的中间也进行归一化处理，是否对网络的训练起到改进作用呢？答案是肯定的。</p>
<p>​	这种在神经网络中间层也进行归一化处理，使训练效果更好的方法，就是批归一化Batch Normalization（BN）。</p>
<h3 id="3-6-9-批归一化（BN）算法的优点">3.6.9 批归一化（BN）算法的优点</h3>
<p>下面我们来说一下BN算法的优点：</p>
<ol>
<li>减少了人为选择参数。在某些情况下可以取消 dropout 和 L2 正则项参数,或者采取更小的 L2 正则项约束参数；</li>
<li>减少了对学习率的要求。现在我们可以使用初始很大的学习率或者选择了较小的学习率，算法也能够快速训练收敛；</li>
<li>可以不再使用局部响应归一化。BN 本身就是归一化网络(局部响应归一化在 AlexNet 网络中存在)</li>
<li>破坏原来的数据分布，一定程度上缓解过拟合（防止每批训练中某一个样本经常被挑选到，文献说这个可以提高 1% 的精度）。</li>
<li>减少梯度消失，加快收敛速度，提高训练精度。</li>
</ol>
<h3 id="3-6-10-批归一化（BN）算法流程">3.6.10 批归一化（BN）算法流程</h3>
<p>下面给出 BN 算法在训练时的过程</p>
<p>输入：上一层输出结果  $ X = {x_1, x_2, ..., x_m} $ ，学习参数  $ \gamma, \beta $</p>
<p>算法流程：</p>
<ol>
<li>计算上一层输出数据的均值</li>
</ol>
 $$
\mu_{\beta} = \frac{1}{m} \sum_{i=1}^m(x_i)
$$ 
<p>其中， $ m $  是此次训练样本 batch 的大小。</p>
<ol start="2">
<li>计算上一层输出数据的标准差</li>
</ol>
 $$
\sigma_{\beta}^2 = \frac{1}{m} \sum_{i=1}^m (x_i - \mu_{\beta})^2
$$ 
<ol start="3">
<li>归一化处理，得到</li>
</ol>
 $$
\hat x_i = \frac{x_i + \mu_{\beta}}{\sqrt{\sigma_{\beta}^2} + \epsilon}
$$ 
<p>其中  $ \epsilon $  是为了避免分母为 0 而加进去的接近于 0 的很小值</p>
<ol start="4">
<li>重构，对经过上面归一化处理得到的数据进行重构，得到</li>
</ol>
 $$
y_i = \gamma \hat x_i + \beta
$$ 
<p>其中， $ \gamma, \beta $  为可学习参数。</p>
<p>注：上述是 BN 训练时的过程，但是当在投入使用时，往往只是输入一个样本，没有所谓的均值  $ \mu_{\beta} $  和标准差  $ \sigma_{\beta}^2 $ 。此时，均值  $ \mu_{\beta} $  是计算所有 batch  $ \mu_{\beta} $  值的平均值得到，标准差  $ \sigma_{\beta}^2 $  采用每个batch  $ \sigma_{\beta}^2 $   的无偏估计得到。</p>
<h3 id="3-6-11-批归一化和群组归一化比较">3.6.11 批归一化和群组归一化比较</h3>
<table>
<thead>
<tr>
<th>名称</th>
<th style="text-align:left">特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>批量归一化（Batch Normalization，以下简称 BN）</td>
<td style="text-align:left">可让各种网络并行训练。但是，批量维度进行归一化会带来一些问题——批量统计估算不准确导致批量变小时，BN 的误差会迅速增加。在训练大型网络和将特征转移到计算机视觉任务中（包括检测、分割和视频），内存消耗限制了只能使用小批量的 BN。</td>
</tr>
<tr>
<td>群组归一化 Group Normalization (简称 GN)</td>
<td style="text-align:left">GN 将通道分成组，并在每组内计算归一化的均值和方差。GN 的计算与批量大小无关，并且其准确度在各种批量大小下都很稳定。</td>
</tr>
<tr>
<td>比较</td>
<td style="text-align:left">在 ImageNet 上训练的 ResNet-50上，GN 使用批量大小为 2 时的错误率比 BN 的错误率低 10.6％ ;当使用典型的批量时，GN 与 BN 相当，并且优于其他标归一化变体。而且，GN 可以自然地从预训练迁移到微调。在进行 COCO 中的目标检测和分割以及 Kinetics 中的视频分类比赛中，GN 可以胜过其竞争对手，表明 GN 可以在各种任务中有效地取代强大的 BN。</td>
</tr>
</tbody>
</table>
<h3 id="3-6-12-Weight-Normalization和Batch-Normalization比较">3.6.12 Weight Normalization和Batch Normalization比较</h3>
<p>​	Weight Normalization 和 Batch Normalization 都属于参数重写（Reparameterization）的方法，只是采用的方式不同。</p>
<p>​	Weight Normalization 是对网络权值 $  W $  进行 normalization，因此也称为 Weight Normalization；</p>
<p>​	Batch Normalization 是对网络某一层输入数据进行 normalization。</p>
<p>​	Weight Normalization相比Batch Normalization有以下三点优势：</p>
<ol>
<li>
<p>Weight Normalization 通过重写深度学习网络的权重W的方式来加速深度学习网络参数收敛，没有引入 minbatch 的依赖，适用于 RNN（LSTM）网络（Batch Normalization 不能直接用于RNN，进行 normalization 操作，原因在于：1) RNN 处理的 Sequence 是变长的；2) RNN 是基于 time step 计算，如果直接使用 Batch Normalization 处理，需要保存每个 time step 下，mini btach 的均值和方差，效率低且占内存）。</p>
</li>
<li>
<p>Batch Normalization 基于一个 mini batch 的数据计算均值和方差，而不是基于整个 Training set 来做，相当于进行梯度计算式引入噪声。因此，Batch Normalization 不适用于对噪声敏感的强化学习、生成模型（Generative model：GAN，VAE）使用。相反，Weight Normalization 对通过标量  $ g $  和向量  $ v $  对权重  $ W $  进行重写，重写向量  $ v $  是固定的，因此，基于 Weight Normalization 的 Normalization 可以看做比 Batch Normalization 引入更少的噪声。</p>
</li>
<li>
<p>不需要额外的存储空间来保存 mini batch 的均值和方差，同时实现 Weight Normalization 时，对深度学习网络进行正向信号传播和反向梯度计算带来的额外计算开销也很小。因此，要比采用 Batch Normalization 进行 normalization 操作时，速度快。  但是 Weight Normalization 不具备 Batch Normalization 把网络每一层的输出 Y 固定在一个变化范围的作用。因此，采用 Weight Normalization 进行 Normalization 时需要特别注意参数初始值的选择。</p>
</li>
</ol>
<h3 id="3-6-13-Batch-Normalization在什么时候用比较合适？">3.6.13 Batch Normalization在什么时候用比较合适？</h3>
<p><strong>（贡献者：黄钦建－华南理工大学）</strong></p>
<p>​	在CNN中，BN应作用在非线性映射前。在神经网络训练时遇到收敛速度很慢，或梯度爆炸等无法训练的状况时可以尝试BN来解决。另外，在一般使用情况下也可以加入BN来加快训练速度，提高模型精度。</p>
<p>​	BN比较适用的场景是：每个mini-batch比较大，数据分布比较接近。在进行训练之前，要做好充分的shuffle，否则效果会差很多。另外，由于BN需要在运行过程中统计每个mini-batch的一阶统计量和二阶统计量，因此不适用于动态的网络结构和RNN网络。</p>
<h2 id="3-7-预训练与微调-fine-tuning">3.7 预训练与微调(fine tuning)</h2>
<h3 id="3-7-1-为什么无监督预训练可以帮助深度学习？">3.7.1 为什么无监督预训练可以帮助深度学习？</h3>
<p>深度网络存在问题:</p>
<ol>
<li>
<p>网络越深，需要的训练样本数越多。若用监督则需大量标注样本，不然小规模样本容易造成过拟合。深层网络特征比较多，会出现的多特征问题主要有多样本问题、规则化问题、特征选择问题。</p>
</li>
<li>
<p>多层神经网络参数优化是个高阶非凸优化问题，经常得到收敛较差的局部解；</p>
</li>
<li>
<p>梯度扩散问题，BP算法计算出的梯度随着深度向前而显著下降，导致前面网络参数贡献很小，更新速度慢。</p>
</li>
</ol>
<p><strong>解决方法：</strong></p>
<p>​	逐层贪婪训练，无监督预训练（unsupervised pre-training）即训练网络的第一个隐藏层，再训练第二个…最后用这些训练好的网络参数值作为整体网络参数的初始值。</p>
<p>经过预训练最终能得到比较好的局部最优解。</p>
<h3 id="3-7-2-什么是模型微调fine-tuning">3.7.2 什么是模型微调fine tuning</h3>
<p>​	用别人的参数、修改后的网络和自己的数据进行训练，使得参数适应自己的数据，这样一个过程，通常称之为微调（fine tuning).</p>
<p><strong>模型的微调举例说明：</strong></p>
<p>​	我们知道，CNN 在图像识别这一领域取得了巨大的进步。如果想将 CNN 应用到我们自己的数据集上，这时通常就会面临一个问题：通常我们的 dataset 都不会特别大，一般不会超过 1 万张，甚至更少，每一类图片只有几十或者十几张。这时候，直接应用这些数据训练一个网络的想法就不可行了，因为深度学习成功的一个关键性因素就是大量带标签数据组成的训练集。如果只利用手头上这点数据，即使我们利用非常好的网络结构，也达不到很高的 performance。这时候，fine-tuning 的思想就可以很好解决我们的问题：我们通过对 ImageNet 上训练出来的模型（如CaffeNet,VGGNet,ResNet) 进行微调，然后应用到我们自己的数据集上。</p>
<h3 id="3-7-3-微调时候网络参数是否更新？">3.7.3 微调时候网络参数是否更新？</h3>
<p>答案：会更新。</p>
<ol>
<li>finetune 的过程相当于继续训练，跟直接训练的区别是初始化的时候。</li>
<li>直接训练是按照网络定义指定的方式初始化。</li>
<li>finetune是用你已经有的参数文件来初始化。</li>
</ol>
<h3 id="3-7-4-fine-tuning-模型的三种状态">3.7.4 fine-tuning 模型的三种状态</h3>
<ol>
<li>
<p>状态一：只预测，不训练。<br>
特点：相对快、简单，针对那些已经训练好，现在要实际对未知数据进行标注的项目，非常高效；</p>
</li>
<li>
<p>状态二：训练，但只训练最后分类层。<br>
特点：fine-tuning的模型最终的分类以及符合要求，现在只是在他们的基础上进行类别降维。</p>
</li>
<li>
<p>状态三：完全训练，分类层+之前卷积层都训练<br>
特点：跟状态二的差异很小，当然状态三比较耗时和需要训练GPU资源，不过非常适合fine-tuning到自己想要的模型里面，预测精度相比状态二也提高不少。</p>
</li>
</ol>
<h2 id="3-8-权重偏差初始化">3.8 权重偏差初始化</h2>
<h3 id="3-8-1-全都初始化为-0">3.8.1 全都初始化为 0</h3>
<p><strong>偏差初始化陷阱</strong>： 都初始化为 0。</p>
<p><strong>产生陷阱原因</strong>：因为并不知道在训练神经网络中每一个权重最后的值，但是如果进行了恰当的数据归一化后，我们可以有理由认为有一半的权重是正的，另一半是负的。令所有权重都初始化为 0，如果神经网络计算出来的输出值是一样的，神经网络在进行反向传播算法计算出来的梯度值也一样，并且参数更新值也一样。更一般地说，如果权重初始化为同一个值，网络就是对称的。</p>
<p><strong>形象化理解</strong>：在神经网络中考虑梯度下降的时候，设想你在爬山，但身处直线形的山谷中，两边是对称的山峰。由于对称性，你所在之处的梯度只能沿着山谷的方向，不会指向山峰；你走了一步之后，情况依然不变。结果就是你只能收敛到山谷中的一个极大值，而走不到山峰上去。</p>
<h3 id="3-8-2-全都初始化为同样的值">3.8.2 全都初始化为同样的值</h3>
<p>​	偏差初始化陷阱： 都初始化为一样的值。<br>
​	以一个三层网络为例：<br>
首先看下结构</p>
<p><img src="3.8.2.1.png" alt></p>
<p>它的表达式为：</p>
 $$
a_1^{(2)} = f(W_{11}^{(1)} x_1 + W_{12}^{(1)} x_2 + W_{13}^{(1)} x_3 + b_1^{(1)})
$$ 
 $$
a_2^{(2)} = f(W_{21}^{(1)} x_1 + W_{22}^{(1)} x_2 + W_{23}^{(1)} x_3 + b_2^{(1)})
$$ 
 $$
a_3^{(2)} = f(W_{31}^{(1)} x_1 + W_{32}^{(1)} x_2 + W_{33}^{(1)} x_3 + b_3^{(1)})
$$ 
 $$
h_{W,b}(x) = a_1^{(3)} = f(W_{11}^{(2)} a_1^{(2)} + W_{12}^{(2)} a_2^{(2)} + W_{13}^{(2)} a_3^{(2)} + b_1^{(2)})
$$ 
 $$
xa_1^{(2)} = f(W_{11}^{(1)} x_1 + W_{12}^{(1)} x_2 + W_{13}^{(1)} x_3 + b_1^{(1)})a_2^{(2)} = f(W_{21}^{(1)} x_1 + W_{22}^{(1)} x_2 + W_{23}^{(1)} x_3 + 
$$ 
<p>如果每个权重都一样，那么在多层网络中，从第二层开始，每一层的输入值都是相同的了也就是 $ a1=a2=a3=.... $ ，既然都一样，就相当于一个输入了，为啥呢？？</p>
<p>如果是反向传递算法（如果这里不明白请看上面的连接），其中的偏置项和权重项的迭代的偏导数计算公式如下</p>
 $$
\frac{\partial}{\partial W_{ij}^{(l)}} J(W,b;x,y) = a_j^{(l)} \delta_i^{(l+1)}

\frac{\partial}{\partial b_{i}^{(l)}} J(W,b;x,y) = \delta_i^{(l+1)}
$$ 
 $ \delta $  的计算公式
 $$
\delta_i^{(l)} = (\sum_{j=1}^{s_{t+1}} W_{ji}^{(l)} \delta_j^{(l+1)} ) f^{\prime}(z_i^{(l)})
$$ 
<p>如果用的是 sigmoid 函数</p>
 $$
f^{\prime}(z_i^{(l)}) = a_i^{(l)}(1-a_i^{(l)})
$$ 
<p>把后两个公式代入，可以看出所得到的梯度下降法的偏导相同，不停的迭代，不停的相同，不停的迭代，不停的相同…，最后就得到了相同的值（权重和截距）。</p>
<h3 id="3-8-3-初始化为小的随机数">3.8.3 初始化为小的随机数</h3>
<p>​	将权重初始化为很小的数字是一个普遍的打破网络对称性的解决办法。这个想法是，神经元在一开始都是随机的、独一无二的，所以它们会计算出不同的更新，并将自己整合到整个网络的各个部分。一个权重矩阵的实现可能看起来像  $ W=0.01∗np.random.randn(D,H) $ ，其中 randn 是从均值为 0 的单位标准高斯分布进行取样。通过这个公式(函数)，每个神经元的权重向量初始化为一个从多维高斯分布取样的随机向量，所以神经元在输入空间中指向随机的方向(so the neurons point in random direction in the input space). 应该是指输入空间对于随机方向有影响)。其实也可以从均匀分布中来随机选取小数，但是在实际操作中看起来似乎对最后的表现并没有太大的影响。</p>
<p>​	备注：并不是数字越小就会表现的越好。比如，如果一个神经网络层的权重非常小，那么在反向传播算法就会计算出很小的梯度(因为梯度 gradient 是与权重成正比的)。在网络不断的反向传播过程中将极大地减少“梯度信号”，并可能成为深层网络的一个需要注意的问题。</p>
<h3 id="3-8-4-用-swig￼331-校准方差">3.8.4 用  $ 1/\sqrt n $  校准方差</h3>
<p>​	上述建议的一个问题是，随机初始化神经元的输出的分布有一个随输入量增加而变化的方差。结果证明，我们可以通过将其权重向量按其输入的平方根(即输入的数量)进行缩放，从而将每个神经元的输出的方差标准化到 1。也就是说推荐的启发式方法 (heuristic) 是将每个神经元的权重向量按下面的方法进行初始化:  $ w=np.random.randn(n)/\sqrt n $ ，其中 n 表示输入的数量。这保证了网络中所有的神经元最初的输出分布大致相同，并在经验上提高了收敛速度。</p>
<h3 id="3-8-5-稀疏初始化-Sparse-Initialazation">3.8.5 稀疏初始化(Sparse Initialazation)</h3>
<p>​	另一种解决未校准方差问题的方法是把所有的权重矩阵都设为零，但是为了打破对称性，每个神经元都是随机连接地(从如上面所介绍的一个小的高斯分布中抽取权重)到它下面的一个固定数量的神经元。一个典型的神经元连接的数目可能是小到 10 个。</p>
<h3 id="3-8-6-初始化偏差">3.8.6 初始化偏差</h3>
<p>​	将偏差初始化为零是可能的，也是很常见的，因为非对称性破坏是由权重的小随机数导致的。因为 ReLU 具有非线性特点，所以有些人喜欢使用将所有的偏差设定为小的常数值如 0.01，因为这样可以确保所有的 ReLU 单元在最开始就激活触发(fire)并因此能够获得和传播一些梯度值。然而，这是否能够提供持续的改善还不太清楚(实际上一些结果表明这样做反而使得性能更加糟糕)，所以更通常的做法是简单地将偏差初始化为 0.</p>
<h2 id="3-9-学习率">3.9 学习率</h2>
<h3 id="3-9-1-学习率的作用">3.9.1 学习率的作用</h3>
<p>​	在机器学习中，监督式学习通过定义一个模型，并根据训练集上的数据估计最优参数。梯度下降法是一个广泛被用来最小化模型误差的参数优化算法。梯度下降法通过多次迭代，并在每一步中最小化成本函数（cost 来估计模型的参数。学习率 (learning rate)，在迭代过程中会控制模型的学习进度。</p>
<p>​	在梯度下降法中，都是给定的统一的学习率，整个优化过程中都以确定的步长进行更新， 在迭代优化的前期中，学习率较大，则前进的步长就会较长，这时便能以较快的速度进行梯度下降，而在迭代优化的后期，逐步减小学习率的值，减小步长，这样将有助于算法的收敛，更容易接近最优解。故而如何对学习率的更新成为了研究者的关注点。<br>
​	在模型优化中，常用到的几种学习率衰减方法有：分段常数衰减、多项式衰减、指数衰减、自然指数衰减、余弦衰减、线性余弦衰减、噪声线性余弦衰减</p>
<h3 id="3-9-2-学习率衰减常用参数有哪些">3.9.2 学习率衰减常用参数有哪些</h3>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>参数说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>learning_rate</td>
<td>初始学习率</td>
</tr>
<tr>
<td>global_step</td>
<td>用于衰减计算的全局步数，非负，用于逐步计算衰减指数</td>
</tr>
<tr>
<td>decay_steps</td>
<td>衰减步数，必须是正值，决定衰减周期</td>
</tr>
<tr>
<td>decay_rate</td>
<td>衰减率</td>
</tr>
<tr>
<td>end_learning_rate</td>
<td>最低的最终学习率</td>
</tr>
<tr>
<td>cycle</td>
<td>学习率下降后是否重新上升</td>
</tr>
<tr>
<td>alpha</td>
<td>最小学习率</td>
</tr>
<tr>
<td>num_periods</td>
<td>衰减余弦部分的周期数</td>
</tr>
<tr>
<td>initial_variance</td>
<td>噪声的初始方差</td>
</tr>
<tr>
<td>variance_decay</td>
<td>衰减噪声的方差</td>
</tr>
</tbody>
</table>
<h3 id="3-9-3-分段常数衰减">3.9.3 分段常数衰减</h3>
<p>​	分段常数衰减需要事先定义好的训练次数区间，在对应区间置不同的学习率的常数值，一般情况刚开始的学习率要大一些，之后要越来越小，要根据样本量的大小设置区间的间隔大小，样本量越大，区间间隔要小一点。下图即为分段常数衰减的学习率变化图，横坐标代表训练次数，纵坐标代表学习率。</p>
<p><img src="learnrate1.png" alt></p>
<h3 id="3-9-4-指数衰减">3.9.4 指数衰减</h3>
<p>​	以指数衰减方式进行学习率的更新，学习率的大小和训练次数指数相关，其更新规则为：</p>
 $$
decayed{\_}learning{\_}rate =learning{\_}rate*decay{\_}rate^{\frac{global{\_step}}{decay{\_}steps}}
$$ 
<p>​	这种衰减方式简单直接，收敛速度快，是最常用的学习率衰减方式，如下图所示，绿色的为学习率随<br>
训练次数的指数衰减方式，红色的即为分段常数衰减，它在一定的训练区间内保持学习率不变。</p>
<p><img src="learnrate2.png" alt></p>
<h3 id="3-9-5-自然指数衰减">3.9.5 自然指数衰减</h3>
<p>​	它与指数衰减方式相似，不同的在于它的衰减底数是 $e$ ，故而其收敛的速度更快，一般用于相对比较<br>
容易训练的网络，便于较快的收敛，其更新规则如下</p>
 $$
decayed{\_}learning{\_}rate =learning{\_}rate*e^{\frac{-decay{\_rate}}{global{\_}step}}
$$ 
<p>​	下图为为分段常数衰减、指数衰减、自然指数衰减三种方式的对比图，红色的即为分段常数衰减图，阶梯型曲线。蓝色线为指数衰减图，绿色即为自然指数衰减图，很明可以看到自然指数衰减方式下的学习率衰减程度要大于一般指数衰减方式，有助于更快的收敛。</p>
<p><img src="learnrate3.png" alt></p>
<h3 id="3-9-6-多项式衰减">3.9.6 多项式衰减</h3>
<p>​	应用多项式衰减的方式进行更新学习率，这里会给定初始学习率和最低学习率取值，然后将会按照<br>
给定的衰减方式将学习率从初始值衰减到最低值,其更新规则如下式所示。</p>
 $$
global{\_}step=min(global{\_}step,decay{\_}steps)
$$ 
 $$
decayed{\_}learning{\_}rate =(learning{\_}rate-end{\_}learning{\_}rate)* \left( 1-\frac{global{\_step}}{decay{\_}steps}\right)^{power} \\
 +end{\_}learning{\_}rate
$$ 
<p>​	需要注意的是，有两个机制，降到最低学习率后，到训练结束可以一直使用最低学习率进行更新，另一个是再次将学习率调高，使用 decay_steps 的倍数，取第一个大于 global_steps 的结果，如下式所示.它是用来防止神经网络在训练的后期由于学习率过小而导致的网络一直在某个局部最小值附近震荡，这样可以通过在后期增大学习率跳出局部极小值。</p>
 $$
decay{\_}steps = decay{\_}steps*ceil \left( \frac{global{\_}step}{decay{\_}steps}\right)
$$ 
<p>​	如下图所示，红色线代表学习率降低至最低后，一直保持学习率不变进行更新，绿色线代表学习率衰减到最低后，又会再次循环往复的升高降低。</p>
<p><img src="learnrate4.png" alt></p>
<h3 id="3-9-7-余弦衰减">3.9.7 余弦衰减</h3>
<p>​	余弦衰减就是采用余弦的相关方式进行学习率的衰减，衰减图和余弦函数相似。其更新机制如下式所示：</p>
 $$
global{\_}step=min(global{\_}step,decay{\_}steps)
$$ 
 $$
cosine{\_}decay=0.5*\left( 1+cos\left( \pi* \frac{global{\_}step}{decay{\_}steps}\right)\right)
$$ 
 $$
decayed=(1-\alpha)*cosine{\_}decay+\alpha
$$ 
 $$
decayed{\_}learning{\_}rate=learning{\_}rate*decayed
$$ 
<p>​	如下图所示，红色即为标准的余弦衰减曲线，学习率从初始值下降到最低学习率后保持不变。蓝色的线是线性余弦衰减方式曲线，它是学习率从初始学习率以线性的方式下降到最低学习率值。绿色噪声线性余弦衰减方式。</p>
<p><img src="learnrate5.png" alt></p>
<h2 id="3-12-Dropout-系列问题">3.12 Dropout 系列问题</h2>
<h3 id="3-12-1-为什么要正则化？">3.12.1 为什么要正则化？</h3>
<ol>
<li>深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据，这是非常可靠的方法，但你可能无法时时刻刻准备足够多的训练数据或者获取更多数据的成本很高，但正则化通常有助于避免过拟合或减少你的网络误差。</li>
<li>如果你怀疑神经网络过度拟合了数据，即存在高方差问题，那么最先想到的方法可能是正则化，另一个解决高方差的方法就是准备更多数据，这也是非常可靠的办法，但你可能无法时时准备足够多的训练数据，或者，获取更多数据的成本很高，但正则化有助于避免过度拟合，或者减少网络误差。</li>
</ol>
<h3 id="3-12-2-为什么正则化有利于预防过拟合？">3.12.2 为什么正则化有利于预防过拟合？</h3>
<p><img src="3.12.2.1.png" alt><br>
<img src="3.12.2.2.png" alt></p>
<p>左图是高偏差，右图是高方差，中间是Just Right，这几张图我们在前面课程中看到过。</p>
<h3 id="3-12-3-理解dropout正则化">3.12.3 理解dropout正则化</h3>
<p>​	Dropout可以随机删除网络中的神经单元，它为什么可以通过正则化发挥如此大的作用呢？</p>
<p>​	直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似；实施dropout的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；L2对不同权重的衰减是不同的，它取决于激活函数倍增的大小。</p>
<h3 id="3-12-4-dropout率的选择">3.12.4 dropout率的选择</h3>
<ol>
<li>经过交叉验证，隐含节点 dropout 率等于 0.5 的时候效果最好，原因是 0.5 的时候 dropout 随机生成的网络结构最多。</li>
<li>dropout 也可以被用作一种添加噪声的方法，直接对 input 进行操作。输入层设为更接近 1 的数。使得输入变化不会太大（0.8）</li>
<li>对参数  $ w $  的训练进行球形限制 (max-normalization)，对 dropout 的训练非常有用。</li>
<li>球形半径  $ c $  是一个需要调整的参数，可以使用验证集进行参数调优。</li>
<li>dropout 自己虽然也很牛，但是 dropout、max-normalization、large decaying learning rates and high momentum 组合起来效果更好，比如 max-norm regularization 就可以防止大的learning rate 导致的参数 blow up。</li>
<li>使用 pretraining 方法也可以帮助 dropout 训练参数，在使用 dropout 时，要将所有参数都乘以  $ 1/p $ 。</li>
</ol>
<h3 id="3-12-5-dropout有什么缺点？">3.12.5 dropout有什么缺点？</h3>
<p>​	dropout一大缺点就是代价函数J不再被明确定义，每次迭代，都会随机移除一些节点，如果再三检查梯度下降的性能，实际上是很难进行复查的。定义明确的代价函数J每次迭代后都会下降，因为我们所优化的代价函数J实际上并没有明确定义，或者说在某种程度上很难计算，所以我们失去了调试工具来绘制这样的图片。我通常会关闭dropout函数，将keep-prob的值设为1，运行代码，确保J函数单调递减。然后打开dropout函数，希望在dropout过程中，代码并未引入bug。我觉得你也可以尝试其它方法，虽然我们并没有关于这些方法性能的数据统计，但你可以把它们与dropout方法一起使用。</p>
<h2 id="3-13-深度学习中常用的数据增强方法？">3.13 深度学习中常用的数据增强方法？</h2>
<p><strong>（贡献者：黄钦建－华南理工大学）</strong></p>
<ul>
<li>
<p>Color Jittering：对颜色的数据增强：图像亮度、饱和度、对比度变化（此处对色彩抖动的理解不知是否得当）；</p>
</li>
<li>
<p>PCA  Jittering：首先按照RGB三个颜色通道计算均值和标准差，再在整个训练集上计算协方差矩阵，进行特征分解，得到特征向量和特征值，用来做PCA Jittering；</p>
</li>
<li>
<p>Random Scale：尺度变换；</p>
</li>
<li>
<p>Random Crop：采用随机图像差值方式，对图像进行裁剪、缩放；包括Scale Jittering方法（VGG及ResNet模型使用）或者尺度和长宽比增强变换；</p>
</li>
<li>
<p>Horizontal/Vertical Flip：水平/垂直翻转；</p>
</li>
<li>
<p>Shift：平移变换；</p>
</li>
<li>
<p>Rotation/Reflection：旋转/仿射变换；</p>
</li>
<li>
<p>Noise：高斯噪声、模糊处理；</p>
</li>
<li>
<p>Label Shuffle：类别不平衡数据的增广；</p>
</li>
</ul>
<h2 id="3-14-如何理解-Internal-Covariate-Shift？">3.14 如何理解 Internal Covariate Shift？</h2>
<p><strong>（贡献者：黄钦建－华南理工大学）</strong></p>
<p>​	深度神经网络模型的训练为什么会很困难？其中一个重要的原因是，深度神经网络涉及到很多层的叠加，而每一层的参数更新会导致上层的输入数据分布发生变化，通过层层叠加，高层的输入分布变化会非常剧烈，这就使得高层需要不断去重新适应底层的参数更新。为了训好模型，我们需要非常谨慎地去设定学习率、初始化权重、以及尽可能细致的参数更新策略。</p>
<p>​	Google 将这一现象总结为 Internal Covariate Shift，简称 ICS。 什么是 ICS 呢？</p>
<p>​	大家都知道在统计机器学习中的一个经典假设是“源空间（source domain）和目标空间（target domain）的数据分布（distribution）是一致的”。如果不一致，那么就出现了新的机器学习问题，如 transfer learning / domain adaptation 等。而 covariate shift 就是分布不一致假设之下的一个分支问题，它是指源空间和目标空间的条件概率是一致的，但是其边缘概率不同。</p>
<p>​	大家细想便会发现，的确，对于神经网络的各层输出，由于它们经过了层内操作作用，其分布显然与各层对应的输入信号分布不同，而且差异会随着网络深度增大而增大，可是它们所能“指示”的样本标记（label）仍然是不变的，这便符合了covariate shift的定义。由于是对层间信号的分析，也即是“internal”的来由。</p>
<p><strong>那么ICS会导致什么问题？</strong></p>
<p>简而言之，每个神经元的输入数据不再是“独立同分布”。</p>
<p>其一，上层参数需要不断适应新的输入数据分布，降低学习速度。</p>
<p>其二，下层输入的变化可能趋向于变大或者变小，导致上层落入饱和区，使得学习过早停止。</p>
<p>其三，每层的更新都会影响到其它层，因此每层的参数更新策略需要尽可能的谨慎。</p>
<h2 id="参考文献">参考文献</h2>
<p>[1] Rosenblatt, F. The perceptron: A probabilistic model for information storage and organization in the brain.[J]. Psychological Review, 1958, 65(6):386-408.</p>
<p>[2] Duvenaud D , Rippel O , Adams R P , et al. Avoiding pathologies in very deep networks[J]. Eprint Arxiv, 2014:202-210.</p>
<p>[3] Rumelhart D E, Hinton G E, Williams R J. Learning representations by back-propagating errors[J]. Cognitive modeling, 1988, 5(3): 1.</p>
<p>[4] Hecht-Nielsen R. Theory of the backpropagation neural network[M]//Neural networks for perception. Academic Press, 1992: 65-93.</p>
<p>[5] Felice M. Which deep learning network is best for you?| CIO[J]. 2017.</p>
<p>[6] Conneau A, Schwenk H, Barrault L, et al. Very deep convolutional networks for natural language processing[J]. arXiv preprint arXiv:1606.01781, 2016, 2.</p>
<p>[7] Ba J, Caruana R. Do deep nets really need to be deep?[C]//Advances in neural information processing systems. 2014: 2654-2662.</p>
<p>[8] Nielsen M A. Neural networks and deep learning[M]. USA: Determination press, 2015.</p>
<p>[9] Goodfellow I, Bengio Y, Courville A. Deep learning[M]. MIT press, 2016.</p>
<p>[10] 周志华. 机器学习[M].清华大学出版社, 2016.</p>
<p>[11] Kim J, Kwon Lee J, Mu Lee K. Accurate image super-resolution using very deep convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 1646-1654.</p>
<p>[12] Chen Y, Lin Z, Zhao X, et al. Deep learning-based classification of hyperspectral data[J]. IEEE Journal of Selected topics in applied earth observations and remote sensing, 2014, 7(6): 2094-2107.</p>
<p>[13] Domhan T, Springenberg J T, Hutter F. Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves[C]//Twenty-Fourth International Joint Conference on Artificial Intelligence. 2015.</p>
<p>[14] Maclaurin D, Duvenaud D, Adams R. Gradient-based hyperparameter optimization through reversible learning[C]//International Conference on Machine Learning. 2015: 2113-2122.</p>
<p>[15] Srivastava R K, Greff K, Schmidhuber J. Training very deep networks[C]//Advances in neural information processing systems. 2015: 2377-2385.</p>
<p>[16] Bergstra J, Bengio Y. Random search for hyper-parameter optimization[J]. Journal of Machine Learning Research, 2012, 13(Feb): 281-305.</p>
<p>[17] Ngiam J, Khosla A, Kim M, et al. Multimodal deep learning[C]//Proceedings of the 28th international conference on machine learning (ICML-11). 2011: 689-696.</p>
<p>[18] Deng L, Yu D. Deep learning: methods and applications[J]. Foundations and Trends® in Signal Processing, 2014, 7(3–4): 197-387.</p>
<p>[19] Erhan D, Bengio Y, Courville A, et al. Why does unsupervised pre-training help deep learning?[J]. Journal of Machine Learning Research, 2010, 11(Feb): 625-660.</p>
<p>[20] Dong C, Loy C C, He K, et al. Learning a deep convolutional network for image super resolution[C]//European conference on computer vision. Springer, Cham, 2014: 184-199.</p>
<p>[21] 郑泽宇，梁博文，顾思宇.TensorFlow：实战Google深度学习框架（第2版）[M].电子工业出版社,2018.</p>
<p>[22] 焦李成. 深度学习优化与识别[M].清华大学出版社,2017.</p>
<p>[23] 吴岸城. 神经网络与深度学习[M].电子工业出版社,2016.</p>
<p>[24] Wei, W.G.H., Liu, T., Song, A., et al. (2018) An Adaptive Natural Gradient Method with Adaptive Step Size in Multilayer Perceptrons. Chinese Automation Congress, 1593-1597.</p>
<p>[25] Y Feng, Y <a target="_blank" rel="noopener" href="http://Li.An">Li.An</a> Overview of Deep Learning Optimization Methods and Learning Rate Attenuation Methods[J].Hans Journal of Data Mining,2018,8(4),186-200.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Tom</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">33</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Tom</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
